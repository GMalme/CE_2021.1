FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Gomez-de-Agreda, A
   Feijoo, C
   Salazar-Garcia, IA
AF Gomez-de-Agreda, Angel
   Feijoo, Claudio
   Salazar-Garcia, Idoia-Ana
TI A new taxonomy for image use in the intentional shaping of the digital
   narrative: deep fakes and artificial intelligence
SO PROFESIONAL DE LA INFORMACION
LA Spanish
DT Article
DE Influence operations; Fake news; Deep fakes; Narrative shaping;
   Disinformation; Journalism; Manipulation; Artificial intelligence;
   Technology; Image; Video; Warlike conflict; Cognitive domain
ID NEWS
AB Any confrontation seeks the (partial) imposition of one party's will on an adversary. In recent years, digital technologies and data science have combined to create new ways of controlling the narrative and carrying out powerful information or disinformation campaigns that are part of a new type of warfare with digital characteristics. In particular, based on a literature review and the direct work of authors in different expert groups, this paper studies the use of either static or moving images (real, altered, or wholly artificially generated) as one of the most efficient means of altering perceptions and thereby narratives in the so-called cognitive domain. To this aim, this article collects in an orderly and exhaustive way the most recent military and intelligence doctrine related to such "influence operations," from a dual technological-sociological perspective. Based on this, the paper determines the differences between traditional disinformation techniques and those incorporating digital and artificial intelligence technologies in the form of images and video. The paper proposes a new double-entry taxonomy that can display the degree of image faking and the objective of disinformation. This helps to identify and prioritize the most relevant cases and thus adopt the most appropriate countermeasures. These are also examined in detail, leading to the conclusion that only a combination of transparency, consumer education, technology, and regulation can counteract the increasing use of images and video with false content.
C1 [Gomez-de-Agreda, Angel] Univ Politecn Madrid, Minist Def, Paseo Castellana 109, Madrid 28071, Spain.
   [Feijoo, Claudio] Univ Politecn Madrid, Ctr Apoyo Innovac Tecnol CAIT, Parque Cient & Tecnol UPM,Campus Montegancedo S-N, Pozuelo De Alarcon 28223, Madrid, Spain.
   [Salazar-Garcia, Idoia-Ana] Univ San Pablo CEU, Fac Humanidades & Ciencias Comunicac, Paseo Juan XXIII,3, Madrid 28040, Spain.
C3 Universidad Politecnica de Madrid; Universidad Politecnica de Madrid;
   San Pablo CEU University
RP Gomez-de-Agreda, A (corresponding author), Univ Politecn Madrid, Minist Def, Paseo Castellana 109, Madrid 28071, Spain.
EM angel@angelgomezdeagreda.es; claudio.feijoo@upm.es;
   idoiaana.salazargarcia@ceu.es
CR Aguado Juan -Miguel, 2013, COMUNICACIAN MOVIL H
   Aguado Juan -Miguel, 2020, MEDIACIONES UBICUAS
   Alcaiiiz, 2007, CYBERPSYCHOLOGY BEHA
   Allcott H, 2017, J ECON PERSPECT, V31, P211, DOI 10.1257/jep.31.2.211
   Allport G. W., 1947, PSYCHOL RUMOR
   Alonso-Gonzalez Marian., 2019, AMBITOS REV INT COMU, P29, DOI [10.12795/ambitos.2019.i45.03, DOI 10.12795/AMBITOS.2019.I45.03]
   [Anonymous], HTTPS NDUPRESS NDU P
   Arendt H., 2006, ORIGENES TOTALITARIS
   Arsenault Amelia., 2020, MAJOR RES PAPER
   AUSTIN JL, 1957, P ARISTOTELIAN SOC, V57, P1
   Barnes Curtis., 2019, PERCEPTION INCEPTION
   BBC, 2020, BBC NEWS 0730
   Bennett WL, 2018, EUR J COMMUN, V33, P122, DOI 10.1177/0267323118760317
   Bickert M., 2020, FACEBOOK
   Bienvenue Emily, 2019, THE COVE
   Bregler C., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P353
   Buchanan Ben, 2020, HACKER STATE
   Castells M., 2005, ERA INFORM EC SOC CU
   Chen M, 2020, PR MACH LEARN RES, V119
   Chesney Robert, 2018, FOREIGN AFF
   Chick Jesse, 2020, MCAFEE
   Cloutier Jean., 1994, COMMUNICATION ENGAGE, P42
   Codina Lluis, 2018, METHODOS ANUARIO RNE
   Craig Alan B., 2018, UNDERSTANDING VIRTUA, DOI [10.1016/C2013-0-18583-2, DOI 10.1016/C2013-0-18583-2]
   De-Granda-Orive Jose-Ignacio, 2013, REV ESPALIOLA DOCUME, V36
   Donoso-Rodriguez, 2020, IMPLICACIONES AMBITO
   Donoso-Rodriguez Daniel., 2020, IMPLICACIONES AMBITO
   Donovan J., 2019, DEEPFAKES CHEAP FAKE
   EU vs Disinformation, 2020, ACTUALIZED INFORME E
   Fallis D, 2015, LIBR TRENDS, V63, P401, DOI 10.1353/lib.2015.0014
   Fard AE, 2020, WWW'20: COMPANION PROCEEDINGS OF THE WEB CONFERENCE 2020, P510, DOI 10.1145/3366424.3384373
   FLORESVIVAR JM, 2019, DOXA COMUN, P00197, DOI DOI 10.31921/DOXACOM.N29A10
   Freedland Jonathan, 2020, NEW YORK REV
   Galloso I, 2016, MULTIMED TOOLS APPL, V75, P12365, DOI 10.1007/s11042-016-3360-z
   Gomez-de-Agreda, 2019, MUNDO ORWELL MANUAL
   Gomez-de-Agreda Angel., 2018, TELOS
   Greene David., 2018, ELECT FRONTIER FDN
   Greengard S, 2020, COMMUN ACM, V63, P17, DOI 10.1145/3371409
   Gregory Sam., 2020, DEEPFAKES SYNTHETIC
   Grijelmo Alex., 2017, PAIS
   Hamd-Alla Tarek-Bahaa-EI-Deen, 2007, PHIL 12 C IM CULT, P220
   Hameleers M, 2020, POLIT COMMUN, V37, P281, DOI 10.1080/10584609.2019.1674979
   Harris, 2019, DEEP FAKES NATL SEC
   Holbrook Deric J., 2018, THE STRATEGIST
   Howard Phillip N., 2020, LIE MACHINES SAVE DE
   James Tomas., 2020, CYBER SECURITY IMPLI
   Kapantai E, 2021, NEW MEDIA SOC, V23, P1301, DOI 10.1177/1461444820959296
   Kautilya, 2016, ARTHASHASTRA
   Klein Naomi, 2012, DOCTRINA SHOCK AUGE
   Korshunov P., 2018, DEEPFAKES NEW THREAT
   Kramer ADI, 2014, P NATL ACAD SCI USA, V111, P8788, DOI 10.1073/pnas.1320040111
   Lessenski Marin., 2018, SENSE WANTED RESILIE
   Lin Herb., 2018, LAWFARE
   Lopez-Borrull A, 2018, PROF INFORM, V27, P1346, DOI 10.3145/epi.2018.nov.17
   Lorenz-Spreen P, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-09311-w
   LQBAL T, 2018, J MED SYSTEMS, V0042, DOI DOI 10.1007/S10916-018-1072-9
   Maddock Jay., 2020, CONVERSATION
   Makowski D, 2017, CONSCIOUS COGN, V53, P194, DOI 10.1016/j.concog.2017.06.015
   Manfredi -Sanchez Juan-Luis., 2020, REV CIDOB AFERS INF, P49, DOI [10.24241/rcai.2020.124.1.49, DOI 10.24241/RCAI.2020.124.1.49]
   Manfredi -Sanchez Juan-Luis., 2021, IMPACT COVID 19 NARR
   Marques David., 2020, SEGURITECNIA
   METZ S, 2001, ASYMMETRY US MILITAR
   Miller M. Nina., 2020, DIGITAL THREATS DEMO
   MODINA N, 2015, BEHAV RES THER, DOI DOI 10.1016/J.BRAT.2015.08.010
   Molina MD, 2021, AM BEHAV SCI, V65, P180, DOI 10.1177/0002764219878224
   Moret-Millas Vicente., 2020, PECO YESTE MIGUEL
   Nettis, 2020, AIR FORCES CYBER
   Nguyen T., 2019, DEEP LEARNING DEEPFA
   Nielsen RasmusK., 2017, NEWS YOU DONT BELIEV
   O'Brolchain F, 2016, SCI ENG ETHICS, V22, P1, DOI 10.1007/s11948-014-9621-1
   Pamment James, 2019, COUNTERING ONLINE PR
   Parker Lucie, 2018, DIGITAL RESILIENCE S
   Peirano Marta., 2020, MEDIOS CONNUNICACION
   Piasecki J, 2018, SCI ENG ETHICS, V24, P809, DOI 10.1007/s11948-017-0010-4
   Rettberg JW, 2014, PALGRAVE PIVOT, P1, DOI 10.1057/9781137476661
   Rodriguez Rory., 2020, ELECT FRONTIER FDN
   Santos-Porras Borja., 2020, CONVERSATION 0105
   Sasse Ben., 2018, MALICIOUS DEEP FAKE
   Satter, 2020, REUTERS GRAPHICS
   Schmidt Todd., 2020, MISSING DOMAIN WAR A
   Simon Felix, 2020, REUTERS I
   Sitawarin C., 2018, DARTS DECEIVING AUTO
   Stupp C., 2019, WALL STREET J, V30
   Tandoc EC, 2018, DIGIT JOURNAL, V6, P137, DOI 10.1080/21670811.2017.1360143
   Thompson N.C., 2020, ARXIV200705558
   Tzu Sun, 2013, EL ARTE DE LA GUERRA
   UK Ministry of Defence, 2017, JCN 1 17 FUT FORC CO
   Universidad Andina de Cuzco, 2019, REAT VIRT INTRO HIST
   Vosoughi S, 2018, SCIENCE, V359, P1146, DOI 10.1126/science.aap9559
   Vougioukas K, 2020, INT J COMPUT VISION, V128, P1398, DOI 10.1007/s11263-019-01251-8
   Warzel C., 2020, NEW YORK TIMES
   Watts Clint, 2019, ADV PERSISTENT MANIP
   Wheeler Tarah, 2018, FOREIGN POLICY
   Woolley Samuel, 2020, NATL ENDOWMENT DEMOC
   Yu Chia-Mu, 2019, DETECTING DEEPFAKE F
   Zhang Wanqing., 2020, SITH TONE
   Zittrain Jonathan, 2019, NEW YORKER
NR 97
TC 1
Z9 1
U1 2
U2 2
PU  EDICIONES PROFESIONALES INFORMACION SL-EPI
PI BARCELONA
PA MISTRAL, 36, BARCELONA, ALBOLOTE, SPAIN
SN 1386-6710
J9 PROF INFORM
JI Prof. Inf.
PD MAR-APR
PY 2021
VL 30
IS 2
AR e300216
DI 10.3145/epi.2021.mar.16
PG 24
WC Communication; Information Science & Library Science
WE Social Science Citation Index (SSCI)
SC Communication; Information Science & Library Science
GA SB1EQ
UT WOS:000649745700002
OA Bronze, Green Accepted
DA 2022-02-06
ER

PT J
AU Ahmed, S
AF Ahmed, Saifuddin
TI Navigating the maze: Deepfakes, cognitive ability, and social media news
   skepticism
SO NEW MEDIA & SOCIETY
LA English
DT Article; Early Access
DE Cognitive ability; deep fakes; disinformation; news skepticism; social
   media
ID SELF-ESTEEM; FAKE NEWS; EXPOSURE; TRUST; CREDIBILITY; INFORMATION;
   LOCUS; ATTRIBUTIONS; INVOLVEMENT; SUCCESS
AB The early apprehensions about how deepfakes (also deep fakes) could be weaponized for social and political purposes are now coming to pass. This study is one of the first to examine the social impact of deepfakes. Using an online survey sample in the United States, this study investigates the relationship between citizen concerns regarding deepfakes, exposure to deepfakes, inadvertent sharing of deepfakes, the cognitive ability of individuals, and social media news skepticism. Results suggest that deepfakes exposure and concerns are positively related to social media news skepticism. In contrast, those who frequently rely on social media as a news platform are less skeptical. Higher cognitive abled individuals are more skeptical of news on social media. The moderation findings suggest that among those who are more concerned about deepfakes, inadvertently sharing a deepfake is associated with heightened skepticism. However, these patterns are more pronounced among low than high cognitive individuals.
C1 [Ahmed, Saifuddin] Nanyang Technol Univ, Wee Kim Wee Sch Commun & Informat, 31 Nanyang Link, Singapore 637718, Singapore.
C3 Nanyang Technological University & National Institute of Education (NIE)
   Singapore; Nanyang Technological University
RP Ahmed, S (corresponding author), Nanyang Technol Univ, Wee Kim Wee Sch Commun & Informat, 31 Nanyang Link, Singapore 637718, Singapore.
EM sahmed@ntu.edu.sg
OI Ahmed, Saifuddin/0000-0001-6372-213X
FU Nanyang Technological UniversityNanyang Technological University
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: This study
   was funded by the 2019 Nanyang Technological University Start-up Grant.
CR Abouserie R., 1994, ED PSYCHOL, V14, P323, DOI [10.1080/0144341940140306, DOI 10.1080/0144341940140306]
   ANDERSON CR, 1977, ACAD MANAGE J, V20, P260, DOI 10.2307/255399
   Basol Melisa, 2020, J Cogn, V3, P2, DOI 10.5334/joc.91
   Blaine B., 1993, SELF ESTEEM PLENUM S, P55, DOI DOI 10.1007/978-1-4684-8956-9_4
   Brandt MJ, 2016, SOC PSYCHOL PERS SCI, V7, P884, DOI 10.1177/1948550616660592
   Campbell W. K., 1999, REV GEN PSYCHOL, V3, P23, DOI DOI 10.1037/1089-2680.3.1.23
   Chen S, 1999, DUAL-PROCESS THEORIES IN SOCIAL PSYCHOLOGY, P73
   Chesney B, 2019, CALIF LAW REV, V107, P1753, DOI 10.15779/Z38RV0D15J
   Cho J, 2018, COMMUN RES, V45, P83, DOI 10.1177/0093650216644020
   Christopher N., 2020, VICE reports
   Clifford C., 2019, FAKE NEWS HAS DECR G
   Coleman J., 1990, FDN SOCIAL THEORY
   Coleman S, 2012, JOURNALISM STUD, V13, P37, DOI 10.1080/1461670X.2011.592353
   COZZENS MD, 1987, COMMUN RES, V14, P437, DOI 10.1177/009365087014004004
   CRAVENS RW, 1977, J PERS, V45, P150, DOI 10.1111/j.1467-6494.1977.tb00597.x
   Dawsey J., 2017, WASH POST
   Ellison NB, 2014, J COMPUT-MEDIAT COMM, V19, P855, DOI 10.1111/jcc4.12078
   FINDLEY MJ, 1983, J PERS SOC PSYCHOL, V44, P419, DOI 10.1037/0022-3514.44.2.419
   Fiske S.T., 2013, SOCIAL COGNITION BRA
   Flanagin AJ, 2008, GEOJOURNAL, V72, P137, DOI 10.1007/s10708-008-9188-y
   Fogg BJ., 2003, P SIGCHI C HUM FACT, P722
   FREEDMAN JL, 1964, J ABNORM SOC PSYCH, V69, P290, DOI 10.1037/h0042717
   Ganzach Y, 2019, SOC PSYCHOL PERS SCI, V10, P924, DOI 10.1177/1948550618800494
   GAZIANO C, 1986, JOURNALISM QUART, V63, P451, DOI 10.1177/107769908606300301
   GLICK P, 1989, PERS SOC PSYCHOL B, V15, P572, DOI 10.1177/0146167289154010
   Gonzalez C, 2005, INTELLIGENCE, V33, P169, DOI 10.1016/j.intell.2004.10.002
   Goyanes M, 2020, JOURNAL PRACT, V14, P714, DOI 10.1080/17512786.2019.1631710
   Graham Megan., 2020, CNBC
   Guess A, 2019, SCI ADV, V5, DOI 10.1126/sciadv.aau4586
   Hadjikhani N, 2009, NEUROREPORT, V20, P403, DOI 10.1097/WNR.0b013e328325a8e1
   Hao K., 2019, BIGGEST THREAT DEEPF
   Hattrup K, 2005, J BUS PSYCHOL, V19, P461, DOI 10.1007/s10869-005-4519-1
   Hayes AF, 2017, INTRO MEDIATION MODE
   Hopmann DN, 2015, MASS COMMUN SOC, V18, P776, DOI 10.1080/15205436.2015.1022190
   JAQUISH GA, 1981, HUM DEV, V24, P110, DOI 10.1159/000272654
   Kim Y, 2013, COMPUT HUM BEHAV, V29, P2607, DOI 10.1016/j.chb.2013.06.005
   Lang A, 2000, J COMMUN, V50, P46, DOI 10.1093/joc/50.1.46
   LODGE M, 1986, AM POLIT SCI REV, V80, P505, DOI 10.2307/1958271
   Metzger MJ, 2013, J PRAGMATICS, V59, P210, DOI 10.1016/j.pragma.2013.07.012
   MILLER DT, 1976, J PERS SOC PSYCHOL, V34, P901
   Mitchell A., 2019, MANY AM SAY MADE UP
   Mitchell A., 2021, NEWS USE SOCIAL MEDI
   O'Brien GE., 1984, RES LOCUS CONTROL CO, V3, P7
   Oeldorf-Hirsch A, 2018, MASS COMMUN SOC, V21, P225, DOI 10.1080/15205436.2017.1384022
   Pennycook G, 2019, P NATL ACAD SCI USA, V116, P2521, DOI 10.1073/pnas.1806781116
   Pennycook G, 2019, COGNITION, V188, P39, DOI 10.1016/j.cognition.2018.06.011
   Phares EJ, 1976, LOCUS CONTROL PERSON
   Pinkleton BE, 2012, J MASS COMMUN Q, V89, P23, DOI 10.1177/1077699011428586
   Potter WJ, 2004, AM BEHAV SCI, V48, P266, DOI 10.1177/0002764204267274
   Powers E., 2014, THESIS U MARYLAND CO
   Rossler Andreas, 2018, FACEFORENSICS LARGE
   ROTTER JB, 1966, PSYCHOL MONOGR, V80, P1, DOI 10.1037/h0092976
   SCHLENKER BR, 1994, PERS SOC PSYCHOL B, V20, P20, DOI 10.1177/0146167294201002
   Seligman AB., 1997, PROBLEM TRUST
   Sereno K., 1968, COMMUNICATIONS MONOG, V35, P476
   Shearer E, 2019, AM ARE WARY ROLE SOC
   SIMON WE, 1975, PSYCHOL SCHOOLS, V12, P97, DOI 10.1002/1520-6807(197501)12:1<97::AID-PITS2310120119>3.0.CO;2-F
   Smith T., 2019, MEDIUM          1209
   Stahl T, 2018, PERS INDIV DIFFER, V122, P155, DOI 10.1016/j.paid.2017.10.026
   Stanovich KE, 2000, BEHAV BRAIN SCI, V23, P645, DOI 10.1017/S0140525X00003435
   Stefanone MA., P 10 INT C SOC MED S, P136
   Sundar SS., 2008, DIGITAL MEDIA YOUTH, P73, DOI DOI 10.1162/DMAL.9780262562324.073
   Talwar S, 2019, J RETAIL CONSUM SERV, V51, P72, DOI 10.1016/j.jretconser.2019.05.026
   Thorndike RL, 1942, J APPL PSYCHOL, V26, P128, DOI 10.1037/h0060053
   Tsfati Y, 2003, INT J PUBLIC OPIN R, V15, P65, DOI 10.1093/ijpor/15.1.65
   Tsfati Y, 2003, COMMUN RES, V30, P504, DOI 10.1177/0093650203253371
   TSFATI Y, 2002, THESIS U PENNSYLVANI
   Tsfati Y, 2010, AM BEHAV SCI, V54, P22, DOI 10.1177/0002764210376309
   Vaccari C, 2020, SOC MEDIA SOC, V6, DOI 10.1177/2056305120903408
   Valeriani A, 2016, NEW MEDIA SOC, V18, P1857, DOI 10.1177/1461444815616223
   van der Meer TWG., 2017, HDB POLITICAL TRUST
   Vargo CJ, 2018, NEW MEDIA SOC, V20, P2028, DOI 10.1177/1461444817712086
   Vraga EK, 2021, INFORM COMMUN SOC, V24, P150, DOI 10.1080/1369118X.2019.1637445
   WANTA W, 1994, JOURNALISM QUART, V71, P90, DOI 10.1177/107769909407100109
   Wasserman H, 2019, AFR JOURNAL STUD, V40, P107, DOI 10.1080/23743670.2019.1627230
   Wechsler D., 1958, MEASUREMENT APPRAISA, DOI [10.1037/11167-000, DOI 10.1037/11167-000]
   Wineburg S., 2016, STANFORD DIGITAL REP
   WORTMAN CB, 1973, J PERS SOC PSYCHOL, V27, P372, DOI 10.1037/h0034949
   Yamamoto M, 2014, J COMPUT-MEDIAT COMM, V19, P430, DOI 10.1111/jcc4.12046
   ZUCKERMAN M, 1979, J PERS, V47, P245, DOI 10.1111/j.1467-6494.1979.tb00202.x
NR 80
TC 0
Z9 0
U1 14
U2 21
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 1461-4448
EI 1461-7315
J9 NEW MEDIA SOC
JI New Media Soc.
AR 14614448211019198
DI 10.1177/14614448211019198
EA JUN 2021
PG 22
WC Communication
WE Social Science Citation Index (SSCI)
SC Communication
GA SN7EZ
UT WOS:000658451800001
DA 2022-02-06
ER

PT J
AU Rupapara, V
   Rustam, F
   Amaar, A
   Washington, PB
   Lee, E
   Ashraf, I
AF Rupapara, Vaibhav
   Rustam, Furqan
   Amaar, Aashir
   Washington, Patrick Bernard
   Lee, Ernesto
   Ashraf, Imran
TI Deepfake tweets classification using stacked Bi-LSTM and words embedding
SO PEERJ COMPUTER SCIENCE
LA English
DT Article
DE Deepfake; Deepfake sentiment analysis; Machine learning; Deep learning;
   Stacked Bi-LSTM
ID SENTIMENT CLASSIFICATION; NETWORKS; ENSEMBLE; FEATURES; CARE
AB The spread of altered media in the form of fake videos, audios, and images, has been largely increased over the past few years. Advanced digital manipulation tools and techniques make it easier to generate fake content and post it on social media. In addition, tweets with deep fake content make their way to social platforms. The polarity of such tweets is significant to determine the sentiment of people about deep fakes. This paper presents a deep learning model to predict the polarity of deep fake tweets. For this purpose, a stacked bi-directional long short-term memory (SBi-LSTM) network is proposed to classify the sentiment of deep fake tweets. Several well-known machine learning classifiers are investigated as well such as support vector machine, logistic regression, Gaussian Naive Bayes, extra tree classifier, and AdaBoost classifier. These classifiers are utilized with term frequency-inverse document frequency and a bag of words feature extraction approaches. Besides, the performance of deep learning models is analyzed including long short-term memory network, gated recurrent unit, bi-direction LSTM, and convolutional neural network+LSTM. Experimental results indicate that the proposed SBi-LSTM outperforms both machine and deep learning models and achieves an accuracy of 0.92.
C1 [Rupapara, Vaibhav] Florida Int Univ, Sch Comp & Informat Sci, Miami, FL 33199 USA.
   [Rustam, Furqan; Amaar, Aashir] Khwaja Fareed Univ Engn & Informat Technol, Dept Comp Sci, Rahim Yar Khan, Pakistan.
   [Washington, Patrick Bernard] Morehouse Coll, Div Business Adm & Econ, Atlanta, GA USA.
   [Lee, Ernesto] Broward Coll, Dept Comp Sci, Broward County, FL 33332 USA.
   [Ashraf, Imran] Yeungnam Univ, Informat & Commun Engn, Gyongsan, Daegu, South Korea.
C3 State University System of Florida; Florida International University;
   Morehouse College; Yeungnam University
RP Lee, E (corresponding author), Broward Coll, Dept Comp Sci, Broward County, FL 33332 USA.; Ashraf, I (corresponding author), Yeungnam Univ, Informat & Commun Engn, Gyongsan, Daegu, South Korea.
EM elee@broward.edu; imranashraf@ynu.ac.kr
RI Rupapara, Vaibhav/AAE-3416-2021
OI Rupapara, Vaibhav/0000-0002-7889-4521; Lee, Ernesto/0000-0002-1209-8565
FU Florida Center for Advanced Analytics and Data Science - Ernesto.Net
   (under the Algorithms for Good Grant); Basic Science Research Program
   through the National Research Foundation of Korea (NRF) - Ministry of
   Education [NRF-2019R1A2C1006159]; MSIT (Ministry of Science and ICT),
   Korea, under the ITRC (Information Technology Research Center) support
   program [IITP-2020-2016-0-00313]; IITP (Institute for Information &
   communications Technology Promotion)
FX This research was funded by the Florida Center for Advanced Analytics
   and Data Science funded by Ernesto.Net (under the Algorithms for Good
   Grant). This research was also funded by Basic Science Research Program
   through the National Research Foundation of Korea (NRF) funded by the
   Ministry of Education (NRF-2019R1A2C1006159) and MSIT (Ministry of
   Science and ICT), Korea, under the ITRC (Information Technology Research
   Center) support program (IITP-2020-2016-0-00313) supervised by the IITP
   (Institute for Information & communications Technology Promotion). The
   funders had no role in study design, data collection and analysis,
   decision to publish, or preparation of the manuscript.
CR Alawneh Emad, 2021, 2021 International Symposium on Electronics and Smart Devices (ISESD), DOI 10.1109/ISESD53023.2021.9501725
   Anjaria M., 2014, 2014 6 INT C COMM SY P 6 INT C COMM SYST, P1
   Baccianella S, 2010, LREC 2010 - SEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION
   BOYD CR, 1987, J TRAUMA, V27, P370, DOI 10.1097/00005373-198704000-00005
   Chung J., 2014, ARXIV14123555
   Deng SY, 2017, DECIS SUPPORT SYST, V94, P65, DOI 10.1016/j.dss.2016.11.001
   Freund Y., 1999, Journal of Japanese Society for Artificial Intelligence, V14, P771
   Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
   Gokulakrishnan B, 2012, INT CONF ADV ICT, P182, DOI 10.1109/ICTer.2012.6423033
   Hasan A, 2018, MATH COMPUT APPL, V23, DOI 10.3390/mca23010011
   Hu M., 2004, P 10 ACM SIGKDD INT, P168
   Hu X, 2009, P 10 INT SOC MUS INF, P411
   Huang FR, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3388861
   Khalid M, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10082788
   Kolchyna O., 2015, ARXIV PREPRINT ARXIV
   Kumar HIK, 2019, INT J INTERACT MULTI, V5, P109, DOI 10.9781/ijimai.2018.12.005
   Kwok AOJ, 2021, CURR ISSUES TOUR, V24, P1798, DOI 10.1080/13683500.2020.1738357
   Li W., 2012, J INF COMPUT SCI, V9, P4551
   Lochter JV, 2016, EXPERT SYST APPL, V62, P243, DOI 10.1016/j.eswa.2016.06.025
   Moraes R, 2013, EXPERT SYST APPL, V40, P621, DOI 10.1016/j.eswa.2012.07.059
   Vo N, 2019, IEEE WINT CONF APPL, P589, DOI 10.1109/WACV.2019.00068
   Neethu MS, 2013, 2013 FOURTH INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATIONS AND NETWORKING TECHNOLOGIES (ICCCNT)
   Onan A, 2016, EXPERT SYST APPL, V62, P1, DOI 10.1016/j.eswa.2016.06.005
   Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79, DOI 10.3115/1118693.1118704
   Pantserev K.A., 2020, CYBER DEFENCE AGE AL, P37, DOI 10.1007/978-3-030-35746-7_3
   Perera SN, 2020, 2020 INT C ART INT, P89
   Perez A, 2006, INT J APPROX REASON, V43, P1, DOI 10.1016/j.ijar.2006.01.002
   Roesslein J., 2009, TWEEPY DOCUMENTATION
   Rupapara V, 2021, IEEE ACCESS, V9, P78621, DOI 10.1109/ACCESS.2021.3083638
   Rustam F, 2021, COMPUT INTELL-US, V37, P964, DOI 10.1111/coin.12440
   Rustam F, 2021, IEEE ACCESS, V9, P33675, DOI 10.1109/ACCESS.2021.3061592
   Rustam F, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0245909
   Rustam F, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21111078
   Saad E, 2021, IEEE ACCESS, V9, P85721, DOI 10.1109/ACCESS.2021.3088838
   Saha S., 2017, INDIAN J SCI TECHNOL, V10, P1, DOI DOI 10.17485/ijst/2017/v10i25/114443
   Saif H, 2016, INFORM PROCESS MANAG, V52, P5, DOI 10.1016/j.ipm.2015.01.005
   Sarvabhotla K, 2011, INFORM RETRIEVAL, V14, P337, DOI 10.1007/s10791-010-9161-5
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Scholkopf B., 1996, Artificial Neural Networks - ICANN 96. 1996 International Conference Proceedings, P47
   Sharaff A, 2019, ADV INTELL SYST, V924, P189, DOI 10.1007/978-981-13-6861-5_17
   Stone P.J., 1966, GEN INQUIRER COMPUTE
   Su Y, 2012, CHINESE LEXICAL SEMA, V7717, DOI [10.1007/978-3-642-36337-5_10, DOI 10.1007/978-3-642-36337-5_10]
   Taboada M, 2011, COMPUT LINGUIST, V37, P267, DOI 10.1162/COLI_a_00049
   Tang DY, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1555
   Thuseethan S, 2020, 2020 IEEE/WIC/ACM INTERNATIONAL JOINT CONFERENCE ON WEB INTELLIGENCE AND INTELLIGENT AGENT TECHNOLOGY (WI-IAT 2020), P267, DOI 10.1109/WIIAT50758.2020.00039
   Tsutsumi K, 2007, PACLIC 21: THE 21ST PACIFIC ASIA CONFERENCE ON LANGUAGE, INFORMATION AND COMPUTATION, PROCEEDINGS, P481
   Turney PD, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P417
   Waheed A, 2021, LEXICON LEARN BASED, P97
   Wang G, 2014, DECIS SUPPORT SYST, V57, P77, DOI 10.1016/j.dss.2013.08.002
   Westerlund M, 2019, TECHNOL INNOV MANAG, V9, P39, DOI 10.22215/timreview/1282
   Wilson T, 2006, COMPUT INTELL-US, V22, P73, DOI 10.1111/j.1467-8640.2006.00275.x
   Wilson T, 2009, COMPUT LINGUIST, V35, P399, DOI 10.1162/coli.08-012-R1-06-90
   Wu FZ, 2016, INFORM SCIENCES, V373, P149, DOI 10.1016/j.ins.2016.09.002
   Xie HL, 2020, IEEE ACCESS, V8, P161519, DOI 10.1109/ACCESS.2020.3021527
   Yu B, 2008, LIT LINGUIST COMPUT, V23, P327, DOI 10.1093/llc/fqn015
   Zhang MX, 2020, IEEE ACCESS, V8, P178849, DOI 10.1109/ACCESS.2020.3027567
NR 56
TC 0
Z9 0
U1 5
U2 5
PU PEERJ INC
PI LONDON
PA 341-345 OLD ST, THIRD FLR, LONDON, EC1V 9LL, ENGLAND
EI 2376-5992
J9 PEERJ COMPUT SCI
JI PeerJ Comput. Sci.
PD OCT 21
PY 2021
VL 7
AR e745
DI 10.7717/peerj-cs.745
PG 25
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WL1NX
UT WOS:000710181800001
PM 34805502
OA Green Published, gold
DA 2022-02-06
ER

PT J
AU Matsumura, H
   Taketomi, T
   Kato, H
AF Matsumura, Haruka
   Taketomi, Takafumi
   Kato, Hirokazu
TI Impact of facial contour compensation on self-recognition in
   face-swapping technology
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face-swapping; Self-recognizability; Facial contour compensation
ID MENTAL PRACTICE
AB Experts in sports science anticipate substantial training gains that can result from elevated cerebral activity when face-swapping technology is used in videos of athletes to facilitate their motor imagery (Matsumura et al. 2017). In Matsumura et al. (2017), we confirmed that self-recognizability in face-swapping positively influences an individual's cerebral activity. However, to the best of our knowledge, self-recognizability in face-swapping is yet to be investigated. In this study, we evaluate self-recognizability in face-swapping from the following perspectives: the impact of facial contour compensation on face-swapped videos, the impact of face orientation, and the difference in the face-swapped targets. In our experiment, we use the visual analog scale for subjective evaluation. The experimental results confirm that facial contour compensation helps improve self-recognizability in face-swapping.
C1 [Matsumura, Haruka; Taketomi, Takafumi; Kato, Hirokazu] Nara Inst Sci & Technol, 8916-5 Takayama, Nara 6300192, Japan.
C3 Nara Institute of Science & Technology
RP Taketomi, T (corresponding author), Nara Inst Sci & Technol, 8916-5 Takayama, Nara 6300192, Japan.
EM matsumura.haruka.md7@is.naist.jp; takafumi-t@is.naist.jp;
   kato@is.naist.jp
RI Taketomi, Takafumi/AAE-7546-2021; Taketomi, Takafumi/T-4236-2017
OI Kato, Hirokazu/0000-0003-3921-2871; Taketomi,
   Takafumi/0000-0002-5353-0895
CR Afchar D., 2018, 2018 IEEE INT WORKSH, P1, DOI DOI 10.1109/WIFS.2018.8630761
   [Anonymous], 2020, DEEPFACELAB
   [Anonymous], 2019, DLIB C LIB
   Bitouk D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360638
   Blanz V, 2004, COMPUT GRAPH FORUM, V23, P669, DOI 10.1111/j.1467-8659.2004.00799.x
   Blefari ML, 2015, FRONT BEHAV NEUROSCI, V9, DOI 10.3389/fnbeh.2015.00018
   Dale K, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024164
   DECETY J, 1990, ACTA PSYCHOL, V73, P13, DOI 10.1016/0001-6918(90)90056-L
   DRISKELL JE, 1994, J APPL PSYCHOL, V79, P481, DOI 10.1037/0021-9010.79.4.481
   FELTZ DL, 1983, J SPORT PSYCHOL, V5, P25, DOI 10.1123/jsp.5.1.25
   Kazemi V, 2014, PROC CVPR IEEE, P1867, DOI 10.1109/CVPR.2014.241
   Keyes H, 2010, BRAIN COGNITION, V72, P244, DOI 10.1016/j.bandc.2009.09.006
   Matsumura H, 2017, P INT C ART REAL TEX, P7
   Microsoft garage, 2019, FAC SWAP
   Morishima S, 2008, IEICE T INF SYST, VE91D, P1594, DOI 10.1093/ietisy/e91-d.6.1594
   Nirkin Y, 2018, IEEE INT CONF AUTOMA, P98, DOI 10.1109/FG.2018.00024
   Perez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269
   Platek SM, 2004, COGNITIVE BRAIN RES, V19, P114, DOI 10.1016/j.cogbrainres.2003.11.014
   Sugase-Miyamoto Y, 2014, J NEUROSCI, V34, P12457, DOI 10.1523/JNEUROSCI.0485-14.2014
   Sugiura M, 2005, NEUROIMAGE, V24, P143, DOI 10.1016/j.neuroimage.2004.07.063
   Uddin LQ, 2005, NEUROIMAGE, V25, P926, DOI 10.1016/j.neuroimage.2004.12.018
   YIN RK, 1969, J EXP PSYCHOL, V81, P141, DOI 10.1037/h0027474
   YUE G, 1992, J NEUROPHYSIOL, V67, P1114, DOI 10.1152/jn.1992.67.5.1114
NR 23
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 7727
EP 7748
DI 10.1007/s11042-020-09866-7
EA OCT 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000587058000003
OA Green Submitted
DA 2022-02-06
ER

PT J
AU Kaur, S
   Kumar, P
   Kumaraguru, P
AF Kaur, Sawinder
   Kumar, Parteek
   Kumaraguru, Ponnurangam
TI Deepfakes: temporal sequential analysis to detect face-swapped video
   clips using convolutional long short-term memory
SO JOURNAL OF ELECTRONIC IMAGING
LA English
DT Article
DE deepfake; news; politicians; face swap; forged; frames; videos
ID RECOGNITION
AB Deepfake (a bag of "deep learning" and "fake") is a technique for human image synthesis based on artificial intelligence, i.e., to superimpose the existing (source) images or videos onto destination images or videos using neural networks (NNs). Deepfake enthusiasts have been using NNs to produce convincing face swaps. Deepfakes are a type of video or image forgery developed to spread misinformation, invade privacy, and mask the truth using advanced technologies such as trained algorithms, deep learning applications, and artificial intelligence. They have become a nuisance to social media users by publishing fake videos created by fusing a celebrity's face over an explicit video. The impact of deepfakes is alarming, with politicians, senior corporate officers, and world leaders being targeted by nefarious actors. An approach to detect deepfake videos of politicians using temporal sequential frames is proposed. The proposed approach uses the forged video to extract the frames at the first level followed by a deep depth-based convolutional long short-term memory model to identify the fake frames at the second level. Also the proposed model is evaluated on our newly collected ground truth dataset of forged videos using source and destination video frames of famous politicians. Experimental results demonstrate the effectiveness of our method. (C) 2020 SPIE and IS&T
C1 [Kaur, Sawinder] Thapar Inst Engn & Technol, Dept Comp Sci & Engn, Doctoral Res Lab 2, Patiala, Punjab, India.
   [Kumar, Parteek] Thapar Inst Engn & Technol, Dept Comp Sci & Engn, Patiala, Punjab, India.
   [Kumaraguru, Ponnurangam] Indraprastha Inst Informat Technol, Dept Comp Sci & Engn, Delhi, India.
C3 Thapar Institute of Engineering & Technology; Thapar Institute of
   Engineering & Technology; Indraprastha Institute of Information
   Technology Delhi
RP Kaur, S (corresponding author), Thapar Inst Engn & Technol, Dept Comp Sci & Engn, Doctoral Res Lab 2, Patiala, Punjab, India.
EM skaur_phd17@thapar.edu
FU NVIDIA Corporation
FX This publication is an outcome of the R&D work undertaken in the project
   under the Visvesvaraya PhD Scheme of Ministry of Electronics and
   Information Technology, Government of India, being implemented by
   Digital India Corporation (formerly Media Lab Asia). We gratefully
   acknowledge the support of NVIDIA Corporation with the donation of the
   Titan Xp GPU used for this research.
CR Abadi M, 2015, TENSORFLOW LARGE SCA
   Abudarham N, 2016, J VISION, V16, DOI 10.1167/16.3.40
   Afchar D, 2018, IEEE INT WORKS INFOR
   Agarwal S., 2019, P CVPR WORKSH LONG B, P38
   Bayar Y, 2016, TRANSYLV REV ADM SCI, P5
   Benevenuto F, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P620, DOI 10.1145/1571941.1572047
   Bergstra J, 2010, P 9 PYTH SCI C, P3
   CAETANO J. A., 2018, ANAL CHARACTERIZING
   Canini K. R., 2011, Proceedings of the 2011 IEEE Third International Conference on Privacy, Security, Risk and Trust and IEEE Third International Conference on Social Computing (PASSAT/SocialCom 2011), P1, DOI 10.1109/PASSAT/SocialCom.2011.91
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Dewan P, 2017, SOC NETW ANAL MIN, V7, DOI 10.1007/s13278-017-0434-5
   Dolhansky Brian, 2019, DEEPFAKE DETECTION C
   Goswami G, 2014, IEEE T INF FOREN SEC, V9, P1629, DOI 10.1109/TIFS.2014.2343913
   GUERA D, 2018, 15 IEEE INT C ADV VI, P00001
   HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871
   Hosseinmardi H., 2015, DETECTION CYBERBULLY
   Kaur S., ISITFAKE
   Kaur S, 2020, SOFT COMPUT, V24, P9049, DOI 10.1007/s00500-019-04436-y
   Korshunov P, 2019, INT CONF BIOMETR
   Korshunova I, 2017, IEEE I CONF COMP VIS, P3697, DOI 10.1109/ICCV.2017.397
   LI Y, 2018, P IEEE INT WORKSH IN, P00001
   Li Yuezun, 2019, CELEB DF NEW DATASET
   Lyon B., FACESWAP
   Nguyen H. H., 2019, USE CAPSULE NETWORK
   Nguyen HH, 2019, INT CONF ACOUST SPEE, P2307, DOI 10.1109/ICASSP.2019.8682602
   Perov I., DEEPFACELAB
   Rossler Andreas, 2018, FACEFORENSICS LARGE
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Sivaram M., 2019, ICTACT J SOFT COMPUT, V9, P1844
   Tariq S, 2018, MPS'18: PROCEEDINGS OF THE 2ND INTERNATIONAL WORKSHOP ON MULTIMEDIA PRIVACY AND SECURITY, P81, DOI 10.1145/3267357.3267367
   Ullah A, 2018, IEEE ACCESS, V6, P1155, DOI 10.1109/ACCESS.2017.2778011
   Vondrick C, 2016, P ADV NEUR INF PROC, P613
   Wang AH, 2010, SECRYPT 2010: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SECURITY AND CRYPTOGRAPHY, P142
   Xu ZQ, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P141, DOI 10.1109/ACPR.2015.7486482
   Yang X, 2019, INT CONF ACOUST SPEE, P8261, DOI 10.1109/ICASSP.2019.8683164
   Zhou P, 2017, IEEE COMPUT SOC CONF, P1831, DOI 10.1109/CVPRW.2017.229
NR 36
TC 2
Z9 2
U1 2
U2 8
PU IS&T & SPIE
PI BELLINGHAM
PA 1000 20TH ST, BELLINGHAM, WA 98225 USA
SN 1017-9909
EI 1560-229X
J9 J ELECTRON IMAGING
JI J. Electron. Imaging
PD MAY
PY 2020
VL 29
IS 3
AR 033013
DI 10.1117/1.JEI.29.3.033013
PG 17
WC Engineering, Electrical & Electronic; Optics; Imaging Science &
   Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Optics; Imaging Science & Photographic Technology
GA OH1ZM
UT WOS:000582369600013
OA Bronze
DA 2022-02-06
ER

PT J
AU Su, YS
   Xia, HW
   Liang, Q
   Nie, WZ
AF Su, Yishan
   Xia, Huawei
   Liang, Qi
   Nie, Weizhi
TI Exposing DeepFake Videos Using Attention Based Convolutional LSTM
   Network
SO NEURAL PROCESSING LETTERS
LA English
DT Article
DE DeepFake detection; Convolutional LSTM; Attention
AB The detection of face tampering in videos created by artificial intelligence techniques (commonly known as the Deep Fakes) has become an important and challenging task in network security defense. In this paper, we propose a novel attention-based deep fake video detection method, which captures the sharp changes in terms of the facial features caused by the composite video. We utilize the convolutional long short-term memory to extract both spatial and temporal information of DeeFake videos. Meanwhile, we apply the attention mechanism to emphasize the specific facial area of each video frame. Finally, we design a decoder to further fusion multiple frames information for more accurate detection results. Experimental results and comparisons with state-of-the-art methods demonstrate that our framework achieves superior performance.
C1 [Su, Yishan; Xia, Huawei; Nie, Weizhi] Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
   [Liang, Qi] Tianjin Univ, Sch Microelect, Tianjin 300072, Peoples R China.
C3 Tianjin University; Tianjin University
RP Liang, Q (corresponding author), Tianjin Univ, Sch Microelect, Tianjin 300072, Peoples R China.
EM yishan.su@tju.edu.cn; xiahuawei@tju.edu.cn; tjuliangqi@tju.edu.cn;
   weizhinie@tju.edu.cn
RI Liang, Qi/ABF-4426-2021; Nie, Weizhi/ABF-5316-2021
OI Qi, Liang/0000-0001-5598-6012
FU National Key Research and Development Program of China [2020YFB1711704];
   National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61872267, 61772359, 61572356, 61862020,
   61861014]
FX This work was supported in part by the National Key Research and
   Development Program of China (2020YFB1711704) and the National Natural
   Science Foundation of China (61872267, 61772359, 61572356, 61862020,
   61861014).
CR Afchar D, 2018, IEEE INT WORKS INFOR
   Ahmed F, 2010, SIGNAL PROCESS, V90, P1456, DOI 10.1016/j.sigpro.2009.05.024
   Amerini Irene, 2020, IH&MMSec '20: Proceedings of the 2020 ACM Workshop on Information Hiding and Multimedia Security, P97, DOI 10.1145/3369412.3395070
   Amerini I., 2019, IEEE INT CONF COMP V, DOI DOI 10.1109/ICCVW.2019.00152
   Amerini I, 2019, IEEE ACCESS, V7, P35264, DOI 10.1109/ACCESS.2019.2903876
   Barret Zoph, 2017, INT C LEARN REPR
   Chung J., 2014, EMPIRICAL EVALUATION
   Cornia M, 2018, IEEE T IMAGE PROCESS, V27, P5142, DOI 10.1109/TIP.2018.2851672
   Graves A, 2016, INT C LEARN REPR ICL, P15
   Guera D, 2018, 2018 15TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P127
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735
   Hong CQ, 2019, IEEE T IND INFORM, V15, P3952, DOI 10.1109/TII.2018.2884211
   Krizhevsky A., 2012, ADV NEURAL INF PROCE, P1097, DOI DOI 10.1145/3065386
   Li X, 2019, SIGNAL PROCESS, V161, P136, DOI 10.1016/j.sigpro.2019.03.019
   [李艳歌 Li Yange], 2018, [高分子通报, Polymer Bulletin], P46
   Li YZ, 2018, IEEE INT WORKS INFOR
   Ma YK, 2018, THIRTY-SECOND AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTIETH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / EIGHTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P5876
   Matern F, 2019, IEEE WINT CONF APPL, P83, DOI 10.1109/WACVW.2019.00020
   McCloskey Scott, 2018, ARXIV181208247
   Mitra A., 2021, SN COMPUT SCI, V2, P98, DOI [10.1007/s42979-021-00495-x, DOI 10.1007/S42979-021-00495-X]
   Nguyen HV, 2019, 2019 2ND INTERNATIONAL CONFERENCE ON APPLIED INFORMATION TECHNOLOGY AND INNOVATION (ICAITI2019), P1, DOI 10.1109/ICAITI48442.2019.8982119
   Niener M., 2020, ABS200714808 CORR
   Park M, 2020, IEEE ACCESS, V8, P188883, DOI 10.1109/ACCESS.2020.3031292
   Rossler A, 2019, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2019.00009
   Sabir Ekraam, 2019, INTERFACES GUI, P80
   Seelamantula CS, 2009, SIGNAL PROCESS, V89, P523, DOI 10.1016/j.sigpro.2008.10.014
   Shalaby MAW, 2013, SIGNAL PROCESS, V93, P56, DOI 10.1016/j.sigpro.2012.06.021
   Simonyan K, 2015, ICLR 2015, DOI DOI 10.1109/CVPR.2015.7298594
   Singh A, 2020, SN COMPUT SCI, V1, P212, DOI [10.1007/s42979-020-00225-9, DOI 10.1007/S42979-020-00225-9]
   Tan MX, 2019, PR MACH LEARN RES, V97
   THIES J, 2016, PROC CVPR IEEE, P2387, DOI DOI 10.1109/CVPR.2016.262
   Thies J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323035
   Tolosana R, 2020, INFORM FUSION, V64, P131, DOI 10.1016/j.inffus.2020.06.014
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang NN, 2017, SIGNAL PROCESS, V130, P1, DOI 10.1016/j.sigpro.2016.06.014
   Wang YH, 2020, PROC CVPR IEEE, P5263, DOI 10.1109/CVPR42600.2020.00531
   Wang YL, 2018, IEEE WINT CONF APPL, P112, DOI 10.1109/WACV.2018.00019
   Woo W.-C., 2015, ADV NEURAL INFORM PR
   Wu SE, 2018, SIGNAL PROCESS, V144, P384, DOI 10.1016/j.sigpro.2017.11.003
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang X, 2019, INT CONF ACOUST SPEE, P8261, DOI 10.1109/ICASSP.2019.8683164
   Yang Y, 2018, IEEE T IMAGE PROCESS, V27, P5600, DOI 10.1109/TIP.2018.2855422
   Yu J., 2019, IEEE T CYBERNETICS, DOI DOI 10.1109/TCYB.2019.2901250
   Yu J, 2015, IEEE T CYBERNETICS, V45, P767, DOI 10.1109/TCYB.2014.2336697
   Yu J, 2014, IEEE T IMAGE PROCESS, V23, P2019, DOI 10.1109/TIP.2014.2311377
   Zhang H, 2019, PR MACH LEARN RES, V97
   Zhang Y, 2017, 2017 IEEE 2ND INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP), P15, DOI 10.1109/SIPROCESS.2017.8124497
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
   Zhou P, 2017, IEEE COMPUT SOC CONF, P1831, DOI 10.1109/CVPRW.2017.229
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 51
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1370-4621
EI 1573-773X
J9 NEURAL PROCESS LETT
JI Neural Process. Lett.
PD DEC
PY 2021
VL 53
IS 6
BP 4159
EP 4175
DI 10.1007/s11063-021-10588-6
EA SEP 2021
PG 17
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WR0LL
UT WOS:000692437900004
OA Bronze
DA 2022-02-06
ER

PT J
AU Ismail, A
   Elpeltagy, M
   Zaki, MS
   Eldahshan, K
AF Ismail, Aya
   Elpeltagy, Marwa
   S. Zaki, Mervat
   Eldahshan, Kamal
TI A New Deep Learning-Based Methodology for Video Deepfake Detection Using
   XGBoost
SO SENSORS
LA English
DT Article
DE deepfake; YOLO; face detector; convolutional neural network; XGBoost;
   deepfake; fake video detection
ID FACIAL LANDMARK LOCALIZATION; IMAGES; NETWORKS
AB Currently, face-swapping deepfake techniques are widely spread, generating a significant number of highly realistic fake videos that threaten the privacy of people and countries. Due to their devastating impacts on the world, distinguishing between real and deepfake videos has become a fundamental issue. This paper presents a new deepfake detection method: you only look once-convolutional neural network-extreme gradient boosting (YOLO-CNN-XGBoost). The YOLO face detector is employed to extract the face area from video frames, while the InceptionResNetV2 CNN is utilized to extract features from these faces. These features are fed into the XGBoost that works as a recognizer on the top level of the CNN network. The proposed method achieves 90.62% of an area under the receiver operating characteristic curve (AUC), 90.73% accuracy, 93.53% specificity, 85.39% sensitivity, 85.39% recall, 87.36% precision, and 86.36% F1-measure on the CelebDF-FaceForencics++ (c23) merged dataset. The experimental study confirms the superiority of the presented method as compared to the state-of-the-art methods.
C1 [Ismail, Aya] Tanta Univ, Math Dept, Tanta 31511, Egypt.
   [Elpeltagy, Marwa] Al Azhar Univ, Syst & Comp Dept, Cairo 11884, Egypt.
   [S. Zaki, Mervat; Eldahshan, Kamal] Al Azhar Univ, Girls Branch, Math Dept, Cairo 11884, Egypt.
C3 Egyptian Knowledge Bank (EKB); Tanta University; Egyptian Knowledge Bank
   (EKB); Al Azhar University; Egyptian Knowledge Bank (EKB); Al Azhar
   University
RP Elpeltagy, M (corresponding author), Al Azhar Univ, Syst & Comp Dept, Cairo 11884, Egypt.
EM aya.ismail@science.tanta.edu.eg; marwa.elpeltagy@ejust.edu.eg;
   mervatzaki.1959@azhar.edu.eg; dahshan@gmail.com
OI elpeltaagy, marwa/0000-0002-6618-7723; Zaki, Mervat/0000-0003-0472-042X
CR Afchar D, 2018, IEEE INT WORKS INFOR
   Banerjee B., 2019, 2019 INT C COMM INF
   Bojia Zi, 2020, MM '20: Proceedings of the 28th ACM International Conference on Multimedia, P2382, DOI 10.1145/3394171.3413769
   Bonettini N, 2021, INT C PATT RECOG, P5012, DOI 10.1109/ICPR48806.2021.9412711
   Cao, 2020, ADV DRIVER INTENTION, P99
   Chen T., P 22 ACM SIGKDD INT, P785
   Chen WJ, 2021, VISUAL COMPUT, V37, P805, DOI 10.1007/s00371-020-01831-7
   Chollet F., P IEEE C COMP VIS PA, P1251
   Dang H, 2020, PROC CVPR IEEE, P5780, DOI 10.1109/CVPR42600.2020.00582
   Dave P, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.586
   Deng J., 2019, ABS190500641 CORR
   Dozat T., 2016, ICLR WORKSH, P2013
   Dufour N, 2019, GOOGLE AI BLOG
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Ferrer C.C., 200607397 ARXIV
   George A., 200614749 ARXIV
   Grundmann M., 190705047 ARXIV
   Guera D, 2018, 2018 15TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P127
   HANLEY JA, 1982, RADIOLOGY, V143, P29, DOI 10.1148/radiology.143.1.7063747
   He Y., 2016, OBJECT DETECTION YOL
   Hui KH, 2021, WIREL COMMUN MOB COM, V2021, DOI 10.1155/2021/5582132
   Jayasri B.S., 2020, P 1 INT C ADV PHYS S
   Jiang LM, 2020, PROC CVPR IEEE, P2886, DOI 10.1109/CVPR42600.2020.00296
   Kaati L, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DATA MINING WORKSHOP (ICDMW), P954, DOI 10.1109/ICDMW.2015.9
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Khalil SS, 2021, FUTURE INTERNET, V13, DOI 10.3390/fi13040093
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Kompatsiaris I., 200607084 ARXIV
   Kotecha K., 2018, P 2018 IEEE PUN PUN, P1
   Kumar A, 2020, ADV INTELL SYST COMP, V1069, P1, DOI [10.1016/j.puhip.2020.100009, 10.1007/978-3-030-32520-6_1]
   Kumar R., 2020, ACCURATE PREDICTION, DOI [10.1101/2020.04.13.20063461, DOI 10.1101/2020.04.13.20063461]
   Le, P INT C MACH LEARN L, P6105
   Li XL, 2020, LECT NOTES ELECTR EN, V586, P88, DOI 10.1007/978-981-32-9050-1_10
   Li YZ, 2020, PROC CVPR IEEE, P3204, DOI 10.1109/CVPR42600.2020.00327
   Li Yuezun, 2018, 2018 IEEE INT WORKSH, P1, DOI DOI 10.1109/WIFS.2018.8630787
   Liu J., 210512931 ARXIV
   Lyu S., 181100656 ARXIV
   Marcel S., 181208685 ARXIV
   Mariette Awad, 2015, EFFICIENT LEARNING M, P67
   Masi Iacopo, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12352), P667, DOI 10.1007/978-3-030-58571-6_39
   Mehra, 2020, THESIS U 20 ENSCHEDE
   Montserrat Daniel Mas, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW). Proceedings, P2851, DOI 10.1109/CVPRW50498.2020.00342
   Nahavandi S., 190911573 ARXIV
   Nguyen HV, 2019, 2019 2ND INTERNATIONAL CONFERENCE ON APPLIED INFORMATION TECHNOLOGY AND INNOVATION (ICAITI2019), P1, DOI 10.1109/ICAITI48442.2019.8982119
   Nguyen HH, 2019, INT CONF ACOUST SPEE, P2307, DOI 10.1109/ICASSP.2019.8682602
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Rossler A, 2019, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2019.00009
   Sabir Ekraam, 2019, INTERFACES GUI, P80
   Singh A, 2020, SN COMPUT SCI, V1, P212, DOI [10.1007/s42979-020-00225-9, DOI 10.1007/S42979-020-00225-9]
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Staelin, 2003, PARAMETER SELECTION, V1
   Szegedy C, 2017, THIRTY-FIRST AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4278
   Truong, 2021, FORENSIC SCI INT DIG, V36, P301108, DOI 10.1016/j.fsidi.2021.301108
   Vezzetti E, 2016, INT J BIOMETRICS, V8, P216
   Viola P, 2001, P 2001 IEEE COMP VIS
   Ward T.E., 190601529 ARXIV
   Wodajo D., 2021, ARXIV210211126
   Wubet WorkuMuluye, 2020, IJITEE, V9
   Yang X, 2019, INT CONF ACOUST SPEE, P8261, DOI 10.1109/ICASSP.2019.8683164
   Zhang L., 2017, PROC INT GEOPHYS C, DOI 10.1190/igc2017-351
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
   Zhang ZP, 2014, IEEE T CIRC SYST VID, V24, P1475, DOI 10.1109/TCSVT.2014.2308639
NR 62
TC 1
Z9 1
U1 6
U2 6
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 1424-8220
J9 SENSORS-BASEL
JI Sensors
PD AUG
PY 2021
VL 21
IS 16
AR 5413
DI 10.3390/s21165413
PG 15
WC Chemistry, Analytical; Engineering, Electrical & Electronic; Instruments
   & Instrumentation
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Chemistry; Engineering; Instruments & Instrumentation
GA UH2NQ
UT WOS:000689775000001
PM 34450855
OA gold, Green Published
DA 2022-02-06
ER

PT J
AU Zhang, T
AF Zhang, Tao
TI Deepfake generation and detection, a survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deepfake; Detection; Generation; Survey; Media forensics
ID NETWORKS; FAKES
AB Deepfake refers to realistic, but fake images, sounds, and videos generated by articial intelligence methods. Recent advances in deepfake generation make deepfake more realistic and easier to make. Deepfake has been a signicant threat to national security, democracy, society, and our privacy, which calls for deepfake detection methods to combat potential threats. In the paper, we make a survey on state-ofthe-art deepfake generation methods, detection methods, and existing datasets. Current deepfake generation methods can be classified into face swapping and facial reenactment. Deepfake detection methods are mainly based features and machine learning methods. There are still some challenges for deepfake detection, such as progress on deepfake generation, lack of high quality datasets and benchmark. Future trends on deepfake detection can be efficient, robust and systematical detection methods and high quality datasets.
C1 [Zhang, Tao] Beihang Univ, Sch Cyber Sci & Technol, Beijing, Peoples R China.
   [Zhang, Tao] Guilin Univ Elect Technol, Guangxi Key Lab Cryptog & Informat Secur, Guilin, Peoples R China.
   [Zhang, Tao] Guilin Univ Elect Technol, Guangxi Key Lab Trusted Software, Guilin, Peoples R China.
   [Zhang, Tao] Key Lab Film & TV Media Technol Zhejiang Prov, Hangzhou, Peoples R China.
C3 Beihang University; Guilin University of Electronic Technology; Guilin
   University of Electronic Technology
RP Zhang, T (corresponding author), Beihang Univ, Sch Cyber Sci & Technol, Beijing, Peoples R China.; Zhang, T (corresponding author), Guilin Univ Elect Technol, Guangxi Key Lab Cryptog & Informat Secur, Guilin, Peoples R China.; Zhang, T (corresponding author), Guilin Univ Elect Technol, Guangxi Key Lab Trusted Software, Guilin, Peoples R China.; Zhang, T (corresponding author), Key Lab Film & TV Media Technol Zhejiang Prov, Hangzhou, Peoples R China.
EM tao.zhang.cn@outlook.com
OI zhang, tao/0000-0001-8242-5691
FU Guangxi Key Laboratory of Cryptography and Information Security
   [GCIS201806]; Guangxi Key Laboratory of Trusted Software [kx202016]; Key
   Lab of Film and TV Media Technology of Zhejiang Province [2020E10015];
   Guangxi Key Laboratory of Hybrid Computation and IC Design Analysis,
   Guangxi University for Nationalities [GXIC20-03]; Key Laboratory of
   Oceanographic Big Data Mining & Application of Zhejiang Province
   [obdma202001]
FX This work was supported by Guangxi Key Laboratory of Cryptography and
   Information Security (GCIS201806), Guangxi Key Laboratory of Trusted
   Software (No. kx202016), Key Lab of Film and TV Media Technology of
   Zhejiang Province (No.2020E10015), Guangxi Key Laboratory of Hybrid
   Computation and IC Design Analysis, Guangxi University for
   Nationalities(GXIC20-03), Key Laboratory of Oceanographic Big Data
   Mining & Application of Zhejiang Province(obdma202001). We'd like to
   thank Zelei Cheng from Purdue University and Yingjie Wang from Virginia
   Tech for writing assistance, language editing, and proofreading.
CR Afchar D, 2018, IEEE INT WORKS INFOR
   Agarwal S., 2019, P CVPR WORKSH LONG B, P38
   Ajder H, 2019, STATE DEEPFAKES LAND
   Amerini Irene, 2020, IH&MMSec '20: Proceedings of the 2020 ACM Workshop on Information Hiding and Multimedia Security, P97, DOI 10.1145/3369412.3395070
   Amerini I, 2019, IEEE INT CONF COMP V, P1205, DOI 10.1109/ICCVW.2019.00152
   Avd Oord., 2016, ARXIV160903499
   Bayar B., 2016, P 4 ACM WORKSH INF H, P5, DOI DOI 10.1145/2909827.2930786
   Bojia Zi, 2020, MM '20: Proceedings of the 28th ACM International Conference on Multimedia, P2382, DOI 10.1145/3394171.3413769
   Carlini N., 2020, P IEEE CVF C COMP VI, P2804
   Chan Caroline, 2018, ARXIV180807371
   Chang X, 2020, CHIN CONTR CONF, P7252, DOI 10.23919/CCC50068.2020.9189596
   Du CXT, 2020, 2020 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (SSCI), P707, DOI 10.1109/SSCI47803.2020.9308305
   Chen DY, 2019, MATH PROBL ENG, V2019, DOI 10.1155/2019/8902701
   Chesney B, 2019, CALIF LAW REV, V107, P1753, DOI 10.15779/Z38RV0D15J
   Chintha A, 2020, IEEE/IAPR INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB 2020)
   Chintha A, 2020, IEEE J-STSP, V14, P1024, DOI 10.1109/JSTSP.2020.2999185
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Ciftci UA, 2020, IEEE/IAPR INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB 2020)
   Dang LM, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8122610
   Ding Xinyi, 2019, ARXIV190904217
   Dolhansky B., 2019, DEEPFAKE DETECTION C
   Dolhansky B., 2020, DEEPFAKE DETECTION C
   Farid H, 2009, IEEE SIGNAL PROC MAG, V26, P16, DOI 10.1109/MSP.2008.931079
   Fernandes S, 2019, IEEE INT CONF COMP V, P1721, DOI 10.1109/ICCVW.2019.00213
   Gandhi A, 2020, IEEE IJCNN
   Geng ZL, 2019, PROC CVPR IEEE, P9813, DOI 10.1109/CVPR.2019.01005
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   GOUHARA K, 1991, IEEE IJCNN, P746, DOI 10.1109/IJCNN.1991.170489
   Guan HY, 2019, IEEE WINT CONF APPL, P63, DOI 10.1109/WACVW.2019.00018
   Guarnera Luca, 2020, P IEEE CVF C COMP VI
   Guera D, 2018, 2018 15TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P127
   Gupta Parul, 2020, ICMI '20: Proceedings of the 2020 International Conference on Multimodal Interaction, P519, DOI 10.1145/3382507.3418857
   Hearst MA, 1998, IEEE INTELL SYST APP, V13, P18, DOI 10.1109/5254.708428
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735
   Hsu CC, 2018, INT SYMP COMP CONS, P388, DOI 10.1109/IS3C.2018.00104
   Huh M, 2018, LECT NOTES COMPUT SC, V11215, P106, DOI 10.1007/978-3-030-01252-6_7
   Isola P., 2017, P IEEE C COMPUTER VI, P5967, DOI DOI 10.1109/CVPR.2017.632
   Jung T, 2020, IEEE ACCESS, V8, P83144, DOI 10.1109/ACCESS.2020.2988660
   Karras T., 2017, ARXIV171010196
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Khalid Hasam, 2020, P IEEE CVF C COMP VI, P656
   Kharbat FF, 2019, I C COMP SYST APPLIC
   Khodabakhsh A, 2020, LECT NOTE INFORM, VP-306
   Khodabakhsh A, 2018, 2018 INTERNATIONAL CONFERENCE OF THE BIOMETRICS SPECIAL INTEREST GROUP (BIOSIG)
   Kim H, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201283
   Korshunov P., 2018, DEEPFAKES NEW THREAT
   Korshunov P, 2019, INT CONF BIOMETR
   Korshunov P, 2018, EUR SIGNAL PR CONF, P2375, DOI 10.23919/EUSIPCO.2018.8553270
   Korshunova I, 2017, IEEE I CONF COMP VIS, P3697, DOI 10.1109/ICCV.2017.397
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li HD, 2018, ASIAPAC SIGN INFO PR, P722, DOI 10.23919/APSIPA.2018.8659461
   [李艳歌 Li Yange], 2018, [高分子通报, Polymer Bulletin], P46
   Li YZ, 2018, IEEE INT WORKS INFOR
   Li YZ, 2020, PROC CVPR IEEE, P3204, DOI 10.1109/CVPR42600.2020.00327
   Liang T, 2020, PROC INT C TOOLS ART, P675, DOI 10.1109/ICTAI50040.2020.00108
   Matern F, 2019, IEEE WINT CONF APPL, P83, DOI 10.1109/WACVW.2019.00020
   Mittal Trisha, 2020, MM '20: Proceedings of the 28th ACM International Conference on Multimedia, P2823, DOI 10.1145/3394171.3413570
   Mo HX, 2018, PROCEEDINGS OF THE 6TH ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY (IH&MMSEC'18), P43, DOI 10.1145/3206004.3206009
   Montserrat Daniel Mas, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW). Proceedings, P2851, DOI 10.1109/CVPRW50498.2020.00342
   Nataraj L, 2019, ELECT IMAGING, V2019, P532, DOI DOI 10.2352/ISSN.2470-1173.2019.5.MWSF-532
   Natsume Ryota, 2018, ARXIV180403447, DOI DOI 10.1145/3230744.3230818
   Neves JC, 2020, IEEE J-STSP, V14, P1038, DOI 10.1109/JSTSP.2020.3007250
   Nguyen H, 2020, LECT NOTE INFORM, VP-306
   Nguyen HH, 2019, INT CONF ACOUST SPEE, P2307, DOI 10.1109/ICASSP.2019.8682602
   Nirkin Y, 2019, IEEE I CONF COMP VIS, P7183, DOI 10.1109/ICCV.2019.00728
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Patel M., 2020, 2020 IEEE 5 INT C CO
   Pu JM, 2020, ANN COMPUT SECURITY, P913, DOI 10.1145/3427228.3427285
   Pumarola A, 2018, LECT NOTES COMPUT SC, V11214, P835, DOI 10.1007/978-3-030-01249-6_50
   Rahmouni N, 2017, IEEE INT WORKS INFOR
   Rana MS, 2020, 2020 7TH IEEE INTERNATIONAL CONFERENCE ON CYBER SECURITY AND CLOUD COMPUTING (CSCLOUD 2020)/2020 6TH IEEE INTERNATIONAL CONFERENCE ON EDGE COMPUTING AND SCALABLE CLOUD (EDGECOM 2020), P70, DOI 10.1109/CSCloud-EdgeCom49738.2020.00021
   Ranjan P, 2020, 2020 3RD INTERNATIONAL CONFERENCE ON INFORMATION AND COMPUTER TECHNOLOGIES (ICICT 2020), P86, DOI 10.1109/ICICT50521.2020.00021
   Rossler A, 2019, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2019.00009
   Rssler A., 2018, ARXIV180309179
   Sabir Ekraam, 2019, INTERFACES GUI, P80
   Thies J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323035
   Thies J, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201350
   Thies J, 2016, PROC CVPR IEEE, P2387, DOI 10.1109/CVPR.2016.262
   Tursman E., 2020, 2020 IEEE CVF C COMP
   Wang SY, 2019, IEEE I CONF COMP VIS, P10071, DOI 10.1109/ICCV.2019.01017
   Xie D, 2020, 2020 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (SSCI), P1866, DOI 10.1109/SSCI47803.2020.9308428
   Yang TF, 2020, CHIN CONTR CONF, P7247, DOI 10.23919/CCC50068.2020.9188580
   Yang X, 2019, INT CONF ACOUST SPEE, P8261, DOI 10.1109/ICASSP.2019.8683164
   Yihao Huang, 2020, MM '20: Proceedings of the 28th ACM International Conference on Multimedia, P1217, DOI 10.1145/3394171.3413732
   Yu N., 2018, ABS181108180 CORR
   Zakharov E, 2019, IEEE I CONF COMP VIS, P9458, DOI 10.1109/ICCV.2019.00955
   Zhao Y, 2020, CAPTURING PERSISTENC, DOI [10.1007/978-3-030-41579-2_37, DOI 10.1007/978-3-030-41579-2_37]
   Zheng Zhao, 2020, ICCAI '20: Proceedings of the 2020 6th International Conference on Computing and Artificial Intelligence, P291, DOI 10.1145/3404555.3404564
   Zhou P, 2017, IEEE COMPUT SOC CONF, P1831, DOI 10.1109/CVPRW.2017.229
   Zhu K, 2020, 2020 IEEE 5 INT C DA
   Zhuang YX, 2019, IEEE IMAGE PROC, P3212, DOI 10.1109/ICIP.2019.8803464
NR 91
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
DI 10.1007/s11042-021-11733-y
EA JAN 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YD4YF
UT WOS:000740419000005
DA 2022-02-06
ER

PT J
AU Baek, JY
   Yoo, YS
   Bae, SH
AF Baek, Jae-Yong
   Yoo, Yong-Sang
   Bae, Seung-Hwan
TI Generative Adversarial Ensemble Learning for Face Forensics
SO IEEE ACCESS
LA English
DT Article
DE Face; Generators; Feature extraction; Transform coding; Image
   generation; Machine learning; Image coding; Digital image forensics;
   generative adversarial ensemble learning; deep learning; synthetic image
   detection; face image
ID IMAGE; LOCALIZATION
AB The recent advance of synthetic image generation and manipulation methods allows us to generate synthetic face images close to real images. On the other hand, the importance of identifying the synthetic face images increases more and more to protect personal privacy from those. Although some deep learning-based image forensic methods have been developed recently, it is still challenging to distinguish synthetic images generated by recent image generation and manipulation methods such as the deep fake, face2face, and face swap. To resolve this challenge, we propose a novel generative adversarial ensemble learning method. We train multiple discriminative and generative networks based on the adversarial learning. Compared to the conventional adversarial learning, our method is however more focused on improving the discrimination ability rather than image generation one. To this end, we improve the discriminabilty by ensembling outputs from different two discriminators. In addition, we train two generators in order to generate general and hard synthetic images. By ensemble learning of all the generators and discriminators, we improve the discriminators by using the generated synthetic face images, and improve the generators by passing the combined feedback of the discriminators. On the FaceForensics benchmark challenge, we thoroughly evaluate our methods by comparing the recent methods. We also provide the ablation study to prove the effectiveness and usefulness of our method.
C1 [Baek, Jae-Yong] Autonomous A2Z, R&D Ctr, Gyongsan 14057, South Korea.
   [Yoo, Yong-Sang] Incheon Natl Univ, Dept Comp Sci & Engn, Incheon 22012, South Korea.
   [Bae, Seung-Hwan] Inha Univ, Dept Comp Engn, Incheon 22212, South Korea.
C3 Incheon National University; Inha University
RP Bae, SH (corresponding author), Inha Univ, Dept Comp Engn, Incheon 22212, South Korea.
EM shbae@inha.ac.kr
FU INHA UNIVERSITY Research Grant; National Research Foundation of Korea
   (NRF) - Korea Government (MSIT) [NRF-2018R1C1B6003785]
FX This work was supported in part by the INHA UNIVERSITY Research Grant
   and in part by the National Research Foundation of Korea (NRF) Grant
   funded by the Korea Government (MSIT) under Grant NRF-2018R1C1B6003785.
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Afchar D., 2018, 2018 IEEE INT WORKSH, P1, DOI DOI 10.1109/WIFS.2018.8630761
   Bappy JH, 2017, IEEE I CONF COMP VIS, P4980, DOI 10.1109/ICCV.2017.532
   Bayar Y, 2016, TRANSYLV REV ADM SCI, P5
   Bianchi T, 2011, INT CONF ACOUST SPEE, P2444
   Carvalho T, 2015, PROC SPIE, V9409, DOI 10.1117/12.2075544
   Cheng C.-M., 2008, P INT C INF FUS, P1
   Chintala S., 2017, ARXIV170107875
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Cozzolino D, 2014, IEEE IMAGE PROC, P5302, DOI 10.1109/ICIP.2014.7026073
   Cozzolino Davide, 2017, P 5 ACM WORKSH INF H, P159, DOI DOI 10.1145/3082031.3083247
   Dang LM, 2019, EXPERT SYST APPL, V129, P156, DOI 10.1016/j.eswa.2019.04.005
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383
   Ferrara P, 2012, IEEE T INF FOREN SEC, V7, P1566, DOI 10.1109/TIFS.2012.2202227
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Frith C, 2009, PHILOS T R SOC B, V364, P3453, DOI 10.1098/rstb.2009.0142
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Gulrajani I., 2017, ADV NEURAL INFORM PR, P5769, DOI DOI 10.5555/3295222.3295327
   Hertzmann A, 2001, COMP GRAPH, P327, DOI 10.1145/383259.383295
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Kingma D. P., 2015, INT C LEARN REPR
   Komodakis N, 2007, IEEE T IMAGE PROCESS, V16, P2649, DOI 10.1109/TIP.2007.906269
   Laine, 2018, INT C LEARN REPR
   Li Yuezun, 2019, IEEE C COMP VIS PATT
   Miyato T, 2018, INT C LEARN REPR
   Qi Guo-Jun, 2019, INT J COMPUT VISION, P1
   Rahmouni Nicolas, 2017, P IEEE WORKSH INF FO, P1, DOI DOI 10.1109/WIFS.2017.8267647
   Rao Y., 2016, P IEEE INT WORKSH IN, P1, DOI [10.1109/WIFS.2016.7823911, DOI 10.1109/WIFS.2016.7823911]
   Rossler A, 2019, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2019.00009
   Rossler A., 2018, ABS180309179 CORR, P1
   Salloum R, 2018, J VIS COMMUN IMAGE R, V51, P201, DOI 10.1016/j.jvcir.2018.01.010
   Simonyan K., 2015, ICLR, V1, P3
   THIES J, 2016, PROC CVPR IEEE, P2387, DOI DOI 10.1109/CVPR.2016.262
   Thies J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323035
   Zhou P, 2017, IEEE COMPUT SOC CONF, P1831, DOI 10.1109/CVPRW.2017.229
NR 38
TC 2
Z9 2
U1 0
U2 6
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2020
VL 8
BP 45421
EP 45431
DI 10.1109/ACCESS.2020.2968612
PG 11
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA LB6GF
UT WOS:000524731600007
OA gold
DA 2022-02-06
ER

PT J
AU Kaliyar, RK
   Goswami, A
   Narang, P
AF Kaliyar, Rohit Kumar
   Goswami, Anurag
   Narang, Pratik
TI DeepFakE: improving fake news detection using tensor decomposition-based
   deep neural network
SO JOURNAL OF SUPERCOMPUTING
LA English
DT Article
DE Social media; Fake news; Deep learning; Echo chamber; Tensor
   factorization
ID CLASSIFICATION
AB Social media platforms have simplified the sharing of information, which includes news as well, as compared to traditional ways. The ease of access and sharing the data with the revolution in mobile technology has led to the proliferation of fake news. Fake news has the potential to manipulate public opinions and hence, may harm society. Thus, it is necessary to examine the credibility and authenticity of the news articles being shared on social media. Nowadays, the problem of fake news has gained massive attention from research communities and needed an optimal solution with high efficiency and low efficacy. Existing detection methods are based on either news-content or social-context using user-based features as an individual. In this paper, the content of the news article and the existence of echo chambers (community of social media-based users sharing the same opinions) in the social network are taken into account for fake news detection. A tensor representing social context (correlation between user profiles on social media and news articles) is formed by combining the news, user and community information. The news content is fused with the tensor, and coupled matrix-tensor factorization is employed to get a representation of both news content and social context. The proposed method has been tested on a real-world dataset: BuzzFeed. The factors obtained after decomposition have been used as features for news classification. An ensemble machine learning classifier (XGBoost) and a deep neural network model (DeepFakE) are employed for the task of classification. Our proposed model (DeepFakE) outperforms with the existing fake news detection methods by applying deep learning on combined news content and social context-based features as an echo-chamber.
C1 [Kaliyar, Rohit Kumar; Goswami, Anurag] Bennett Univ, Dept Comp Sci Engn, Greater Noida, India.
   [Narang, Pratik] BITS Pilani, Dept CSIS, Pilani, Rajasthan, India.
C3 Birla Institute of Technology & Science Pilani (BITS Pilani)
RP Narang, P (corresponding author), BITS Pilani, Dept CSIS, Pilani, Rajasthan, India.
EM rk5370@bennett.edu.in; anurag.goswami@bennett.edu.in;
   pratik.narang@pilani.bits-pilani.ac.in
CR ACAR E., 2011, P KDD WORKSH MIN LEA
   Chen G, 2014, IEEE INT C AC SPEECH, P4087
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Chen Y., 2015, P 2015 ACM WORKSH MU, P15, DOI DOI 10.1145/2823465.2823467
   Chong E, 2017, EXPERT SYST APPL, V83, P187, DOI 10.1016/j.eswa.2017.04.030
   Clauset A, 2004, PHYS REV E, V70, DOI 10.1103/PhysRevE.70.066111
   Fazil M, 2018, IEEE T INF FOREN SEC, V13, P2707, DOI 10.1109/TIFS.2018.2825958
   Feng S., 2012, P 50 ANN M ASS COMP, V50, P171
   Ghani NA, 2019, COMPUT HUM BEHAV, V101, P417, DOI 10.1016/j.chb.2018.08.039
   Gupta MP, 2012, PROCEEDINGS OF THE ASME PACIFIC RIM TECHNICAL CONFERENCE AND EXHIBITION ON PACKAGING AND INTEGRATION OF ELECTRONIC AND PHOTONIC SYSTEMS, MEMS AND NEMS 2011, VOL 2, P153
   Gupta S, 2018, 2018 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM), P278, DOI 10.1109/ASONAM.2018.8508408
   Hancock, 2011, P 49 ANN M ASS COMP, P309, DOI DOI 10.1145/2567948.2577293
   Harshman RA, 1970, FDN PARAFAC PROCEDUR, P1
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Jain AK, 1996, COMPUTER, V29, P31, DOI 10.1109/2.485891
   Kai Shu, 2017, ACM SIGKDD Explorations Newsletter, V19, P22, DOI 10.1145/3137597.3137600
   Khatri C. G., 1968, SANKHYA, V30, P167
   Lee DD, 2001, ADV NEUR IN, V13, P556
   Li Y., 2017, NIPS, P597
   Lloret L, 2019, ARXIV191003496
   Ma J., 2016, P 25 INT JOINT C ART, P3818
   Maciej S, 2019, FAKENEWSCORPUS ONLIN
   MORENO PJ, 2001, 7 EUR C SPEECH COMM
   Natekin A, 2013, FRONT NEUROROBOTICS, V7, DOI 10.3389/fnbot.2013.00021
   Papanastasiou F, 2019, ARXIV190803957
   Patidar R, 2011, INT J SOFT COMPUT EN, V1
   Persily N, 2017, J DEMOCR, V28, P63, DOI 10.1353/jod.2017.0025
   Rabanser S., 2017, ARXIV171110781
   Ruchansky N, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P797, DOI 10.1145/3132847.3132877
   Sharma K, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3305260
   Shu K, 2019, PROCEEDINGS OF THE TWELFTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'19), P312, DOI 10.1145/3289600.3290994
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   TACCHINI Eugenio, 2017, ARXIV170407506
   Torlay L, 2017, Brain Inform, V4, P159, DOI 10.1007/s40708-017-0065-7
   Vasudevan V, 2019, U.S. Patent Application, Patent No. [16/040,067, 16040067]
   Wager S., 2013, ADV NEURAL INFORM PR, P351
   Wang, 2018, ARXIV180901286
   Wang YQ, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P849, DOI 10.1145/3219819.3219903
   Wu HB, 2015, LECT NOTES COMPUT SC, V9489, P46, DOI 10.1007/978-3-319-26532-2_6
   Yang Y., 2018, ARXIV180600749
   Yu, 2018, ARXIV180508751
   Zhang QS, 2016, COMPUT NETW, V107, P133, DOI 10.1016/j.comnet.2016.06.002
   Zhang XJ, 2019, INFORM SCIENCES, V494, P193, DOI 10.1016/j.ins.2019.04.051
   Zheng XH, 2015, NEUROCOMPUTING, V159, P27, DOI 10.1016/j.neucom.2015.02.047
   Zhong BT, 2019, ADV ENG INFORM, V40, P46, DOI 10.1016/j.aei.2019.02.009
   Zhong SP, 2014, NEURAL NETWORKS, V57, P51, DOI 10.1016/j.neunet.2014.05.014
   Zhou X., 2018, ARXIV181200315
   Zurada, 1992, INTRO ARTIFICIAL NEU
NR 48
TC 13
Z9 13
U1 4
U2 54
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0920-8542
EI 1573-0484
J9 J SUPERCOMPUT
JI J. Supercomput.
PD FEB
PY 2021
VL 77
IS 2
BP 1015
EP 1037
DI 10.1007/s11227-020-03294-y
EA MAY 2020
PG 23
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PX9JK
UT WOS:000530585200001
DA 2022-02-06
ER

PT J
AU Zhao, YC
   Tang, F
   Dong, WM
   Huang, FY
   Zhang, XP
AF Zhao, Yucheng
   Tang, Fan
   Dong, Weiming
   Huang, Feiyue
   Zhang, Xiaopeng
TI Joint face alignment and segmentation via deep multi-task learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face alignment; Face segmentation; Multi-task learning; Virtual makeup;
   Face swap
AB Face alignment and segmentation are challenging problems which have been extensively studied in the field of multimedia. These two tasks are closely related and their learning processes are supposed to benefit each other. Hence, we present a joint multi-task learning algorithm for both face alignment and segmentation using deep convolutional neural network (CNN). The proposed multi-task learning approach allows CNN model to simultaneously share visual knowledge between different tasks. With a carefully designed refinement residual module, the cross-layer features are fused in a collaborative manner. To the best of our knowledge, this is the first time that face alignment and segmentation are learned together via deep multi-task learning. Our experiments show that learning these two related tasks simultaneously builds a synergy between them, improves the performance of each individual task, and rivals recent approaches. Furthermore, we demonstrate the effectiveness of our model in two practical applications: virtual makeup and face swap.
C1 [Zhao, Yucheng; Tang, Fan; Dong, Weiming; Zhang, Xiaopeng] Chinese Acad Sci, Inst Automat, NLPR LIAMA, Beijing, Peoples R China.
   [Zhao, Yucheng; Tang, Fan] Univ Chinese Acad Sci, Beijing, Peoples R China.
   [Huang, Feiyue] Tencent, YouTu Lab, Shanghai, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Automation, CAS; Chinese
   Academy of Sciences; University of Chinese Academy of Sciences, CAS;
   Tencent
RP Dong, WM (corresponding author), Chinese Acad Sci, Inst Automat, NLPR LIAMA, Beijing, Peoples R China.
EM weiming.dong@ia.ac.cn; xiaopeng.zhang@ia.ac.cn
RI tang, fan/O-3923-2018; DONG, Weiming/AAG-7678-2020
OI tang, fan/0000-0002-3975-2483; DONG, Weiming/0000-0001-6502-145X
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61672520, 61702488, 61501464, 6120106003];
   Beijing Natural Science FoundationBeijing Natural Science Foundation
   [4162056]; National Key Technology R&D Program of ChinaNational Key
   Technology R&D Program [2015BAH53F02]; CASIA-Tencent YouTu jointly
   research project
FX This work was supported by National Natural Science Foundation of China
   under nos. 61672520, 61702488, 61501464 and 6120106003, by Beijing
   Natural Science Foundation under No. 4162056, by National Key Technology
   R&D Program of China under No. 2015BAH53F02, and by CASIA-Tencent YouTu
   jointly research project.
CR Badrinarayanan V., 2015, ARXIV151100561
   Bao BK, 2013, IEEE T IMAGE PROCESS, V22, P860, DOI 10.1109/TIP.2012.2219543
   Bao BK, 2012, IEEE T IMAGE PROCESS, V21, P3794, DOI 10.1109/TIP.2012.2192742
   Belhumeur PN, 2013, IEEE T PATTERN ANAL, V35, P2930, DOI 10.1109/TPAMI.2013.23
   BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792
   Cao XD, 2014, INT J COMPUT VISION, V107, P177, DOI 10.1007/s11263-013-0667-3
   Caruana R, 1998, LEARNING TO LEARN, P95, DOI 10.1007/978-1-4615-5529-2_5
   Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304
   Elad M, 2017, IEEE T IMAGE PROCESS, V26, P2338, DOI 10.1109/TIP.2017.2678168
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Gkioxari G., 2014, ARXIV14065212
   Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002
   Happy SL, 2015, IEEE T AFFECT COMPUT, V6, P1, DOI 10.1109/TAFFC.2014.2386334
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Koestinger Martin, 2011, P IEEE INT C COMP VI, P2144, DOI DOI 10.1109/ICCVW.2011.6130513
   Korshunova I., 2016, ARXIV161109577
   Liang L, 2008, LECT NOTES COMPUT SC, V5303, P72, DOI 10.1007/978-3-540-88688-4_6
   Liu S, 2016, 25 INT JOINT C ART I
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu JY, 2016, IEEE INT CONF MULTI
   Luo P, 2012, PROC CVPR IEEE, P2480, DOI 10.1109/CVPR.2012.6247963
   Masi I, 2016, LECT NOTES COMPUT SC, V9909, P579, DOI 10.1007/978-3-319-46454-1_35
   Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3
   Mosaddegh Saleh, 2014, P AS C COMP VIS, P159
   Oikawa MA, 2016, IEEE T INF FOREN SEC, V11, P5, DOI 10.1109/TIFS.2015.2442527
   Pinheiro PO, 2016, LECT NOTES COMPUT SC, V9905, P75, DOI 10.1007/978-3-319-46448-0_5
   Ranjan R, 2016, ARXIV160301249, P99
   Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629
   Saito S, 2016, LECT NOTES COMPUT SC, V9912, P244, DOI 10.1007/978-3-319-46484-8_15
   Sheng KK, 2015, COMPUT GRAPH FORUM, V34, P213, DOI 10.1111/cgf.12760
   Smith BM, 2013, PROC CVPR IEEE, P3484, DOI 10.1109/CVPR.2013.447
   Sun Y, 2013, PROC CVPR IEEE, P3476, DOI 10.1109/CVPR.2013.446
   van de Sande KEA, 2011, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2011.6126456
   Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75
   Yang Y, 2014, ARXIV14127489
   Zhang JH, 2014, ELECTRON J QUAL THEO, P1, DOI [10.1007/978-3-319-10605-2_1, 10.14232/ejqtde.2014.1.50]
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
   Zhang ZP, 2014, LECT NOTES COMPUT SC, V8694, P94, DOI 10.1007/978-3-319-10599-4_7
   Zhou Jiayu, 2011, Adv Neural Inf Process Syst, V2011, P702
   Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014
NR 42
TC 11
Z9 12
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 10
BP 13131
EP 13148
DI 10.1007/s11042-018-5609-1
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ID4NZ
UT WOS:000471654900022
DA 2022-02-06
ER

PT J
AU Liu, JR
   Zhu, KM
   Lu, W
   Luo, XY
   Zhao, XF
AF Liu, Jiarui
   Zhu, Kaiman
   Lu, Wei
   Luo, Xiangyang
   Zhao, Xianfeng
TI A lightweight 3D convolutional neural network for deepfake detection
SO INTERNATIONAL JOURNAL OF INTELLIGENT SYSTEMS
LA English
DT Article
DE 3D CNN; deepfake; deepfake detection; face swapping; face manipulation
AB The rapid development of DeepFake technologies has brought great challenges to the authenticity of video contents. It is of vital importance to develop DeepFake detection methods, among which three-dimensional (3D) convolution neural networks (CNN) have attracted wide interest and achieved satisfying performances. However, there are few 3D CNNs designed for DeepFake detection and the parameters of them are large, which cause heavy memory and storage consumption. In this paper, a lightweight 3D CNN is proposed for DeepFake detection. Channel transformation module is designed to extract features with much fewer parameters in higher level. Serving as spatial-temporal module, 3D CNNs are adopted to fuse the spatial features in time dimension. To suppress frame content and highlight frame texture, spatial rich model features are extracted from the input frames, which helps the spatial-temporal module achieve better performance. Experimental results show that the number of parameters of the proposed network is much less than those of other networks and the proposed network outperforms other state-of-the-art DeepFake detection methods on mainstream DeepFake data sets.
C1 [Liu, Jiarui; Zhu, Kaiman; Lu, Wei] Sun Yat Sen Univ, Sch Comp Sci & Engn, Guangdong Prov Key Lab Informat Secur Technol, Minist Educ,Key Lab Machine Intelligence & Adv Co, Guangzhou, Peoples R China.
   [Luo, Xiangyang] State Key Lab Math Engn & Adv Comp, Zhengzhou, Peoples R China.
   [Zhao, Xianfeng] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing, Peoples R China.
   [Zhao, Xianfeng] Univ Chinese Acad Sci, Sch Cyber Secur, Beijing, Peoples R China.
C3 Sun Yat Sen University; PLA Information Engineering University; Chinese
   Academy of Sciences; Institute of Information Engineering, CAS; Chinese
   Academy of Sciences; University of Chinese Academy of Sciences, CAS
RP Lu, W (corresponding author), Sun Yat Sen Univ, Sch Comp Sci & Engn, Guangzhou 510006, Peoples R China.
EM luwei3@mail.sysu.edu.cn
RI Zhao, Xianfeng/AAE-7278-2021
OI Zhao, Xianfeng/0000-0002-5617-8399; Liu, Jiarui/0000-0002-0002-3945;
   Zhu, Kaiman/0000-0001-7960-1869; Lu, Wei/0000-0002-4068-1766
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [U2001202, 62072480, U1736118]; National Key
   R&D Program of China [2019QY2202, 2019QY(Y)0207]; Key Areas R&D Program
   of Guangdong [2019B010136002]; Key Science Research Program of Guangzhou
   [201804020068]
FX This study is supported by the National Natural Science Foundation of
   China (No. U2001202, 62072480, and U1736118), the National Key R&D
   Program of China (No. 2019QY2202 and 2019QY(Y)0207), the Key Areas R&D
   Program of Guangdong (No. 2019B010136002), the Key Science Research
   Program of Guangzhou (No. 201804020068).
CR Afchar D., 2018, 2018 IEEE INT WORKSH, P1, DOI DOI 10.1109/WIFS.2018.8630761
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chen P, 2020, INT J COMPUT ASS RAD, V15, P1407, DOI 10.1007/s11548-020-02211-1
   Chen ZF, 2021, INT J INTELL SYST, V36, P1668, DOI 10.1002/int.22356
   Choi DH, 2020, IEEE IMAGE PROC, P823, DOI 10.1109/ICIP40778.2020.9190655
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Cozzolino Davide, 2018, ARXIV181202510
   Cozzolino Davide, 2017, P 5 ACM WORKSH INF H, P159, DOI DOI 10.1145/3082031.3083247
   Dang H, 2020, PROC CVPR IEEE, P5780, DOI 10.1109/CVPR42600.2020.00582
   de Lima O, 2020, DEEPFAKE DETECTION U
   Dolhansky B., 2019, DEEPFAKE DETECTION C
   Gevers T., 2020, ARXIV PREPRINT ARXIV
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Guera David, 2018, 15 IEEE INT C ADV VI, P1, DOI [DOI 10.1109/AVSS.2018.8639163, 10.1109/AVSS.2018.8639163]
   Hara K, 2017, IEEE INT CONF COMP V, P3154, DOI 10.1109/ICCVW.2017.373
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Khalid Hasam, 2020, P IEEE CVF C COMP VI, P656
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Kingma DP, 2015, 3 INT C LEARN REPR I, DOI DOI 10.1145/1830483.1830503
   Korshunov P., 2018, DEEPFAKES NEW THREAT
   Li FY, 2020, INT J INTELL SYST, DOI 10.1002/int.22283
   Li LZ, 2020, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR42600.2020.00505
   [李旭嵘 Li Xurong], 2020, [信息安全学报, Journal of Cyber Security], V5, P84
   Li Yuezun, 2019, IEEE C COMP VIS PATT
   Liu XZ, 2020, INT J INTELL SYST, V35, P2087, DOI 10.1002/int.22285
   Matern F, 2019, IEEE WINT CONF APPL, P83, DOI 10.1109/WACVW.2019.00020
   Nguyen HV, 2019, 2019 2ND INTERNATIONAL CONFERENCE ON APPLIED INFORMATION TECHNOLOGY AND INNOVATION (ICAITI2019), P1, DOI 10.1109/ICAITI48442.2019.8982119
   Nguyen Huy H, 2019, ARXIV191012467
   Nie&beta;ner, 2014, 2016 IEEE C COMPUTER, P2672
   Padilla M, 2006, INT J INTELL SYST, V21, P785, DOI 10.1002/int.20160
   Rana MS, 2020, 2020 7TH IEEE INTERNATIONAL CONFERENCE ON CYBER SECURITY AND CLOUD COMPUTING (CSCLOUD 2020)/2020 6TH IEEE INTERNATIONAL CONFERENCE ON EDGE COMPUTING AND SCALABLE CLOUD (EDGECOM 2020), P70, DOI 10.1109/CSCloud-EdgeCom49738.2020.00021
   Rossler A, 2019, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2019.00009
   Sabir Ekraam, 2019, INTERFACES GUI, P80
   Sanderson C, 2009, LECT NOTES COMPUT SC, V5558, P199, DOI 10.1007/978-3-642-01793-3_21
   Sun ZC, 2021, INT J INTELL SYST, V36, P2058, DOI 10.1002/int.22371
   Tolosana R, 2020, INFORM FUSION, V64, P131, DOI 10.1016/j.inffus.2020.06.014
   Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675
   Wang YH, 2020, IEEE INT CONF AUTOMA, P515, DOI 10.1109/FG47880.2020.00089
   Xiao YT, 2021, INT J INTELL SYST, V36, P2036, DOI 10.1002/int.22370
   Yan ZQ, 2020, INT J INTELL SYST, V35, P1492, DOI 10.1002/int.22261
   Yuezun Li, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P3204, DOI 10.1109/CVPR42600.2020.00327
   Zhao Q, 2020, INT J INTELL SYST, V35, P1262, DOI 10.1002/int.22241
   Zheng WB, 2021, INT J INTELL SYST, V36, P2081, DOI 10.1002/int.22372
NR 43
TC 6
Z9 6
U1 19
U2 23
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0884-8173
EI 1098-111X
J9 INT J INTELL SYST
JI Int. J. Intell. Syst.
PD SEP
PY 2021
VL 36
IS 9
BP 4990
EP 5004
DI 10.1002/int.22499
EA JUN 2021
PG 15
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TY4DZ
UT WOS:000657369100001
DA 2022-02-06
ER

PT J
AU Ballesteros, DM
   Rodriguez-Ortega, Y
   Renza, D
   Arce, G
AF Ballesteros, M. Dora
   Rodriguez-Ortega, Yohanna
   Renza, Diego
   Arce, Gonzalo
TI Deep4SNet: deep learning for fake speech classification
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Fake voice; Convolutional neural network; Imitation; Deep learning; Deep
   voice; Classification
ID SPEAKER VERIFICATION; SPECTROGRAM
AB Fake speech consists on voice recordings created even by artificial intelligence or signal processing techniques. Among the methods for generating false voice recordings are Deep Voice and Imitation. In Deep voice, the recordings sound slightly synthesized, whereas in Imitation, they sound natural. On the other hand, the task of detecting fake content is not trivial considering the large number of voice recordings that are transmitted over the Internet. In order to detect fake voice recordings obtained by Deep Voice and Imitation, we propose a solution based on a Convolutional Neural Network (CNN), using image augmentation and dropout. The proposed architecture was trained with 2092 histograms of both original and fake voice recordings and cross-validated with 864 histograms. 476 new histograms were used for external validation, and Precision (P) and Recall (R) were calculated. Detection of fake audios reached P = 0.997, R = 0.997 for Imitation-based recordings, and P = 0.985, R = 0.944 for Deep Voice-based recordings. The global accuracy was 0.985. According to the results, the proposed system is successful in detecting fake voice content.
C1 [Ballesteros, M. Dora; Rodriguez-Ortega, Yohanna; Renza, Diego] Univ Militar Nueva Granada, Cra 11 101-80, Bogota 110111, Colombia.
   [Arce, Gonzalo] Univ Delaware, 210 South Coll Ave, Newark, DE 19716 USA.
C3 Universidad Militar Nueva Granada; University of Delaware
RP Ballesteros, DM (corresponding author), Univ Militar Nueva Granada, Cra 11 101-80, Bogota 110111, Colombia.
EM dora.ballesteros@unimilitar.edu.co;
   est.yohanna.rodrig@unimilitar.edu.co; diego.renza@unimilitar.edu.co;
   arce@udel.edu
FU Universidad Militar Nueva Granada-Vicerrectoria de Investigaciones
   [IMP-ING-2936]
FX This work is supported by the "Universidad Militar Nueva
   Granada-Vicerrectoria de Investigaciones" (Grant IMP-ING-2936 of
   2019-2021).
CR Arik SO, 2017, PR MACH LEARN RES, V70
   Ballesteros DM, 2020, DATA BRIEF, V29, DOI 10.1016/j.dib.2020.105331
   Ballesteros DM, 2012, EXPERT SYST APPL, V39, P12574, DOI 10.1016/j.eswa.2012.05.027
   Ballesteros DM, 2012, EXPERT SYST APPL, V39, P9141, DOI 10.1016/j.eswa.2012.02.066
   Bunrit Supaporn, 2019, International Journal of Machine Learning and Computing, V9, P143, DOI 10.18178/ijmlc.2019.9.2.778
   Chao YH, 2008, IEEE T AUDIO SPEECH, V16, P1675, DOI 10.1109/TASL.2008.2004297
   Chao YH, 2014, SPEECH COMMUN, V57, P76, DOI 10.1016/j.specom.2013.09.005
   Feng Y, 2017, IEICE T INF SYST, VE100D, P215, DOI 10.1587/transinf.2016EDL8106
   Goel N, 2021, IET IMAGE PROCESS, V15, P656, DOI 10.1049/ipr2.12051
   Jati A, 2019, IEEE-ACM T AUDIO SPE, V27, P1577, DOI 10.1109/TASLP.2019.2921890
   Jin Z., 2017, SIGGRAPH
   Kelarestaghi M., 2015, 2015 2 INT C PATT RE, P1
   Liu Y, 2015, SPEECH COMMUN, V73, P1, DOI 10.1016/j.specom.2015.07.003
   Loughran R, 2017, EVOL INTELL, V10, P1, DOI 10.1007/s12065-016-0150-5
   Ping W., 2018, P INT C LEARN REPR
   REYNOLDS DA, 1995, SPEECH COMMUN, V17, P91, DOI 10.1016/0167-6393(95)00009-D
   Reynolds DA, 2000, DIGIT SIGNAL PROCESS, V10, P19, DOI 10.1006/dspr.1999.0361
   Robinson DW, 2008, ENTROPY, V10, P493, DOI 10.3390/e10040493
   Rodriguez-Ortega Y, 2021, J IMAGING, V7, DOI 10.3390/jimaging7030059
   Rollins J., 2015, FDN METHODOLOGY DATA
   Satt A, 2017, INTERSPEECH, P1089, DOI 10.21437/Interspeech.2017-200
   Shin Y, 2017, P ANN INT IEEE EMBS, P3277, DOI 10.1109/EMBC.2017.8037556
   Taqi AM, 2018, IEEE 1ST CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2018), P140, DOI 10.1109/MIPR.2018.00032
   Yaman S, 2013, IEEE SIGNAL PROC LET, V20, P901, DOI 10.1109/LSP.2013.2273127
   Yenigalla P, 2018, INTERSPEECH, P3688, DOI 10.21437/Interspeech.2018-1811
   Zakariah M, 2018, MULTIMED TOOLS APPL, V77, P1009, DOI 10.1007/s11042-016-4277-2
   Zeng YN, 2019, MULTIMED TOOLS APPL, V78, P3705, DOI 10.1007/s11042-017-5539-3
   Zhao Jian, 2008, Tsinghua Science and Technology, V13, P522, DOI 10.1016/S1007-0214(08)70083-X
   Zhuo L, 2018, ASIAPAC SIGN INFO PR, P733, DOI 10.23919/APSIPA.2018.8659761
NR 29
TC 2
Z9 2
U1 4
U2 4
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD DEC 1
PY 2021
VL 184
AR 115465
DI 10.1016/j.eswa.2021.115465
PG 12
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic; Operations Research & Management Science
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Operations Research & Management Science
GA WI0YM
UT WOS:000708093400006
DA 2022-02-06
ER

PT J
AU Ayers, D
AF Ayers, Drew
TI The limits of transactional identity: Whiteness and embodiment in
   digital facial replacement
SO CONVERGENCE-THE INTERNATIONAL JOURNAL OF RESEARCH INTO NEW MEDIA
   TECHNOLOGIES
LA English
DT Article
DE 1980s action film; Arnold Schwarzenegger; critical race theory;
   deepfakes; digital technology; Dwayne Johnson; embodiment; facial
   replacement; hardbodies; Jean-Claude Van Damme; Keanu Reeves;
   masculinity; Sylvester Stallone; whiteness
ID DEEPFAKES
AB Focusing on a series of YouTube creators, this essay interrogates the persistence of the hegemonic power of the white male hardbody, arguing that digital facial replacements - in particular those of 1980s action stars - produce a mode of white, masculine identity that is essentially exchangeable and transactional. These bodies are capitalist commodities, fundamentally interchangable and asserting the same bundle of ideological traits. The technology of digital facial replacement allows creators to visualize this exchange value. As opposed to the pornographic, invasive, and misogynistic face swap videos originally posted on reddit.com by user 'deepfakes' in 2017, the facial replacement videos found on YouTube are more playful in nature, imagining alternate histories and using face swapping as a mode of comedy. This case study of 1980s action stars opens up to a broader examination of issues of identity in digital facial replacement. In the videos under analysis, gender swaps are relatively common, but ethnic swaps are scarce. The reluctance of the YouTubers to 'blindcast' their revisionist videos reveals a subtle critique of the fantasy of a post-racial world. Racial difference - and, perhaps, cultural specificity - remains intact, and the creators take a seemingly apolitical, comical, 'safe' approach to identity rather than an explicitly critical stance. By denuding the more threatening and destructive aspects of deepfakes, these YouTube videos produce a more palatable version of facial replacement. This version, however, is no less ideologically complex than its more explicitly political and misogynistic counterparts. These contemporary facial substitutions not only continue to 'reboot' white male hegemony, but they also function as an ideological reclamation of masculine power in the present through modified images of the (revisionist) past.
C1 [Ayers, Drew] Eastern Washington Univ, Cheney, WA 99004 USA.
C3 Eastern Washington University
RP Ayers, D (corresponding author), Eastern Washington Univ, Film Program, 1029 Washington St, Cheney, WA 99004 USA.
EM dayers5@ewu.edu
OI Ayers, Drew/0000-0002-8303-0322
CR Allison T, 2015, SPECIAL EFFECTS: NEW HISTORIES/THEORIES/CONTEXTS, P114
   Ayers D, 2008, FILM CRITICISM, V32, P41
   Ayers D, 2019, COMPANION TO THE ACTION FILM, P165
   Bernardi D, 2008, PERSISTENCE WHITENES
   BLEWER A., 2019, OPEN INFORM SCI, V3, P32, DOI DOI 10.1515/OPIS-2019-0003
   Bode L, 2010, CINEMA J, V49, P46
   Ctrl Shift Face, 2019, TERM LEARNS SMIL DEE
   Ctrl Shift Face, 2019, HUNGR TERM
   DiAngelo R., 2018, WHITE FRAGILITY WHY
   DiAngelo R.J., 2016, WHAT DOES IT MEAN BE
   DrFakenstein, 2019, KEAN REEV SINGS NOTH
   Dyer R., 1997, WHITE
   Dyer R., 2004, HEAVENLY BODIES FILM
   EW Staff, 2015, 10 FAR FETCH TOT RID
   Fletcher J, 2018, THEATRE J, V70, P455, DOI 10.1353/tj.2018.0097
   Greengard S, 2020, COMMUN ACM, V63, P17, DOI 10.1145/3371409
   Haraway Donna., 1991, SIMIANS CYBORGS WOME
   Hughey, 2011, OBAMAS POSTRACIAL AM, P1
   Hughey MW, 2014, WHITE SAVIOR FILM: CONTENT, CRITICS, AND CONSUMPTION, P1
   Jeffords S, 2019, COMPANION TO THE ACTION FILM, P256
   Jeffords Susan, 1994, HARD BODIES HOLLYWOO
   Kirchengast T, 2020, INF COMMUN TECHNOL L, V29, P308, DOI 10.1080/13600834.2020.1794615
   Lawrence, 2019, W SMITH EXPLAINS WHY
   Nakamura L., 1995, WORKS DAYS, V25, P13, DOI DOI 10.1017/CBO9781107415324.004
   Nakamura L, 2008, PMLA, V123, P1673, DOI 10.1632/pmla.2008.123.5.1673
   Oppenheim Y., 2020, CONVERGENCE-US, VOnline First, P1
   Purse L, 2007, FILM CRITICISM, V32, P5
   Raengo Alessandra., 2013, SLEEVE VISUAL RACE F
   Shamook, 2020, J KRAS IS CAPT AM
   Shamook, 2020, T SELL IS IND JON
   Shamook, 2019, W SMITH NEO MATR
   Stephens V., 2017, POSTRACIAL AM INTERD, P1
   Tasker Yvonne, 1993, SPECTACULAR BODIES G
   TheFakening, 2019, DWAYN ROCK JOHNS DOR
   TheTerminatorFans.com, 2020, LAST ACT HER TIM SYL
   TwinkieMan, 2019, ROCK IMP A SCHWARZ
   Warner KJ, 2017, FILM QUART, V71, P32, DOI 10.1525/FQ.2017.71.2.32
   Westerlund M, 2019, TECHNOL INNOV MANAG, V9, P39, DOI 10.22215/timreview/1282
   Wojewidka John, 2020, Biometric Technology Today, V2020, P5, DOI 10.1016/S0969-4765(20)30023-0
NR 39
TC 0
Z9 0
U1 4
U2 4
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 1354-8565
EI 1748-7382
J9 CONVERGENCE-US
JI Convergence
PD AUG
PY 2021
VL 27
IS 4
SI SI
BP 1018
EP 1037
AR 13548565211027810
DI 10.1177/13548565211027810
EA JUL 2021
PG 20
WC Communication
WE Social Science Citation Index (SSCI)
SC Communication
GA UK7UP
UT WOS:000675663300001
DA 2022-02-06
ER

PT J
AU Yu, MM
   Zhang, J
   Li, SH
   Lei, J
   Wang, FL
   Zhou, H
AF Yu, Miaomiao
   Zhang, Jun
   Li, Shuohao
   Lei, Jun
   Wang, Fenglei
   Zhou, Hao
TI Deep forgery discriminator via image degradation analysis
SO IET IMAGE PROCESSING
LA English
DT Article
ID MODEL
AB Generative adversarial network-based deep generative model is widely applied in creating hyper-realistic face-swapping images and videos. However, its malicious use has posed a great threat to online contents, thus making detecting the authenticity of images and videos a tricky task. Most of the existing detection methods are only suitable for one type of forgery and only work for low-quality tampered images, restricting their applications. This paper concerns the construction of a novel discriminator with better comprehensive capabilities. Through analysis of the visual characteristics of manipulated images from the perspective of image quality, it is revealed that the synthesized face does have different degrees of quality degradation compared to the source content. Therefore, several kinds of image quality-related handicraft features are extracted, including texture, sharpness, frequency domain features, and deep features, to unveil the inconsistent information and modification traces in the fake faces. In this way, a 1065-dimensional vector of each image is obtained through multi-feature fusion, and it is then fed into RF to train a targeted binary classification detector. Extensive experiments have shown that the proposed scheme is superior to the previous methods in recognition accuracy on multiple manipulation databases including the Celeb-DF database with better visual quality.
C1 [Yu, Miaomiao; Zhang, Jun; Li, Shuohao; Lei, Jun; Wang, Fenglei; Zhou, Hao] Natl Univ Def Technol, Sci & Technol Informat Syst Engn Lab, Changsha, Peoples R China.
C3 National University of Defense Technology - China
RP Zhang, J; Li, SH (corresponding author), Natl Univ Def Technol, Sci & Technol Informat Syst Engn Lab, Changsha, Peoples R China.
EM zhangjun1975@nudt.edu.cn; lishuohao@nudt.edu.cn
FU National natural Science Foundation of China (NSFC)National Natural
   Science Foundation of China (NSFC) [61806215, 61671459]; National
   University of Defense Technology Scientific Research Project [ZK20-48]
FX This work was funded by the National natural Science Foundation of China
   (NSFC) with grant numbers 61806215 and 61671459, and National University
   of Defense Technology Scientific Research Project with grant number
   ZK20-48.
CR Afchar D, 2018, IEEE INT WORKS INFOR
   Akhtar Z, 2019, 2019 IEEE INT S TECH
   Antipov G, 2017, ARXIV170201983
   Bae SH, 2016, IEEE T IMAGE PROCESS, V25, P2392, DOI 10.1109/TIP.2016.2545863
   Bae SH, 2013, IEEE SIGNAL PROC LET, V20, P893, DOI 10.1109/LSP.2013.2272193
   Boulkenafet Z, 2017, IEEE SIGNAL PROC LET, V24, P141, DOI 10.1109/LSP.2016.2630740
   Chang X, 2020, 2020 39 CHIN CONTR C
   Chen, 2020, 2020 IEEE INT C MULT
   Chen HY, 2017, 2017 IEEE CONFERENCE ON ENERGY INTERNET AND ENERGY SYSTEM INTEGRATION (EI2)
   Chintha A, 2020, IEEE J-STSP, V14, P1024, DOI 10.1109/JSTSP.2020.2999185
   Cho W, 2019, 2019 IEEE CVF C COMP
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Du M., 2020, P 29 ACM INT C INF K
   Durall Ricard, 2019, ARXIV191100686
   Galvan F, 2014, IEEE T INF FOREN SEC, V9, P1299, DOI 10.1109/TIFS.2014.2330312
   Giudice O, 2019, IMAGE ANAL PROCESSIN
   Guarnera L, 2020, 2020 IEEE CVF C COMP
   Guo ZQ, 2021, COMPUT VIS IMAGE UND, V204, DOI 10.1016/j.cviu.2021.103170
   He ZL, 2019, IEEE T IMAGE PROCESS, V28, P5464, DOI 10.1109/TIP.2019.2916751
   Jafar MT, 2020, INT CONF INFORM COMM, P053, DOI 10.1109/ICICS49469.2020.239493
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Karras T, 2018, PROGRESSIVE GROWING
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Kharbat FF, 2019, I C COMP SYST APPLIC
   Larson E., 2009, CATEGORICAL IMAGE QU
   Li Y., 2020, IEEE C COMP VIS PATT IEEE C COMP VIS PATT
   Marcel Sebastien, 2018, ARXIV PREPRINT ARXIV
   Marra F, 2019, IEEE INT WORKS INFOR
   Matern F, 2019, IEEE WINT CONF APPL, P83, DOI 10.1109/WACVW.2019.00020
   McCloskey S, 2019, 2019 IEEE INT C IM P
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Nguyen H.H, 2019, 2019 IEEE 10 INT C B
   Nguyen H.M, 2020, 2020 INT C BIOM SPEC
   Nguyen Huy H, 2019, ARXIV191012467
   Patel K, 2016, IEEE T INF FOREN SEC, V11, P2268, DOI 10.1109/TIFS.2016.2578288
   Pereira TD, 2013, INT CONF BIOMETR
   Rana MS, 2020, 2020 7TH IEEE INTERNATIONAL CONFERENCE ON CYBER SECURITY AND CLOUD COMPUTING (CSCLOUD 2020)/2020 6TH IEEE INTERNATIONAL CONFERENCE ON EDGE COMPUTING AND SCALABLE CLOUD (EDGECOM 2020), P70, DOI 10.1109/CSCloud-EdgeCom49738.2020.00021
   Rossler A, 2019, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2019.00009
   Sanderson Conrad, 2009, 2009 INT C BIOM
   Tero Karras T.A., 2018, ARXIV171010196
   Tewari A, 2017, IEEE I CONF COMP VIS, P3735, DOI 10.1109/ICCV.2017.401
   Thakur R, 2020, FORENSIC SCI INT, V312, DOI 10.1016/j.forsciint.2020.110311
   Truong, 2021, FORENSIC SCI INT DIG, V36, P301108, DOI 10.1016/j.fsidi.2021.301108
   Tulyakov S, 2016, 2016 IEEE C COMP VIS
   Wang R., 2020, P INT JOINT C ART IN, P3444
   Xiang, 2019, IGARSS 2019 2019 IEE
   Yang T, 2020, 2020 39 CHIN CONTR C
   Yang X, 2019, 2019 IEEE INT C AC S
   Yu N, 2019, IEEE I CONF COMP VIS, P7555, DOI 10.1109/ICCV.2019.00765
   Zhou P, 2017, IEEE COMPUT SOC CONF, P1831, DOI 10.1109/CVPRW.2017.229
NR 50
TC 0
Z9 0
U1 11
U2 12
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1751-9659
EI 1751-9667
J9 IET IMAGE PROCESS
JI IET Image Process.
PD SEP
PY 2021
VL 15
IS 11
BP 2478
EP 2493
DI 10.1049/ipr2.12234
EA MAY 2021
PG 16
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Imaging Science & Photographic Technology
GA TV5NS
UT WOS:000647998900001
OA gold
DA 2022-02-06
ER

PT J
AU Kim, E
   Cho, S
AF Kim, Eunji
   Cho, Sungzoon
TI Exposing Fake Faces Through Deep Neural Networks Combining Content and
   Trace Feature Extractors
SO IEEE ACCESS
LA English
DT Article
DE Feature extraction; Face recognition; Videos; Faces; Information
   integrity; Image forensics; Media; Convolutional neural networks;
   DeepFake; Face2Face; fake face detection; fake face image forensics;
   multi-channel constrained convolution; transfer learning
ID CONTRAST ENHANCEMENT; FORENSIC DETECTION; JPEG COMPRESSION; IMAGE
AB With the breakthrough of computer vision and deep learning, there has been a surge of realistic-looking fake face media manipulated by AI such as DeepFake or Face2Face that manipulate facial identities or expressions. The fake faces were mostly created for fun, but abuse has caused social unrest. For example, some celebrities have become victims of fake pornography made by DeepFake. There are also growing concerns about fake political speech videos created by Face2Face. To maintain individual privacy as well as social, political, and international security, it is imperative to develop models that detect fake faces in media. Previous research can be divided into general-purpose image forensics and face image forensics. While the former has been studied for several decades and focuses on extracting hand-crafted features of traces left in the image after manipulation, the latter is based on convolutional neural networks mainly inspired by object detection models specialized to extract images' content features. This paper proposes a hybrid face forensics framework based on a convolutional neural network combining the two forensics approaches to enhance the manipulation detection performance. To validate the proposed framework, we used a public Face2Face dataset and a custom DeepFake dataset collected on our own. Experimental results using the two datasets showed that the proposed model is more accurate and robust at various video compression rates compared to the previous methods. Throughout class activation map visualization, the proposed framework provided information on which face parts are considered important and revealed the tempering traces invisible to naked eyes.
C1 [Kim, Eunji] Chung Ang Univ, Sch Business Adm, Seoul 06974, South Korea.
   [Cho, Sungzoon] Seoul Natl Univ, Dept Ind Engn, Seoul 08826, South Korea.
   [Cho, Sungzoon] Seoul Natl Univ, Inst Ind Syst Innovat, Seoul 08826, South Korea.
C3 Chung Ang University; Seoul National University (SNU); Seoul National
   University (SNU)
RP Cho, S (corresponding author), Seoul Natl Univ, Dept Ind Engn, Seoul 08826, South Korea.; Cho, S (corresponding author), Seoul Natl Univ, Inst Ind Syst Innovat, Seoul 08826, South Korea.
EM zoon@snu.ac.kr
FU National Research Foundation of Korea (NRF) - Korean Government (MSIT)
   [2021R1G1A1093263]
FX This work was supported by the National Research Foundation of Korea
   (NRF) funded by the Korean Government (MSIT) under Grant
   2021R1G1A1093263.
CR Afchar D, 2018, IEEE INT WORKS INFOR
   Alexander O., 2009, 2009 C VIS MED PROD, P176, DOI DOI 10.1109/CVMP.2009.29
   Bayar B, 2018, IEEE T INF FOREN SEC, V13, P2691, DOI 10.1109/TIFS.2018.2825953
   Bethge M., 2016, PROC CVPR IEEE, P2414, DOI DOI 10.1109/CVPR.2016.265
   Bianchi T., P1929
   Bianchi T, 2012, IEEE T INF FOREN SEC, V7, P1003, DOI 10.1109/TIFS.2012.2187516
   Bitouk D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360638
   Blanz V, 2004, COMPUT GRAPH FORUM, V23, P669, DOI 10.1111/j.1467-8659.2004.00799.x
   Bohme R., 2013, DIGITAL IMAGE FORENS, P327
   Bregler C., 1997, P353
   Bulat A., 2017, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2017.116
   Busch C., 2017, IEEE COMPUT SOC CONF, P1822, DOI DOI 10.1109/CVPRW.2017.228
   Cao G., 2010, IEEE INT CON MULTI, P89
   Chen C., 2011, P INT WORK DIG WAT, P361
   Chollet F., 2017, PROC CVPR IEEE, P1251, DOI DOI 10.1109/CVPR.2017.195
   Cozzolino D., 2017, P 5 ACM WORKSH INF H, P159
   Dale K, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024164
   Dalgaard N., 2010, IEEE IMAGE PROC, P1753
   Dambre J., 2017, IEEE I CONF COMP VIS, P3697, DOI DOI 10.1109/ICCV.2017.397
   Dang LM, 2019, EXPERT SYST APPL, V129, P156, DOI 10.1016/j.eswa.2019.04.005
   Feng XY, 2012, IEEE T MULTIMEDIA, V14, P536, DOI 10.1109/TMM.2012.2191946
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Garrido P, 2015, COMPUT GRAPH FORUM, V34, P193, DOI 10.1111/cgf.12552
   Garrido P., 2014, PROC CVPR IEEE, P4217, DOI DOI 10.1109/CVPR.2014.537
   Goljan M, 2015, PROC SPIE, V9409, DOI 10.1117/12.2078399
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huh M, 2018, LECT NOTES COMPUT SC, V11215, P106, DOI 10.1007/978-3-030-01252-6_7
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   Jain AK, 2006, IEEE T INF FOREN SEC, V1, P125, DOI 10.1109/TIFS.2006.873653
   Jones M., 2001, PROC CVPR IEEE, V1
   Kang XG, 2013, IEEE T INF FOREN SEC, V8, P1456, DOI 10.1109/TIFS.2013.2273394
   Kemelmacher-Shlizerman I, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925871
   Khodabakhsh A, 2018, 2018 INTERNATIONAL CONFERENCE OF THE BIOMETRICS SPECIAL INTEREST GROUP (BIOSIG)
   King DB, 2015, ACS SYM SER, V1214, P1
   Kirchner M., 2008, MMSEC08 P MULT SEC, P11
   Kirchner M, 2010, PROC SPIE, V7541, DOI 10.1117/12.839100
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Liu W., 2015, PROC CVPR IEEE, P1, DOI DOI 10.1109/cvpr.2015.7298594
   Mahdian B, 2008, IEEE T INF FOREN SEC, V3, P529, DOI 10.1109/TIFS.2004.924603
   Neelamani R, 2006, IEEE T IMAGE PROCESS, V15, P1365, DOI 10.1109/TIP.2005.864171
   Oliva A., 2016, PROC CVPR IEEE, P2921, DOI DOI 10.1109/CVPR.2016.319
   Perez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269
   Popescu AC, 2005, IEEE T SIGNAL PROCES, V53, P758, DOI 10.1109/TSP.2004.839932
   Qiu X., 2014, P 2 ACM WORKSH INF H, P165
   Qu Z., 2008, INT CONF ACOUST SPEE, P1661
   Rossler A., 2018, FACEFORENSICS LARGE
   Rossler A., 2019, IEEE I CONF COMP VIS, P1, DOI DOI 10.1109/ICCV.2019.00009
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shlens J., 2016, PROC CVPR IEEE, P2818, DOI DOI 10.1109/CVPR.2016.308
   Simonyan K, 2015, ICLR 2015, DOI DOI 10.1109/CVPR.2015.7298594
   Stamm M., 2008, IEEE IMAGE PROC, P3112
   Stamm MC, 2010, IEEE T INF FOREN SEC, V5, P492, DOI 10.1109/TIFS.2010.2053202
   Sun JY, 2018, SIGNAL PROCESS-IMAGE, V63, P149, DOI 10.1016/j.image.2018.02.001
   Suwajanakorn S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073640
   Thies J., P2387
   Thies J, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818056
   Wolf L., 2010, PROC CVPR IEEE PROC CVPR IEEE, P817, DOI DOI 10.1109/CVPR.2010.5540133
   Yao H., 2009, P94
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhou P., 2017, IEEE COMPUT SOC CONF, P1831, DOI DOI 10.1109/CVPRW.2017.229
NR 60
TC 0
Z9 0
U1 3
U2 3
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2021
VL 9
BP 123493
EP 123503
DI 10.1109/ACCESS.2021.3110859
PG 11
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA UQ4ZU
UT WOS:000696074000001
OA gold
DA 2022-02-06
ER

PT J
AU Guo, JT
   Liu, Y
AF Guo, Jingtao
   Liu, Yi
TI Facial parts swapping with generative adversarial networks
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Facial parts swapping; Generative adversarial network; Deep leaning
AB In this paper, we present a novel deep generative facial parts swapping method: parts-swapping generative adversarial network (PSGAN). PSGAN independently handles facial parts, such as eyes (left eye and right eye), nose, mouth and jaw, which achieves facial parts swapping by replacing the target facial parts with source facial parts and reconstructing the entire face image with these parts. By separately modeling the facial parts in the form of region inpainting, the proposed method can successfully achieve highly photorealistic face swapping results, enabling users to freely manipulate facial parts. In addition, the proposed method is able to perform jaw editing based on sketch guidance information. Experimental results on the CelebA dataset suggest that our method achieves superior performance for facial parts swapping and provides higher user control flexibility.
C1 [Guo, Jingtao; Liu, Yi] Beijing Jiaotong Univ, Beijing Key Lab Traff Data Anal & Min, Sch Comp & Informat Technol, Beijing, Peoples R China.
C3 Beijing Jiaotong University
RP Liu, Y (corresponding author), Beijing Jiaotong Univ, Beijing Key Lab Traff Data Anal & Min, Sch Comp & Informat Technol, Beijing, Peoples R China.
EM yiliu@bjtu.edu.cn
FU Natural Science Foundation of ChinaNational Natural Science Foundation
   of China (NSFC) [61300072, 31771475]
FX The authors acknowledge support from the Natural Science Foundation of
   China (No.61300072, 31771475) .
CR Abadi Martin, 12 USENIX S OP SYST
   Alexander O, 2009, 2009 CONFERENCE FOR VISUAL MEDIA PRODUCTION: CVMP 2009, P176, DOI 10.1109/CVMP.2009.29
   Ballester C, 2001, IEEE T IMAGE PROCESS, V10, P1200, DOI 10.1109/83.935036
   Bao JM, 2017, IEEE I CONF COMP VIS, P2764, DOI 10.1109/ICCV.2017.299
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Bitouk D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360638
   Blanz V, 2004, COMPUT GRAPH FORUM, V23, P669, DOI 10.1111/j.1467-8659.2004.00799.x
   Chou JK, 2012, MULTIMED TOOLS APPL, V56, P569, DOI 10.1007/s11042-010-0624-x
   Gatys L.A, 2015, ARXIV PREPRINT ARXIV
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Iizuka S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073659
   Kemelmacher-Shlizerman I, 2016, ACM T GRAPHICS, V35, P1
   Korshunova I, 2017, IEEE I CONF COMP VIS, P3697, DOI 10.1109/ICCV.2017.397
   Li M., 2016, ARXIV PREPRINT ARXIV
   Li YJ, 2017, PROC CVPR IEEE, P5892, DOI 10.1109/CVPR.2017.624
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Masi I, 2016, LECT NOTES COMPUT SC, V9909, P579, DOI 10.1007/978-3-319-46454-1_35
   Mirza M, 2014, ARXIV PREPRINT ARXIV
   Mosaddegh S, 2015, LECT NOTES COMPUT SC, V9005, P159, DOI 10.1007/978-3-319-16811-1_11
   Nirkin Y, 2018, IEEE INT CONF AUTOMA, P98, DOI 10.1109/FG.2018.00024
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Shen W., 2017, P IEEE C COMP VIS PA, P4030
   Wilczkowiak M., 2005, BRIT MACH VIS C, P492
   Yu F., 2016, MULTI SCALE CONTEXT
   Yu JH, 2018, PROC CVPR IEEE, P5505, DOI 10.1109/CVPR.2018.00577
   Yuan L., 2012, IEEE INT C MULT EXP IEEE INT C MULT EXP
   Zhou S., 2017, ARXIV PREPRINT ARXIV
NR 27
TC 0
Z9 0
U1 4
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2021
VL 78
AR 103152
DI 10.1016/j.jvcir.2021.103152
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TL1LJ
UT WOS:000674616200001
DA 2022-02-06
ER

PT J
AU Xu, BZ
   Liu, JR
   Liang, JF
   Lu, W
   Zhang, Y
AF Xu, Bozhi
   Liu, Jiarui
   Liang, Jifan
   Lu, Wei
   Zhang, Yue
TI DeepFake Videos Detection Based on Texture Features
SO CMC-COMPUTERS MATERIALS & CONTINUA
LA English
DT Article
DE DeepFake; video tampering; tampering detection; texture feature
ID CLASSIFICATION; FORENSICS
AB In recent years, with the rapid development of deep learning technologies, some neural network models have been applied to generate fake media. DeepFakes, a deep learning based forgery technology, can tamper with the face easily and generate fake videos that are difficult to be distinguished by human eyes. The spread of face manipulation videos is very easy to bring fake information. Therefore, it is important to develop effective detection methods to verify the authenticity of the videos. Due to that it is still challenging for current forgery technologies to generate all facial details and the blending operations are used in the forgery process, the texture details of the fake face are insufficient. Therefore, in this paper, a new method is proposed to detect DeepFake videos. Firstly, the texture features are constructed, which are based on the gradient domain, standard deviation, gray level co-occurrence matrix and wavelet transform of the face region. Then, the features are processed by the feature selection method to form a discriminant feature vector, which is finally employed to SVM for classification at the frame level. The experimental results on the mainstream DeepFake datasets demonstrate that the proposed method can achieve ideal performance, proving the effectiveness of the proposed method for DeepFake videos detection.
C1 [Xu, Bozhi; Liu, Jiarui; Liang, Jifan; Lu, Wei] Sun Yat Sen Univ, Key Lab Machine Intelligence & Adv Comp, Guangdong Prov Key Lab Informat Secur Technol, Sch Comp Sci & Engn,Minist Educ, Guangzhou 510006, Peoples R China.
   [Zhang, Yue] Univ Massachusetts, Dept Comp Sci, Lowell, MA 01854 USA.
C3 Sun Yat Sen University; University of Massachusetts System; University
   of Massachusetts Lowell
RP Lu, W (corresponding author), Sun Yat Sen Univ, Key Lab Machine Intelligence & Adv Comp, Guangdong Prov Key Lab Informat Secur Technol, Sch Comp Sci & Engn,Minist Educ, Guangzhou 510006, Peoples R China.
EM luwei3@mail.sysu.edu.cn
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [U2001202, 62072480, U1736118]; National Key
   R&D Program of China [2019QY2202, 2019QY(Y)0207]; Key Areas R&D Program
   of Guangdong [2019B010136002]; Key Scientific Research Program of
   Guangzhou [201804020068]
FX This work is supported by the National Natural Science Foundation of
   China (Nos. U2001202, 62072480, U1736118), the National Key R&D Program
   of China (Nos. 2019QY2202, 2019QY(Y)0207), the Key Areas R&D Program of
   Guangdong (No. 2019B010136002), the Key Scientific Research Program of
   Guangzhou (No. 201804020068).
CR Afchar D, 2018, IEEE INT WORKS INFOR
   Agarwal S., 2019, P CVPR WORKSH LONG B, P38
   Arazm N, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON CYBERNETICS AND COMPUTATIONAL INTELLIGENCE (CYBERNETICSCOM), P50, DOI 10.1109/CYBERNETICSCOM.2017.8311683
   Arivazhagan S, 2003, PATTERN RECOGN LETT, V24, P3197, DOI 10.1016/j.patrec.2003.08.005
   BARALDI A, 1995, IEEE T GEOSCI REMOTE, V33, P293, DOI 10.1109/36.377929
   CHELLAPPA R, 1985, IEEE T ACOUST SPEECH, V33, P959, DOI 10.1109/TASSP.1985.1164641
   Chen CL, 2017, IEEE T IMAGE PROCESS, V26, P2811, DOI 10.1109/TIP.2017.2682963
   Chen HK, 2020, IEEE T CYBERNETICS, V50, P3367, DOI 10.1109/TCYB.2019.2899225
   Dolhansky B., 2019, DEEPFAKE DETECTION C
   Guera D, 2018, 2018 15TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P127
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hu BX, 2020, INTELL AUTOM SOFT CO, V26, P1549, DOI 10.32604/iasc.2020.011721
   Jung T, 2020, IEEE ACCESS, V8, P83144, DOI 10.1109/ACCESS.2020.2988660
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Korshunov P., 2018, DEEPFAKES NEW THREAT
   Korshunova I, 2017, IEEE I CONF COMP VIS, P3697, DOI 10.1109/ICCV.2017.397
   [李艳歌 Li Yange], 2018, [高分子通报, Polymer Bulletin], P46
   Li YZ, 2018, IEEE INT WORKS INFOR
   Liu X, 2020, SIGNAL IMAGE VIDEO P, V14, P1227, DOI 10.1007/s11760-020-01644-0
   Liu Zhengzhe, 2020, P IEEE CVF C COMP VI, P8060, DOI DOI 10.1109/CVPR42600.2020.00808
   Lu M, 2020, CMC-COMPUT MATER CON, V64, P887, DOI 10.32604/cmc.2020.09770
   Matern F, 2019, IEEE WINT CONF APPL, P83, DOI 10.1109/WACVW.2019.00020
   Nguyen HV, 2019, 2019 2ND INTERNATIONAL CONFERENCE ON APPLIED INFORMATION TECHNOLOGY AND INNOVATION (ICAITI2019), P1, DOI 10.1109/ICAITI48442.2019.8982119
   Nirkin Y, 2018, IEEE INT CONF AUTOMA, P98, DOI 10.1109/FG.2018.00024
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Peng AJ, 2020, CMC-COMPUT MATER CON, V65, P2217, DOI 10.32604/cmc.2020.011006
   Petkova L, 2020, 2020 55TH INTERNATIONAL SCIENTIFIC CONFERENCE ON INFORMATION, COMMUNICATION AND ENERGY SYSTEMS AND TECHNOLOGIES (IEEE ICEST 2020), P177, DOI 10.1109/ICEST49890.2020.9232887
   Reis MS, 2010, COMPUT CHEM ENG, V34, P2014, DOI 10.1016/j.compchemeng.2010.06.013
   Rossler A, 2019, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2019.00009
   Tuceryan M., 1993, HDB PATTERN RECOGNIT, P235, DOI DOI 10.1142/9789814343138_0010
   Wang S, 2020, EUR RESPIR J, V56, DOI 10.1183/13993003.00775-2020
   Yang X, 2019, INT CONF ACOUST SPEE, P8261, DOI 10.1109/ICASSP.2019.8683164
   Yuezun Li, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P3204, DOI 10.1109/CVPR42600.2020.00327
   [张怡暄 Zhang Yixuan], 2020, [信息安全学报, Journal of Cyber Security], V5, P49
   Zhou P, 2017, IEEE COMPUT SOC CONF, P1831, DOI 10.1109/CVPRW.2017.229
NR 35
TC 0
Z9 0
U1 15
U2 24
PU TECH SCIENCE PRESS
PI HENDERSON
PA 871 CORONADO CENTER DR, SUTE 200, HENDERSON, NV 89052 USA
SN 1546-2218
EI 1546-2226
J9 CMC-COMPUT MATER CON
JI CMC-Comput. Mat. Contin.
PY 2021
VL 68
IS 1
BP 1375
EP 1388
DI 10.32604/cmc.2021.016760
PG 14
WC Computer Science, Information Systems; Materials Science,
   Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Materials Science
GA RB6CV
UT WOS:000632198600002
OA gold
DA 2022-02-06
ER

PT J
AU Jung, T
   Kim, S
   Kim, K
AF Jung, Tackhyun
   Kim, Sangwon
   Kim, Keecheon
TI DeepVision: Deepfakes Detection Using Human Eye Blinking Pattern
SO IEEE ACCESS
LA English
DT Article
DE Gallium nitride; Detectors; Visualization; Target tracking; Machine
   learning; Generative adversarial networks; Biology; Cyber security;
   deep-fake; GANs; deep learning
AB In this paper, we propose a new approach to detect Deepfakes generated through the generative adversarial network (GANs) model via an algorithm called DeepVision to analyze a significant change in the pattern of blinking, which is a voluntary and spontaneous action that does not require conscious effort. Human eye blinking pattern has been known to significantly change according to the person & x2019;s overall physical conditions, cognitive activities, biological factors, and information processing level. For example, an individual & x2019;s gender or age, the time of day, or the person & x2019;s emotional state or degree of alertness can all influence the pattern. As a result, Deepfakes can be determined through integrity verification by tracking significant changes in the eye blinking patterns in deepfakes by means of a heuristic method based on the results of medicine, biology, and brain engineering research, as well as machine learning and various algorithms based on engineering and statistical knowledge. This means we can perform integrity verification through tracking significant changes in the eye blinking pattern of a subject in a video. The proposed method called DeepVision is implemented as a measure to verify an anomaly based on the period, repeated number, and elapsed eye blink time when eye blinks were continuously repeated within a very short period of time. DeepVision accurately detected Deepfakes in seven out of eight types of videos (87.5 & x0025; accuracy rate), suggesting we can overcome the limitations of integrity verification algorithms performed only on the basis of pixels.
C1 [Jung, Tackhyun] Konkuk Univ, Dept IT Convergence Informat Secur, Seoul 05029, South Korea.
   [Kim, Sangwon] Konkuk Univ, Dept Comp Informat & Commun Engn, Seoul 05029, South Korea.
   [Kim, Keecheon] Konkuk Univ, Dept Comp Sci & Engn, Seoul 05029, South Korea.
C3 Konkuk University; Konkuk University; Konkuk University
RP Kim, K (corresponding author), Konkuk Univ, Dept Comp Sci & Engn, Seoul 05029, South Korea.
EM kckim@konkuk.ac.kr
OI Kim, Sangwon/0000-0002-6146-4103
FU Konkuk University
FX This work was supported by the Konkuk University, in 2019.
CR Afchar D, 2018, 2018 IEEE INT WORKSH, P1
   Barbato G, 2000, PSYCHIAT RES, V93, P145, DOI 10.1016/S0165-1781(00)00108-6
   Bayar Y, 2016, TRANSYLV REV ADM SCI, P5
   Bentivoglio AR, 1997, MOVEMENT DISORD, V12, P1028, DOI 10.1002/mds.870120629
   Box G. E. P., 2016, TIME SERIES ANAL FOR, V5th
   Cozzolino Davide, 2017, P 5 ACM WORKSH INF H, P159, DOI DOI 10.1145/3082031.3083247
   Dang LC, 2017, ENEURO, V4, DOI 10.1523/ENEURO.0211-17.2017
   DEJONG PJ, 1990, INT J NEUROSCI, V51, P89, DOI 10.3109/00207459009000513
   Edwards S., 2018, WASH POST
   FREED WJ, 1980, BIOL PSYCHIAT, V15, P329
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   GUERA D, 2018, 15 IEEE INT C ADV VI, P00001
   Hsu CC, 2018, INT SYMP COMP CONS, P388, DOI 10.1109/IS3C.2018.00104
   Kaggle, 2018, P COMP SUMM COMP
   Kendrae, 2018, ASSIGNMENT RC TOM CH
   Koopman M, 2018, P IR MACH VIS IM PRO, P133
   Lawrence S, 1997, IEEE T NEURAL NETWOR, V8, P98, DOI 10.1109/72.554195
   Lawrenson JG, 2005, J ANAT, V206, P265, DOI 10.1111/j.1469-7580.2005.00386.x
   Lee H, 2018, EUROSURVEILLANCE, V23, P9, DOI 10.2807/1560-7917.ES.2018.23.42.1700734
   Li Y., 2018, ARXIV180602877
   Oh J, 2012, KOR J MED HIST, V21, P1
   PONDER ERIC, 1927, QUART JOUR EXP PHYSIOL, V18, P89
   Radford A., 2015, ARXIV151106434
   Rahmouni Nicolas, 2017, P IEEE WORKSH INF FO, P1
   Ranjan R, 2016, ARXIV160301249, P99
   Rosler O., 2013, P AIHLS IST TURK
   ROSSLER A, 2019, ARXIV190108971
   Rossler Andreas, 2018, ARXIV180309179
   Soukupova T., 2016, P COMP VIS WINT WORK, P42
   Suwajanakorn S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073640
   Taylor SJ, 2018, AM STAT, V72, P37, DOI 10.1080/00031305.2017.1380080
   VONCRAMON D, 1980, NEUROPSYCHOLOGIA, V18, P603, DOI 10.1016/0028-3932(80)90164-5
   ZAMETKIN AJ, 1979, ANN NEUROL, V5, P453, DOI 10.1002/ana.410050509
NR 34
TC 12
Z9 13
U1 2
U2 11
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2020
VL 8
BP 83144
EP 83154
DI 10.1109/ACCESS.2020.2988660
PG 11
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA ML5JL
UT WOS:000549502200119
OA gold
DA 2022-02-06
ER

PT J
AU Kanagavalli, N
   Priya, SB
AF Kanagavalli, N.
   Priya, S. Baghavathi
TI Social Networks Fake Account and Fake News Identification with Reliable
   Deep Learning
SO INTELLIGENT AUTOMATION AND SOFT COMPUTING
LA English
DT Article
DE Social networking; fake account; fake news; rumor detection; deep
   learning; linguistic features
AB Recent developments of the World Wide Web (WWW) and social networking (Twitter, Instagram, etc.) paves way for data sharing which has never been observed in the human history before. A major security issue in this network is the creation of fake accounts. In addition, the automatic classification of the text article as true or fake is also a crucial process. The ineffectiveness of humans in distinguishing the true and false information exposes the fake news as a risk to credibility, democracy, logical truth, and journalism in government sectors. Besides, the automatic fake news or rumors from the social networking sites is a major research area in the field of social media analytics. With this motivation, this paper develops a new reliable deep learning (DL) based fake account and fake news detection (RDL-FAFND) model for the social networking sites. The goal of the RDL-FAFND model is to resolve the major problems involved in the social media platforms namely fake accounts, fake news/rumor identification. The presented RDL-FAFND model detects the fake account by the use of a parameter tuned deep stacked Auto encoder (DSAE) using the krill herd (KH) optimization algorithm for detecting the fake social networking accounts. Besides, the prese nted RDL-FAFND model involves an ensemble of the machine learning (ML) models with different linguistic features (EML-LF) for categorizing the text as true or fake. An extensive set of experiments have been carried out for highlighting the superior performance of the RDL-FAFND model. A detailed comparative results analysis has stated that the presented RDL-FAFND model is considerably better than the existing methods.
C1 [Kanagavalli, N.] Rajalakshmi Inst Technol, Dept CSE, Chennai 600124, Tamil Nadu, India.
   [Priya, S. Baghavathi] Rajalakshmi Engn Coll, Dept CSE, Chennai 602105, Tamil Nadu, India.
C3 Rajalakshmi Engineering College
RP Kanagavalli, N (corresponding author), Rajalakshmi Inst Technol, Dept CSE, Chennai 600124, Tamil Nadu, India.
EM kanagavallirec@gmail.com
CR Agarwal A, 2020, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS 2020), P1178, DOI 10.1109/ICICCS48265.2020.9121030
   Ahmad I, 2020, COMPLEXITY, V2020, DOI 10.1155/2020/8885861
   Alves J. L., 2019, P IB C PATT REC BERL, V11, P72
   Avudaiappan T., 2020, INT J SCI TECHNOLOGY, V9, P2573
   Boshmaf Y, 2016, COMPUT SECUR, V61, P142, DOI 10.1016/j.cose.2016.05.005
   Cao J., 2017, INFORM SCIENTIST, V3, P1
   de Oliveira NR, 2021, INFORMATION, V12, DOI 10.3390/info12010038
   Fayaz M, 2020, COMPLEXITY, V2020, DOI 10.1155/2020/8857570
   Kagan D, 2018, SOC NETW ANAL MIN, V8, DOI 10.1007/s13278-018-0503-4
   Kumar S, 2020, T EMERG TELECOMMUN T, V31, DOI 10.1002/ett.3767
   Liu L., 2016, P NAACL HLT SAN DIEG, P1
   Madhan E. S., 2020, J COMPUT THEOR NANOS, V17, P2237
   Mahyoob M., 2020, INT J ENGL LINGUIST, V11, P99, DOI 10.5539/ijel.v11n1p99
   Maragoudakis, 2020, IFIP INT C ART INT A, P177
   Jeronimo CLM, 2019, IIWAS2019: THE 21ST INTERNATIONAL CONFERENCE ON INFORMATION INTEGRATION AND WEB-BASED APPLICATIONS & SERVICES, P15, DOI 10.1145/3366030.3366039
   Miao XY, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0208989
   Mohammadrezaei M, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/5923156
   Mouratidis D., COMPUTATION, V9, P2021
   Neelakandan S., 2016, INT J ENG COMPUTER S, V5, P16731
   Neelakandan S., 2020, PROCEDIA COMPUTER SC, V172, P145
   Shu K, 2020, BIG DATA-US, V8, P171, DOI 10.1089/big.2020.0062
   Thota Aswini., 2018, SMU DATA SCI REV, V1, P10
   Uthayakumar J., 2014, INT J MODERN ENG RES, V4, P70
   Victor U., 2020, THESIS PRAIRIE VIEW
   Wang GG, 2013, MATH PROBL ENG, V2013, DOI [10.1155/2013/682073, 10.1155/2013/796304]
   Wang YQ, 2020, AAAI CONF ARTIF INTE, V34, P516
   Wenlin Han, 2019, 2019 IEEE International Conference on Industrial Internet (ICII). Proceedings, P375, DOI 10.1109/ICII.2019.00070
NR 27
TC 0
Z9 0
U1 1
U2 1
PU TECH SCIENCE PRESS
PI HENDERSON
PA 871 CORONADO CENTER DR, SUTE 200, HENDERSON, NV 89052 USA
SN 1079-8587
EI 2326-005X
J9 INTELL AUTOM SOFT CO
JI Intell. Autom. Soft Comput.
PY 2022
VL 33
IS 1
BP 191
EP 205
DI 10.32604/iasc.2022.022720
PG 15
WC Automation & Control Systems; Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Automation & Control Systems; Computer Science
GA YF4TP
UT WOS:000741801200014
OA hybrid
DA 2022-02-06
ER

PT J
AU Cao, M
   Huang, HZ
   Wang, H
   Wang, X
   Shen, L
   Wang, S
   Bao, LC
   Li, ZF
   Luo, JB
AF Cao, Meng
   Huang, Haozhi
   Wang, Hao
   Wang, Xuan
   Shen, Li
   Wang, Sheng
   Bao, Linchao
   Li, Zhifeng
   Luo, Jiebo
TI UniFaceGAN: A Unified Framework for Temporally Consistent Facial Video
   Editing
SO IEEE TRANSACTIONS ON IMAGE PROCESSING
LA English
DT Article
DE Faces; Three-dimensional displays; Training; Task analysis; Image
   reconstruction; Optical losses; Solid modeling; Facial video editing;
   dynamic training sample selection; 3D temporal loss; region-aware
   conditional normalization
AB Recent research has witnessed advances in facial image editing tasks including face swapping and face reenactment. However, these methods are confined to dealing with one specific task at a time. In addition, for video facial editing, previous methods either simply apply transformations frame by frame or utilize multiple frames in a concatenated or iterative fashion, which leads to noticeable visual flickers. In this paper, we propose a unified temporally consistent facial video editing framework termed UniFaceGAN. Based on a 3D reconstruction model and a simple yet efficient dynamic training sample selection mechanism, our framework is designed to handle face swapping and face reenactment simultaneously. To enforce the temporal consistency, a novel 3D temporal loss constraint is introduced based on the barycentric coordinate interpolation. Besides, we propose a region-aware conditional normalization layer to replace the traditional AdaIN or SPADE to synthesize more context-harmonious results. Compared with the state-of-the-art facial image editing methods, our framework generates video portraits that are more photo-realistic and temporally smooth.
C1 [Cao, Meng] Peking Univ, Dept Elect & Comp Engn, Beijing 100871, Peoples R China.
   [Huang, Haozhi; Wang, Sheng] Xverse, Shenzhen 518052, Peoples R China.
   [Wang, Hao; Wang, Xuan; Wang, Sheng; Bao, Linchao; Li, Zhifeng] Tencent AI Lab, Shenzhen 518057, Peoples R China.
   [Shen, Li] JD Explore Acad, Beijing 100000, Peoples R China.
   [Luo, Jiebo] Univ Rochester, Dept Comp Sci, Rochester, NY 14627 USA.
C3 Peking University; Tencent; University of Rochester
RP Bao, LC (corresponding author), Tencent AI Lab, Shenzhen 518057, Peoples R China.
EM linchaobao@gmail.com
RI Bao, Linchao/AAG-9148-2020
OI Bao, Linchao/0000-0001-9543-3754; Cao, Meng/0000-0002-8946-4228; Shen,
   Li/0000-0001-5659-3464
FU Tencent AI Lab
FX This work was supported by Tencent AI Lab. The associate editor
   coordinating the review of this manuscript and approving it for
   publication was Prof. Andrea Fusiello. (Meng Cao and Haozhi Huang
   contributed equally to this work.)
CR Averbuch-Elor H, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130818
   Bao JM, 2018, PROC CVPR IEEE, P6713, DOI 10.1109/CVPR.2018.00702
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Blanz V, 2004, COMPUT GRAPH FORUM, V23, P669, DOI 10.1111/j.1467-8659.2004.00799.x
   Burgos-Artizzu XP, 2013, IEEE I CONF COMP VIS, P1513, DOI 10.1109/ICCV.2013.191
   Cao C, 2014, IEEE T VIS COMPUT GR, V20, P413, DOI 10.1109/TVCG.2013.249
   Chung JS, 2018, ARXIV180605622
   Dong XY, 2018, PROC CVPR IEEE, P360, DOI 10.1109/CVPR.2018.00045
   Garrido P, 2014, PROC CVPR IEEE, P4217, DOI 10.1109/CVPR.2014.537
   Ha S., 2019, ARXIV191108139
   Heusel M., 2017, NIPS, V30, P6629
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179
   Jin X., 2017, ARXIV171203451
   Kim H, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201283
   Korshunova I, 2017, IEEE I CONF COMP VIS, P3697, DOI 10.1109/ICCV.2017.397
   Li Lingzhi, 2019, ARXIV191213457
   Lim J.H., 2017, GEOMETRIC GAN
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Maze B, 2018, INT CONF BIOMETR, P158, DOI 10.1109/ICB2018.2018.00033
   Nagano K, 2019, ACM T GRAPHIC, V37, P1
   Nirkin Y, 2019, IEEE I CONF COMP VIS, P7183, DOI 10.1109/ICCV.2019.00728
   Nirkin Y, 2018, IEEE INT CONF AUTOMA, P98, DOI 10.1109/FG.2018.00024
   Olszewski K, 2017, IEEE I CONF COMP VIS, P5439, DOI 10.1109/ICCV.2017.580
   Park T, 2019, PROC CVPR IEEE, P2332, DOI 10.1109/CVPR.2019.00244
   Paysan P, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P296, DOI 10.1109/AVSS.2009.58
   Siarohin A., 2019, NEURIPS
   Siarohin A, 2019, PROC CVPR IEEE, P2372, DOI 10.1109/CVPR.2019.00248
   Simonyan K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.8
   Suwajanakorn S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073640
   Thies J, 2016, PROC CVPR IEEE, P2387, DOI 10.1109/CVPR.2016.262
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wiles O, 2018, P EUR C COMP VIS ECC, P670
   Wu W., 2018, P EUR C COMP VIS ECC, P603
   Zakharov Egor, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P524, DOI 10.1007/978-3-030-58610-2_31
   Zakharov E, 2019, IEEE I CONF COMP VIS, P9458, DOI 10.1109/ICCV.2019.00955
   Zhao J., 2017, ADV NEURAL INFORM PR, P66
   Zhu XY, 2019, IEEE T PATTERN ANAL, V41, P78, DOI 10.1109/TPAMI.2017.2778152
   Zhu XY, 2016, PROC CVPR IEEE, P146, DOI 10.1109/CVPR.2016.23
NR 40
TC 0
Z9 0
U1 1
U2 1
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1057-7149
EI 1941-0042
J9 IEEE T IMAGE PROCESS
JI IEEE Trans. Image Process.
PY 2021
VL 30
BP 6107
EP 6116
DI 10.1109/TIP.2021.3089909
PG 10
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TF2MK
UT WOS:000670545900006
PM 34166189
OA Green Submitted
DA 2022-02-06
ER

PT J
AU Seo, Y
   Han, SS
   Jeon, YB
   Jeong, CS
AF Seo, Youngkyung
   Han, Seong-Soo
   Jeon, You-Boo
   Jeong, Chang-Sung
TI FAGON: Fake News Detection Model Using Grammatical Transformation on
   Deep Neural Network
SO KSII TRANSACTIONS ON INTERNET AND INFORMATION SYSTEMS
LA English
DT Article
DE Fake news detection; Grammatical transformation; Deep neural network
AB As technology advances, the amount of fake news is increasing more and more by various reasons such as political issues and advertisement exaggeration. However, there have been very few research works on fake news detection, especially which uses grammatical transformation on deep neural network. In this paper, we shall present a new Fake News Detection Model, called FAGON(Fake news detection model using Grammatical transformation On deep Neural network) which determines efficiently if the proposition is true or not for the given article by learning grammatical transformation on neural network. Especially, our model focuses the Korean language. It consists of two modules: sentence generator and classification. The former generates multiple sentences which have the same meaning as the proposition, but with different grammar by training the grammatical transformation. The latter classifies the proposition as true or false by training with vectors generated from each sentence of the article and the multiple sentences obtained from the former model respectively. We shall show that our model is designed to detect fake news effectively by exploiting various grammatical transformation and proper classification structure.
C1 [Seo, Youngkyung; Jeong, Chang-Sung] Korea Univ, Dept Elect Engn, Seoul, South Korea.
   [Han, Seong-Soo] Korea Univ, Visual Informat Proc, Seoul, South Korea.
   [Jeon, You-Boo] Soonchunhyang Univ, Dept Comp Software Engn, Asan, Chungcheongnam, South Korea.
C3 Korea University; Korea University; Soonchunhyang University
RP Jeong, CS (corresponding author), Korea Univ, Dept Elect Engn, Seoul, South Korea.
EM ygseo@korea.ac.kr; postsky0@korea.ac.kr; jeonyb@sch.ac.kr;
   csjeong@korea.ac.kr
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [2017R1D1A1B03035461]; Brain
   Korea 21 Plus Project in 2018; Institute for Information &
   communications Technology Promotion(IITP) - Korean government (MSIP)
   [2018-0-00739]
FX This research was supported by the Basic Science Research Program
   through the National Research Foundation of Korea (NRF) funded by the
   Ministry of Education (2017R1D1A1B03035461), the Brain Korea 21 Plus
   Project in 2018, and the Institute for Information & communications
   Technology Promotion(IITP) grant funded by the Korean government (MSIP)
   (No. 2018-0-00739, Deep learning-based natural language contents
   evaluation technology for detecting fake news).
CR Bojanowski P., 2017, TACL, V5, P135, DOI [DOI 10.1162/TACL_A_00051, 10.1162/tacl_a_00051]
   Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401
   Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2
   Dyer Chris, 2016, ARXIV PREPRINT ARXIV, P199, DOI [10.18653/v1/N16-1024, DOI 10.18653/V1/N16-1024]
   Kezhi M., 2017, WORLD ACAD SCI ENG T, V11, P697
   Luo Y, 2018, J AM MED INFORM ASSN, V25, P93, DOI 10.1093/jamia/ocx090
   Sakaguchi Keisuke, 2017, ARXIV170700299
   Sebastian R., 2013, P 2013 C N AM CHAPT, P74
   Seo Youngkyung, 2018, P 13 INT C KNOWL
   Spitkovsky Valentin I, 2012, P 2012 JOINT C EMP M, P688
   Sutskever I., 2014, ADV NEURAL INFORM PR, P3104
   Tan Z, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10090357
   Wang T., 2016, ARXIV160903663
   Zhou P, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P207, DOI 10.18653/v1/p16-2034
NR 14
TC 0
Z9 0
U1 1
U2 5
PU KSII-KOR SOC INTERNET INFORMATION
PI GANGNAM-GU
PA KOR SCI & TECHNOL CTR, 409 ON 4TH FLR, MAIN BLDG, 635-4 YEOKSAM 1-DONG,
   GANGNAM-GU, SEOUL 00000, SOUTH KOREA
SN 1976-7277
J9 KSII T INTERNET INF
JI KSII Trans. Internet Inf. Syst.
PD OCT 31
PY 2019
VL 13
IS 10
BP 4958
EP 4970
DI 10.3837/tiis.2019.10.008
PG 13
WC Computer Science, Information Systems; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA JI9WJ
UT WOS:000493813800008
OA gold
DA 2022-02-06
ER

PT J
AU Lee, G
   Kim, M
AF Lee, Gihun
   Kim, Mihui
TI Deepfake Detection Using the Rate of Change between Frames Based on
   Computer Vision
SO SENSORS
LA English
DT Article
DE deepfake; computer vision; the rate of change
AB Recently, artificial intelligence has been successfully used in fields, such as computer vision, voice, and big data analysis. However, various problems, such as security, privacy, and ethics, also occur owing to the development of artificial intelligence. One such problem are deepfakes. Deepfake is a compound word for deep learning and fake. It refers to a fake video created using artificial intelligence technology or the production process itself. Deepfakes can be exploited for political abuse, pornography, and fake information. This paper proposes a method to determine integrity by analyzing the computer vision features of digital content. The proposed method extracts the rate of change in the computer vision features of adjacent frames and then checks whether the video is manipulated. The test demonstrated the highest detection rate of 97% compared to the existing method or machine learning method. It also maintained the highest detection rate of 96%, even for the test that manipulates the matrix of the image to avoid the convolutional neural network detection method.
C1 [Lee, Gihun; Kim, Mihui] Hankyong Natl Univ, Comp Syst Inst, Dept Comp Sci & Engn, Anseong 17579, Gyeonggi Do, South Korea.
C3 Hankyong National University
RP Kim, M (corresponding author), Hankyong Natl Univ, Comp Syst Inst, Dept Comp Sci & Engn, Anseong 17579, Gyeonggi Do, South Korea.
EM comb1001@hknu.ac.kr; mhkim@hknu.ac.kr
FU National Research Foundation of Korea (NRF) - Korea government (MSIT)
   [2018R1A2B6009620]
FX FundingThis research was supported by the National Research Foundation
   of Korea (NRF) grant funded by the Korea government (MSIT)
   [No.2018R1A2B6009620].
CR Afchar D., 2018, 2018 IEEE INT WORKSH, P1, DOI DOI 10.1109/WIFS.2018.8630761
   Agarwal Shruti, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW). Proceedings, P2814, DOI 10.1109/CVPRW50498.2020.00338
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Grm K, 2018, IET BIOMETRICS, V7, P81, DOI 10.1049/iet-bmt.2017.0083
   Guera D, 2018, 2018 15TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P127
   Hou XX, 2017, IEEE WINT CONF APPL, P1133, DOI 10.1109/WACV.2017.131
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li Yuezun, 2018, 2018 IEEE INT WORKSH, P1, DOI DOI 10.1109/WIFS.2018.8630787
   Li Yuezun, 2019, IEEE C COMP VIS PATT
   Rossler A, 2019, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2019.00009
   Roy P., 2019, ARXIV180710108
   Ruben T., 2020, ARXIV200100179
   Schuldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Yang X, 2019, INT CONF ACOUST SPEE, P8261, DOI 10.1109/ICASSP.2019.8683164
   Zhang KP, 2016, IEEE SIGNAL PROC LET, V23, P1499, DOI 10.1109/LSP.2016.2603342
NR 16
TC 0
Z9 0
U1 1
U2 1
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 1424-8220
J9 SENSORS-BASEL
JI Sensors
PD NOV
PY 2021
VL 21
IS 21
AR 7367
DI 10.3390/s21217367
PG 11
WC Chemistry, Analytical; Engineering, Electrical & Electronic; Instruments
   & Instrumentation
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Chemistry; Engineering; Instruments & Instrumentation
GA XB1BF
UT WOS:000721069400001
PM 34770675
OA gold, Green Published
DA 2022-02-06
ER

PT J
AU Hashmi, MF
   Ashish, BKK
   Keskar, AG
   Bokde, ND
   Yoon, JH
   Geem, ZW
AF Hashmi, Mohammad Farukh
   Ashish, B. Kiran Kumar
   Keskar, Avinash G.
   Bokde, Neeraj Dhanraj
   Yoon, Jin Hee
   Geem, Zong Woo
TI An Exploratory Analysis on Visual Counterfeits Using Conv-LSTM Hybrid
   Architecture
SO IEEE ACCESS
LA English
DT Article
DE Face; Training; Visualization; Decoding; Gallium nitride; Machine
   learning; Recurrent neural networks; DeepFakes; generative adversarial
   network (GANs); facial landmarks; convolutional neural networks (CNN);
   recurrent neural network (RNN); visual counterfeits
AB In recent years, with the advancements in the Deep Learning realm, it has been easy to create and generate synthetically the face swaps from GANs and other tools, which are very realistic, leaving few traces which are unclassifiable by human eyes. These are known as 'DeepFakes' and most of them are anchored in video formats. Such realistic fake videos and images are used to create a ruckus and affect the quality of public discourse on sensitive issues; defaming one's profile, political distress, blackmailing and many more fake cyber terrorisms are envisioned. This work proposes a microscopic-typo comparison of video frames. This temporal-detection pipeline compares very minute visual traces on the faces of real and fake frames using Convolutional Neural Network (CNN) and stores the abnormal features for training. A total of 512 facial landmarks were extracted and compared. Parameters such as eye-blinking lip-synch; eyebrows movement, and position, are few main deciding factors that classify into real or counterfeit visual data. The Recurrent Neural Network (RNN) pipeline learns based on these features-fed inputs and then evaluates the visual data. The model was trained with the network of videos consisting of their real and fake, collected from multiple websites. The proposed algorithm and designed network set a new benchmark for detecting the visual counterfeits and show how this system can achieve competitive results on any fake generated video or image.
C1 [Hashmi, Mohammad Farukh] Natl Inst Technol, Dept Elect & Commun Engn, Warangal 506004, Andhra Pradesh, India.
   [Ashish, B. Kiran Kumar] Tericsoft Technol, Hyderabad 500036, India.
   [Keskar, Avinash G.] Visvesvaraya Natl Inst Technol, Dept Elect & Commun Engn, Nagpur 440010, Maharashtra, India.
   [Bokde, Neeraj Dhanraj] Aarhus Univ, Dept Engn Renewable Energy & Thermodynam, DK-8000 Aarhus, Denmark.
   [Yoon, Jin Hee] Sejong Univ, Sch Math & Stat, Seoul 05006, South Korea.
   [Geem, Zong Woo] Gachon Univ, Dept Energy IT, Seongnam 13120, South Korea.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Warangal; National Institute of Technology (NIT System);
   Visvesvaraya National Institute of Technology, Nagpur; Aarhus
   University; Sejong University; Gachon University
RP Geem, ZW (corresponding author), Gachon Univ, Dept Energy IT, Seongnam 13120, South Korea.
EM geem@gachon.ac.kr
RI Bokde, Neeraj Dhanraj/I-2621-2016; Ashish, B Kiran Kumar/AAT-9050-2020;
   Geem, Zong Woo/A-2718-2008
OI Bokde, Neeraj Dhanraj/0000-0002-3493-9302; Ashish, B Kiran
   Kumar/0000-0001-6582-4009; Geem, Zong Woo/0000-0002-0370-5562; Hashmi,
   Mohammad Farukh/0000-0002-3808-9122
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [NRF-2017R1D1A1B03034813]; Energy
   Cloud Research and Development Program through the National Research
   Foundation of Korea (NRF) - Ministry of Science, ICT [2019m3f2a1073164]
FX This work was supported in part by the Basic Science Research Program
   through the National Research Foundation of Korea (NRF) funded by the
   Ministry of Education under Grant NRF-2017R1D1A1B03034813, and in part
   by the Energy Cloud Research and Development Program through the
   National Research Foundation of Korea (NRF) funded by the Ministry of
   Science, ICT, under Grant 2019m3f2a1073164.
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Agarwal S., 2019, P CVPR WORKSH LONG B, P38
   Averbuch-Elor H, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130818
   Bau D, 2019, IEEE I CONF COMP VIS, P4501, DOI 10.1109/ICCV.2019.00460
   Bestagini P, 2013, IEEE INT WORKSH MULT, P488, DOI 10.1109/MMSP.2013.6659337
   Brock A., 2018, INT C LEARN REPR
   Brundage M., 2018, ARXIV180207228
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Conotter V, 2014, IEEE IMAGE PROC, P248, DOI 10.1109/ICIP.2014.7025049
   Cozzolino Davide, 2018, ARXIV181202510
   Dale K, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024164
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Durall R., 2020, ARXIV200301826
   Farid H, 2016, PHOTO FORENSICS, P1
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   GUERA D, 2018, 15 IEEE INT C ADV VI, P00001
   Guera D, 2017, IEEE COMPUT SOC CONF, P1840, DOI 10.1109/CVPRW.2017.230
   Hasan HR, 2019, IEEE ACCESS, V7, P41596, DOI 10.1109/ACCESS.2019.2905689
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735
   Hyeon Yoo J., 2017, ARXIV170704045
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Ivanov Nikita S., 2020, 2020 IEEE Conference of Russian Young Researchers in Electrical and Electronic Engineering (EIConRus). Proceedings, P326, DOI 10.1109/EIConRus49466.2020.9039498
   Karras T, 2018, PROGRESSIVE GROWING
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Krizhevsky A., 2012, ADV NEURAL INF PROCE, P1097, DOI DOI 10.1145/3065386
   Lample Guillaume, 2017, ADV NEURAL INFORM PR, P5967
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Li MK, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON SERVICE OPERATIONS AND LOGISTICS, AND INFORMATICS (SOLI), P200, DOI 10.1109/SOLI.2016.7551687
   Liao YY, 2017, IEEE T IMAGE PROCESS, V26, P2839, DOI 10.1109/TIP.2016.2605010
   Lu Y., 2017, ARXIV170509966
   Mangal S., 2019, ARXIV190804332
   Marra F, 2018, IEEE 1ST CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2018), P384, DOI 10.1109/MIPR.2018.00084
   Mittal T., 2020, ARXIV200306711
   Mohamed A. A., 2018, ARXIV180802016
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Park T, 2019, PROC CVPR IEEE, P2332, DOI 10.1109/CVPR.2019.00244
   Rossler A, 2019, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2019.00009
   Simonyan K., 2014, ADV NEURAL INFORM PR, DOI DOI 10.5555/2968826.2968890
   Srivastava N, 2015, PR MACH LEARN RES, V37, P843
   Sutskever I., 2014, P 27 INT C NEUR INF, V3104, P3112, DOI DOI 10.1021/acs.analchem.7b05329
   Verma A.K, 2019, P 4 IEEE INT C INT T, P1, DOI 10.1109/NPEC47332.2019.9034706
   Vinyals O., 2016, NIPS, P3637
   Wang S.-Y., 2019, ARXIV191211035
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Xu X, 2015, IEEE ICC, P2048, DOI 10.1109/ICC.2015.7248627
   Xu ZW, 2015, PROC CVPR IEEE, P1798, DOI 10.1109/CVPR.2015.7298789
   Zhang H., 2018, SELF ATTENTION GEN A
   Zhang X, 2019, IEEE INT WORKS INFOR
   Zhihe Lu, 2017, 2017 4th IAPR Asian Conference on Pattern Recognition (ACPR), P7, DOI 10.1109/ACPR.2017.2
   Zhu L, 2018, ROUTL CONTEMP CHINA, P75
NR 52
TC 2
Z9 2
U1 3
U2 5
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2020
VL 8
BP 101293
EP 101308
DI 10.1109/ACCESS.2020.2998330
PG 16
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA MH0FL
UT WOS:000546406500017
OA gold
DA 2022-02-06
ER

PT J
AU Fouad, KM
   Sabbeh, SF
   Medhat, W
AF Fouad, Khaled M.
   Sabbeh, Sahar F.
   Medhat, Walaa
TI Arabic Fake News Detection Using Deep Learning
SO CMC-COMPUTERS MATERIALS & CONTINUA
LA English
DT Article
DE Fake news detection; deep learning; machine learning; natural language
   processing
ID SOCIAL MEDIA
AB Nowadays, an unprecedented number of users interact through social media platforms and generate a massive amount of content due to the explosion of online communication. However, because user-generated content is unregulated, it may contain offensive content such as fake news, insults, and harassment phrases. The identification of fake news and rumors and their dissemination on social media has become a critical requirement. They have adverse effects on users, businesses, enterprises, and even political regimes and governments. State of the art has tackled the English language for news and used feature-based algorithms. This paper proposes a model architecture to detect fake news in the Arabic language by using only textual features. Machine learning and deep learning algorithms were used. The deep learning models are used depending on conventional neural nets (CNN), long short-ter m memory (LSTM), bidirectional LSTM (BiLSTM), CNN+LSTM, and CNN + BiLSTM. Three datasets were used in the experiments, each containing the textual content of Arabic news articles; one of them is real-life data. The results indicate that the BiLSTM model outperforms the other models regarding accuracy rate when both simple data split and recursive training modes are used in the training process.
C1 [Fouad, Khaled M.; Sabbeh, Sahar F.; Medhat, Walaa] Benha Univ, Fac Comp & Artificial Intelligence, Banha, Egypt.
   [Sabbeh, Sahar F.] Univ Jeddah, Coll Comp Sci & Engn, Jeddah 21493, Saudi Arabia.
   [Fouad, Khaled M.; Medhat, Walaa] Nile Univ, Informat Technol & Comp Sci, Giza, Egypt.
C3 Egyptian Knowledge Bank (EKB); Benha University; University of Jeddah;
   Egyptian Knowledge Bank (EKB); Nile University
RP Sabbeh, SF (corresponding author), Benha Univ, Fac Comp & Artificial Intelligence, Banha, Egypt.; Sabbeh, SF (corresponding author), Univ Jeddah, Coll Comp Sci & Engn, Jeddah 21493, Saudi Arabia.
EM sfsabbeh@uj.edu.sa
CR Abbasi A, 2021, IEEE ACCESS, V9, P66408, DOI 10.1109/ACCESS.2021.3076264
   Agarwala V, 2019, PROCEDIA COMPUT SCI, V165, P377, DOI 10.1016/j.procs.2020.01.035
   Ahsan Mohammad, 2019, Online Social Networks and Media, V14, P1, DOI 10.1016/j.osnem.2019.100050
   Al-Sarem M, 2019, IEEE ACCESS, V7, P152788, DOI 10.1109/ACCESS.2019.2947855
   Alzanin SM, 2019, KNOWL-BASED SYST, V185, DOI 10.1016/j.knosys.2019.104945
   Alzanin SM, 2018, PROCEDIA COMPUT SCI, V142, P294, DOI 10.1016/j.procs.2018.10.495
   Bondielli A, 2019, INFORM SCIENCES, V497, P38, DOI 10.1016/j.ins.2019.05.035
   Elnagar A, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102121
   Floos Ahmad Yahya M., 2016, International Journal of Knowledge Society Research, V7, P72, DOI 10.4018/IJKSR.2016040105
   Fouad Khaled M., 2021, International Journal of Sociotechnology and Knowledge Development, V13, P119, DOI 10.4018/IJSKD.2021040108
   Fouad KM, 2020, INT J COMPUT APPL T, V63, P93, DOI 10.1504/IJCAT.2020.107906
   Francisco R., 2019, WORK NOT FOR INF RET, P70
   Girgis S, 2018, PROCEEDINGS OF 2018 13TH INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING AND SYSTEMS (ICCES), P93, DOI 10.1109/ICCES.2018.8639198
   Granik M, 2017, 2017 IEEE FIRST UKRAINE CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING (UKRCON), P900, DOI 10.1109/UKRCON.2017.8100379
   Heikal M, 2018, PROCEDIA COMPUT SCI, V142, P114, DOI 10.1016/j.procs.2018.10.466
   Jin ZW, 2016, THIRTIETH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2972
   Jin ZW, 2017, IEEE T MULTIMEDIA, V19, P598, DOI 10.1109/TMM.2016.2617078
   Kaliyar RK, 2021, MULTIMED TOOLS APPL, V80, P11765, DOI 10.1007/s11042-020-10183-2
   Kaliyar RK, 2020, COGN SYST RES, V61, P32, DOI 10.1016/j.cogsys.2019.12.005
   Kumar S., 2018, ARXIV180408559
   Kumar S, 2020, T EMERG TELECOMMUN T, V31, DOI 10.1002/ett.3767
   Lai SW, 2015, PROCEEDINGS OF THE TWENTY-NINTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2267
   Lakshmi R. Deepa, 2010, IJCSE INT J COMPUTER, V02, P2783
   Lee DH, 2019, J INF PROCESS SYST, V15, P1119, DOI 10.3745/JIPS.04.0142
   Liu Q., 2018, P INT C COMP LING CO, P2023
   Ma J., 2016, P 25 INT JOINT C ART, P3818
   Ma J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1980
   Menczer F., 2009, P 5 INT WORKSH ADV I, P41, DOI DOI 10.1145/1531914.1531924
   Mouty R, 2018, 2018 21ST SAUDI COMPUTER SOCIETY NATIONAL COMPUTER CONFERENCE (NCC)
   Muhammad A., 2019, J AMB INTEL HUM COMP, V12, P4315
   Oscar A., 2017, EXPERT SYST APPL, V77, P246
   Pavithra C., 2019, INT C SYST EN ENV IC
   Peng Y., 2020, ELSEVIER MICCAI SOC
   Perez-Rosas V, 2018, P 27 INT C COMPUTATI, P3391
   Pierri F, 2019, SIGMOD REC, V48, P18, DOI 10.1145/3377330.3377334
   Reis JCS, 2019, IEEE INTELL SYST, V34, P76, DOI 10.1109/MIS.2019.2899143
   Sabbeh Sahar F., 2018, Journal of Theoretical and Applied Information Technology, V96, P2327
   Sabbeh SF, 2019, INT J ADV COMPUT SC, V10, P245
   Tandoc EC, 2018, DIGIT JOURNAL, V6, P137, DOI 10.1080/21670811.2017.1360143
   Tarnpradab Sansiri, 2018, 2018 Thirteenth International Conference on Digital Information Management (ICDIM), P82, DOI 10.1109/ICDIM.2018.8847052
   Umer M, 2020, IEEE ACCESS, V8, P156695, DOI 10.1109/ACCESS.2020.3019735
   Verma A.K, 2019, P 4 IEEE INT C INT T, P1, DOI 10.1109/NPEC47332.2019.9034706
   Vohra M, 2018, PROCEEDINGS OF THE 8TH INTERNATIONAL CONFERENCE CONFLUENCE 2018 ON CLOUD COMPUTING, DATA SCIENCE AND ENGINEERING, P485, DOI 10.1109/CONFLUENCE.2018.8442442
   Wang QS, 2018, INFORM MANAGE-AMSTER, V55, P441, DOI 10.1016/j.im.2017.10.004
   Xiang Lin, 2019, Natural Language Processing and Chinese Computing. 8th CCF International Conference, NLPCC 2019. Proceedings. Lecture Notes in Artificial Intelligence, Subseries of Lecture Notes in Computer Science (LNAI 11839), P338, DOI 10.1007/978-3-030-32236-6_30
   Xu YC, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11111408
   Zannettou S, 2019, ACM J DATA INF QUAL, V11, DOI 10.1145/3309699
NR 47
TC 0
Z9 0
U1 4
U2 4
PU TECH SCIENCE PRESS
PI HENDERSON
PA 871 CORONADO CENTER DR, SUTE 200, HENDERSON, NV 89052 USA
SN 1546-2218
EI 1546-2226
J9 CMC-COMPUT MATER CON
JI CMC-Comput. Mat. Contin.
PY 2022
VL 71
IS 2
BP 3647
EP 3665
DI 10.32604/cmc.2022.021449
PG 19
WC Computer Science, Information Systems; Materials Science,
   Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Materials Science
GA XN7CX
UT WOS:000729659500011
OA gold
DA 2022-02-06
ER

PT J
AU Kaliyar, RK
   Goswami, A
   Narang, P
   Sinha, S
AF Kaliyar, Rohit Kumar
   Goswami, Anurag
   Narang, Pratik
   Sinha, Soumendu
TI FNDNet - A deep convolutional neural network for fake news detection
SO COGNITIVE SYSTEMS RESEARCH
LA English
DT Article
DE Fake news; Social media; Machine learning; Deep learning; Neural network
ID SENTIMENT ANALYSIS; CLASSIFICATION; KNOWLEDGE
AB With the increasing popularity of social media and web-based forums, the distribution of fake news has become a major threat to various sectors and agencies. This has abated trust in the media, leaving readers in a state of perplexity. There exists an enormous assemblage of research on the theme of Artificial Intelligence (AI) strategies for fake news detection. In the past, much of the focus has been given on classifying online reviews and freely accessible online social networking-based posts. In this work, we propose a deep convolutional neural network (FNDNet) for fake news detection. Instead of relying on hand-crafted features, our model (FNDNet) is designed to automatically learn the discriminatory features for fake news classification through multiple hidden layers built in the deep neural network. We create a deep Convolutional Neural Network (CNN) to extract several features at each layer. We compare the performance of the proposed approach with several baseline models. Benchmarked datasets were used to train and test the model, and the proposed model achieved state-of-the-art results with an accuracy of 98.36% on the test data. Various performance evaluation parameters such as Wilcoxon, false positive, true negative, precision, recall, Fl, and accuracy, etc. were used to validate the results. These results demonstrate significant improvements in the area of fake news detection as compared to existing state-of-the-art results and affirm the potential of our approach for classifying fake news on social media. This research will assist researchers in broadening the understanding of the applicability of CNN-based deep models for fake news detection. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Kaliyar, Rohit Kumar; Goswami, Anurag] Bennett Univ, Dept Comp Sci Engn, Greater Noida, India.
   [Narang, Pratik] BITS Pilani, Dept CSIS, Pilani, Rajasthan, India.
   [Sinha, Soumendu] Cent Elect Engn Res Inst, CSIR, Smart Sensors Area, Pilani, Rajasthan, India.
C3 Birla Institute of Technology & Science Pilani (BITS Pilani); Council of
   Scientific & Industrial Research (CSIR) - India; CSIR - Central
   Electronics Engineering Research Institute (CEERI)
RP Narang, P (corresponding author), BITS Pilani, Dept CSIS, Pilani, Rajasthan, India.
EM rk5370@bennett.edu.in; anurag.goswami@bennett.edu.in;
   pratik.narang@pilani.bits-pila-ni.ac.in; soumendu@ceeri.res.in
RI Sinha, Soumendu/W-7931-2019
OI Sinha, Soumendu/0000-0003-3088-7637
CR Araque O, 2017, EXPERT SYST APPL, V77, P236, DOI 10.1016/j.eswa.2017.02.002
   Basak R, 2019, IEEE T COMPUT SOC SY, V6, P208, DOI 10.1109/TCSS.2019.2895734
   Caliskan A, 2017, SCIENCE, V356, DOI 10.1126/science.aal4230
   Camacho-Collados J, 2016, ARTIF INTELL, V240, P36, DOI 10.1016/j.artint.2016.07.005
   Cerisara C, 2018, COMPUT SPEECH LANG, V47, P175, DOI 10.1016/j.csl.2017.07.009
   Dougherty J., 1995, Machine Learning. Proceedings of the Twelfth International Conference on Machine Learning, P194
   Egele M., 2013, NDSS
   Founta A.-M., 2019, P 11 INT C WEB SCI B, P105
   Fu XH, 2017, NEUROCOMPUTING, V241, P18, DOI 10.1016/j.neucom.2017.01.079
   Ghanem B., 2018, P 1 WORKSH FACT EXTR, P66
   Ghosh Souvick, 2018, Proceedings of the Association for Information Science and Technology, V55, DOI 10.1002/pra2.2018.14505501125
   Giatsoglou M, 2017, EXPERT SYST APPL, V69, P214, DOI 10.1016/j.eswa.2016.10.043
   Gupta S, 2018, 2018 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM), P278, DOI 10.1109/ASONAM.2018.8508408
   Haitam C, 2017, 2017 INTERNATIONAL CONFERENCE ON SMART DIGITAL ENVIRONMENT (ICSDE'17), P127, DOI 10.1145/3128128.3128148
   Huang JW, 2017, 2017 17TH IEEE INTERNATIONAL CONFERENCE ON COMMUNICATION TECHNOLOGY (ICCT 2017), P598, DOI 10.1109/ICCT.2017.8359706
   Iyyer M, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1681
   Kai Shu, 2017, ACM SIGKDD Explorations Newsletter, V19, P22, DOI 10.1145/3137597.3137600
   Kamkarhaghighi M, 2017, EXPERT SYST APPL, V90, P241, DOI 10.1016/j.eswa.2017.08.021
   Karimi H., 2018, P 27 INT C COMP LING, P1546
   Kim Y., 2014, EMNLP
   Kumar S., 2018, ARXIV180408559
   Lebret R, 2015, LECT NOTES COMPUT SC, V9041, P417, DOI 10.1007/978-3-319-18111-0_31
   Liang G, 2015, IEEE TRANS COMPUT SO, V2, P99, DOI 10.1109/TCSS.2016.2517458
   Liu Y., 2018, 32 AAAI C ART INT
   Medhat W, 2014, AIN SHAMS ENG J, V5, P1093, DOI 10.1016/j.asej.2014.04.011
   Mikolov T., 2013, NIPS, V26, P3111
   Mikolov T., 2013, ARXIV13013781
   Nagi J., 2011, 2011 IEEE International Conference on Signal and Image Processing Applications (ICSIPA 2011), P342, DOI 10.1109/ICSIPA.2011.6144164
   OBrien N., 2018, LANGUAGE FAKE NEWS O
   Pan JZ, 2018, LECT NOTES COMPUT SC, V11136, P669, DOI 10.1007/978-3-030-00671-6_39
   Pe rez-Rosas V, 2017, ARXIV170807104
   Pennington J, 2014, EMNLP, P1532, DOI 10.3115/v1/D14-1162
   Persily N, 2017, J DEMOCR, V28, P63, DOI 10.1353/jod.2017.0025
   Potthast M., 2017, ARXIV PREPRINT ARXIV
   Ren YF, 2016, INFORM SCIENCES, V369, P188, DOI 10.1016/j.ins.2016.06.040
   Roy A., 2018, ARXIV181104670
   Ruchansky N, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P797, DOI 10.1145/3132847.3132877
   Seide F., 2011, 2011 IEEE Workshop on Automatic Speech Recognition & Understanding (ASRU), P24, DOI 10.1109/ASRU.2011.6163899
   Shu Kai, 2019, AAAI
   Singh D, 2017, IMAGING SCI J, V65, P108, DOI 10.1080/13682199.2017.1289629
   Stein RA, 2019, INFORM SCIENCES, V471, P216, DOI 10.1016/j.ins.2018.09.001
   Tang DY, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1555
   Vasudevan V, 2019, U.S. Patent Application, Patent No. [16/040,067, 16040067]
   Vishwakarma DK, 2019, COGN SYST RES, V58, P217, DOI 10.1016/j.cogsys.2019.07.004
   Wang Y., 2016, P 2016 C EMPIRICAL M, P606, DOI [10.18653/v1/D16-1058, DOI 10.18653/V1/D16-1058]
   Wang YQ, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P849, DOI 10.1145/3219819.3219903
   Wei W, 2019, LECT NOTES ARTIF INT, V11508, P530, DOI 10.1007/978-3-030-20912-4_48
   Yang Y., 2018, ARXIV180600749
   Zhang HL, 2014, 2014 11TH WEB INFORMATION SYSTEM AND APPLICATION CONFERENCE (WISA), P262, DOI 10.1109/WISA.2014.55
   Zhang X., 2015, ADV NEURAL INFORM PR, V28, P649, DOI DOI 10.1063/1.4906785
   Zhang Y., 2015, ARXIV151003820
   Zhong BT, 2019, ADV ENG INFORM, V40, P46, DOI 10.1016/j.aei.2019.02.009
   Zhou X., 2018, ARXIV181200315
NR 53
TC 37
Z9 37
U1 6
U2 84
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1389-0417
J9 COGN SYST RES
JI Cogn. Syst. Res.
PD JUN
PY 2020
VL 61
BP 32
EP 44
DI 10.1016/j.cogsys.2019.12.005
PG 13
WC Computer Science, Artificial Intelligence; Neurosciences; Psychology,
   Experimental
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Neurosciences & Neurology; Psychology
GA KU9DE
UT WOS:000520021400003
DA 2022-02-06
ER

PT J
AU Choudhary, M
   Chouhan, SS
   Pilli, SE
   Vipparthi, SK
AF Choudhary, Monika
   Chouhan, Satyendra Singh
   Pilli, S. Emmanuel
   Vipparthi, Santosh Kumar
TI BerConvoNet: A deep learning framework for fake news classification
SO APPLIED SOFT COMPUTING
LA English
DT Article
DE Deep learning; Fake news; BERT; CNN; Ablation study
ID CUES
AB Fake news has become a major concern over the Internet. It influences people directly and should be identified. In the recent years, various Machine Learning (ML) and Deep Learning (DL) based data driven approaches have been suggested for fake news classification. Most of the ML based approaches use hand-crafted features extracted from input textual content. Moreover, in DL based approaches, an efficient word embedding representation of input data is also a major concern. This paper presents a deep learning framework, BerConvoNet, to classify the given news text into fake or real with minimal error. The presented framework has two main building blocks: a news embedding block (NEB) and a multi-scale feature block (MSFB). NEB uses Bidirectional Encoder Representations from Transformers (BERT) for extracting word embeddings from a news article. Next, these embeddings are fed as an input to MSFB. The MSFB consists of multiple kernels (filters) of varying sizes. It extracts various features from news word embedding. The output of MSFB is fed as an input to a fully connected layer for classification. To validate the performance of BerConvoNet, several experiments have been performed on four benchmark datasets and various performance measures are used to evaluate the results. Furthermore, the ablative experiments with respect to news article embedding, kernel size, and batch size have been carried out to ensure the quality of prediction. Comparative analysis of the presented model is done with other state of the art models. It shows that BerConvoNet outplays other models on various performance metrics. (C) 2021 Elsevier B.V. All rights reserved.
C1 [Choudhary, Monika; Chouhan, Satyendra Singh; Pilli, S. Emmanuel; Vipparthi, Santosh Kumar] MNIT Jaipur, Dept CSE, Jaipur 302017, Rajasthan, India.
C3 National Institute of Technology (NIT System); Malaviya National
   Institute of Technology Jaipur
RP Chouhan, SS (corresponding author), MNIT Jaipur, Dept CSE, Jaipur 302017, Rajasthan, India.
EM 2019rcp9186@mnit.ac.in; sschouhan.cse@mnit.ac.in;
   espilli.cse@mnit.ac.in; skvipparthi@mnit.ac.in
RI Pilli, Emmanuel/H-7984-2017; Vipparthi, Santosh Kumar/AAV-8694-2020
OI Pilli, Emmanuel/0000-0002-6056-1147; Vipparthi, Santosh
   Kumar/0000-0002-5672-3537
CR A.P. Institute, 2014, SOC DEM DIFF NEWS HA
   Afroz S, 2019, ARXIV190504749
   Ahmed H, 2017, LECT NOTES COMPUT SC, V10618, P127, DOI 10.1007/978-3-319-69155-8_9
   Allcott H, 2017, J ECON PERSPECT, V31, P211, DOI 10.1257/jep.31.2.211
   Baziotis C., 2017, P 11 INT WORKSH SEM, P747, DOI DOI 10.18653/V1/S17-2126
   Ciampaglia GL, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0128193
   De Sarkar Sohan, 2018, 27 INT C COMP LING C, P3371
   DePaulo BM, 2003, PSYCHOL BULL, V129, P74, DOI 10.1037//0033-2909.129.1.74
   Devlin J, 2019, PROC C N AM CHAPTER, P4171, DOI DOI 10.18653/V1/N19-1423
   Dougall D.M., 2020, FINLANDS FAKE 4 DAY
   Feng S., 2012, P 50 ANN M ASS COMP, V50, P171
   Gravanis G, 2019, EXPERT SYST APPL, V128, P201, DOI 10.1016/j.eswa.2019.03.036
   Gupta S, 2018, 2018 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM), P278, DOI 10.1109/ASONAM.2018.8508408
   Hamel L., 2018, FAKE NEWS
   Huang Z, 2020, IEEE ACCESS, V8, P130782, DOI 10.1109/ACCESS.2020.3009393
   Jangid H, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), P1961, DOI 10.1145/3184558.3191827
   Jin ZW, 2016, THIRTIETH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2972
   Jodhani G., 2019, THESIS GB PANT U AGR
   Jwa H, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9194062
   Kaggle, 2018, FAKE NEWS
   Kaliyar RK, 2021, J SUPERCOMPUT, V77, P1015, DOI 10.1007/s11227-020-03294-y
   Karimi Hamid, 2019, ARXIV190307389, V1, P3432
   Kaur P., 2019, INT J ENG ADV TECHNO, V8, P2388
   Ketkar N, 2017, DEEP LEARNING PYTHON, P97, DOI 10.1007/978-1-4842-2766-4_7
   Kim Y., 2014, P EMNLP 2014, P1746, DOI 10.3115/v1/D14-1181
   Lai SW, 2015, PROCEEDINGS OF THE TWENTY-NINTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2267
   Li CB, 2018, 2018 NINTH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY IN MEDICINE AND EDUCATION (ITME 2018), P890, DOI 10.1109/ITME.2018.00199
   Lin YK, 2015, PROCEEDINGS OF THE TWENTY-NINTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2181
   Liu W., 2020, MATEC WEB C, V309, P3015
   Long C., 2020, P ACM C HYP SOC MED, P75
   Pan JZ, 2018, LECT NOTES COMPUT SC, V11136, P669, DOI 10.1007/978-3-030-00671-6_39
   Perez-Rosas V, 2017, ARXIV PREPRINT ARXIV
   Popat Kashyap, 2018, P 2018 C EMP METH NA, P22, DOI DOI 10.18653/V1/D18-1003
   Qian Feng, 2018, IJCAI, P3834
   Reis JCS, 2019, IEEE INTELL SYST, V34, P76, DOI 10.1109/MIS.2019.2899143
   Rubin V.L., 2015, P ASS INFORM SCI TEC, V52, P1, DOI [https://doi.org/10.1002/pra2.2015.145052010083, DOI 10.1002/PRA2.2015.145052010083]
   Rubin Victoria L, 2015, P HAW INT C SYST HIC, P5
   Ruchansky N, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P797, DOI 10.1145/3132847.3132877
   Shi BX, 2016, KNOWL-BASED SYST, V104, P123, DOI 10.1016/j.knosys.2016.04.015
   ShiyaoWang Minlie Huang, 2018, IJCAI, P4468
   Shu K., 2019, FAKENEWSNET
   Shu K., 2019, EMERGING RES CHALLEN, P43, DOI [10.1007/978-3-319-94105-9_3, DOI 10.1007/978-3-319-94105-9_3]
   Shu K, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P395, DOI 10.1145/3292500.3330935
   Shu K, 2019, PROCEEDINGS OF THE TWELFTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'19), P312, DOI 10.1145/3289600.3290994
   Singhania S, 2017, LECT NOTES COMPUT SC, V10635, P572, DOI 10.1007/978-3-319-70096-0_59
   Sitaula N., 2020, DISINFORMATION MISIN, P163
   Socher R, 2014, P 19 C EMPIRICAL MET, V2014, P1532, DOI DOI 10.3115/V1/D14-1162
   Strapparava, 2009, P ACL IJCNLP 2009 C, P309, DOI DOI 10.3115/1667583.1667679
   Tausczik YR, 2010, J LANG SOC PSYCHOL, V29, P24, DOI 10.1177/0261927X09351676
   Thota A, 2018, SMU DATA SCI REV, V1
   Vosoughi S, 2018, SCIENCE, V359, P1146, DOI 10.1126/science.aap9559
   Wang YQ, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P849, DOI 10.1145/3219819.3219903
   Wu L, 2018, WSDM'18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P637, DOI 10.1145/3159652.3159677
   Zhang JW, 2020, PROC INT CONF DATA, P1826, DOI 10.1109/ICDE48307.2020.00180
NR 54
TC 2
Z9 2
U1 3
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1568-4946
EI 1872-9681
J9 APPL SOFT COMPUT
JI Appl. Soft. Comput.
PD OCT
PY 2021
VL 110
AR 107614
DI 10.1016/j.asoc.2021.107614
PG 11
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA WP4IZ
UT WOS:000713098900009
DA 2022-02-06
ER

PT J
AU Yu, CM
   Chen, KC
   Chang, CT
   Ti, YW
AF Yu, Chia-Mu
   Chen, Kang-Cheng
   Chang, Ching-Tang
   Ti, Yen-Wu
TI SegNet: a network for detecting deepfake facial videos
SO MULTIMEDIA SYSTEMS
LA English
DT Article; Early Access
DE Deepfake; Video manipulation
AB Recent advancements in artificial intelligence have made the forgery of digital images and videos easy. Deepfake technology uses a deep learning approach to identify and replace faces in images or videos. It can make people distrust digital content, thereby significantly affecting political and social stability. If the sources of the training and test data are different, the existing solutions for identifying forged images can achieve a considerably low accuracy. In many cases, the detection accuracy is significantly lower than 50%. In this study, we propose SegNet, which is a face-forgery-detection method, to determine whether images or videos have been processed using deepfake technology. By focusing on the changes in various regions of an image and ignoring the characteristics of different forgery techniques, SegNet solves the problem of low detection accuracy. SegNet achieves satisfactory detection accuracy using the recently proposed separable convolutional neural networks, ensemble models, and image segmentation. Moreover, we examine the effects of different image-segmentation methods on the detection results. A comprehensive comparison between SegNet and the existing solutions shows the superior detection capability of SegNet.
C1 [Yu, Chia-Mu] Natl Yang Ming Chiao Tung Univ, Dept Informat Management & Finance, Hsinchu, Taiwan.
   [Chen, Kang-Cheng] Ind Technol Res Inst, Computat Intelligence Technol Ctr, Zhudong, Taiwan.
   [Chang, Ching-Tang] Natl Chung Hsing Univ, Dept Comp Sci & Engn, Taichung, Taiwan.
   [Ti, Yen-Wu] Yango Univ, Coll Artificial Intelligence, Fuzhou, Peoples R China.
C3 National Yang Ming Chiao Tung University; Industrial Technology Research
   Institute - Taiwan; National Chung Hsing University
RP Yu, CM (corresponding author), Natl Yang Ming Chiao Tung Univ, Dept Informat Management & Finance, Hsinchu, Taiwan.
EM chiamuyu@nycu.edu.tw
FU MOST [110-2636-E-009-018]
FX Chia-Mu Yu is supported by MOST 110-2636-E-009-018. We thank to National
   Center for High-performance Computing (NCHC) of National Applied
   Research Laboratories (NARLabs) in Taiwan for providing computational
   and storage resources.
CR Afchar D, 2018, IEEE INT WORKS INFOR
   Agarwal S., 2019, P CVPR WORKSH LONG B, P38
   Barni M, 2017, J VIS COMMUN IMAGE R, V49, P153, DOI 10.1016/j.jvcir.2017.09.003
   Bonettini Nicolo, 2020, INT C PATT REC ICPR
   Cheng J, 2018, IEEE T NEUR NET LEAR, V29, P4730, DOI 10.1109/TNNLS.2017.2774288
   Chintha A, 2020, IEEE J-STSP, V14, P1024, DOI 10.1109/JSTSP.2020.2999185
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Dang H, 2020, PROC CVPR IEEE, P5780, DOI 10.1109/CVPR42600.2020.00582
   Fei JW, 2021, MULTIMED TOOLS APPL, V80, P30789, DOI 10.1007/s11042-020-09147-3
   Gardiner N, 2019, FACIAL RE ENACTMENT
   Guera D, 2018, 2018 15TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P127
   He K., 2016, DEEP RESIDUAL LEARNI, DOI DOI 10.1109/CVPR.2016.90
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Jaiswal Ayush, 2019, ARXIV190500582
   Kakar P, 2011, IEEE T MULTIMEDIA, V13, P443, DOI 10.1109/TMM.2011.2121056
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   King DB, 2015, ACS SYM SER, V1214, P1
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Li YZ, 2018, IEEE INT WORKS INFOR
   Lin M, 2013, ARXIV13124400
   Maheshwari A., 2019, DIGITAL TRANSFORMATI
   Nguyen HH, 2019, INT CONF ACOUST SPEE, P2307, DOI 10.1109/ICASSP.2019.8682602
   Quan Y., 2016, ARXIV200611539
   Simonyan K, 2015, ICLR 2015, DOI DOI 10.1109/CVPR.2015.7298594
   Singh RD, 2017, DIGIT INVEST, V21, P31, DOI 10.1016/j.diin.2017.01.001
   Singh RD, 2017, J CIRCUIT SYST COMP, V26, DOI 10.1142/S0218126617501079
   Su LC, 2018, IEEE T MULTIMEDIA, V20, P825, DOI 10.1109/TMM.2017.2760098
   Tan MX, 2019, PR MACH LEARN RES, V97
   Thies J, 2016, PROC CVPR IEEE, P2387, DOI 10.1109/CVPR.2016.262
   Tolosana R, 2020, INFORM FUSION, V64, P131, DOI 10.1016/j.inffus.2020.06.014
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang Sheng-Yu, 2020, CVPR, V7
   Yang X, 2019, INT CONF ACOUST SPEE, P8261, DOI 10.1109/ICASSP.2019.8683164
   Zhou P, 2018, PROC CVPR IEEE, P1053, DOI 10.1109/CVPR.2018.00116
   Zhou P, 2017, IEEE COMPUT SOC CONF, P1831, DOI 10.1109/CVPRW.2017.229
NR 35
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0942-4962
EI 1432-1882
J9 MULTIMEDIA SYST
JI Multimedia Syst.
DI 10.1007/s00530-021-00876-5
EA JAN 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Theory &
   Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA YF1TV
UT WOS:000741598800002
DA 2022-02-06
ER

PT J
AU Mridha, MF
   Keya, AJ
   Hamid, MA
   Monowar, MM
   Rahman, MS
AF Mridha, M. F.
   Keya, Ashfia Jannat
   Hamid, Md. Abdul
   Monowar, Muhammad Mostafa
   Rahman, Md. Saifur
TI A Comprehensive Review on Fake News Detection With Deep Learning
SO IEEE ACCESS
LA English
DT Review
DE Social networking (online); Deep learning; Natural language processing;
   Machine learning; Convolutional neural networks; Terminology; Feature
   extraction; Natural language processing; machine learning; deep
   learning; fake news
ID RUMOR DETECTION; NEURAL-NETWORK; SOCIAL MEDIA
AB A protuberant issue of the present time is that, organizations from different domains are struggling to obtain effective solutions for detecting online-based fake news. It is quite thought-provoking to distinguish fake information on the internet as it is often written to deceive users. Compared with many machine learning techniques, deep learning-based techniques are capable of detecting fake news more accurately. Previous review papers were based on data mining and machine learning techniques, scarcely exploring the deep learning techniques for fake news detection. However, emerging deep learning-based approaches such as Attention, Generative Adversarial Networks, and Bidirectional Encoder Representations for Transformers are absent from previous surveys. This study attempts to investigate advanced and state-of-the-art fake news detection mechanisms pensively. We begin with highlighting the fake news consequences. Then, we proceed with the discussion on the dataset used in previous research and their NLP techniques. A comprehensive overview of deep learning-based techniques has been bestowed to organize representative methods into various categories. The prominent evaluation metrics in fake news detection are also discussed. Nevertheless, we suggest further recommendations to improve fake news detection mechanisms in future research directions.
C1 [Mridha, M. F.; Keya, Ashfia Jannat; Rahman, Md. Saifur] Bangladesh Univ Business & Technol, Dept Comp Sci & Engn, Dhaka 1216, Bangladesh.
   [Hamid, Md. Abdul; Monowar, Muhammad Mostafa] King Abdulaziz Univ, Dept Informat Technol, Jeddah 21589, Saudi Arabia.
C3 Bangladesh University of Business & Technology (BUBT); King Abdulaziz
   University
RP Mridha, MF (corresponding author), Bangladesh Univ Business & Technol, Dept Comp Sci & Engn, Dhaka 1216, Bangladesh.
EM firoz@bubt.edu.bd
OI Keya, Ashfia Jannat/0000-0002-8553-6546; Mridha, Dr. M.
   Firoz/0000-0001-5738-1631; Hamid, Md Abdul/0000-0001-9698-4726
CR Abdullah-All-Tanvir E. M., 2019, P 7 INT C SMART COMP, P1, DOI 10.1109/ICSCC. 2019.8843612
   Aceto G, 2019, IEEE T NETW SERV MAN, V16, P445, DOI 10.1109/TNSM.2019.2899085
   Adadi A, 2018, IEEE ACCESS, V6, P52138, DOI 10.1109/ACCESS.2018.2870052
   Agarwal A, 2020, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS 2020), P1178, DOI 10.1109/ICICCS48265.2020.9121030
   Ahmed Hadeer, 2018, Security and Privacy, V1, DOI 10.1002/spy2.9
   Ahmed H, 2017, LECT NOTES COMPUT SC, V10618, P127, DOI 10.1007/978-3-319-69155-8_9
   Ahn YC, 2019, INT JOINT CONF COMP, P289, DOI 10.1109/JCSSE.2019.8864171
   Ajao O, 2019, INT CONF ACOUST SPEE, P2507, DOI 10.1109/ICASSP.2019.8683170
   Ajao Oluwaseun, 2018, P 9 INT C SOC MED SO, DOI 10.1145/3217804.3217917
   Al Asaad B, 2019, INT SYMP SYMB NUMERI, P379, DOI 10.1109/SYNASC.2018.00064
   Al-Ahmad B, 2021, SYMMETRY-BASEL, V13, DOI 10.3390/sym13061091
   Albahar M, 2021, IET INFORM SECUR, V15, P169, DOI 10.1049/ise2.12021
   Allcott H, 2017, J ECON PERSPECT, V31, P211, DOI 10.1257/jep.31.2.211
   Aloshban Nujud, 2020, WebSci '20: 12th ACM Conference on Web Science, P115, DOI 10.1145/3394231.3397901
   Alsaeedi A, 2020, ARAB J SCI ENG, V45, P10813, DOI 10.1007/s13369-020-04839-2
   Amine BM, 2019, 2019 INTERNATIONAL CONFERENCE ON ADVANCED ELECTRICAL ENGINEERING (ICAEE)
   Amjad M, 2020, J INTELL FUZZY SYST, V39, P2457, DOI 10.3233/JIFS-179905
   [Anonymous], 2020, YEAR FAKE NEWS COVID
   Aphiwongsophon S, 2018, 2018 15TH INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING/ELECTRONICS, COMPUTER, TELECOMMUNICATIONS AND INFORMATION TECHNOLOGY (ECTI-CON), P528, DOI 10.1109/ECTICon.2018.8620051
   Faustini PHA, 2020, EXPERT SYST APPL, V158, DOI 10.1016/j.eswa.2020.113503
   Asghar MZ, 2021, J AMB INTEL HUM COMP, V12, P4315, DOI 10.1007/s12652-019-01527-4
   Aslam N, 2021, COMPLEXITY, V2021, DOI 10.1155/2021/5557784
   Bahad P, 2019, PROCEDIA COMPUT SCI, V165, P74, DOI 10.1016/j.procs.2020.01.072
   Bali APS, 2019, INT C ADV COMP DAT S
   Ben Veyseh AP, 2019, PROCEEDINGS OF THE 2019 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2019), P113, DOI 10.1145/3341161.3342896
   Bhatt G, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), P1353, DOI 10.1145/3184558.3191577
   Bhutani B., 2019, 2019 12 INT C CONT C, P1, DOI 10.1109/IC3.2019.8844880
   Bian T, 2020, AAAI CONF ARTIF INTE, V34, P549
   Boididou C, 2018, INT J MULTIMED INF R, V7, P71, DOI 10.1007/s13735-017-0143-x
   Bondielli A, 2019, INFORM SCIENCES, V497, P38, DOI 10.1016/j.ins.2019.05.035
   Bugueno M, 2019, LECT NOTES COMPUT SC, V11578, P293, DOI 10.1007/978-3-030-21902-4_21
   Castillo C., 2011, WWW, P675
   Chen T, 2018, LECT NOTES ARTIF INT, V11154, P40, DOI 10.1007/978-3-030-04503-6_4
   Choudhary A, 2021, EXPERT SYST APPL, V169, DOI 10.1016/j.eswa.2020.114171
   Collins B, 2021, J INFORM TELECOMMUN, V5, P247, DOI 10.1080/24751839.2020.1847379
   Conroy NJ, 2015, P ASS INF SCI TECHN, V51, P1, DOI [10.1002/pra2.2015.145052010082, DOI 10.1002/PRA2.2015.145052010082]
   Deepak S, 2020, PROCEDIA COMPUT SCI, V167, P2236, DOI 10.1016/j.procs.2020.03.276
   Della Vedova ML, 2018, PROC CONF OPEN INNOV, P272, DOI 10.23919/FRUCT.2018.8468301
   Devlin J, 2019, PROC C N AM CHAPTER, P4171, DOI DOI 10.18653/V1/N19-1423
   Ding J., 2020, P 6 INT C COMP ART I, P396, DOI [10.1145/3404555.3404607, DOI 10.1145/3404555.3404607]
   Dong MQ, 2018, LECT NOTES COMPUT SC, V11233, P199, DOI 10.1007/978-3-030-02922-7_14
   Elhadad MK, 2019, IEEE PAC RIM CONF CO
   Fernandez-Reyes FC, 2018, LECT NOTES ARTIF INT, V11238, P206, DOI 10.1007/978-3-030-03928-8_17
   Ghanem B, 2020, ACM T INTERNET TECHN, V20, DOI 10.1145/3381750
   Giachanou A, 2020, PR INT CONF DATA SC, P647, DOI 10.1109/DSAA49011.2020.00091
   Giachanou A, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P877, DOI 10.1145/3331184.3331285
   Girgis S, 2018, PROCEEDINGS OF 2018 13TH INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING AND SYSTEMS (ICCES), P93, DOI 10.1109/ICCES.2018.8639198
   Golbeck J, 2018, WEBSCI'18: PROCEEDINGS OF THE 10TH ACM CONFERENCE ON WEB SCIENCE, P17, DOI 10.1145/3201064.3201100
   Granik M, 2017, 2017 IEEE FIRST UKRAINE CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING (UKRCON), P900, DOI 10.1109/UKRCON.2017.8100379
   Gravanis G, 2019, EXPERT SYST APPL, V128, P201, DOI 10.1016/j.eswa.2019.03.036
   Guo H, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P943, DOI 10.1145/3269206.3271709
   Habib A, 2019, SOC NETW ANAL MIN, V9, DOI 10.1007/s13278-019-0595-5
   Hakak S, 2021, FUTURE GENER COMP SY, V117, P47, DOI 10.1016/j.future.2020.11.022
   Helmstetter S, 2018, 2018 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM), P274, DOI 10.1109/ASONAM.2018.8508520
   Hiramath Chaitra K., 2019, 2019 1st International Conference on Advances in Information Technology (ICAIT). Proceedings, P411, DOI 10.1109/ICAIT47043.2019.8987258
   Hiriyannaiah S., 2020, HYBRID COMPUTATIONAL, P69
   Hossain MZ, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P2862
   Hosseinzadeh S, 2019, POLYM BULL, V76, P4827, DOI 10.1007/s00289-018-2618-1
   Hu BB, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P120, DOI 10.1145/3292500.3330970
   Huang CR, 2017, P 8 INT JOINT C NAT, V2, P252
   Huang Q, 2019, IEEE IJCNN
   Hussain MG, 2020, 2020 INTERNATIONAL CONFERENCE ON COMPUTING, ELECTRONICS & COMMUNICATIONS ENGINEERING (ICCECE, P81, DOI 10.1109/iCCECE49321.2020.9231167
   Ibrishimova M. D., 2019, P INT C INT NETW COL, P223
   Jadhav SS, 2019, APPL ARTIF INTELL, V33, P1058, DOI 10.1080/08839514.2019.1661579
   Jain Akshat, 2018, 2018 International Conference on Sustainable Energy, Electronics, and Computing Systems (SEEMS)
   Jin ZW, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P795, DOI 10.1145/3123266.3123454
   Jin ZW, 2016, THIRTIETH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2972
   Jwa H, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9194062
   Kai Shu, 2017, ACM SIGKDD Explorations Newsletter, V19, P22, DOI 10.1145/3137597.3137600
   Kaliyar Rohit, 2018, 2018 4 INT C COMP CO, P1
   Kaliyar RK, 2021, MULTIMED TOOLS APPL, V80, P11765, DOI 10.1007/s11042-020-10183-2
   Kaliyar RK, 2021, NEURAL COMPUT APPL, V33, P8597, DOI 10.1007/s00521-020-05611-1
   Kaliyar RK, 2021, J SUPERCOMPUT, V77, P1015, DOI 10.1007/s11227-020-03294-y
   Kaliyar RK, 2020, COGN SYST RES, V61, P32, DOI 10.1016/j.cogsys.2019.12.005
   Kamath U., 2019, DEEP LEARNING NLP SP, V84
   Kapusta J, 2020, INFORMATICS-BASEL, V7, DOI 10.3390/informatics7010004
   Karimi H., 2018, P 27 INT C COMP LING, P1546
   Khattar D, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P2915, DOI 10.1145/3308558.3313552
   Kim J, 2018, WSDM'18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P324, DOI 10.1145/3159652.3159734
   Kotteti CMM, 2018, 2018 16TH IEEE INT CONF ON DEPENDABLE, AUTONOM AND SECURE COMP, 16TH IEEE INT CONF ON PERVAS INTELLIGENCE AND COMP, 4TH IEEE INT CONF ON BIG DATA INTELLIGENCE AND COMP, 3RD IEEE CYBER SCI AND TECHNOL CONGRESS (DASC/PICOM/DATACOM/CYBERSCITECH), P187, DOI 10.1109/DASC/PiCom/DataCom/CyberSciTec.2018.00042
   Krishna AN, 2020, 2020 IEEE INT C EL C, P1, DOI [10.1109/CONECCT50063.2020.9198610, DOI 10.1109/CONECCT50063.2020.9198610]
   Kula S., 2019, P COMP INT SEC INF S, P239
   Kumar S, 2020, T EMERG TELECOMMUN T, V31, DOI 10.1002/ett.3767
   Kumari R, 2021, EXPERT SYST APPL, V184, DOI 10.1016/j.eswa.2021.115412
   Le Q., 2014, P 31 INT C INT C MAC
   Li LZ, 2018, 2018 IEEE 3RD INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC), P755, DOI 10.1109/ICIVC.2018.8492819
   Li Q, 2020, PERS UBIQUIT COMPUT, V24, P259, DOI 10.1007/s00779-019-01289-y
   Li Y, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1715, DOI 10.1145/3219819.3219956
   Liao Q., 2021, IEEE T KNOWL DATA EN, DOI [10.1109/TKDE.2021.3054993, DOI 10.1109/TKDE.2021.3054993]
   Lu YJ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P505
   Ma J., 2016, P 25 INT JOINT C ART, P3818
   Ma J, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P708, DOI 10.18653/v1/P17-1066
   Mangal Deepak, 2020, 2020 8th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO), P68, DOI 10.1109/ICRITO48877.2020.9197817
   Meel P, 2020, EXPERT SYST APPL, V153, DOI 10.1016/j.eswa.2019.112986
   Mikolov T., 2013, P INT C LEARN REPR I, DOI DOI 10.5555/2999792.2999959
   Monti F., 2019, ICLR 2019 WORKSH REP
   Nascita A., 2021, IEEE T NETW SERVICE, DOI [10.1109/TNSM.2021.3098157, DOI 10.1109/TNSM.2021.3098157]
   Nasir J. A., 2021, INT J INF MANAGE DAT, V1, DOI DOI 10.1016/J.JJIMEI.2020.100007
   O'Shea T, 2017, IEEE T COGN COMMUN, V3, P563, DOI 10.1109/TCCN.2017.2758370
   Ozbay FA, 2020, PHYSICA A, V540, DOI 10.1016/j.physa.2019.123174
   Padnekar S. M., 2020, P INT C DAT SCI ENG, P1
   Parikh SB, 2018, IEEE 1ST CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2018), P436, DOI 10.1109/MIPR.2018.00093
   Pathak AR, 2020, PROCEDIA COMPUT SCI, V167, P2286, DOI 10.1016/j.procs.2020.03.281
   Popat Kashyap, 2018, P 2018 C EMP METH NA, P22, DOI DOI 10.18653/V1/D18-1003
   Potthast M., 2017, ARXIV PREPRINT ARXIV
   Providel Eliana, 2020, Social Computing and Social Media. Design, Ethics, User Behavior, and Social Network Analysis. 12th International Conference, SCSM 2020 Held as Part of the 22nd HCI International Conference, HCII 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12194), P321, DOI 10.1007/978-3-030-49570-1_22
   Qawasmeh E, 2019, 2019 SIXTH INTERNATIONAL CONFERENCE ON SOCIAL NETWORKS ANALYSIS, MANAGEMENT AND SECURITY (SNAMS), P383, DOI 10.1109/SNAMS.2019.8931873
   Qi P, 2019, IEEE DATA MINING, P518, DOI 10.1109/ICDM.2019.00062
   Rasool T, 2019, INT CONF COMPUT AUTO, P73, DOI 10.1145/3313991.3314008
   Reddy H, 2020, INT J AUTOM COMPUT, V17, P210, DOI 10.1007/s11633-019-1216-5
   Reis JCS, 2019, P 10 ACM C WEB SCI A, P17, DOI [10.1145/3292522.3326027, DOI 10.1145/3292522.3326027]
   Ren YX, 2020, IEEE DATA MINING, P452, DOI 10.1109/ICDM50108.2020.00054
   Rong Y, 2019, ARXIV190710903
   Ruchansky N, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P797, DOI 10.1145/3132847.3132877
   Rusli Andre, 2020, 2020 IEEE International Conference on Industry 4.0, Artificial Intelligence, and Communications Technology (IAICT). Proceedings, P86, DOI 10.1109/IAICT50021.2020.9172020
   Sahoo SR, 2021, APPL SOFT COMPUT, V100, DOI 10.1016/j.asoc.2020.106983
   Saikh T, 2019, LECT NOTES COMPUT SC, V11608, P345, DOI 10.1007/978-3-030-23281-8_30
   Sangamnerkar S., 2020, P INT C EM TECHN INC, P1
   Savyan P., 2020, MULTIMEDIA TOOLS APP, V79, P1
   Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605
   Shabani S, 2018, 2018 4TH IEEE INTERNATIONAL CONFERENCE ON COLLABORATION AND INTERNET COMPUTING (CIC 2018), P299, DOI 10.1109/CIC.2018.00048
   Sharma K, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3305260
   Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI [10.1146/annurev-bioeng-071516-044442, 10.1146/annurev-bioeng-071516044442]
   Shishah W, 2021, ARAB J SCI ENG, V46, P9115, DOI 10.1007/s13369-021-05780-8
   Shu A. S. K., 1970, SOCIAL NETW COMPUT S, V1, P1
   Shu K, 2020, BIG DATA-US, V8, P171, DOI 10.1089/big.2020.0062
   Shu K, 2019, PROCEEDINGS OF THE 2019 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2019), P436, DOI 10.1145/3341161.3342927
   Shu K, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P395, DOI 10.1145/3292500.3330935
   Shu K, 2019, PROCEEDINGS OF THE TWELFTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'19), P312, DOI 10.1145/3289600.3290994
   Shu K, 2018, IEEE 1ST CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2018), P430, DOI 10.1109/MIPR.2018.00092
   Singhania S, 2017, LECT NOTES COMPUT SC, V10635, P572, DOI 10.1007/978-3-319-70096-0_59
   Socher R, 2014, P 19 C EMPIRICAL MET, V2014, P1532, DOI DOI 10.3115/V1/D14-1162
   Tacchini E., 2017, ARXIV170407506, DOI DOI 10.1257/JEP.31.2.211
   Le T, 2020, IEEE DATA MINING, P282, DOI [10.1109/ICDM50108.2020.00037, 10.1109/CSCI51800.2020.00054]
   Thota A, 2018, SMU DATA SCI REV, V1
   Tiwari V, 2020, IR SIG SYST CON, P192
   Umer M, 2020, IEEE ACCESS, V8, P156695, DOI 10.1109/ACCESS.2020.3019735
   Veres M, 2020, IEEE T INTELL TRANSP, V21, P3152, DOI 10.1109/TITS.2019.2929020
   Verma A.K, 2019, P 4 IEEE INT C INT T, P1, DOI 10.1109/NPEC47332.2019.9034706
   Vishwakarma DK, 2019, COGN SYST RES, V58, P217, DOI 10.1016/j.cogsys.2019.07.004
   Wang, 2018, ARXIV181100770
   Wang, 2018, ARXIV180901286
   Wang J, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P515, DOI 10.1145/3077136.3080786
   Wang WY, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P422, DOI 10.18653/v1/P17-2067
   Wang YQ, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P849, DOI 10.1145/3219819.3219903
   Waszak PM, 2018, HEALTH POLICY TECHN, V7, P115, DOI 10.1016/j.hlpt.2018.03.002
   Wu L, 2018, WSDM'18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P637, DOI 10.1145/3159652.3159677
   Wu LW, 2018, LECT NOTES COMPUT SC, V11186, P323, DOI 10.1007/978-3-030-01159-8_31
   Wu ZY, 2020, EXPERT SYST APPL, V158, DOI 10.1016/j.eswa.2020.113595
   Yildirim P, 2018, 2018 3RD INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND ENGINEERING (UBMK), P22, DOI 10.1109/UBMK.2018.8566611
   Yu PS, 2018, ARXIV180600749, DOI DOI 10.1145/3070644
   Yuan H, 2021, DECIS SUPPORT SYST, V151, DOI 10.1016/j.dss.2021.113633
   Zhang JW, 2020, PROC INT CONF DATA, P1826, DOI 10.1109/ICDE48307.2020.00180
   Zhang L, 2021, MACH LEARN KNOW EXTR, V3, P84, DOI 10.3390/make3010005
   Zhang T, 2020, IEEE IJCNN
   Zhang X., 2019, ARXIV190301728
   Zhang XC, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.03.004
   Zhou X., 2020, DIGITAL THREATS RES, DOI 10.1145/3377478
   Zhou XY, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3395046
   Zhou XY, 2019, COMPANION OF THE WORLD WIDE WEB CONFERENCE (WWW 2019 ), P1292, DOI 10.1145/3308560.3316476
   Zubiaga A., 2016, ARXIV161007363
   Zubiaga A, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3161603
NR 162
TC 0
Z9 0
U1 14
U2 14
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2021
VL 9
BP 156151
EP 156170
DI 10.1109/ACCESS.2021.3129329
PG 20
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA XG0RY
UT WOS:000724470100001
OA gold
DA 2022-02-06
ER

PT J
AU Liu, Y
   Wu, YFB
AF Liu, Yang
   Wu, Yi-Fang Brook
TI FNED: A Deep Network for Fake News Early Detection on Social Media
SO ACM TRANSACTIONS ON INFORMATION SYSTEMS
LA English
DT Article
DE Fake news detection; social media; deep learning
AB The fast spreading of fake news stories on social media can cause inestimable social harm. Developing effective methods to detect them early is of paramount importance. A major challenge of fake news early detection is fully utilizing the limited data observed at the early stage of news propagation and then learning useful patterns from it for identifying fake news. In this article, we propose a novel deep neural network to detect fake news early. It has three novel components: (1) a status-sensitive crowd response feature extractor that extracts both text features and user features from combinations of users' text response and their corresponding user profiles, (2) a position-aware attention mechanism that highlights important user responses at specific ranking positions, and (3) a multi-region mean-pooling mechanism to perform feature aggregation based on multiple window sizes. Experimental results on two real-world datasets demonstrate that our proposed model can detect fake news with greater than 90% accuracy within 5 minutes after it starts to spread and before it is retweeted 50 times, which is significantly faster than state-of-the-art baselines. Most importantly, our approach requires only 10% labeled fake news samples to achieve this effectiveness under PU-Learning settings.
C1 [Liu, Yang; Wu, Yi-Fang Brook] New Jersey Inst Technol, 323 Dr MLK Jr Blvd, Newark, NJ 07102 USA.
C3 New Jersey Institute of Technology
RP Liu, Y (corresponding author), New Jersey Inst Technol, 323 Dr MLK Jr Blvd, Newark, NJ 07102 USA.
EM yl558@njit.edu; yi-fang.wu@njit.edu
RI Liu, Yang/AAM-6557-2020
CR Afroz S, 2012, P IEEE S SECUR PRIV, P461, DOI 10.1109/SP.2012.34
   Bing L, 2003, THIRD IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P179, DOI 10.1109/icdm.2003.1250918
   Blitz Marc Jonathan, 2018, OKLA L REV, V71, P59
   Castillo C., 2011, WWW, P675
   Chen Tong, 2017, ARXIV170405973
   Cho K., 2014, ARXIV14090473
   Chowdhury GG, 2003, ANNU REV INFORM SCI, V37, P51, DOI 10.1002/aris.1440370103
   Conroy NJ, 2015, P ASS INF SCI TECHN, V51, P1, DOI [10.1002/pra2.2015.145052010082, DOI 10.1002/PRA2.2015.145052010082]
   Dhar J, 2016, SOC NETW ANAL MIN, V6, DOI 10.1007/s13278-016-0366-5
   El Ballouli R., 2017, P 3 AR NAT LANG PROC, P62
   Galitsky Boris, 2015, P 2015 AAAI SPRING S
   Guo H, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P943, DOI 10.1145/3269206.3271709
   Gupta A, 2014, LECT NOTES COMPUT SC, V8851, P228, DOI 10.1007/978-3-319-13734-6_16
   Gupta MP, 2012, PROCEEDINGS OF THE ASME PACIFIC RIM TECHNICAL CONFERENCE AND EXHIBITION ON PACKAGING AND INTEGRATION OF ELECTRONIC AND PHOTONIC SYSTEMS, MEMS AND NEMS 2011, VOL 2, P153
   Hsieh CJ, 2015, PR MACH LEARN RES, V37, P2445
   Hu X, 2013, P 23 INT JOINT C ART, P2633
   Jain A, 2016, SOC NETW ANAL MIN, V6, DOI 10.1007/s13278-016-0373-6
   Jain S, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2015, DOI 10.1109/ICACCI.2016.7732347
   Jin Fang, 2013, P 7 WORKSH SOC NETW, V8, p[1, 3], DOI DOI 10.1145/2501025.2501027
   Jin ZW, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P795, DOI 10.1145/3123266.3123454
   Jin ZW, 2017, IEEE T MULTIMEDIA, V19, P598, DOI 10.1109/TMM.2016.2617078
   Kai Shu, 2017, ACM SIGKDD Explorations Newsletter, V19, P22, DOI 10.1145/3137597.3137600
   KeWu Song Yang, 2015, P 31 IEEE INT C DAT
   Kwon S, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0168344
   Kwon S, 2013, IEEE DATA MINING, P1103, DOI 10.1109/ICDM.2013.61
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee W. S., 2003, P 20 INT C MACH LEAR, P448, DOI DOI 10.1016/J.TCS.2005.09.007
   LI CL, 2017, CONCURRENCY COMPUTAT, V0030, pE4281
   Li T, 2015, INT C ELECTR MACH SY, P1752, DOI 10.1109/ICEMS.2015.7385324
   Li X., 2003, IJCAI, P587
   Li XL, 2005, LECT NOTES ARTIF INT, V3720, P218
   Liu B., 2002, P 19 INT C ICML SYDN, V2, P387
   Liu SG, 2017, COMPUT SECUR, V69, P35, DOI 10.1016/j.cose.2016.12.004
   Liu X., 2015, P 24 ACM INT C INF K, P1867, DOI DOI 10.1145/2806416.2806651
   Liu Y.F., 2016, PIPELINE TECH EQUIP, V02, P46
   Liu YH, 2017, LECT NOTES ARTIF INT, V10234, P407, DOI 10.1007/978-3-319-57454-7_32
   Liu Yang, 2015, Soc Comput Behav Cult Model Predict (2015), V9021, P121, DOI 10.1007/978-3-319-16268-3_13
   Liu Yang, 2018, P 32 AAAI C ART INT
   Lukasik M, 2019, ACM T INFORM SYST, V37, DOI 10.1145/3295823
   Ma J., 2016, P 25 INT JOINT C ART, P3818
   Ma J, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P3049, DOI 10.1145/3308558.3313741
   Ma J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1980
   Ma J, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P708, DOI 10.18653/v1/P17-1066
   Menczer F., 2009, P 5 INT WORKSH ADV I, P41, DOI DOI 10.1145/1531914.1531924
   Mikolov T., 2013, NIPS, V26, P3111
   Mnih V, 2014, P 27 INT C NEURAL IN, V2, P2204
   Popat K, 2017, WWW'17 COMPANION: PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P735, DOI 10.1145/3041021.3053379
   Qazvinian V., 2011, P 2011 C EMP METH NA, P1589
   Rubin V., 2016, P 2 WORKSH COMP APPR, P7, DOI DOI 10.18653/V1/W16-0802
   Rubin V.L., 2015, P ASS INFORM SCI TEC, V52, P1, DOI [https://doi.org/10.1002/pra2.2015.145052010083, DOI 10.1002/PRA2.2015.145052010083]
   Rubin V. L., 2017, SAGE HDB SOCIAL MEDI, P342
   Ruchansky N, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P797, DOI 10.1145/3132847.3132877
   Sampson J, 2016, CIKM'16: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P2377, DOI 10.1145/2983323.2983697
   Shengyun Sun, 2013, Web Technologies and Applications. 15th Asia-Pacific Web Conference, APWeb 2013. Proceedings, P120, DOI 10.1007/978-3-642-37401-2_14
   Shu K, 2018, IEEE 1ST CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2018), P430, DOI 10.1109/MIPR.2018.00092
   Shu Kai, 2019, AAAI
   Spencer S, 2016, INT CONF ACOUST SPEE, P2199, DOI 10.1109/ICASSP.2016.7472067
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Tang WB, 2019, IEEE ACCESS, V7, P29193, DOI 10.1109/ACCESS.2019.2901756
   Tolosi Laura, 2016, P 10 INT AAAI C ART
   Vosoughi S., 2015, THESIS
   Vosoughi S, 2018, SCIENCE, V359, P1146, DOI 10.1126/science.aap9559
   Wang D, 2011, P 8 ANN COLL EL MESS, P46, DOI DOI 10.1145/2030376.2030382
   Wang SH, 2015, PROCEEDINGS 2015 IEEE INTERNATIONAL CONFERENCE ON BIG DATA, P2709, DOI 10.1109/BigData.2015.7364071
   Wang YQ, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P849, DOI 10.1145/3219819.3219903
   Wu L., 2017, P 2017 SIAM INT C DA, P99
   Yang F., P MDS 12 ACM SIGKDD, DOI [10.1145/2350190.2350203, DOI 10.1145/2350190.2350203]
   Yang YK, 2015, INT JOINT CONF COMP, P41, DOI 10.1109/JCSSE.2015.7219767
   Yang ZF, 2015, 2015 12TH WEB INFORMATION SYSTEM AND APPLICATION CONFERENCE (WISA), P53, DOI 10.1109/WISA.2015.19
   Yu H., 2002, P 8 ACM SIGKDD INT C, P239, DOI DOI 10.1145/775047.775083
   Zeiler M.D., 2012, ARXIV12125701
   Zhang HL, 2016, ACM T INFORM SYST, V34, DOI 10.1145/2885494
   Zhang Q, 2015, LECT NOTES ARTIF INT, V9362, P113, DOI 10.1007/978-3-319-25207-0_10
   Zhao Z, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P1395, DOI 10.1145/2736277.2741637
   Zheng L, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P765, DOI 10.1109/ICDSP.2015.7251979
   Zubiaga A, 2017, INT C SOC INF, P109
   Zubiaga A., 2016, ARXIV161007363
NR 77
TC 15
Z9 15
U1 18
U2 27
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1046-8188
EI 1558-2868
J9 ACM T INFORM SYST
JI ACM Trans. Inf. Syst.
PD JUN
PY 2020
VL 38
IS 3
AR 25
DI 10.1145/3386253
PG 33
WC Computer Science, Information Systems
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OJ0YZ
UT WOS:000583695800005
DA 2022-02-06
ER

PT J
AU Samadi, M
   Mousavian, M
   Momtazi, S
AF Samadi, Mohammadreza
   Mousavian, Maryam
   Momtazi, Saeedeh
TI Deep contextualized text representation and learning for fake news
   detection
SO INFORMATION PROCESSING & MANAGEMENT
LA English
DT Article
DE Fake news detection; Deep neural network; Contextualized text
   representation
AB In recent years, due to the widespread use of social media and broadcasting agencies around the world, people are extremely exposed to being affected by false information and fake news, all of which have negative impacts on both collective thoughts and governments' policies. In recent years, the great success of pre-trained models for embedding contextual information from texts motivates researchers to utilize these embeddings in different natural language processing tasks. However, in a complex task like fake news detection, it is not determined which contextualized embedding can assist the classifier with more valuable features. Due to the lack of a comparative study about utilizing different contextualized pre-trained models besides distinct neural classifiers, we aim to dive into a comparative study about using different classifiers and embedding models. In this paper, we propose three classifiers with different pretrained models for embedding input news articles. We connect Single-Layer Perceptron (SLP), Multi-Layer Perceptron (MLP), and Convolutional Neural Network (CNN) after the embedding layer which consists of novel pre-trained models such as BERT, RoBERTa, GPT2, and Funnel Transformer in order to benefit from deep contextualized representation provided by those models as well as deep neural classifications. We evaluate our proposed models on three wellknown fake news datasets: LIAR (Wang, 2017), ISOT (Ahmed et al., 2017), and COVID-19 Patwa et al. (2020). The results on these three datasets show the superiority of our proposed models for fake news detection compared to the state-of-the-art models. The results show 7% and 0.1% improvements in classification accuracy compared to the proposed model by Goldani et al. (2021) on LIAR and ISOT, respectively. We also achieved 1% improvement compared to the proposed model by Shifath et al. (2021) on the COVID-19 dataset.
C1 [Samadi, Mohammadreza; Mousavian, Maryam; Momtazi, Saeedeh] Amirkabir Univ Technol, Comp Engn Dept, Tehran, Iran.
C3 Amirkabir University of Technology
RP Momtazi, S (corresponding author), Amirkabir Univ Technol, Comp Engn Dept, Tehran, Iran.
EM mhmd.samadi@aut.ac.ir; maryam.mousavian@aut.ac.ir; momtazi@aut.ac.ir
OI Samadi, Mohammadreza/0000-0002-9297-1693
CR Ahmed H, 2017, LECT NOTES COMPUT SC, V10618, P127, DOI 10.1007/978-3-319-69155-8_9
   Amjad M, 2020, J INTELL FUZZY SYST, V39, P2457, DOI 10.3233/JIFS-179905
   Antoun Wissam, 2020, 2020 IEEE International Conference on Informatics, IoT, and Enabling Technologies (ICIoT), P519, DOI 10.1109/ICIoT48696.2020.9089487
   Bojanowski P., 2017, TACL, V5, P135, DOI [DOI 10.1162/TACL_A_00051, 10.1162/tacl_a_00051]
   Chao Liu, 2019, Knowledge Science, Engineering and Management. 12th International Conference, KSEM 2019. Proceedings: Lecture Notes in Artificial Intelligence (LNAI 11776), P172, DOI 10.1007/978-3-030-29563-9_17
   Chollet F., 2015, GITHUB REPOS
   Clark K.., 2020, P INT C LEARN REPR I
   Dai Z., 2020, ABS200603236 CORR
   Devlin J, 2019, PROC C N AM CHAPTER, P4171, DOI DOI 10.18653/V1/N19-1423
   Goldani MH, 2021, APPL SOFT COMPUT, V101, DOI 10.1016/j.asoc.2020.106991
   Goldani MH, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2020.102418
   Granik M, 2017, 2017 IEEE FIRST UKRAINE CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING (UKRCON), P900, DOI 10.1109/UKRCON.2017.8100379
   Hakak S, 2021, FUTURE GENER COMP SY, V117, P47, DOI 10.1016/j.future.2020.11.022
   Horne BD, 2017, THIS JUST FAKE NEWS, P9
   Huang CR, 2017, P 8 INT JOINT C NAT, V2, P252
   Huang YF, 2020, EXPERT SYST APPL, V159, DOI 10.1016/j.eswa.2020.113584
   Kaliyar RK, 2020, COGN SYST RES, V61, P32, DOI 10.1016/j.cogsys.2019.12.005
   Khattar D, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P2915, DOI 10.1145/3308558.3313552
   Krizhevsky A., 2012, ADV NEURAL INF PROCE, P1097, DOI DOI 10.1145/3065386
   Lazer DMJ, 2018, SCIENCE, V359, P1094, DOI 10.1126/science.aao2998
   Liu Y., 2019, ARXIV190711692
   Ma J, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P708, DOI 10.18653/v1/P17-1066
   Mikolov T., 2013, NIPS, V26, P3111
   Nagel S., 2016, CC NEWS
   Ozbay FA, 2020, PHYSICA A, V540, DOI 10.1016/j.physa.2019.123174
   Patwa P., 2021, COMBATING ONLINE HOS, P21
   Pennington J., 2014, EMNLP, P1532, DOI [10.3115/v1/D14-1162, DOI 10.3115/V1/D14-1162]
   Peters ME, 2018, P C N AM CHAPT ASS C, DOI DOI 10.18653/V1/N18-1202
   Posadas-Duran JP, 2019, J INTELL FUZZY SYST, V36, P4869, DOI 10.3233/JIFS-179034
   Radford A., 2019, LANGUAGE MODELS ARE, V1, P9
   Shifath S., 2021, ABS210112027 CORR
   Silverman C., 2016, BUZZFEED NEWS 0125
   Simonyan K, 2015, ICLR 2015, DOI DOI 10.1109/CVPR.2015.7298594
   Tacchini E., 2017, ARXIV170407506, DOI DOI 10.1257/JEP.31.2.211
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang WY, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P422, DOI 10.18653/v1/P17-2067
   Wani A., 2021, COMBATING ONLINE HOS, P153
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Zhang D., 2018, ABS180408166 CORR
   Zhang JW, 2020, PROC INT CONF DATA, P1826, DOI 10.1109/ICDE48307.2020.00180
   Zhang T, 2020, IEEE IJCNN
NR 41
TC 1
Z9 1
U1 10
U2 10
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 0306-4573
EI 1873-5371
J9 INFORM PROCESS MANAG
JI Inf. Process. Manage.
PD NOV
PY 2021
VL 58
IS 6
AR 102723
DI 10.1016/j.ipm.2021.102723
PG 13
WC Computer Science, Information Systems; Information Science & Library
   Science
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Information Science & Library Science
GA US8TR
UT WOS:000697699500003
DA 2022-02-06
ER

PT J
AU Hajek, P
   Barushka, A
   Munk, M
AF Hajek, Petr
   Barushka, Aliaksandr
   Munk, Michal
TI Fake consumer review detection using deep neural networks integrating
   word embeddings and emotion mining
SO NEURAL COMPUTING & APPLICATIONS
LA English
DT Review
DE Neural network; Deep learning; Fake review; Review spam; Word embedding;
   Emotion
ID OPINION SPAM DETECTION; SENTIMENT ANALYSIS; PRODUCT REVIEWS; SOCIAL
   NETWORKS; FRAMEWORK
AB Fake consumer review detection has attracted much interest in recent years owing to the increasing number of Internet purchases. Existing approaches to detect fake consumer reviews use the review content, product and reviewer information and other features to detect fake reviews. However, as shown in recent studies, the semantic meaning of reviews might be particularly important for text classification. In addition, the emotions hidden in the reviews may represent another potential indicator of fake content. To improve the performance of fake review detection, here we propose two neural network models that integrate traditional bag-of-words as well as the word context and consumer emotions. Specifically, the models learn document-level representation by using three sets of features: (1) n-grams, (2) word embeddings and (3) various lexicon-based emotion indicators. Such a high-dimensional feature representation is used to classify fake reviews into four domains. To demonstrate the effectiveness of the presented detection systems, we compare their classification performance with several state-of-the-art methods for fake review detection. The proposed systems perform well on all datasets, irrespective of their sentiment polarity and product category.
C1 [Hajek, Petr; Barushka, Aliaksandr] Univ Pardubice, Inst Syst Engn & Informat, Fac Econ & Adm, Studentska 84, Pardubice 53210, Czech Republic.
   [Munk, Michal] Constantine Philosopher Univ Nitra, Dept Comp Sci, Nitra 94974, Slovakia.
C3 University of Pardubice; Constantine the Philosopher University in Nitra
RP Hajek, P (corresponding author), Univ Pardubice, Inst Syst Engn & Informat, Fac Econ & Adm, Studentska 84, Pardubice 53210, Czech Republic.
EM petr.hajek@upce.cz; aliaksandr.barushka@student.upce.cz; mmunk@ukf.sk
RI Munk, Michal/N-1724-2017; Munk, Michal/AAE-7199-2020
OI Munk, Michal/0000-0002-9913-3596; Hajek, Petr/0000-0001-5579-1215
FU scientific research project of the Czech Sciences Foundation Grant
   [19-15498S]; Operational Program: Research and Innovation project "Fake
   news on the Internet-identification, content analysis, emotions'';
   European Regional Development FundEuropean Commission
FX This article was supported by the scientific research project of the
   Czech Sciences Foundation Grant No: 19-15498S and by the Operational
   Program: Research and Innovation project "Fake news on the
   Internet-identification, content analysis, emotions'', co-funded by the
   European Regional Development Fund.
CR Ahmed Hadeer, 2018, Security and Privacy, V1, DOI 10.1002/spy2.9
   Ahmed K, 2015, IEEE SYS MAN CYBERN, P2174, DOI 10.1109/SMC.2015.380
   [Anonymous], 2015, J BIG DATA-GER, DOI [10.1186/s40537-015-0029-9, DOI 10.1186/S40537-015-0029-9]
   [Anonymous], 2018, TIMES
   [Anonymous], 2012, P 18 ACM SIGKDD INT, DOI DOI 10.1145/2339530.2339662
   Asghar MZ, 2020, SOFT COMPUT, V24, P3475, DOI 10.1007/s00500-019-04107-y
   Baccianella FSS, 2010, P 7 INT C LANG RES O, P2200, DOI DOI citeulike-article-id:9238846
   Barbado R, 2019, INFORM PROCESS MANAG, V56, P1234, DOI 10.1016/j.ipm.2019.03.002
   Barushka A, 2019, ARTIF INTELL, V559, P340
   Barushka A, 2018, IFIP ADV INF COMM TE, V519, P38, DOI 10.1007/978-3-319-92007-8_4
   Barushka A, 2020, NEURAL COMPUT APPL, V32, P4239, DOI 10.1007/s00521-019-04331-5
   Barushka A, 2018, APPL INTELL, V48, P3538, DOI 10.1007/s10489-018-1161-y
   Barushka A, 2016, LECT NOTES COMPUT SC, V10037, P65, DOI 10.1007/978-3-319-49130-1_6
   Bravo-Marquez F, 2016, 2016 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE (WI 2016), P536, DOI [10.1109/WI.2016.90, 10.1109/WI.2016.0091]
   Bravo-Marquez F, 2014, KNOWL-BASED SYST, V69, P86, DOI 10.1016/j.knosys.2014.05.016
   Brazdil PB, 2003, MACH LEARN, V50, P251, DOI 10.1023/A:1021713901879
   BrightLocal, 2018, LOC CONS REV SURV 20
   Chandy R, 2012, P 2 JOINT WICOW AIRW, P56
   Chatzakou D, 2015, IEEE INTERNET COMPUT, V19, P46, DOI 10.1109/MIC.2015.28
   Chen W, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0182487
   Elmurngi E, 2017, 7 INT C INN COMP TEC, DOI [10.1109/intech.2017.8102442, DOI 10.1109/INTECH.2017.8102442]
   Felbermayr A, 2016, J INTERACT MARK, V36, P60, DOI 10.1016/j.intmar.2016.05.004
   Floyd K, 2014, J RETAILING, V90, P217, DOI 10.1016/j.jretai.2014.04.004
   Garcia L, 2018, DECEPTION AMAZON NLP
   Garcia S, 2010, INFORM SCIENCES, V180, P2044, DOI 10.1016/j.ins.2009.12.010
   Ghai R, 2019, ADV INTELL SYST, V670, P189, DOI 10.1007/978-981-10-8971-8_18
   Hajek P, 2018, NEURAL COMPUT APPL, V29, P343, DOI 10.1007/s00521-017-3194-2
   Hancock, 2011, P 49 ANN M ASS COMP, P309, DOI DOI 10.1145/2567948.2577293
   Harris C.G.., 2012, WORKSH 26 AAAI C ART
   He RN, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16), P507, DOI 10.1145/2872427.2883037
   Heydari A, 2015, EXPERT SYST APPL, V42, P3634, DOI 10.1016/j.eswa.2014.12.029
   Hu M., 2004, P 10 ACM SIGKDD INT, P168
   Hussain N, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9050987
   Ikeda K, 2013, KNOWL-BASED SYST, V51, P35, DOI 10.1016/j.knosys.2013.06.020
   Jain G., 2018, INT J KNOWL DISCOVER, V8, P12
   Jain G, 2019, ANN MATH ARTIF INTEL, V85, P21, DOI 10.1007/s10472-018-9612-z
   Jindal N, 2007, IEEE DATA MINING, P547, DOI 10.1109/ICDM.2007.68
   Kennedy S, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019:): STUDENT RESEARCH WORKSHOP, P344
   Kiritchenko S, 2014, J ARTIF INTELL RES, V50, P723, DOI 10.1613/jair.4272
   Le Q., 2014, P 31 INT C INT C MAC
   Li Fangtao, 2011, IJCAI P INT JOINT C, V22, P2488, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-414
   Li H., 2015, 9 INT AAAI C WEB SOC
   Li HY, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P1063, DOI 10.1145/3038912.3052582
   Li JW, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1566
   Li LY, 2017, NEUROCOMPUTING, V254, P33, DOI 10.1016/j.neucom.2016.10.080
   Lin M., 2014, NETWORK NETWORK, DOI DOI 10.1109/ASRU.2015.7404828
   Liu YC, 2019, NEUROCOMPUTING, V366, P276, DOI 10.1016/j.neucom.2019.08.013
   Liu YC, 2018, EXPERT SYST APPL, V112, P148, DOI 10.1016/j.eswa.2018.06.028
   Madisetty S, 2018, IEEE T COMPUT SOC SY, V5, P973, DOI 10.1109/TCSS.2018.2878852
   Malik MSI, 2017, COMPUT HUM BEHAV, V73, P290, DOI 10.1016/j.chb.2017.03.053
   Mikolov T., 2013, NIPS, V26, P3111
   Mohammad SM, 2013, COMPUT INTELL-US, V29, P436, DOI 10.1111/j.1467-8640.2012.00460.x
   Nguyen V.-A., 2010, P 19 ACM INT C INF K, P939, DOI DOI 10.1145/1871437.1871557
   Nielsen F.A., 2011, P ESWC2011 WORKSH MA, P93, DOI DOI 10.1016/J.KN0SYS.2015.06.015
   Ott M., 2012, P 21 INT C WORLD WID, V21, P201, DOI DOI 10.1145/2187836.2187864
   Ott M, 2013, P NAACL HLT 2013, P497
   Pandey AC, 2019, EVOL INTELL, V12, P147, DOI 10.1007/s12065-019-00204-x
   Patel E, 2018, OUR COMPEL INTEREST, P1
   Qingxi Peng, 2014, Journal of Software, V9, P2065, DOI 10.4304/jsw.9.8.2065-2072
   Rayana S, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P985, DOI 10.1145/2783258.2783370
   Ren YF, 2017, INFORM SCIENCES, V385, P213, DOI 10.1016/j.ins.2017.01.015
   Rout Jitendra Kumar, 2018, 2018 International Conference on Information Technology (ICIT), P7, DOI 10.1109/ICIT.2018.00014
   Rout JK, 2017, IEEE ACCESS, V5, P1319, DOI 10.1109/ACCESS.2017.2655032
   Shojaee S, 2013, INT CONF INTELL SYST, P53, DOI 10.1109/ISDA.2013.6920707
   Sun CG, 2016, MATH PROBL ENG, V2016, DOI 10.1155/2016/4935792
   Tang XY, 2019, LECT NOTES COMPUT SC, V11448, P324, DOI 10.1007/978-3-030-18590-9_38
   Venkataraman V., 2013, P INT AAAI C WEBL SO, V7, P409
   Vidanagama DU, 2020, ARTIF INTELL REV, V53, P1323, DOI 10.1007/s10462-019-09697-5
   Wang G., 2011, 2011 IEEE 11 INT C D, P1242, DOI [10.1109/ICDM.2011.124, DOI 10.1109/ICDM.2011.124]
   Wang GY, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2321
   Wilson TS, 2005, PHIL EDUC, P347, DOI 10.3115/1220575.1220619
   Xue H, 2019, ACM J DATA INF QUAL, V11, DOI 10.1145/3305258
   Yan X, 2011, ACM T INFORM SYST, V29, DOI 10.1145/1993036.1993039
   Ye J., 2016, 10 INT AAAI C WEB SO, V10
   Yilmaz CM, 2018, 2018 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM), P306, DOI 10.1109/ASONAM.2018.8508314
   Zeng ZY, 2019, INFORMATION, V10, DOI 10.3390/info10070243
NR 76
TC 18
Z9 18
U1 28
U2 74
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0941-0643
EI 1433-3058
J9 NEURAL COMPUT APPL
JI Neural Comput. Appl.
PD DEC
PY 2020
VL 32
IS 23
SI SI
BP 17259
EP 17274
DI 10.1007/s00521-020-04757-2
EA FEB 2020
PG 16
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA OS0SU
UT WOS:000510362100001
DA 2022-02-06
ER

PT J
AU Garbe, L
   Selvik, LM
   Lemaire, P
AF Garbe, Lisa
   Selvik, Lisa-Marie
   Lemaire, Pauline
TI How African countries respond to fake news and hate speech
SO INFORMATION COMMUNICATION & SOCIETY
LA English
DT Article; Early Access
DE Content regulation; fake news; hate speech; Africa; structural topic
   modelling
ID DEMOCRACY; ACCOUNTABILITY; COVERAGE; MEDIA
AB While scholars have already identified and discussed some of the most urgent problems in content moderation in the Global North, fewer scholars have paid attention to content regulation in the Global South, and notably Africa. In the absence of content moderation by Western tech giants themselves, African countries appear to have shifted their focus towards state-centric approaches to regulating content. We argue that those approaches are largely informed by a regime's motivation to repress media freedom as well as institutional constraints on the executive. We use structural topic modelling on a corpus of news articles worldwide (N = 7 ' 787) mentioning hate speech and fake news in 47 African countries to estimate the salience of discussions of legal and technological approaches to content regulation. We find that, in particular, discussions of technological strategies are more salient in regimes with little respect for media freedom and fewer legislative constraints. Overall, our findings suggest that the state is the dominant actor in shaping content regulation across African countries and point to the need for a better understanding of how regime-specific characteristics shape regulatory decisions.
C1 [Garbe, Lisa] WZB Berlin Social Sci Ctr, Berlin, Germany.
   [Garbe, Lisa] Univ St Gallen, Inst Polit Sci, St Gallen, Switzerland.
   [Selvik, Lisa-Marie; Lemaire, Pauline] Univ Bergen, Dept Comparat Polit, Bergen, Norway.
   [Lemaire, Pauline] Chr Michelsen Inst, Bergen, Norway.
C3 University of St Gallen; University of Bergen
RP Garbe, L (corresponding author), WZB Berlin Social Sci Ctr, Berlin, Germany.; Garbe, L (corresponding author), Univ St Gallen, Inst Polit Sci, St Gallen, Switzerland.
EM lisa.garbe@wzb.eu
OI Selvik, Lisa-Marie Maseidvag/0000-0003-3442-2765; Lemaire,
   Pauline/0000-0002-1785-151X
FU Norwegian Research CouncilResearch Council of NorwayEuropean Commission
   [288489, 262862]
FX This work was supported by the Norwegian Research Council [Grant numbers
   288489, 262862].
CR Abraha HH, 2017, INF COMMUN TECHNOL L, V26, P293, DOI 10.1080/13600834.2017.1374057
   Adegbo E-O., 2019, NIGERIAN TRIBUN 1105
   Africa Check, 2020, CUR PREV
   Ahinkorah BO, 2020, FRONT COMMUN, V5, DOI 10.3389/fcomm.2020.00045
   [Anonymous], 2018, MAIL GUARDIAN
   [Anonymous], 2018, THE CITIZEN 1007
   Asiedu M., 2020, ROLE COURTS SAFEGUAR
   Baayen R.H., 2008, ANAL LINGUISTIC DATA
   Bennett WL, 2012, INFORM COMMUN SOC, V15, P739, DOI 10.1080/1369118X.2012.670661
   Benoit K., 2018, J OPEN SOURCE SOFTW, V3, DOI [DOI 10.21105/JOSS.00774, 10.21105/joss.00774]
   Blei DM, 2012, COMMUN ACM, V55, P77, DOI 10.1145/2133806.2133826
   Boas TC, 2006, HOW REVOLUTIONARY WAS THE DIGITAL REVOLUTION?, P361
   Bolarinwa J.O., 2015, DEV COUNTRY STUDIES, V5, P18
   Bosch TE, 2020, MEDIA CULT SOC, V42, P349, DOI 10.1177/0163443719895194
   Bradshaw S., 2019, 20192 PROJ COMP PROP
   Breuer A, 2015, DEMOCRATIZATION, V22, P764, DOI 10.1080/13510347.2014.885505
   Bunce M, 2017, COMMUN SOC-SER, P17
   Christensen D, 2013, J DEMOCR, V24, P77, DOI 10.1353/jod.2013.0026
   Coppedge M., 2020, V-Dem [Country-Year/Country-Date] Dataset v10, DOI 10.23696/vdemds20.
   DiMaggio P, 2013, POETICS, V41, P570, DOI 10.1016/j.poetic.2013.08.004
   Dresden JR, 2016, DEMOCRATIZATION, V23, P1122, DOI 10.1080/13510347.2015.1045884
   Dube H., 2020, CIVIL SOC DIGITAL AG
   Eloff H., 2019, RANDBURG SUN 1019
   Eltantawy N, 2011, INT J COMMUN-US, V5, P1207
   Ethiopian News Agency, 2019, DISINFORMATION
   Facebook, CONT RESTR BAS LOC L
   Field A., 2009, DISCOVERING STAT USI, V3
   Freedom House, 2016, FREED NET SIL MESS C
   Freedom House, 2015, FREED NET PRIV CENS
   Freedom House, 2019, FREED NET CRIS SOC M
   Freedom House, 2018, FREED NET RIS DIG AU
   Freedom House, 2017, FREED NET MAN SOC ME
   Freedom House, 2020, FREED NET PAND DIG S
   Freyburg T., 2021, POLITICAL POWE UNPUB
   Freyburg T, 2018, INT J COMMUN-US, V12, P3896
   Frieden R., 2015, BERKELEY TECHNOLOGY, V30, P1561, DOI [https://doi.org/10.15779/Z386Z81, DOI 10.15779/Z386Z81]
   Gandhi J, 2008, POLITICAL INSTITUTIONS UNDER DICTATORSHIP, P1, DOI 10.1017/CBO9780511510090
   Garbe L., 2020, DEMOCRACY AFRICA
   Gilardi F, 2021, AM J POLIT SCI, V65, P21, DOI [10.1111/ajps.12521, 10.7302/119]
   Gilbert David, 2020, VICE
   Goetz AM, 2005, INT POLIT ECON SER, P1, DOI 10.1057/9780230500143
   Gorwa R, 2019, INFORM COMMUN SOC, V22, P854, DOI 10.1080/1369118X.2019.1573914
   Grimmer J, 2013, POLIT ANAL, V21, P267, DOI 10.1093/pan/mps028
   Hassanpour N, 2014, POLIT COMMUN, V31, P1, DOI 10.1080/10584609.2012.737439
   Hellmeier S, 2016, POLITICS POLICY, V44, P1158, DOI 10.1111/polp.12189
   Helm RK, 2021, HUM RIGHTS LAW REV, V21, P302, DOI 10.1093/hrlr/ngaa060
   Herron ES, 2015, PARTY POLIT, V21, P131, DOI 10.1177/1354068812472573
   Iosifidis P, 2020, INT COMMUN GAZ, V82, P211, DOI 10.1177/1748048519828595
   Karombo T., 2020, QUARTZ AFRICA 1012
   Kellam M, 2016, COMP POLIT STUD, V49, P36, DOI 10.1177/0010414015592644
   Keremoglu E, 2020, COMP POLIT STUD, V53, P1690, DOI 10.1177/0010414020912278
   Lessig L., 1999, CODE OTHER LAWS CYBE
   Lessig L., 2006, CODE VERSION 2 0
   Ludecke D., 2021, GGEFFECTS MARGINAL E
   Luhrmann A., 2017, REGIMES WORLD RIW RO
   Madebo A., 2020, DEMOCRACY AFRIC 0929
   Mechkova V, 2019, STUD COMP INT DEV, V54, P40, DOI 10.1007/s12116-018-9262-5
   Michaelsen M, 2018, GLOBALIZATIONS, V15, P248, DOI 10.1080/14747731.2016.1263078
   Nanfuka J., 2019, SOCIAL MEDIA TAX CUT
   Nijzink L, 2006, J LEGIS STUD, V12, P311, DOI 10.1080/13572330600875563
   Nothias T, 2020, MEDIA CULT SOC, V42, P329, DOI 10.1177/0163443719890530
   Obijiofor L, 2016, AFR JOURNAL STUD, V37, P41, DOI 10.1080/23743670.2016.1210017
   Owono J., 2020, DEMOCRACY AFRIC 1005
   Rakner L., 2009, DEMOCRATIZATION ELEC
   Roberts ME, 2019, J STAT SOFTW, V91, P1, DOI 10.18637/jss.v091.i02
   RoseAckerman S, 1996, INT SOC SCI J, V48, P365, DOI 10.1111/1468-2451.00038
   Rydzak J, 2020, INT J COMMUN-US, V14, P4264
   Schedler A, 2002, J DEMOCR, V13, P36, DOI 10.1353/jod.2002.0031
   Scheppele KL, 2018, U CHICAGO LAW REV, V85, P545
   Shen-Bayh F, 2018, WORLD POLIT, V70, P321, DOI 10.1017/S0043887118000047
   Solomon S., 2017, ALLAFRICA
   Stier S, 2015, DEMOCRATIZATION, V22, P1273, DOI 10.1080/13510347.2014.964643
   Stoycheff E, 2020, INFORM COMMUN SOC, V23, P474, DOI 10.1080/1369118X.2018.1518472
   Taye B., 2020, ACCESS NOW 1022
   Teorell J, 2019, STUD COMP INT DEV, V54, P71, DOI 10.1007/s12116-018-9268-z
   Twitter, REM REQ
   Vondoepp P, 2005, POLIT SCI QUART, V120, P275, DOI 10.1002/j.1538-165X.2005.tb00548.x
   Walker S, 2019, INFORM COMMUN SOC, V22, P1531, DOI 10.1080/1369118X.2019.1648536
   Zuckerberg M., 2016, LOT YOU HAVE ASKED W
NR 79
TC 0
Z9 0
U1 1
U2 1
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 1369-118X
EI 1468-4462
J9 INFORM COMMUN SOC
JI Info. Commun. Soc.
DI 10.1080/1369118X.2021.1994623
EA NOV 2021
PG 18
WC Communication; Sociology
WE Social Science Citation Index (SSCI)
SC Communication; Sociology
GA WU2CY
UT WOS:000716359500001
OA hybrid, Green Submitted, Green Published
DA 2022-02-06
ER

PT J
AU Bode, L
   Lees, D
   Golding, D
AF Bode, Lisa
   Lees, Dominic
   Golding, Daniel
TI Editorial the digital face and deepfakes on screen
SO CONVERGENCE-THE INTERNATIONAL JOURNAL OF RESEARCH INTO NEW MEDIA
   TECHNOLOGIES
LA English
DT Editorial Material
DE Deepfakes; media manipulation; YouTube; bilibili; digital de-aging;
   post-racial; face swap; visual effects
ID DEEP FAKES
C1 [Bode, Lisa] Univ Queensland, St Lucia, Qld, Australia.
   [Lees, Dominic] Univ Western England, Bristol, Avon, England.
   [Golding, Daniel] Swinburne Univ Technol, Hawthorn, Vic, Australia.
C3 University of Queensland; University of West England; Swinburne
   University of Technology
RP Bode, L (corresponding author), Univ Queensland, Dept Commun & Arts, Chancellor Pl, St Lucia, Qld 4072, Australia.
EM l.bode@uq.edu.au
OI BODE, Lisa/0000-0003-4972-5750
CR Chesney B, 2019, CALIF LAW REV, V107, P1753, DOI 10.15779/Z38RV0D15J
   Cole S., 2017, MOTHERBOARD TECH VIC
   Donovan J., 2019, DEEPFAKES CHEAP FAKE
   Fleming DH, 2020, PORN STUDIES, V7, P357
   Fletcher J, 2018, THEATRE J, V70, P455, DOI 10.1353/tj.2018.0097
   Gosse, 2019, 1 MONDAY, V24, DOI [10.5210/fm.v24i12.10287, DOI 10.5210/FM.V24I12.10287]
   Kietzmann J, 2021, INT J ADVERT, V40, P473, DOI 10.1080/02650487.2020.1834211
   Kikerpill K., 2020, PORN STUD, V1, DOI [10.1080/23268743.2020.1765851, DOI 10.1080/23268743.2020.1765851]
   Kirchengast T, 2020, INF COMMUN TECHNOL L, V29, P308, DOI 10.1080/13600834.2020.1794615
   Maddocks Sophie, 2020, PORN STUDIES, V0, P1, DOI DOI 10.1080/23268743.2020.1757499
   Meskys E, 2020, J INTELLET PROP LAW, V15, P24, DOI 10.1093/jiplp/jpz167
   Ohman C, 2020, ETHICS INF TECHNOL, V22, P133, DOI 10.1007/s10676-019-09522-1
   Parisi P., 1994, WIRED
   Perot E, 2020, J INTELLET PROP LAW, V15, P32, DOI 10.1093/jiplp/jpz164
   Rossler A, 2019, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2019.00009
   Silbey J., 2019, MARYLAND LAW REV, V78, P960
   Stanfill M., 2020, PORN STUDIES, V7, P398
   Tolosana R, 2020, INFORM FUSION, V64, P131, DOI 10.1016/j.inffus.2020.06.014
   Vaccari C, 2020, SOC MEDIA SOC, V6, DOI 10.1177/2056305120903408
   van der nagel E., 2020, PORN STUDIES, V7, P424
   Vincent, 2021, VERGE 0305
   Westerlund M, 2019, TECHNOL INNOV MANAG, V9, P39, DOI 10.22215/timreview/1282
   Yadlin-Segal A, 2021, CONVERGENCE-US, V27, P36, DOI 10.1177/1354856520923963
NR 23
TC 0
Z9 0
U1 2
U2 2
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 1354-8565
EI 1748-7382
J9 CONVERGENCE-US
JI Convergence
PD AUG
PY 2021
VL 27
IS 4
SI SI
BP 849
EP 854
AR 13548565211034044
DI 10.1177/13548565211034044
EA JUL 2021
PG 6
WC Communication
WE Social Science Citation Index (SSCI)
SC Communication
GA UK7UP
UT WOS:000679508000001
OA Bronze
DA 2022-02-06
ER

PT J
AU Kaliyar, RK
   Goswami, A
   Narang, P
AF Kaliyar, Rohit Kumar
   Goswami, Anurag
   Narang, Pratik
TI EchoFakeD: improving fake news detection in social media with an
   efficient deep neural network
SO NEURAL COMPUTING & APPLICATIONS
LA English
DT Article
DE Echo chamber; Deep learning; Social media; Fake news; Tensor
   decomposition
AB The increasing popularity of social media platforms has simplified the sharing of news articles that have led to the explosion in fake news. With the emergence of fake news at a very rapid rate, a serious concern has produced in our society because of enormous fake content dissemination. The quality of the news content is questionable and there exists a necessity for an automated tool for the detection. Existing studies primarily focus on utilizing information extracted from the news content. We suggest that user-based engagements and the context related group of people (echo-chamber) sharing the same opinions can play a vital role in the fake news detection. Hence, in this paper, we have focused on both the content of the news article and the existence of echo chambers in the social network for fake news detection. Standard factorization methods for fake news detection have limited effectiveness due to their unsupervised nature and primarily employed with traditional machine learning models. To design an effective deep learning model with tensor factorization approach is the priority. In our approach, the news content is fused with the tensor following a coupled matrix-tensor factorization method to get a latent representation of both news content as well as social context. We have designed our model with a different number of filters across each dense layer along with dropout. To classify on news content and social context-based information individually as well as in combination, a deep neural network (our proposed model) was employed with optimal hyper-parameters. The performance of our proposed approach has been validated on a real-world fake news dataset: BuzzFeed and PolitiFact. Classification results have demonstrated that our proposed model (EchoFakeD) outperforms existing and appropriate baselines for fake news detection and achieved a validation accuracy of 92.30%. These results have shown significant improvements over the existing state-of-the-art models in the area of fake news detection and affirm the potential use of the technique for classifying fake news.
C1 [Kaliyar, Rohit Kumar; Goswami, Anurag] Bennett Univ, Dept Comp Sci Engn, Greater Noida, India.
   [Narang, Pratik] BITS Pilani, Dept CSIS, Pilani, Rajasthan, India.
C3 Birla Institute of Technology & Science Pilani (BITS Pilani)
RP Narang, P (corresponding author), BITS Pilani, Dept CSIS, Pilani, Rajasthan, India.
EM rk5370@bennett.edu.in; anurag.goswami@bennett.edu.in;
   pratik.narang@pilani.bits-pilani.ac.in
CR Acar E, 2011, ARXIV1105
   Blondel VD, 2008, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2008/10/P10008
   Castillo C., 2011, WWW, P675
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Chen Y., 2015, P 2015 ACM WORKSH MU, P15, DOI DOI 10.1145/2823465.2823467
   Clauset A, 2004, PHYS REV E, V70, DOI 10.1103/PhysRevE.70.066111
   de Vreese CH, 2001, POLIT COMMUN, V18, P107, DOI 10.1080/105846001750322934
   Djidjev HN, 2006, INT WORKSH ALG MOD W, P117
   Fazil M, 2018, IEEE T INF FOREN SEC, V13, P2707, DOI 10.1109/TIFS.2018.2825958
   Feng S., 2012, P 50 ANN M ASS COMP, V50, P171
   Ghosh Souvick, 2018, Proceedings of the Association for Information Science and Technology, V55, DOI 10.1002/pra2.2018.14505501125
   Gupta MP, 2012, PROCEEDINGS OF THE ASME PACIFIC RIM TECHNICAL CONFERENCE AND EXHIBITION ON PACKAGING AND INTEGRATION OF ELECTRONIC AND PHOTONIC SYSTEMS, MEMS AND NEMS 2011, VOL 2, P153
   Gupta S, 2018, 2018 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM), P278, DOI 10.1109/ASONAM.2018.8508408
   Haitam C, 2017, 2017 INTERNATIONAL CONFERENCE ON SMART DIGITAL ENVIRONMENT (ICSDE'17), P127, DOI 10.1145/3128128.3128148
   Hancock, 2011, P 49 ANN M ASS COMP, P309, DOI DOI 10.1145/2567948.2577293
   Harshman RA, 1968, FDN PARAFAC PROCEDUR, V30, P1
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Huang JW, 2017, 2017 17TH IEEE INTERNATIONAL CONFERENCE ON COMMUNICATION TECHNOLOGY (ICCT 2017), P598, DOI 10.1109/ICCT.2017.8359706
   Kaliyar RK, 2021, J SUPERCOMPUT, V77, P1015, DOI 10.1007/s11227-020-03294-y
   Kaliyar RK, 2020, COGN SYST RES, V61, P32, DOI 10.1016/j.cogsys.2019.12.005
   Khatri C. G., 1968, SANKHYA, V30, P167
   Kumar S, 2018, ARXIV1804
   Le, 2019, U.S. Patent, Patent No. [10,521,729, 10521729]
   Lee DD, 2001, ADV NEUR IN, V13, P556
   Ma J., 2016, DETECTING RUMORS MIC
   MacKay DJC, 1999, NEURAL COMPUT, V11, P1035, DOI 10.1162/089976699300016331
   McBeth MK, 2011, STEWART COLBERT EFFE, P79
   Miller Thomas, 2017, LITERACY COMPOSITION, V5, P10
   Natekin A, 2013, FRONT NEUROROBOTICS, V7, DOI 10.3389/fnbot.2013.00021
   Paisitkriangkrai S, 2015, 2015 IEEE C COMP VIS, P36
   Papalexakis E.E, 2018, P WORKSH MIS MISB MI P WORKSH MIS MISB MI
   Papanastasiou F, 2019, ARXIV1908
   Perez-Rosas V, 2018, P 27 INT C COMPUTATI, P3391
   Rabanser S, 2017, ARXIV1711
   Roy A, 2018, ARXIV1811
   Ruchansky N, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P797, DOI 10.1145/3132847.3132877
   Sharma K, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3305260
   Shin J, 2018, COMPUT HUM BEHAV, V83, P278, DOI 10.1016/j.chb.2018.02.008
   Shu K, 2020, BIG DATA-US, V8, P171, DOI 10.1089/big.2020.0062
   Shu K, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P395, DOI 10.1145/3292500.3330935
   Shu K, 2019, PROCEEDINGS OF THE TWELFTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'19), P312, DOI 10.1145/3289600.3290994
   Shu K, 2019, COMPUT MATH ORGAN TH, V25, P60, DOI 10.1007/s10588-018-09280-3
   TACCHINI Eugenio, 2017, ARXIV170407506
   Torlay L, 2017, Brain Inform, V4, P159, DOI 10.1007/s40708-017-0065-7
   Vosoughi S, 2017, ACM T KNOWL DISCOV D, V11, DOI 10.1145/3070644
   Wakita K., 2007, P 16 INT C WORLD WID, P1275
   Wang YQ, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P849, DOI 10.1145/3219819.3219903
   Weir W, 2009, HIST GREATEST LIES S
   Xinyi Zhou, 2019, ACM SIGKDD Explorations Newsletter, V21, P48, DOI 10.1145/3373464.3373473
   Yang Y, 2018, ARXIV1806
   Zagoruyko S, 2015, PROC CVPR IEEE, P4353, DOI 10.1109/CVPR.2015.7299064
   Zhang JW, 2020, PROC INT CONF DATA, P1826, DOI 10.1109/ICDE48307.2020.00180
   Zhong BT, 2019, ADV ENG INFORM, V40, P46, DOI 10.1016/j.aei.2019.02.009
   Zhou X, 2020, SAFE SIMILARITY AWAR
   Zhou X., 2018, ARXIV181200315
NR 55
TC 4
Z9 4
U1 4
U2 10
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0941-0643
EI 1433-3058
J9 NEURAL COMPUT APPL
JI Neural Comput. Appl.
PD JUL
PY 2021
VL 33
IS 14
SI SI
BP 8597
EP 8613
DI 10.1007/s00521-020-05611-1
EA JAN 2021
PG 17
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA SW6VB
UT WOS:000604218100022
PM 33424132
OA Bronze, Green Published
DA 2022-02-06
ER

PT J
AU Dong, XS
   Victor, U
   Qian, LJ
AF Dong, Xishuang
   Victor, Uboho
   Qian, Lijun
TI Two-Path Deep Semisupervised Learning for Timely Fake News Detection
SO IEEE TRANSACTIONS ON COMPUTATIONAL SOCIAL SYSTEMS
LA English
DT Article
DE Convolutional neural networks (CNNs); deep semisupervised learning
   (SSL); fake news detection; joint optimization
AB News in social media, such as Twitter, has been generated in high volume and speed. However, very few of them are labeled (as fake or true news) by professionals in near real time. In order to achieve timely detection of fake news in social media, a novel framework of two-path deep semisupervised learning (SSL) is proposed where one path is for supervised learning and the other is for unsupervised learning. The supervised learning path learns on the limited amount of labeled data, while the unsupervised learning path is able to learn on a huge amount of unlabeled data. Furthermore, these two paths implemented with convolutional neural networks (CNNs) are jointly optimized to complete SSL. In addition, we build a shared CNN to extract the low-level features on both labeled data and unlabeled data to feed them into these two paths. To verify this framework, we implement a Word CNN-based SSL model and test it on two data sets: LIAR and PHEME. Experimental results demonstrate that the model built on the proposed framework can recognize fake news effectively with very few labeled data.
C1 [Dong, Xishuang; Victor, Uboho; Qian, Lijun] Prairie View A&M Univ, Texas A&M Univ Syst, Ctr Excellence Res & Educ Big Mil Data Intelligen, CREDIT Ctr,Dept Elect & Comp Engn, Prairie View, TX 77446 USA.
   [Dong, Xishuang] Prairie View A&M Univ, Texas A&M Univ Syst, Ctr Computat Syst Biol, Dept Elect & Comp Engn, Prairie View, TX 77446 USA.
C3 Texas A&M University System; Prairie View A&M University; Texas A&M
   University System; Prairie View A&M University
RP Dong, XS (corresponding author), Prairie View A&M Univ, Texas A&M Univ Syst, Ctr Excellence Res & Educ Big Mil Data Intelligen, CREDIT Ctr,Dept Elect & Comp Engn, Prairie View, TX 77446 USA.
EM xidong@pvamu.edu; uboho.dpc@outlook.com; liqian@pvamu.edu
OI Qian, Lijun/0000-0003-1577-3359; Dong, Xishuang/0000-0002-3742-0071
FU U.S. Office of the Under Secretary of Defense for Research and
   Engineering (OUSD(RE)) [FA8750-15-2-0119]
FX This work was supported in part by the U.S. Office of the Under
   Secretary of Defense for Research and Engineering (OUSD(R&E)) under
   Agreement FA8750-15-2-0119.
CR Allcott H, 2017, J ECON PERSPECT, V31, P211, DOI 10.1257/jep.31.2.211
   Chang Y, 2016, ACM T KNOWL DISCOV D, V11, DOI 10.1145/2994605
   Chang Y, 2014, IEEE DATA MINING, P749, DOI 10.1109/ICDM.2014.28
   Chawla NV, 2010, DATA MINING AND KNOWLEDGE DISCOVERY HANDBOOK, SECOND EDITION, P875, DOI 10.1007/978-0-387-09823-4_45
   Chowdhury S, 2018, BMC BIOINFORMATICS, V19, DOI 10.1186/s12859-018-2467-9
   Conneau A, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P1107
   Daniela, 2000, P 2 INT C LANG RES E, P99
   Dong XS, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0216046
   Goldberg Y., 2014, ARXIV14023722, V1402, P3722
   Grinberg N, 2019, SCIENCE, V363, P374, DOI 10.1126/science.aau2706
   Hashimoto T, 2011, 2011 IEEE REGION 10 CONFERENCE TENCON 2011, P133, DOI 10.1109/TENCON.2011.6129078
   Hovy D, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P351
   Huang CR, 2017, P 8 INT JOINT C NAT, V2, P252
   Kai Shu, 2017, ACM SIGKDD Explorations Newsletter, V19, P22, DOI 10.1145/3137597.3137600
   Karimi H., 2018, P 27 INT C COMP LING, P1546
   Kim, 2014, ARXIV14085882, P1746, DOI [10.3115/v1/d14, 10.3115/v1/D14-1181]
   Kochkina E., 2018, COLING 2018, P3402
   Kowsari K, 2014, THESIS WASHINGTON U
   Kowsari K, 2015, INT J ADV COMPUT SC, V6, P81
   Kwon S, 2013, IEEE DATA MINING, P1103, DOI 10.1109/ICDM.2013.61
   Lai SW, 2015, PROCEEDINGS OF THE TWENTY-NINTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2267
   Laine S., 2016, ARXIV161002242
   Lan T, 2018, IEEE 20TH INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING AND COMMUNICATIONS / IEEE 16TH INTERNATIONAL CONFERENCE ON SMART CITY / IEEE 4TH INTERNATIONAL CONFERENCE ON DATA SCIENCE AND SYSTEMS (HPCC/SMARTCITY/DSS), P282, DOI 10.1109/HPCC/SmartCity/DSS.2018.00068
   Le Q., 2014, P 31 INT C INT C MAC
   Ma J., 2015, P 24 ACM INT C INF K, V19-23, P1751, DOI DOI 10.1145/2806416.2806607
   Ma J., 2016, P 25 INT JOINT C ART, P3818
   Manning C., 1999, FDN STAT NATURAL LAN
   Mikolov T., 2013, P INT C LEARN REPR I, DOI DOI 10.5555/2999792.2999959
   Mikolov T., 2013, ARXIV13013781
   Paik JH, 2013, SIGIR'13: THE PROCEEDINGS OF THE 36TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH & DEVELOPMENT IN INFORMATION RETRIEVAL, P343
   Papalexakis E. E, 2018, P SOCAL NLNP S
   Pennebaker J.W., 2001, MAHWAY LAWRENCE ERLB
   Pennycook G, 2019, P NATL ACAD SCI USA, V116, P2521, DOI 10.1073/pnas.1806781116
   Potthast M, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P231
   Rajaraman Anand, 2011, MINING MASSIVE DATAS
   Ramos J, 2003, USING TF IDF DETERMI
   Rashkin Hannah, 2017, P 2017 C EMPIRICAL M, P2931
   Ruchansky N, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P797, DOI 10.1145/3132847.3132877
   Ruder S, 2017, ARXIV170605098
   Shi L., 2010, P 2010 C EMP METH NA
   Socher R, 2014, P 19 C EMPIRICAL MET, V2014, P1532, DOI DOI 10.3115/V1/D14-1162
   Speriosu M, 2011, P 1 WORKSH UNS LEARN, P53
   Strapparava, 2009, P ACL IJCNLP 2009 C, P309, DOI DOI 10.3115/1667583.1667679
   Szummer M, 2002, ADV NEUR IN, V14, P945
   Tong S, 2002, J MACH LEARN RES, V2, P45, DOI 10.1162/153244302760185243
   Wang, 2018, ARXIV181100770
   Wang WY, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P422, DOI 10.18653/v1/P17-2067
   Yang Y., 2001, P 24 ANN INT ACM SIG, P137, DOI DOI 10.1145/383952.383975
   Zhang X, 2015, ADV NEUR IN, V28
   Zhang ZP, 2014, LECT NOTES COMPUT SC, V8694, P94, DOI 10.1007/978-3-319-10599-4_7
   Zhao L, 2016, THIRTIETH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2877
   Zhao Z, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P1395, DOI 10.1145/2736277.2741637
   Zhou P, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P207, DOI 10.18653/v1/p16-2034
   Zhou SS, 2014, NEUROCOMPUTING, V131, P312, DOI 10.1016/j.neucom.2013.10.011
   Zhu X, 2005, SEMISUPERVISED LEARN
   Zhu Xiaojin, 2002, LEARNING LABELED UNL
   Zien, 2005, P 10 INT WORKSH ART, P57
   Zien, 2009, IEEE T NEURAL NETWOR, V20, P542, DOI DOI 10.1109/TNN.2009.2015974
   Zubiaga A, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0150989
NR 59
TC 2
Z9 2
U1 1
U2 3
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2329-924X
J9 IEEE T COMPUT SOC SY
JI IEEE Trans. Comput. Soc. Syst.
PD DEC
PY 2020
VL 7
IS 6
BP 1386
EP 1398
DI 10.1109/TCSS.2020.3027639
PG 13
WC Computer Science, Cybernetics; Computer Science, Information Systems
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA PS3AP
UT WOS:000607798800007
OA Green Submitted
DA 2022-02-06
ER

PT J
AU Ismail, A
   Elpeltagy, M
   Zaki, M
   ElDahshan, KA
AF Ismail, Aya
   Elpeltagy, Marwa
   Zaki, Mervat
   ElDahshan, Kamal A.
TI Deepfake video detection: YOLO-Face convolution recurrent approach
SO PEERJ COMPUTER SCIENCE
LA English
DT Article
DE Deepfake; YOLO-Face; Convolution recurrent neural networks; Deepfake
   detection; Video authenticity
ID CLASSIFICATION; NETWORKS
AB Recently, the deepfake techniques for swapping faces have been spreading, allowing easy creation of hyper-realistic fake videos. Detecting the authenticity of a video has become increasingly critical because of the potential negative impact on the world. Here, a new project is introduced; You Only Look Once Convolution Recurrent Neural Networks (YOLO-CRNNs), to detect deepfake videos. The YOLO-Face detector detects face regions from each frame in the video, whereas a fine-tuned EfficientNet-B5 is used to extract the spatial features of these faces. These features are fed as a batch of input sequences into a Bidirectional Long Short-Term Memory (Bi-LSTM), to extract the temporal features. The new scheme is then evaluated on a new large-scale dataset; CelebDF-FaceForencics++ (c23), based on a combination of two popular datasets; FaceForencies++ (c23) and Celeb-DF. It achieves an Area Under the Receiver Operating Characteristic Curve (AUROC) 89.35% score, 89.38% accuracy, 83.15% recall, 85.55% precision, and 84.33% F1-measure for pasting data approach. The experimental analysis approves the superiority of the proposed method compared to the state-of-the-art methods.
C1 [Ismail, Aya] Tanta Univ, Math Dept, Tanta, Al Gharbia, Egypt.
   [Elpeltagy, Marwa] Al Azhar Univ, Syst & Comp Dept, Nasr City, Egypt.
   [Zaki, Mervat] Al Azhar Univ, Girls Branch, Math Dept, Nasr City, Egypt.
   [ElDahshan, Kamal A.] Al Azhar Univ, Math Dept, Nasr City, Egypt.
C3 Egyptian Knowledge Bank (EKB); Tanta University; Egyptian Knowledge Bank
   (EKB); Al Azhar University; Egyptian Knowledge Bank (EKB); Al Azhar
   University; Egyptian Knowledge Bank (EKB); Al Azhar University
RP Ismail, A (corresponding author), Tanta Univ, Math Dept, Tanta, Al Gharbia, Egypt.
EM aya.ismail@science.tanta.edu.eg
OI elpeltaagy, marwa/0000-0002-6618-7723; Zaki, Mervat/0000-0003-0472-042X
CR Afchar D, 2018, IEEE INT WORKS INFOR
   Breiman L, 1999, MACH LEARN, V36, P85, DOI 10.1023/A:1007563306331
   Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655
   Chen W., 2020, VIROL SIN, P1, DOI [10.1007/s12250-020-00221-6, DOI 10.1007/s12250-020-00221-6]
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Dang H, 2020, PROC CVPR IEEE, P5780, DOI 10.1109/CVPR42600.2020.00582
   Dave P, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.586
   de Lima O, 2020, DEEPFAKE DETECTION U
   Dolhansky B., 2019, DEEPFAKE DETECTION C
   Dozat T., 2016, ICLR WORKSH, P2013
   Dufour N, 2019, GOOGLE AI BLOG
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Geron A., 2019, HANDS ON MACHINE LEA
   Graves A, 2005, LECT NOTES COMPUT SC, V3697, P799
   Guera D, 2018, 2018 15TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P127
   Jiang LM, 2020, PROC CVPR IEEE, P2886, DOI 10.1109/CVPR42600.2020.00296
   Korshunov P., 2018, DEEPFAKES NEW THREAT
   Kumar A, 2020, PSYCHON B REV, P1, DOI DOI 10.3758/s13423-020-01792-x
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Li Y, 2018, EXPOSING DEEPFAKE VI
   Li YZ, 2018, IEEE INT WORKS INFOR
   Li YZ, 2020, PROC CVPR IEEE, P3204, DOI 10.1109/CVPR42600.2020.00327
   Masi Iacopo, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12352), P667, DOI 10.1007/978-3-030-58571-6_39
   Montserrat Daniel Mas, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW). Proceedings, P2851, DOI 10.1109/CVPRW50498.2020.00342
   Nguyen HV, 2019, 2019 2ND INTERNATIONAL CONFERENCE ON APPLIED INFORMATION TECHNOLOGY AND INNOVATION (ICAITI2019), P1, DOI 10.1109/ICAITI48442.2019.8982119
   Nguyen HH, 2019, INT CONF ACOUST SPEE, P2307, DOI 10.1109/ICASSP.2019.8682602
   Nguyen Thanh Thi, 2019, ARXIV190911573, V1, Patent No. ArXiv190911573
   Qizhe Xie, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10684, DOI 10.1109/CVPR42600.2020.01070
   Re M, 2012, CH CRC DATA MIN KNOW, P563
   Redmon J, 2018, YOLOV3 INCREMENTAL I
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Rossler A, 2019, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2019.00009
   Sabir Ekraam, 2019, INTERFACES GUI, P80
   Samui P, 2017, HDB NEURAL COMPUTATI
   Singh A, 2020, SN COMPUT SCI, V1, P212, DOI [10.1007/s42979-020-00225-9, DOI 10.1007/S42979-020-00225-9]
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Tan MX, 2019, PR MACH LEARN RES, V97
   Wubet WorkuMuluye, 2020, IJITEE, V9
   Yang X, 2019, INT CONF ACOUST SPEE, P8261, DOI 10.1109/ICASSP.2019.8683164
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
   Zhu QY, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10082950
NR 41
TC 0
Z9 0
U1 7
U2 7
PU PEERJ INC
PI LONDON
PA 341-345 OLD ST, THIRD FLR, LONDON, EC1V 9LL, ENGLAND
EI 2376-5992
J9 PEERJ COMPUT SCI
JI PeerJ Comput. Sci.
PD SEP 21
PY 2021
VL 7
AR e730
DI 10.7717/peerj-cs.730
PG 19
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WQ2YT
UT WOS:000713686900001
PM 34712799
OA gold, Green Published
DA 2022-02-06
ER

PT J
AU Kaliyar, RK
   Goswami, A
   Narang, P
AF Kaliyar, Rohit Kumar
   Goswami, Anurag
   Narang, Pratik
TI FakeBERT: Fake news detection in social media with a BERT-based deep
   learning approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fake news; Neural network; Social media; Deep learning; BERT
AB In the modern era of computing, the news ecosystem has transformed from old traditional print media to social media outlets. Social media platforms allow us to consume news much faster, with less restricted editing results in the spread of fake news at an incredible pace and scale. In recent researches, many useful methods for fake news detection employ sequential neural networks to encode news content and social context-level information where the text sequence was analyzed in a unidirectional way. Therefore, a bidirectional training approach is a priority for modelling the relevant information of fake news that is capable of improving the classification performance with the ability to capture semantic and long-distance dependencies in sentences. In this paper, we propose a BERT-based (Bidirectional Encoder Representations from Transformers) deep learning approach (FakeBERT) by combining different parallel blocks of the single-layer deep Convolutional Neural Network (CNN) having different kernel sizes and filters with the BERT. Such a combination is useful to handle ambiguity, which is the greatest challenge to natural language understanding. Classification results demonstrate that our proposed model (FakeBERT) outperforms the existing models with an accuracy of 98.90%.
C1 [Kaliyar, Rohit Kumar; Goswami, Anurag] Bennett Univ, Dept Comp Sci Engn, Greater Noida, India.
   [Narang, Pratik] BITS Pilani, Dept CSIS, Pilani, Rajasthan, India.
C3 Birla Institute of Technology & Science Pilani (BITS Pilani)
RP Narang, P (corresponding author), BITS Pilani, Dept CSIS, Pilani, Rajasthan, India.
EM rk5370@bennett.edu.in; pratik.narang@pilani.bits-pilani.ac.in
CR Ahmed H, 2017, LECT NOTES COMPUT SC, V10618, P127, DOI 10.1007/978-3-319-69155-8_9
   Allcott H, 2017, J ECON PERSPECT, V31, P211, DOI 10.1257/jep.31.2.211
   Aswani R, 2018, INFORM SYST FRONT, V20, P515, DOI 10.1007/s10796-017-9805-8
   Bondielli A, 2019, INFORM SCIENCES, V497, P38, DOI 10.1016/j.ins.2019.05.035
   Brien N, 2018, LANGUAGE FAKE NEWS O
   Castillo C., 2011, WWW, P675
   Cerisara C, 2018, COMPUT SPEECH LANG, V47, P175, DOI 10.1016/j.csl.2017.07.009
   Chen WL, 2018, PATTERN RECOGN LETT, V105, P226, DOI 10.1016/j.patrec.2017.10.014
   Crestani F, 2020, SAARBRUCKEN GERMANY, V181
   De Sarkar Sohan, 2018, 27 INT C COMP LING C, P3371
   Del Vicario M, 2016, P NATL ACAD SCI USA, V113, P554, DOI 10.1073/pnas.1517441113
   Devlin J., 2019, NAACL HLT
   Fazil M, 2018, IEEE T INF FOREN SEC, V13, P2707, DOI 10.1109/TIFS.2018.2825958
   Ghanem B., 2018, P 1 WORKSH FACT EXTR, P66
   Ghosh Souvick, 2018, Proceedings of the Association for Information Science and Technology, V55, DOI 10.1002/pra2.2018.14505501125
   Gorrell Genevieve, 2019, SEMEVAL NAACL HLT 20, P845
   Greff K, 2017, IEEE T NEUR NET LEAR, V28, P2222, DOI 10.1109/TNNLS.2016.2582924
   Han, 2012, SDM, P153
   Jwa H, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9194062
   Kaliyar RK, 2020, COGN SYST RES, V61, P32, DOI 10.1016/j.cogsys.2019.12.005
   Karimi H., 2018, P 27 INT C COMP LING, P1546
   Kumar S, 2018, ARXIV ARXIV 1804
   Li Y., 2017, CONVERGENCE ANAL 2 L
   Liu Y, 2018, THIRTY-SECOND AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTIETH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / EIGHTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P354
   MALIK S, 1991, IEEE T COMPUT AID D, V10, P74, DOI 10.1109/43.62793
   Monteiro Rafael A., 2018, Computational Processing of the Portuguese Language. 13th International Conference, PROPOR 2018. Proceedings: Lecture Notes in Artificial Intelligence (LNAI 11122), P324, DOI 10.1007/978-3-319-99722-3_33
   Munandar D, 2018, 2018 INTERNATIONAL CONFERENCE ON COMPUTER, CONTROL, INFORMATICS AND ITS APPLICATIONS (IC3INA), P104, DOI 10.1109/IC3INA.2018.8629522
   Muth?n B, 2010, MPLUS TECHNICAL APPE, V2010, P1
   Nagi J, 2011, MAX POOLING CONVOLUT
   Perez-Rosas V, 2018, P 27 INT C COMPUTATI, P3391
   Peters ME, 2018, P C N AM CHAPT ASS C, DOI DOI 10.18653/V1/N18-1202
   Qi Y., 2018, ARXIV PREPRINT ARXIV
   Rashkin Hannah, 2017, P 2017 C EMPIRICAL M, P2931
   Roy A, 2018, ARXIV ARXIV 1811
   Ruchansky N, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P797, DOI 10.1145/3132847.3132877
   Seide F., 2011, FEATURE ENG CONTEXT
   Shin J, 2018, COMPUT HUM BEHAV, V83, P278, DOI 10.1016/j.chb.2018.02.008
   Shu K, 2020, BIG DATA-US, V8, P171, DOI 10.1089/big.2020.0062
   Shu K, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P395, DOI 10.1145/3292500.3330935
   Shu K, 2019, PROCEEDINGS OF THE TWELFTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'19), P312, DOI 10.1145/3289600.3290994
   Sibi P., 2013, Journal of Theoretical and Applied Information Technology, V47, P1264
   Singh D, 2017, IMAGING SCI J, V65, P108, DOI 10.1080/13682199.2017.1289629
   Tacchini E, 2017, 2 WORKSH DAT SCI SOC, P1
   Tenney I, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4593
   Vasudevan Vijay, 2019, U.S. patent, Patent No. [10,521,729, 10521729]
   Vosoughi S, 2017, ACM T KNOWL DISCOV D, V11, DOI 10.1145/3070644
   Wang WY, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P422, DOI 10.18653/v1/P17-2067
   Weiss AP, 2020, INT J EDUC INTEGR, V16, DOI 10.1007/s40979-019-0049-x
   Yang F., P MDS 12 ACM SIGKDD, DOI [10.1145/2350190.2350203, DOI 10.1145/2350190.2350203]
   Young T, 2018, IEEE COMPUT INTELL M, V13, P55, DOI 10.1109/MCI.2018.2840738
   Zhang X., 2015, ADV NEURAL INFORM PR, V28, P649, DOI DOI 10.1063/1.4906785
   Zhong BT, 2019, ADV ENG INFORM, V40, P46, DOI 10.1016/j.aei.2019.02.009
   Zhou X, 2018, ARXIV1812
   Zubiaga A, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3161603
NR 54
TC 16
Z9 16
U1 16
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 8
BP 11765
EP 11788
DI 10.1007/s11042-020-10183-2
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RQ2GA
UT WOS:000642237200002
PM 33432264
OA Bronze, Green Published
DA 2022-02-06
ER

PT J
AU He, PS
   Li, HL
   Li, B
   Wang, HX
   Liu, L
AF He, Peisong
   Li, Haoliang
   Li, Bin
   Wang, Hongxia
   Liu, Liang
TI Exposing Fake Bitrate Videos Using Hybrid Deep-Learning Network From
   Recompression Error
SO IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS FOR VIDEO TECHNOLOGY
LA English
DT Article
DE Video forensics; fake bitrate video; recompression error; hybrid
   deep-learning network
ID COMPRESSION
AB Bitrate is generally regarded as an important criterion of video quality. However, with sophisticated video editing software, forgers can create fake bitrate videos by up-converting the bitrate of original videos with lower video quality to attract more viewers on video sharing websites. In this work, we first model the generation process of fake bitrate videos and analyze the dominant sources of information loss. It is found that the recompression error generated by the proposed one-step-further recompression operation is an efficient measurement to expose distinguishable quality variation tendencies between true and fake bitrate videos. Based on this analysis, we propose a detection method for fake bitrate videos using a hybrid deep-learning network from recompression error. For an input video, the patch-wise recompression errors are first calculated to increase the learning capability of the network. To learn robust representations of recompression errors in local regions with different degrees of predictability, a hybrid deep-learning network that contains two branches with heterogeneous structures is designed. For noise-like recompression errors, the first branch has a shallow CNN structure initialized with an Inception-like module using multisize convolutional kernels. For zero-element clustered recompression errors, the second branch has a multi-layer perceptron structure equipped with a unique layer that extracts the histogram of zero-element clustered square regions. The output vectors of different branches are concatenated and then jointly optimized to obtain the patch-wise detection results. Finally, the majority voting (local-to-global) strategy is applied to obtain the final detection result. Extensive experiments are conducted to evaluate the detection performance under various coding parameter settings, such as different bitrates, rate-distortion optimization strategies and so on. The experimental results demonstrate the superiority of the proposed method compared with several state-of-the-art methods to provide more fine-grained forensic clues.
C1 [He, Peisong; Wang, Hongxia; Liu, Liang] Sichuan Univ, Coll Cybersecur, Chengdu 610065, Peoples R China.
   [Li, Haoliang] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
   [Li, Bin] Shenzhen Univ, Coll Informat Engn, Shenzhen 518060, Peoples R China.
   [Li, Bin] Peng Cheng Lab, Shenzhen 518024, Peoples R China.
C3 Sichuan University; Nanyang Technological University & National
   Institute of Education (NIE) Singapore; Nanyang Technological
   University; Shenzhen University; Peng Cheng Laboratory
RP Wang, HX (corresponding author), Sichuan Univ, Coll Cybersecur, Chengdu 610065, Peoples R China.
EM gokeyhps@scu.edu.cn; lihaoliang@ntu.edu.sg; libin@szu.edu.cn;
   hxwang@scu.edu.cn; liangzhai118@163.com
OI Li, Haoliang/0000-0002-8723-8112; He, Peisong/0000-0003-3121-0599
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61902263, 61972269, 61872244]; Guangdong
   Basic and Applied Basic Research Foundation [2019B151502001];
   Wallenburg-NTU Presidential Post-Doctoral Fellowship Grant
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61902263, Grant 61972269, and Grant
   61872244 and in part by the Guangdong Basic and Applied Basic Research
   Foundation under Grant 2019B151502001. The work of H. Li was supported
   by the Wallenburg-NTU Presidential Post-Doctoral Fellowship Grant.
CR Aghamaleki JA, 2016, SIGNAL PROCESS-IMAGE, V47, P289, DOI 10.1016/j.image.2016.07.001
   Bestagini P, 2016, IEEE T IMAGE PROCESS, V25, P2298, DOI 10.1109/TIP.2016.2541960
   Bian S, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11010067
   Bian S, 2013, IEEE IMAGE PROC, P4492, DOI 10.1109/ICIP.2013.6738925
   Bian S, 2014, IEEE T CIRC SYST VID, V24, P2144, DOI 10.1109/TCSVT.2014.2334031
   Cao Y, 2012, IEEE SIGNAL PROC LET, V19, P35, DOI 10.1109/LSP.2011.2176116
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Gulli A, 2017, DEEP LEARNING KERAS, P45
   Han B, 2018, ADV NEUR IN, V31, DOI 10.5555/3327757.3327944
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   He PS, 2017, J VIS COMMUN IMAGE R, V48, P149, DOI 10.1016/j.jvcir.2017.06.010
   IOFFE S, 2015, ARXIV 1502 03167, V1502, DOI DOI 10.1007/S13398-014-0173-7.2
   Jiang XH, 2018, IEEE T INF FOREN SEC, V13, P170, DOI 10.1109/TIFS.2017.2745687
   Kingma DP, 2015, 3 INT C LEARN REPR I, DOI DOI 10.1145/1830483.1830503
   Li B, 2015, IEEE T INF FOREN SEC, V10, P558, DOI 10.1109/TIFS.2015.2389148
   Li H., 2017, ELECT IMAGING MEDIA, V5, P87
   Li HL, 2018, IEEE T INF FOREN SEC, V13, P2639, DOI 10.1109/TIFS.2018.2825949
   Li HL, 2018, IEEE T INF FOREN SEC, V13, P1794, DOI 10.1109/TIFS.2018.2801312
   Liang XY, 2018, IEEE ACCESS, V6, P53243, DOI 10.1109/ACCESS.2018.2869627
   Ma L, 2004, IEEE T IMAGE PROCESS, V13, P739, DOI 10.1109/TIP.2004.827237
   Nair V., 2010, P 27 INT C MACH LEAR, P807
   Scholkopf B., 2001, LEARNING KERNELS SUP
   Simonyan K, 2015, ICLR 2015, DOI DOI 10.1109/CVPR.2015.7298594
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sutthiwan P, 2011, P INT WORKSH DIG FOR, P411
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yu LF, 2019, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-019-0468-x
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
NR 30
TC 1
Z9 1
U1 3
U2 5
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1051-8215
EI 1558-2205
J9 IEEE T CIRC SYST VID
JI IEEE Trans. Circuits Syst. Video Technol.
PD NOV
PY 2020
VL 30
IS 11
BP 4034
EP 4049
DI 10.1109/TCSVT.2019.2951630
PG 16
WC Engineering, Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA OJ1XS
UT WOS:000583761300015
DA 2022-02-06
ER

PT J
AU Sahoo, SR
   Gupta, BB
AF Sahoo, Somya Ranjan
   Gupta, B. B.
TI Multiple features based approach for automatic fake news detection on
   social networks using deep learning
SO APPLIED SOFT COMPUTING
LA English
DT Article
DE Online Social Network; Fake news; Deep learning; Hybrid approach
AB In recent years, the rise of Online Social Networks has led to proliferation of social news such as product advertisement, political news, celebrity's information, etc. Some of the social networks such as Facebook, Instagram and Twitter affected by their user through fake news. Unfortunately, some users use unethical means to grow their links and reputation by spreading fake news in the form of texts, images, and videos. However, the recent information appearing on an online social network is doubtful, and in many cases, it misleads other users in the network. Fake news is spread intentionally to mislead readers to believe false news, which makes it difficult for detection mechanism to detect fake news on the basis of shared content. Therefore, we need to add some new information related to user's profile, such as user's involvement with others for finding a particular decision. The disseminated information and their diffusion process create a big problem for detecting these contents promptly and thus highlighting the need for automatic fake news detection. In this paper, we are going to introduce automatic fake news detection approach in chrome environment on which it can detect fake news on Facebook. Specifically, we use multiple features associated with Facebook account with some news content features to analyze the behavior of the account through deep learning. The experimental analysis of real-world information demonstrates that our intended fake news detection approach has achieved higher accuracy than the existing state of art techniques.
   (c) 2020 Elsevier B.V. All rights reserved.
C1 [Sahoo, Somya Ranjan; Gupta, B. B.] Natl Inst Technol Kurukshetra, Dept Comp Engn, Kurukshetra, Haryana, India.
   [Gupta, B. B.] Asia Univ, Dept Comp Sci & Informat Engn, Taichung, Taiwan.
   [Gupta, B. B.] Macquarie Univ, N Ryde, NSW, Australia.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Kurukshetra; Asia University Taiwan; Macquarie University
RP Gupta, BB (corresponding author), Natl Inst Technol Kurukshetra, Dept Comp Engn, Kurukshetra, Haryana, India.
EM gupta.brij@gmail.com
FU YFRF, under the project Visvesvaraya PhD Scheme of Ministry of
   Electronics & Information Technology, Government of India; SERB, DST,
   Government of India [SB/FTP/ETA-131/2014]
FX This research work is being supported by sponsored project grant (i)
   YFRF, under the project Visvesvaraya PhD Scheme of Ministry of
   Electronics & Information Technology, Government of India and being
   implemented by Digital India Corporation and (ii) project grant
   (SB/FTP/ETA-131/2014) from SERB, DST, Government of India.
CR Ahmed H., 2017, THESIS
   Ahmed H, 2017, LECT NOTES COMPUT SC, V10618, P127, DOI 10.1007/978-3-319-69155-8_9
   Al-Sharif ZA, 2020, FUTURE GENER COMP SY, V108, P1217, DOI 10.1016/j.future.2018.07.028
   Alsmirat MA, 2019, MULTIMED TOOLS APPL, V78, P3649, DOI 10.1007/s11042-017-5537-5
   Bakshy E, 2015, SCIENCE, V348, P1130, DOI 10.1126/science.aaa1160
   Balmas M, 2014, COMMUN RES, V41, P430, DOI 10.1177/0093650212453600
   Barthel M., 2016, PEW RES CTR, V15
   Bourgonje Peter, 2017, P 2017 EMNLP WORKSHO, P84, DOI 10.18653/v1/W17-4215
   Conroy NJ, 2015, P ASS INF SCI TECHN, V51, P1, DOI [10.1002/pra2.2015.145052010082, DOI 10.1002/PRA2.2015.145052010082]
   Feng Song, ACL 12
   Guacho GB, 2018, 2018 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM), P322, DOI 10.1109/ASONAM.2018.8508241
   Gupta S, 2018, INT J CLOUD APPL COM, V8, P113, DOI 10.4018/IJCAC.2018040106
   Han Y., 2020, ARXIV PREPRINT ARXIV
   Horne BD, 2017, JUST FAKE NEWS PACKS
   Hosseinimotlagh S, 2018, UNSUPERVISED CONTENT
   Huang Y., 2019, IEEE T SERV COMPUT
   Kai Shu, 2017, ACM SIGKDD Explorations Newsletter, V19, P22, DOI 10.1145/3137597.3137600
   Karimi Hamid, 2018, COLING
   Kaur S, 2020, SOFT COMPUT, V24, P9049, DOI 10.1007/s00500-019-04436-y
   Kaushik S, 2019, INT J CLOUD APPL COM, V9, P21, DOI 10.4018/IJCAC.2019100102
   Li C, 2018, INT J CLOUD APPL COM, V8, P32, DOI 10.4018/IJCAC.2018070103
   Li DM, 2019, INFORM SCIENCES, V479, P432, DOI 10.1016/j.ins.2018.02.060
   Marra F, 2018, IEEE 1ST CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2018), P384, DOI 10.1109/MIPR.2018.00084
   Ozbay FA, 2020, PHYSICA A, V540, DOI 10.1016/j.physa.2019.123174
   Qian Feng, 2018, IJCAI, P3834
   Reis JCS, 2019, IEEE INTELL SYST, V34, P76, DOI 10.1109/MIS.2019.2899143
   RUBIN Victoria L., 2015, P 78 ASIS T ANN M IN, P83
   Sabeeh V., 2020, INT J COMPUT SCI INF, V18
   Sahoo SR, 2019, ENTERP INF SYST-UK, V13, P832, DOI 10.1080/17517575.2019.1605542
   Sahoo SR, 2019, COMPUT ELECTR ENG, V76, P65, DOI 10.1016/j.compeleceng.2019.03.003
   Shao C., 2017, ARXIV PREPRINT ARXIV
   Shu K., 2018, ARXIV PREPRINT ARXIV
   Shu K, 2018, IEEE 1ST CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2018), P430, DOI 10.1109/MIPR.2018.00092
   Sunstein C. R., 2014, RUMORS FALSEHOODS SP
   Tacchini E., 2017, ARXIV PREPRINT ARXIV
   Tewari A, 2020, FUTURE GENER COMP SY, V108, P909, DOI 10.1016/j.future.2018.04.027
   Tschiatschek S, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), P517, DOI 10.1145/3184558.3188722
   Wang YQ, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P849, DOI 10.1145/3219819.3219903
   Wu L, 2018, WSDM'18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P637, DOI 10.1145/3159652.3159677
   Yang Y., 2018, ARXIV PREPRINT ARXIV
   Zhang J, 2018, ARXIV PREPRINT ARXIV
NR 41
TC 23
Z9 23
U1 11
U2 28
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1568-4946
EI 1872-9681
J9 APPL SOFT COMPUT
JI Appl. Soft. Comput.
PD MAR
PY 2021
VL 100
AR 106983
DI 10.1016/j.asoc.2020.106983
PG 16
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QE1BY
UT WOS:000615942600009
DA 2022-02-06
ER

PT J
AU Saleh, H
   Alharbi, A
   Alsamhi, SH
AF Saleh, Hager
   Alharbi, Abdullah
   Alsamhi, Saeed Hamood
TI OPCNN-FAKE: Optimized Convolutional Neural Network for Fake News
   Detection
SO IEEE ACCESS
LA English
DT Article
DE Feature extraction; Convolutional neural networks; Social networking
   (online); Training; Support vector machines; Radio frequency; Business;
   Fake news; machine learning; deep learning; neural network;
   convolutional neural network; detection; OPCNN-FAKE
ID DEEP; CLASSIFICATION
AB Recently, there is a rapid and wide increase in fake news, defined as provably incorrect information spread with the goal of fraud. The spread of this type of misinformation is a severe danger to social cohesiveness and well-being since it increases political polarisation and people's distrust of their leaders. Thus, fake news is a phenomenon that is having a significant impact on our social lives, particularly in politics. This paper proposes novel approaches based on Machine Learning (ML) and Deep Learning (DL) for the fake news detection system to address this phenomenon. The main aim of this paper is to find the optimal model that obtains high accuracy performance. Therefore, we propose an optimized Convolutional Neural Network model to detect fake news (OPCNN-FAKE). We compare the performance of the OPCNN-FAKE with Recurrent Neural Network (RNN), Long Short-Term Memory (LSTM), and The six regular ML techniques: Decision Tree (DT), logistic Regression (LR), K Nearest Neighbor (KNN), Random Forest (RF), Support Vector Machine (SVM), and Naive Bayes (NB) using four fake news benchmark datasets. Grid search and hyperopt optimization techniques have been used to optimize the parameters of ML and DL, respectively. In addition, N-gram and Term Frequency-Inverse Document Frequency (TF-IDF) have been used to extract features from the benchmark datasets for regular ML, while Glove word embedding has been used to represent features as a feature matrix for DL models. To evaluate the performance of the OPCNN-FAKE, accuracy, precision, recall, F1-measure were applied to validate the results. The results show that OPCNN-FAKE model has achieved the best performance for each dataset compared with other models. Furthermore, the OPCNN-FAKE has a higher performance of cross-validation results and testing results over the other models, which indicates that the OPCNN-FAKE for fake news detection is significantly better than the other models.
C1 [Saleh, Hager] South Valley Univ, Fac Comp & Artificial Intelligence, Hurghada 83523, Egypt.
   [Alharbi, Abdullah] Taif Univ, Coll Comp & Informat Technol, Dept Informat Technol, At Taif 21944, Saudi Arabia.
   [Alsamhi, Saeed Hamood] Athlone Inst Technol, Athlone N37 HD68, Ireland.
   [Alsamhi, Saeed Hamood] IBB Univ, Dept Elect Engn, Ibb, Yemen.
C3 Egyptian Knowledge Bank (EKB); South Valley University Egypt; Taif
   University; Technological University of the Shannon: Midlands Midwest
RP Saleh, H (corresponding author), South Valley Univ, Fac Comp & Artificial Intelligence, Hurghada 83523, Egypt.
EM hager.saleh.fci@gmail.com
OI alsamhi, saeed/0000-0003-2857-6979
FU Taif University Researchers Supporting Project, Taif University, Taif,
   Saudi Arabia [TURSP-2020/231]
FX This work was supported by Taif University Researchers Supporting
   Project, Taif University, Taif, Saudi Arabia, under Grant
   TURSP-2020/231.
CR Abdullah A., 2020, INT J EMERG TECHNOL, V11, P209
   Agarap A.F, 2018, ARXIV PREPRINT ARXIV
   Ahmed H, 2017, LECT NOTES COMPUT SC, V10618, P127, DOI 10.1007/978-3-319-69155-8_9
   Allcott H, 2017, J ECON PERSPECT, V31, P211, DOI 10.1257/jep.31.2.211
   Bergstra J., 2012, HYPEROPT DISTRIBUTED, V21, P2020
   Bondielli A, 2019, INFORM SCIENCES, V497, P38, DOI 10.1016/j.ins.2019.05.035
   Bozarth L., 2020, P INT AAAI C WEB SOC, V14, P60
   Cheon JH, 2018, IEEE ACCESS, V6, P46938, DOI 10.1109/ACCESS.2018.2866697
   Chollet F., IN PRESS
   Ghosh Souvick, 2018, Proceedings of the Association for Information Science and Technology, V55, DOI 10.1002/pra2.2018.14505501125
   Girgis S, 2018, PROCEEDINGS OF 2018 13TH INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING AND SYSTEMS (ICCES), P93, DOI 10.1109/ICCES.2018.8639198
   Goldani MH, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2020.102418
   Goldberg Y, 2017, SYNTHESIS LECT HUMAN, V10, P1, DOI [10.2200/S00762ED1V01Y201703HLT037, DOI 10.2200/S00762ED1V01Y201703HLT037]
   Graves A, 2012, STUD COMPUT INTELL, V385, P37
   Guo YH, 2018, IEEE ACCESS, V6, P18582, DOI 10.1109/ACCESS.2018.2820043
   Kaliyar RK, 2021, NEURAL COMPUT APPL, V33, P8597, DOI 10.1007/s00521-020-05611-1
   Kaliyar RK, 2021, J SUPERCOMPUT, V77, P1015, DOI 10.1007/s11227-020-03294-y
   Kaliyar RK, 2020, COGN SYST RES, V61, P32, DOI 10.1016/j.cogsys.2019.12.005
   Khalil-Hani M, 2014, 2014 INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING & SIMULATION (HPCS), P707, DOI 10.1109/HPCSim.2014.6903759
   Ksieniewicz P., 2019, P INT C INT DAT ENG, P332
   Li H, 2018, NATL SCI REV, V5, P24, DOI 10.1093/nsr/nwx110
   Li LF, 2019, IEEE ACCESS, V7, P11854, DOI 10.1109/ACCESS.2019.2892063
   Li Q, 2020, PERS UBIQUIT COMPUT, V24, P259, DOI 10.1007/s00779-019-01289-y
   Li Q, 2014, I C CONT AUTOMAT ROB, P844, DOI 10.1109/ICARCV.2014.7064414
   Liang M, 2015, PROC CVPR IEEE, P3367, DOI 10.1109/CVPR.2015.7298958
   Liu Y, 2018, THIRTY-SECOND AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTIETH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / EIGHTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P354
   Ma J., 2016, P 25 INT JOINT C ART, P3818
   Monti F., ARXIV190206673
   Moro R. A., 2008, SUPPORT VECTOR MACHI, DOI DOI 10.2139/SSRN.1424949
   Nasir J. A., 2021, INT J INF MANAGE DAT, V1, DOI DOI 10.1016/J.JJIMEI.2020.100007
   Pal M, 2005, INT J REMOTE SENS, V26, P217, DOI 10.1080/01431160412331269698
   Pennington J, 2014, P EMNLP C, V2014, P1532, DOI DOI 10.3115/V1/D14-1162
   Perez-Rosas V, 2017, ARXIV PREPRINT ARXIV
   Popat Kashyap, 2018, P 2018 C EMP METH NA, P22, DOI DOI 10.18653/V1/D18-1003
   Rapoza K., 2017, FORBES
   Ruchansky N, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P797, DOI 10.1145/3132847.3132877
   Salem F.K.A., 2019, P INT AAAI C WEB SOC, P573
   Sherstinsky A, 2020, PHYSICA D, V404, DOI 10.1016/j.physd.2019.132306
   Shu K, 2020, BIG DATA-US, V8, P171, DOI 10.1089/big.2020.0062
   Sikandar A, 2018, IEEE ACCESS, V6, P22108, DOI 10.1109/ACCESS.2018.2807811
   Singh JP, 2020, INFORM SYST FRONT, DOI 10.1007/s10796-020-10040-5
   Sundermeyer M, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P194
   van Laarhoven T, 2017, ARXIV170605350
   Wang, 2018, ARXIV180901286
   Wanto A., 2017, INT J INFORM SYSTEM, V1, P43
   Yamashita R, 2018, INSIGHTS IMAGING, V9, P611, DOI 10.1007/s13244-018-0639-9
   Yu PS, 2018, ARXIV180600749, DOI DOI 10.1145/3070644
   Yu Y, 2019, STRUCT HEALTH MONIT, V18, P143, DOI 10.1177/1475921718804132
   Zhang ZJ, 2018, 2018 IEEE/ACM 26TH INTERNATIONAL SYMPOSIUM ON QUALITY OF SERVICE (IWQOS), DOI 10.1109/IWQoS.2018.8624183
   Zhong BT, 2019, ADV ENG INFORM, V40, P46, DOI 10.1016/j.aei.2019.02.009
NR 50
TC 2
Z9 2
U1 8
U2 8
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2021
VL 9
BP 129471
EP 129489
DI 10.1109/ACCESS.2021.3112806
PG 19
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA UU5LD
UT WOS:000698840700001
OA gold
DA 2022-02-06
ER

PT J
AU Bode, L
AF Bode, Lisa
TI Deepfaking Keanu: YouTube deepfakes, platform visual effects, and the
   complexity of reception
SO CONVERGENCE-THE INTERNATIONAL JOURNAL OF RESEARCH INTO NEW MEDIA
   TECHNOLOGIES
LA English
DT Article
DE celebrity; deepfakes; media platforms; reception; YouTube; visual
   effects industry; visual effects
AB On July 14, 2019, a 3-minute 36-second video titled "Keanu Reeves Stops A ROBBERY!" was released on YouTube visual effects (VFX) channel, Corridor. The video's click-bait title ensured it was quickly shared by users across platforms such as Facebook, Twitter, and Reddit. Comments on the video suggest that the vast majority of viewers categorised it as fiction. What seemed less universally recognised, though, was that the performer in the clip was not Keanu Reeves himself. It was voice actor and stuntman Reuben Langdon, and his face was digitally replaced with that of Reeves, through the use of an AI generated deepfake, an open access application, Faceswap, and compositing in Adobe After Effects. This article uses Corridor's deepfake Keanu video (hereafter shorted to CDFK) as a case study which allows the fleshing out of an, as yet, under-researched area of deepfakes: the role of framing contexts in shaping how viewers evaluate, categorise, make sense of and discuss these images. This research draws on visual effects scholarship, celebrity studies, cognitive film studies, social media theory, digital rhetoric, and discourse analysis. It is intended to serve as a starting point of a larger study that will eventually map types of online manipulated media creation on a continuum from the professional to the vernacular, across different platforms, and attending to their aesthetic, ethical, cultural and reception dimensions. The focus on context (platform, creator channel, and comments) also reveals the emergence of an industrial and aesthetic category of visual effects, which I call here "platform VFX," a key term that provides us with more nuanced frames for illuminating and analysing a range of manipulated media practices as VFX software becomes ever more accessible and lends itself to more vernacular uses, such as we see with various face swap apps
C1 [Bode, Lisa] Univ Queensland, St Lucia, Qld, Australia.
C3 University of Queensland
RP Bode, L (corresponding author), Univ Queensland, Dept Commun & Arts, Chancellor Pl, St Lucia, Qld 4072, Australia.
EM l.bode@uq.edu.au
OI BODE, Lisa/0000-0003-4972-5750
CR Ahmed S, 2021, TELEMAT INFORM, V57, DOI 10.1016/j.tele.2020.101508
   Ayers D, 2019, SPECTACULAR POSTHUMANISM: THE DIGITAL VERNACULAR OF VISUAL EFFECTS, P1
   Belanger L., 2018, ENTREPRENEUR
   Bode L, 2018, FILM HIST, V30, P1, DOI 10.2979/filmhistory.30.4.01
   Burgess Jean, 2009, YOUTUBE ONLINE VIDEO
   Chesney B, 2019, CALIF LAW REV, V107, P1753, DOI 10.15779/Z38RV0D15J
   Corridor, 2019, KEAN REEV STOPS ROBB
   Corridor Crew, 2019, WE MAD BEST DEEPF IN
   Corridor Crew, 2019, WE FAK KEAN REEV STO
   Diakopoulos N, 2021, NEW MEDIA SOC, V23, P2072, DOI 10.1177/1461444820925811
   Donovan J., 2019, DEEPFAKES CHEAP FAKE
   DYER R, 2008, STARS
   Fletcher J, 2018, THEATRE J, V70, P455, DOI 10.1353/tj.2018.0097
   Murthy D, 2019, NEW MEDIA SOC, V21, P191, DOI 10.1177/1461444818792393
   Ndalianis A, 2015, SPECIAL EFFECTS: NEW HISTORIES/THEORIES/CONTEXTS, P154
   Nikki S, 2011, TELEVISION DIGITAL M
   North Dan, 2008, PERFORMING ILLUSIONS
   Papacharissi Z., 2010, NETWORKED SELF IDENT, P1
   PIERSON M, 2002, SPECIAL EFFECTS STIL
   Plantinga, 2010, RHETORIC REPRESENTAT
   Pomerance M., 2005, JOHNNY DEPP STARTS H
   Purse L, 2017, J POP FILM TV, V45, P16, DOI 10.1080/01956051.2017.1270137
   Rossler A, 2019, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2019.00009
   Stacey Jackie, 1994, STAR GAZING HOLLYWOO
   Stanfill M., 2020, PORN STUDIES, V7, P398
   Strauven W, 2006, CINEMA ATTRACTIONS R
   Vaccari C, 2020, SOC MEDIA SOC, V6, DOI 10.1177/2056305120903408
   Walther J. B., 2010, NETWORKED SELF IDENT, P17
   YouTube, 2020, MANIPULATED MEDIA
NR 29
TC 1
Z9 1
U1 11
U2 12
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 1354-8565
EI 1748-7382
J9 CONVERGENCE-US
JI Convergence
PD AUG
PY 2021
VL 27
IS 4
SI SI
BP 919
EP 934
AR 13548565211030454
DI 10.1177/13548565211030454
EA JUL 2021
PG 16
WC Communication
WE Social Science Citation Index (SSCI)
SC Communication
GA UK7UP
UT WOS:000676909100001
DA 2022-02-06
ER

PT J
AU Manaskasemsak, B
   Tantisuwankul, J
   Rungsawang, A
AF Manaskasemsak, Bundit
   Tantisuwankul, Jirateep
   Rungsawang, Arnon
TI Fake review and reviewer detection through behavioral graph partitioning
   integrating deep neural network
SO NEURAL COMPUTING & APPLICATIONS
LA English
DT Review; Early Access
DE Fake review(er); Behavioral graph; Graph partitioning; Deep neural
   network; Word embedding; Emotion indicator
AB With a profound effect of online reviews on customers' decisions about purchasing products or services, untruthful (fake) reviews written to deceive product quality and receive unfair commercial benefits have become a crucial problem. In this work, we propose a graph partitioning approach (BeGP) and its extension (BeGPX) to distinguish fake reviewers from benign ones. The main idea of BeGP is to first construct a behavioral graph in which reviewers are connected if they share common characteristic features that capture their similar behavior. Then, the algorithm starts with a small subgraph of known fake reviewers and afterwards repeatedly expands the subgraph by inducing other connected suspicious reviewers. Subsequently, all reviews of those suspects are hypothesized to be untruthful. Moreover, to enhance the performance of fake review(er) detection, BeGPX employs additional analysis of semantic content and emotions expressed in reviews. In particular, we use the deep neural network to learn word embeddings representation and lexicon-based emotion indicators in order to integrate into the graph construction process. We demonstrate the effectiveness of BeGP and BeGPX on two real-world review datasets from Yelp.com. The results show that both approaches outperform state-of-the-art methods with accurately identifying fake review(er)s within the k-first order of rankings. In addition, BeGPX shows significant enhancement although being provided with only a few amount of learning labeled data.
C1 [Manaskasemsak, Bundit; Tantisuwankul, Jirateep; Rungsawang, Arnon] Kasetsart Univ, Fac Engn, Dept Comp Engn, Mass Informat & Knowledge Engn Lab, Bangkok 10900, Thailand.
C3 Kasetsart University
RP Manaskasemsak, B (corresponding author), Kasetsart Univ, Fac Engn, Dept Comp Engn, Mass Informat & Knowledge Engn Lab, Bangkok 10900, Thailand.
EM bundit.m@ku.th; jirateep.t@ku.th; arnon.r@ku.th
OI Manaskasemsak, Bundit/0000-0001-8075-2787; Rungsawang,
   Arnon/0000-0002-7960-790X
CR Akoglu L, 2013, P 7 INT AAAI C WEBL
   [Anonymous], 2015, J BIG DATA-GER, DOI [10.1186/s40537-015-0029-9, DOI 10.1186/S40537-015-0029-9]
   [Anonymous], 2013, IN PRESS
   [Anonymous], 2012, P 18 ACM SIGKDD INT, DOI DOI 10.1145/2339530.2339662
   Baccianella FSS, 2010, P 7 INT C LANG RES O, P2200, DOI DOI citeulike-article-id:9238846
   Barushka A, 2019, ARTIF INTELL, V559, P340
   Barushka A, 2018, APPL INTELL, V48, P3538, DOI 10.1007/s10489-018-1161-y
   Bergstra J., 2013, PHILOS PSYCHOL, P115
   Bergstra J.S., 2011, PROC 24 INT C NEURAL, P2546
   Bing L, 2003, THIRD IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P179, DOI 10.1109/icdm.2003.1250918
   Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P92, DOI 10.1145/279943.279962
   Bravo-Marquez F, 2014, KNOWL-BASED SYST, V69, P86, DOI 10.1016/j.knosys.2014.05.016
   Chatzakou D, 2015, IEEE INTERNET COMPUT, V19, P46, DOI 10.1109/MIC.2015.28
   Feng S, 2012, P 6 INT C WEBL SOC M, V12, P98
   Hajek P, 2020, NEURAL COMPUT APPL, V32, P17259, DOI 10.1007/s00521-020-04757-2
   Heaton J., 2008, INTRO NEURAL NETWORK
   Hernandez D, 2013, P 4 WORKSH COMP APPR, P38
   Hu M., 2004, P 10 ACM SIGKDD INT, P168
   Hussain N, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9050987
   Jindal N., 2008, P 2008 INT C WEB SEA, P219
   Jindal N., 2010, P 19 ACM INT C INF K, P1549
   Jindal N, 2007, IEEE DATA MINING, P547, DOI 10.1109/ICDM.2007.68
   Kiritchenko S, 2014, J ARTIF INTELL RES, V50, P723, DOI 10.1613/jair.4272
   Koven J, 2014, 2014 IEEE International Conference on Data Mining Workshop (ICDMW), P1215, DOI 10.1109/ICDMW.2014.49
   Lak P, 2014, P ANN HICSS, P796, DOI 10.1109/HICSS.2014.106
   Le Q., 2014, P 31 INT C INT C MAC
   Li Fangtao, 2011, IJCAI P INT JOINT C, V22, P2488, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-414
   Li LY, 2017, NEUROCOMPUTING, V254, P33, DOI 10.1016/j.neucom.2016.10.080
   Liu J, 2007, P JOINT C EMP METH N
   Manaskasemsak B, 2019, 2019 3RD INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS, METAHEURISTICS & SWARM INTELLIGENCE (ISMSI 2019), P73, DOI 10.1145/3325773.3325783
   Mikolov T., 2013, PROC INT C ADV NEURA, P3111
   Mohammad SM, 2013, COMPUT INTELL-US, V29, P436, DOI 10.1111/j.1467-8640.2012.00460.x
   Mohammad SM, 2013, P 2 JOINT C LEX COMP, V2
   Mukherjee A, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P632
   Murphy R, 2019, LOCAL CONSUMER REV S
   Nguyen V.-A., 2010, P 19 ACM INT C INF K, P939, DOI DOI 10.1145/1871437.1871557
   Nielsen F.A., 2011, P ESWC2011 WORKSH MA, P93, DOI DOI 10.1016/J.KN0SYS.2015.06.015
   Plutchik R., 1988, EMOTIONS PSYCHOPATHO, P1
   Qingxi Peng, 2014, Journal of Software, V9, P2065, DOI 10.4304/jsw.9.8.2065-2072
   Rayana S, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P985, DOI 10.1145/2783258.2783370
   Ren YF, 2017, INFORM SCIENCES, V385, P213, DOI 10.1016/j.ins.2017.01.015
   SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0
   Sharma K. K., 2013, P 51 ACM SE C, P1
   Tan EH, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P479, DOI 10.1145/2505515.2505581
   Turney P., 2010, P NAACL HLT 2010 WOR, P26
   Venkataraman V., 2013, P INT AAAI C WEBL SO, V7, P409
   Wang G., 2011, 2011 IEEE 11 INT C D, P1242, DOI [10.1109/ICDM.2011.124, DOI 10.1109/ICDM.2011.124]
   Wang Z, 2020, DATA MIN KNOWL DISC, V34, P1621, DOI 10.1007/s10618-020-00693-w
   Wilson T, 2005, P C HUM LANG TECHN E, P347, DOI DOI 10.3115/1220575.1220619
   Zhu X., 2014, P 8 INT WORKSH SEM E, P443
NR 50
TC 0
Z9 0
U1 6
U2 7
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0941-0643
EI 1433-3058
J9 NEURAL COMPUT APPL
JI Neural Comput. Appl.
DI 10.1007/s00521-021-05948-1
EA APR 2021
PG 14
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA RP3WX
UT WOS:000641663000003
DA 2022-02-06
ER

PT J
AU Do, TH
   Berneman, M
   Patro, J
   Bekoulis, G
   Deligiannis, N
AF Do, Tien Huu
   Berneman, Marc
   Patro, Jasabanta
   Bekoulis, Giannis
   Deligiannis, Nikos
TI Context-Aware Deep Markov Random Fields for Fake News Detection
SO IEEE ACCESS
LA English
DT Article
DE Correlation; Task analysis; Feature extraction; Social networking
   (online); Deep learning; Transformers; Linguistics; Fake news detection;
   deep learning; Markov random field; representation learning; question
   answering; sentiment analysis; clickbait detection; toxicity detection;
   bias detection
AB Fake news is a serious problem, which has received considerable attention from both industry and academic communities. Over the past years, many fake news detection approaches have been introduced, and most of the existing methods rely on either news content or the social context of the news dissemination process on social media platforms. In this work, we propose a generic model that is able to take into account both the news content and the social context for the identification of fake news. Specifically, we explore different aspects of the news content by using both shallow and deep representations. The shallow representations are produced with word2vec and doc2vec models while the deep representations are generated via transformer-based models. These representations are able to jointly or separately address four individual tasks, namely bias detection, clickbait detection, sentiment analysis, and toxicity detection. In addition, we make use of graph convolutional neural networks and mean-field layers in order to exploit the underlying structural information of the news articles. That way, we are able to take into account the inherent correlation between the articles by leveraging their social context information. Experiments on widely-used benchmark datasets indicate the effectiveness of the proposed method.
C1 [Do, Tien Huu; Berneman, Marc; Patro, Jasabanta; Bekoulis, Giannis; Deligiannis, Nikos] Vrije Univ Brussel VUB, Dept Elect & Informat ETRO, B-1050 Brussels, Belgium.
   [Do, Tien Huu; Patro, Jasabanta; Bekoulis, Giannis; Deligiannis, Nikos] imec, B-3001 Leuven, Belgium.
C3 Vrije Universiteit Brussel; IMEC
RP Deligiannis, N (corresponding author), Vrije Univ Brussel VUB, Dept Elect & Informat ETRO, B-1050 Brussels, Belgium.; Deligiannis, N (corresponding author), imec, B-3001 Leuven, Belgium.
EM ndeligia@etrovub.be
OI patro, jasabanta/0000-0003-2461-9679; Do Huu, Tien/0000-0002-7346-5496;
   Deligiannis, Nikos/0000-0001-9300-5860; Bekoulis,
   Giannis/0000-0003-3377-2675; Berneman, Marc/0000-0002-3821-1933
FU VUB through the Strategic Research Program: Processing of large scale
   multi-dimensional, multi-spectral, multi-sensorial, and distributed data
   [M3D2]; Fonds Voor Wetenschappelijk Onderzoek (FWO)FWO [G0A2617N]
FX This work was supported in part by VUB through the Strategic Research
   Program: Processing of large scale multi-dimensional, multi-spectral,
   multi-sensorial, and distributed data (M3D2), and in part by the Fonds
   Voor Wetenschappelijk Onderzoek (FWO) under Grant G0A2617N.
CR Bekoulis G., 2020, ARXIV201003001
   Bekoulis G., 2021, P 4 WORKSH NLP INT F, P23
   Bekoulis G, 2018, EXPERT SYST APPL, V114, P34, DOI 10.1016/j.eswa.2018.07.032
   Briscoe, 2018, P MIS2 WORKSH HELD C
   Castillo C., 2011, WWW, P675
   Chakraborty A, 2016, PROCEEDINGS OF THE 2016 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING ASONAM 2016, P9, DOI 10.1109/ASONAM.2016.7752207
   Deligiannis N., 2018, P NATO IST SPEC M BI, P1
   Devlin J, 2019, PROC C N AM CHAPTER, P4171, DOI DOI 10.18653/V1/N19-1423
   Do T.H., 2017, ARXIV PREPRINT ARXIV
   Do T. H., ARXIV200812578
   Doer B, 2012, COMMUN ACM, V55, P70, DOI 10.1145/2184319.2184338
   Fan L., 2019, P C EMP METH NAT LAN, P6343
   Ferreira W., 2016, P 2016 C N AM CHAPTE, P1163
   Freire Ana, 2016, WIK WORKSH ICWSM 201, V6, P1
   Grover A, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P855, DOI 10.1145/2939672.2939754
   Kai Shu, 2017, ACM SIGKDD Explorations Newsletter, V19, P22, DOI 10.1145/3137597.3137600
   Kim Y., 2014, P EMNLP 2014, P1746, DOI 10.3115/v1/D14-1181
   Kipf T.N., 2016, ARXIV160902907
   Kochkina E., 2018, INT C COMP LING, P3402
   Kwon S, 2013, IEEE DATA MINING, P1103, DOI 10.1109/ICDM.2013.61
   Li L, 2017, PROCEEDINGS OF 2017 3RD IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATIONS (ICCC), P1985, DOI 10.1109/CompComm.2017.8322884
   Liu X., 2015, P 24 ACM INT C INF K, P1867, DOI DOI 10.1145/2806416.2806651
   Liu Y, 2018, THIRTY-SECOND AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTIETH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / EIGHTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P354
   Ma J., 2016, P 25 INT JOINT C ART, P3818
   Ma J, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), P585, DOI 10.1145/3184558.3188729
   Ma J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1980
   Malo P, 2014, J ASSOC INF SCI TECH, V65, P782, DOI 10.1002/asi.23062
   McCann B., ARXIV180608730
   Meel P, 2020, EXPERT SYST APPL, V153, DOI 10.1016/j.eswa.2019.112986
   Mikolov T., 2013, NIPS, V26, P3111
   Nguyen D. M., 2019, P C N AM CHAPT ASS C, P1391
   OBrien N., 2018, P WORKSH AI SOC GOOD
   Patro J., P C EUR CHAPT ASS CO, V202, P3293
   Patro J., 2020, P241
   Patro J, 2019, PROCEEDINGS OF THE 30TH ACM CONFERENCE ON HYPERTEXT AND SOCIAL MEDIA (HT '19), P279, DOI 10.1145/3342220.3344927
   Pavlopoulos J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P4296
   Potthast M., 2017, ARXIV PREPRINT ARXIV
   Ruchansky N, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P797, DOI 10.1145/3132847.3132877
   Ruder S., 2017, OVERVIEW MULTITASK L
   Shu K, 2019, PROCEEDINGS OF THE TWELFTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'19), P312, DOI 10.1145/3289600.3290994
   Tacchini E., 2017, ARXIV170407506, DOI DOI 10.1257/JEP.31.2.211
   Thorne J., 2018, P 27 INT C COMP LINB, P3346
   Thorne J., 2018, FEVER LARGE SCALE DA, P809, DOI 10.18653/v1/N18-1074
   Do TH, 2019, 2019 IEEE DATA SCIENCE WORKSHOP (DSW), P196, DOI 10.1109/DSW.2019.8755600
   Vaswani A, 2017, ADV NEUR IN, V30
   Vlachos A, 2014, ACL, P18, DOI DOI 10.3115/V1/W14-2508
   Volkova S, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P647, DOI 10.18653/v1/P17-2102
   Wang, 2018, ARXIV180901286
   Wang WY, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P422, DOI 10.18653/v1/P17-2067
   Yang F., P MDS 12 ACM SIGKDD, DOI [10.1145/2350190.2350203, DOI 10.1145/2350190.2350203]
   Yu F., 2017, P 26 INT JOINT C ART P 26 INT JOINT C ART, P3901
   Yu PS, 2018, ARXIV180600749, DOI DOI 10.1145/3070644
   Zhang JW, 2020, PROC INT CONF DATA, P1826, DOI 10.1109/ICDE48307.2020.00180
   Zhang M, 2018, IEEE GLOBE WORK
   Zhang T, 2020, IEEE IJCNN
   Zhao Z, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P1395, DOI 10.1145/2736277.2741637
   Zhou XY, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3395046
   Zubiaga A, 2017, INT C SOC INF, P109
   Zubiaga A, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3161603
   Zubiaga A, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0150989
NR 60
TC 0
Z9 0
U1 2
U2 2
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2021
VL 9
BP 130042
EP 130054
DI 10.1109/ACCESS.2021.3113877
PG 13
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA UY0QE
UT WOS:000701237300001
OA gold, Green Published
DA 2022-02-06
ER

PT J
AU Li, YX
   Lu, QW
   Tao, QC
   Zhao, XB
   Yu, YM
AF Li, Yongxiang
   Lu, Qianwen
   Tao, Qingchuan
   Zhao, Xingbo
   Yu, Yanmei
TI SF-GAN: Face De-Identification Method Without Losing Facial Attribute
   Information
SO IEEE SIGNAL PROCESSING LETTERS
LA English
DT Article
DE Faces; Face recognition; Facial features; Generative adversarial
   networks; Information retrieval; Image segmentation; Generators; Face
   de-identification; generative adversarial networks; privacy protection;
   facial attribute information
ID PRIVACY
AB This paper discusses the face de-identification without losing facial attribute information and provides a solution called SF-GAN (Secret Face Generative Adversarial Network). The proposed model aims to realize face de-identification effectively and generate visually reasonable images while retaining the facial attribute information of original images, such as facial expression, gender, hairstyle and wearing glasses or not, as much as possible. To optimize the face de-identification, we construct a variety of external mechanisms to balance the influence of multiple factors on the effect of face de-identification. The SF-GAN differs from the face replacement and face swapping because the later two fails actually in the privacy protection. As for the multi-attribute retention, we use the shallow face attribute information and deep face attribute information, and adopt different processing strategies for different face attribute information based on the uniqueness of each kind of face attribute information. Finally, we train and test the model on two high-definition datasets Celeba-HQ and FFHD. Compared with existing face de-identification methods, the proposed model proved to perform better in protecting the facial privacy.
C1 [Li, Yongxiang; Tao, Qingchuan; Zhao, Xingbo; Yu, Yanmei] Sichuan Univ, Dept Elect & Informat Engn, Chengdu 610041, Peoples R China.
   [Lu, Qianwen] Univ Tokyo, Grad Sch Interdisciplinary Informat Studies, Tokyo 1638001, Japan.
C3 Sichuan University; University of Tokyo
RP Tao, QC (corresponding author), Sichuan Univ, Dept Elect & Informat Engn, Chengdu 610041, Peoples R China.
EM 838194547@qq.com; 396416324@qq.com; taoqingchuan@scu.edu.cn;
   943004233@qq.com; yuyanmei@scu.edu.cn
CR Aarabi P, 2015, IEEE INT SYM MULTIM, P69, DOI 10.1109/ISM.2015.16
   Abdal R, 2019, IEEE I CONF COMP VIS, P4431, DOI 10.1109/ICCV.2019.00453
   Bell S, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766959
   Du L, 2014, 2014 IEEE/IAPR INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB 2014)
   Fan YK, 2020, J NETW COMPUT APPL, V171, DOI 10.1016/j.jnca.2020.102769
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu P, 2021, PATTERN RECOGN, V112, DOI 10.1016/j.patcog.2020.107734
   Hu P, 2019, KNOWL-BASED SYST, V180, P38, DOI 10.1016/j.knosys.2019.05.017
   Korshunova I, 2017, IEEE I CONF COMP VIS, P3697, DOI 10.1109/ICCV.2017.397
   Letournel G, 2015, IEEE IMAGE PROC, P4366, DOI 10.1109/ICIP.2015.7351631
   Li YZ, 2019, IH&MMSEC '19: PROCEEDINGS OF THE ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, P83, DOI 10.1145/3335203.3335719
   Lin JC, 2021, NEURAL NETWORKS, V133, P132, DOI 10.1016/j.neunet.2020.09.001
   Liu C., 2021, WIRELESS COMMUN MOBI, V2021, P1
   Liu MY, 2017, ADV NEUR IN, V30
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Meden B., 2017, P INT C WORKSH BIOIN P INT C WORKSH BIOIN, P1
   Mirjalili V, 2018, INT CONF BIOMETR, P82, DOI 10.1109/ICB2018.2018.00023
   Mirza M., 2017, IEEE C COMPUT VIS PA, P5967
   Nag A, 2020, J MED INTERNET RES, V22, DOI 10.2196/13810
   Neustaedter C., 2006, ACM Transactions on Computer-Human Interaction, V13, P1, DOI 10.1145/1143518.1143519
   Newton EM, 2005, IEEE T KNOWL DATA EN, V17, P232, DOI 10.1109/TKDE.2005.32
   Ren SQ, 2015, ADV NEUR IN, V28
   Ribaric S, 2016, SIGNAL PROCESS-IMAGE, V47, P131, DOI 10.1016/j.image.2016.05.020
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Ryu B, 2017, IEEE T IMAGE PROCESS, V26, P6006, DOI 10.1109/TIP.2017.2726010
   Sharif M, 2016, CCS'16: PROCEEDINGS OF THE 2016 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1528, DOI 10.1145/2976749.2978392
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wong RK, 2016, LECT NOTES COMPUT SC, V9977, P333, DOI 10.1007/978-3-319-50011-9_26
   Wu YF, 2019, J COMPUT SCI TECH-CH, V34, P47, DOI 10.1007/s11390-019-1898-8
   Yang Y.-B, 2016, IMAGE DENOISING USIN, P2802
NR 30
TC 0
Z9 0
U1 10
U2 10
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1070-9908
EI 1558-2361
J9 IEEE SIGNAL PROC LET
JI IEEE Signal Process. Lett.
PY 2021
VL 28
BP 1345
EP 1349
DI 10.1109/LSP.2021.3067517
PG 5
WC Engineering, Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA TJ5HM
UT WOS:000673512500010
DA 2022-02-06
ER

PT J
AU Hasan, HR
   Salah, K
AF Hasan, Haya R.
   Salah, Khaled
TI Combating Deepfake Videos Using Blockchain and Smart Contracts
SO IEEE ACCESS
LA English
DT Article
DE AI; deepfake; blockchain; Ethereum; smart contracts
AB With the rise of artificial intelligence (AI) and deep learning techniques, fake digital contents have proliferated in recent years. Fake footage, images, audios, and videos (known as deepfakes) can be a scary and dangerous phenomenon and can have the potential of altering the truth and eroding trust by giving false reality. Proof of authenticity (PoA) of digital media is critical to help eradicate the epidemic of forged content. Current solutions lack the ability to provide history tracking and provenance of digital media. In this paper, we provide a solution and a general framework using Ethereum smart contracts to trace and track the provenance and history of digital content to its original source even if the digital content is copied multiple times. The smart contract utilizes the hashes of the interplanetary file system (IPFS) used to store digital content and its metadata. Our solution focuses on video content, but the solution framework provided in this paper is generic enough and can be applied to any other form of digital content. Our solution relies on the principle that if the content can be credibly traced to a trusted or reputable source, the content can then be real and authentic. The full code of the smart contract has been made publicly available at Github.
C1 [Hasan, Haya R.; Salah, Khaled] Khalifa Univ, Dept Elect & Comp Engn, Abu Dhabi 127788, U Arab Emirates.
C3 Khalifa University of Science & Technology
RP Salah, K (corresponding author), Khalifa Univ, Dept Elect & Comp Engn, Abu Dhabi 127788, U Arab Emirates.
EM khaled.salah@ku.ac.ae
CR AlTawy R, 2017, 2017465 CRYPT EPRINT
   [Anonymous], 2019, LAWMAKERS WARN DEEPF
   [Anonymous], 2019, SEEING IS NO LONGER
   Azaria A, 2016, PROCEEDINGS 2016 2ND INTERNATIONAL CONFERENCE ON OPEN AND BIG DATA - OBD 2016, P25, DOI 10.1109/OBD.2016.11
   Biswas K, 2016, PROCEEDINGS OF 2016 IEEE 18TH INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING AND COMMUNICATIONS; IEEE 14TH INTERNATIONAL CONFERENCE ON SMART CITY; IEEE 2ND INTERNATIONAL CONFERENCE ON DATA SCIENCE AND SYSTEMS (HPCC/SMARTCITY/DSS), P1392, DOI [10.1109/HPCC-SmartCity-DSS.2016.0198, 10.1109/HPCC-SmartCity-DSS.2016.178]
   Breitinger C., 2016, MCIS, P51
   Christidis K, 2016, IEEE ACCESS, V4, P2292, DOI 10.1109/ACCESS.2016.2566339
   Floridi L., 2018, PHILOS TECHNOLOGY, V31, P317, DOI [10.1007/s13347-018-0325-3, DOI 10.1007/S13347-018-0325-3]
   Khan MA, 2018, FUTURE GENER COMP SY, V82, P395, DOI 10.1016/j.future.2017.11.022
   Li Y, 2018, EXPOSING DEEPFAKE VI
   Singh S, 2016, PROCEEDINGS OF THE 2016 2ND INTERNATIONAL CONFERENCE ON CONTEMPORARY COMPUTING AND INFORMATICS (IC3I), P463, DOI 10.1109/IC3I.2016.7918009
   Stover D, 2018, B ATOM SCI, V74, P283, DOI 10.1080/00963402.2018.1486618
   Tian F, 2019, POLYCYCL AROMAT COMP, V39, P353, DOI 10.1080/10406638.2017.1326952
   Toyoda K, 2017, IEEE ACCESS, V5, P17465, DOI 10.1109/ACCESS.2017.2720760
   Treleaven P, 2017, COMPUTER, V50, P14, DOI 10.1109/MC.2017.3571047
NR 15
TC 69
Z9 73
U1 5
U2 65
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2019
VL 7
BP 41596
EP 41606
DI 10.1109/ACCESS.2019.2905689
PG 11
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA HU8FA
UT WOS:000465519300001
OA gold
DA 2022-02-06
ER

PT J
AU Umer, M
   Imtiaz, Z
   Ullah, S
   Mehmood, A
   Choi, GS
   On, BW
AF Umer, Muhammad
   Imtiaz, Zainab
   Ullah, Saleem
   Mehmood, Arif
   Choi, Gyu Sang
   On, Byung-Won
TI Fake News Stance Detection Using Deep Learning Architecture (CNN-LSTM)
SO IEEE ACCESS
LA English
DT Article
DE Fake news detection; text mining; deep learning; PCA; Chi-square;
   CNN-LSTM; word embedding
AB Society and individuals are negatively influenced both politically and socially by the widespread increase of fake news either way generated by humans or machines. In the era of social networks, the quick rotation of news makes it challenging to evaluate its reliability promptly. Therefore, automated fake news detection tools have become a crucial requirement. To address the aforementioned issue, a hybrid Neural Network architecture, that combines the capabilities of CNN and LSTM, is used with two different dimensionality reduction approaches, Principle Component Analysis (PCA) and Chi-Square. This work proposed to employ the dimensionality reduction techniques to reduce the dimensionality of the feature vectors before passing them to the classifier. To develop the reasoning, this work acquired a dataset from the Fake News Challenges (FNC) website which has four types of stances: agree, disagree, discuss, and unrelated. The nonlinear features are fed to PCA and chi-square which provides more contextual features for fake news detection. The motivation of this research is to determine the relative stance of a news article towards its headline. The proposed model improves results by similar to 4% and similar to 20% in terms of Accuracy and F1 - score. The experimental results show that PCA outperforms than Chi-square and state-of-the-art methods with 97.8% accuracy.
C1 [Umer, Muhammad; Imtiaz, Zainab; Ullah, Saleem] Khwaja Fareed Univ Engn & Informat Technol, Dept Comp Sci, Rahim Yar Khan 64200, Pakistan.
   [Mehmood, Arif] Islamia Univ Bahawalpur, Dept Comp Sci & Informat Technol, Bahawalpur 63100, Pakistan.
   [Choi, Gyu Sang] Yeungnam Univ, Dept Informat & Commun Engn, Gyongsan 38542, South Korea.
   [On, Byung-Won] Kunsan Natl Univ, Dept Stat & Comp Sci, Gunsan 54150, South Korea.
C3 Yeungnam University; Kunsan National University
RP Choi, GS (corresponding author), Yeungnam Univ, Dept Informat & Commun Engn, Gyongsan 38542, South Korea.; On, BW (corresponding author), Kunsan Natl Univ, Dept Stat & Comp Sci, Gunsan 54150, South Korea.
EM castchoi@ynu.ac.kr; on.byung.won@gmail.com
RI Ullah, Saleem/Y-6891-2019; Umer, Muhammad/AAX-4594-2020
OI Ullah, Saleem/0000-0003-3747-1263; Umer, Muhammad/0000-0002-6015-9326;
   Imtiaz, Zainab/0000-0002-4299-8361
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [NRF-2019R1A2C1006159]; MSIT
   (Ministry of Science and ICT), Korea, under the ITRC (Information
   Technology Research Center) support program [IITP-2020-2016-0-00313];
   Fareed Computing Research Center, Department of Computer Science, Khwaja
   Fareed University of Engineering and Information Technology (KFUEIT),
   Rahim Yar Khan, Pakistan
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education (NRF-2019R1A2C1006159) and MSIT (Ministry of Science and
   ICT), Korea, under the ITRC (Information Technology Research Center)
   support program (IITP-2020-2016-0-00313) supervised by the IITP
   (Institute for Information & communications Technology Promotion), and
   in part by the Fareed Computing Research Center, Department of Computer
   Science, Khwaja Fareed University of Engineering and Information
   Technology (KFUEIT), Rahim Yar Khan, Pakistan.
CR Ahmad, 2011, IACSIT INT J ENG TEC, V3, P606
   Ahmad M., 2011, P INT C MOD SIM CONT
   Ahmad M., 2020, ARXIV200414152
   Ahmad M, 2019, OPTIK, V180, P370, DOI 10.1016/j.ijleo.2018.10.142
   Ahmad M, 2017, IET IMAGE PROCESS, V11, P1310, DOI 10.1049/iet-ipr.2017.0168
   Ahmad M, 2016, IEEE IJCNN, P3060, DOI 10.1109/IJCNN.2016.7727588
   Augenstein I., 2016, ARXIV160605464, P876
   Bhatt G, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), P1353, DOI 10.1145/3184558.3191577
   Borges L, 2019, ACM J DATA INF QUAL, V11, DOI 10.1145/3287763
   Bourgonje Peter, 2017, P 2017 EMNLP WORKSHO, P84, DOI 10.18653/v1/W17-4215
   Chaudhry SA, 2017, PEER PEER NETW APPL, V10, P1, DOI 10.1007/s12083-015-0400-9
   Chopra S., 2017, TECH REP
   Chung J., 2014, ARXIV14123555
   Dadgar SMH, 2016, PROCEEDINGS OF 2ND IEEE INTERNATIONAL CONFERENCE ON ENGINEERING & TECHNOLOGY ICETECH-2016, P112, DOI 10.1109/ICETECH.2016.7569223
   Deegalla S, 2006, ICMLA 2006: 5TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS, PROCEEDINGS, P245
   Derczynski L., 2017, P 11 INT WORKSH SEM, P69
   Dulhanty C., 2019, ARXIV191111951
   Dungs S., 2018, INT C COMP LING, P3360
   Enayet O., 2017, SEMEVAL ACL 2017, P470, DOI 10.18653/v1/S17-2082
   Ferreira W., 2016, P 2016 C N AM CHAPTE, P1163
   Ghanem B., 2018, P 1 WORKSH FACT EXTR, P66
   Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042
   Hanselowski A., 2018, ARXIV180605180
   Hanselowski A., 2017, TEAM ATHENE FAKE NEW
   He H., 2015, P 2015 C EMP METH NA, P1576, DOI DOI 10.18653/V1/D15-1181
   Hou DB, 2015, OPT EXPRESS, V23, P17487, DOI 10.1364/OE.23.017487
   Imtiaz Z, 2020, IEEE ACCESS, V8, P21932, DOI 10.1109/ACCESS.2020.2969041
   Ivanova EP, 2015, 2015 8TH INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, ELECTRONICS AND MICROELECTRONICS (MIPRO), P432, DOI 10.1109/MIPRO.2015.7160310
   Karamizadeh S., 2013, J SIGNAL INF PROCESS, V4, P173, DOI 10.4236/jsip.2013.43B031
   Kiros Ryan, 2015, ADV NEURAL INFORM PR, P3294
   Konstantinovskiy L., 2018, ARXIV180908193
   Lazer DMJ, 2018, SCIENCE, V359, P1094, DOI 10.1126/science.aao2998
   Liu Y., 2019, ARXIV190711692
   Lukasik M, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P393
   Meesad P, 2011, INT PROC COMPUT SCI, V6, P110
   Michael Barthel A. M., 2016, MANY AM BELIEVE FAKE
   Mihaylov T., 2015, P 19 C COMP NAT LANG, V15, P310
   Mihaylov T, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P399
   Mohammad S, 2016, P 10 INT WORKSH SEM, P31
   Mohtarami M., 2018, ARXIV180407581
   Neculoiu P., 2016, P 1 WORKSH REPR LEAR, P148, DOI DOI 10.18653/V1/W16-1617
   Pfohl S. R., 2017, TECH REP
   Pomerleau Dean, 2017, FAKE NEWS CHALLENGE
   Popat K, 2017, WWW'17 COMPANION: PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P1003, DOI 10.1145/3041021.3055133
   Rao D. P., 2017, EXPLORING ARTICIAL I
   Riedel B., 2017, SIMPLE TOUGH TO BEAT
   Sean B., 2017, TALOS TARGETS DISINF
   Shahadat M., 2018, INT J COMPUTER APPL, V180, P1, DOI DOI 10.5120/IJCA2018916800
   Shang J., 2018, ARXIV180207398
   Slovikovskaya V., 2019, ARXIV191014353
   Somasundaran S., 2010, P NAACL HLT 2010 WOR, P116
   Sridhar D, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P116
   Stab C, 2017, COMPUT LINGUIST, V43, P619, DOI 10.1162/COLI_a_00295
   Stab Christian, 2018, ARXIV180205758
   Tai KS, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1556
   Thorne J., 2017, P 2017 EMNLP WORKSH, P80
   Umer M, 2020, IEEE ACCESS, V8, P93782, DOI 10.1109/ACCESS.2020.2994810
   Vosoughi S, 2018, SCIENCE, V359, P1146, DOI 10.1126/science.aap9559
   Walker MarilynA, 2012, P NAACL HLT
   Wang XZ, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), P525, DOI 10.1145/3184558.3188723
   Xie X, 2014, P INT COMP SOFTW APP, P107, DOI 10.1109/COMPSAC.2014.17
   Yang L., 2016, ECIR
   Yang Y., 2015, P 2015 C EMP METH NA, DOI DOI 10.18653/V1/D15-1237
   Yang Y., 1997, P INT C MACH LEARN, V412, P420
   Yang Z, 2019, PREPRINT
   Zarrella G., 2016, ACL, DOI DOI 10.18653/V1/S16-1074
   Zeng Q., 2017, TECH REP
   Zhai YJ, 2018, INT CONF SOFTW ENG, P160, DOI 10.1109/ICSESS.2018.8663882
   Zhang Q, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), P41, DOI 10.1145/3184558.3186919
NR 69
TC 20
Z9 20
U1 7
U2 16
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2020
VL 8
BP 156695
EP 156706
DI 10.1109/ACCESS.2020.3019735
PG 12
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA NN3ZY
UT WOS:000568730600001
OA gold
DA 2022-02-06
ER

PT J
AU Tolosana, R
   Vera-Rodriguez, R
   Fierrez, J
   Morales, A
   Ortega-Garcia, J
AF Tolosana, Ruben
   Vera-Rodriguez, Ruben
   Fierrez, Julian
   Morales, Aythami
   Ortega-Garcia, Javier
TI Deepfakes and beyond: A Survey of face manipulation and fake detection
SO INFORMATION FUSION
LA English
DT Article
DE Fake news; Deepfakes; Media forensics; Face manipulation; Face
   recognition; Benchmark; Databases
ID IMAGE FORGERY DETECTION; MULTIPLE CLASSIFIERS; ADVERSARIAL NETWORK;
   SYSTEMS
AB The free access to large-scale public databases, together with the fast progress of deep learning techniques, in particular Generative Adversarial Networks, have led to the generation of very realistic fake content with its corresponding implications towards society in this era of fake news.
   This survey provides a thorough review of techniques for manipulating face images including DeepFake methods, and methods to detect such manipulations. In particular, four types of facial manipulation are reviewed: i) entire face synthesis, ii) identity swap (DeepFakes), iii) attribute manipulation, and iv) expression swap. For each manipulation group, we provide details regarding manipulation techniques, existing public databases, and key benchmarks for technology evaluation of fake detection methods, including a summary of results from those evaluations. Among all the aspects discussed in the survey, we pay special attention to the latest generation of DeepFakes, highlighting its improvements and challenges for fake detection.
   In addition to the survey information, we also discuss open issues and future trends that should be considered to advance in the field.
C1 [Tolosana, Ruben; Vera-Rodriguez, Ruben; Fierrez, Julian; Morales, Aythami; Ortega-Garcia, Javier] Univ Autonoma Madrid, Biometr & Data Pattern Analyt Lab, Madrid, Spain.
C3 Autonomous University of Madrid
RP Tolosana, R (corresponding author), Univ Autonoma Madrid, Biometr & Data Pattern Analyt Lab, Madrid, Spain.
EM ruben.tolosana@uam.es
RI Tolosana, Ruben/ABE-9297-2021; Moreno, Aythami/ABF-8166-2021
OI Tolosana, Ruben/0000-0002-9393-3066; 
FU project: PRIMA [H2020-MSCA-ITN-2019-860315]; project: TRESPASS-ETN
   [H2020-MSCA-ITN-2019-860813]; project: BIBECA (MINECO/FEDER)
   [RTI2018-101248-B-I00]; Bio-Guard (Ayudas Fundacion BBVA a Equipos de
   Investigacion Cientifica 2017)BBVA Foundation; Accenture; Consejeria de
   Educacion, Juventud y Deporte de la Comunidad de Madrid y Fondo Social
   Europeo
FX This work has been supported by projects: PRIMA
   (H2020-MSCA-ITN-2019-860315), TRESPASS-ETN (H2020-MSCA-ITN-2019-860813),
   BIBECA (MINECO/FEDER RTI2018-101248-B-I00), Bio-Guard (Ayudas Fundacion
   BBVA a Equipos de Investigacion Cientifica 2017), and Accenture. Ruben
   Tolosana is supported by Consejeria de Educacion, Juventud y Deporte de
   la Comunidad de Madrid y Fondo Social Europeo.
CR Adjust and Exaggerate Facial Features, 2016, ADJUST EXAGGERATE FA
   Afchar D, 2018, IEEE INT WORKS INFOR
   Agarwal S., 2020, P IEEE CVF C COMP VI
   Agarwal S., 2019, P IEEE CVF C COMP VI
   Agrawal T, 2017, EUR SIGNAL PR CONF, P1045, DOI 10.23919/EUSIPCO.2017.8081367
   Albright M., 2018, ARXIV181208247
   Albright M., 2019, P IEEE CVF C COMP VI
   Allcott H, 2017, J ECON PERSPECT, V31, P211, DOI 10.1257/jep.31.2.211
   Alvi M., 2018, P EUR C COMP VIS
   Amerini I., 2019, P IEEE CVF INT C COM
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   Amos B, 2016, OPENFACE GEN PURPOSE
   Averbuch-Elor H, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130818
   Baltrusaitis T., 2018, P INT C AUT FAC GEST
   Barni M., 2020, IEEE INT C PATT REC, P2020
   Bau D., 2018, P INT C LEARN REPR V
   Bayar B., 2016, P ACM WORKSH INF HID
   BBC Bitesize, 2019, DEEPFAKES WHAT ARE T
   Bellemare Marc G, 2017, ARXIV170510743
   Bharati A, 2016, IEEE T INF FOREN SEC, V11, P1903, DOI 10.1109/TIFS.2016.2561898
   Biggio B., 2019, INT C MACH LEARN
   Binkowski M., 2018, P INT C LEARN REPR
   Bregler C., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P353
   Brkic K., 2017, P IEEE CVF C COMP VI
   Canton C., 2019, IEEE CVF C COMP VIS
   Cao H, 2009, IEEE T INF FOREN SEC, V4, P899, DOI 10.1109/TIFS.2009.2033749
   Cao Q., 2018, P INT C AUT FAC GEST
   Carlini N., 2020, P IEEE CVF C COMP VI, P2020
   Carreira J., 2017, P IEEE CVF C COMP VI
   Cellan-Jones R., 2019, DEEPFAKE VIDEOS DOUB
   Chen YL, 2011, IEEE T INF FOREN SEC, V6, P396, DOI 10.1109/TIFS.2011.2106121
   Cho W., 2019, P IEEE CVF C COMP VI
   Choi Y., 2018, P IEEE CVF C COMP VI
   Chollet F., 2017, P IEEE CVF C COMP VI
   Citron D., 2019, DEEPFAKE UNDERMINE T
   Cozza D., 2015, 2015 IEEE 42nd Photovoltaic Specialist Conference (PVSC). Proceedings, P1, DOI 10.1109/PVSC.2015.7355795
   Cozzolino D., 2019, ARXIV191112069
   Cozzolino D., 2017, P ACM WORKSH INF HID
   Cozzolino Davide, 2018, ARXIV181202510
   Damer N., 2018, GERM C PATT REC
   Dang H., 2020, P IEEE CVF C COMP VI
   Dantcheva A., 2012, 2012 IEEE 5 INT C BI, DOI DOI 10.1109/BTAS.2012.6374605
   Deng J., 2009, P IEEE CVF C COMP VI
   Dolhansky B., 2019, DEEPFAKE DETECTION C
   Farid H, 2009, IEEE SIGNAL PROC MAG, V26, P16, DOI 10.1109/MSP.2008.931079
   Fernandes S., 2020, P IEEE CVF C COMP VI
   Ferrara M., 2019, ARXIV190108811
   Ferrara M, 2018, IEEE T INF FOREN SEC, V13, P1008, DOI 10.1109/TIFS.2017.2777340
   Fierrez J, 2018, INFORM FUSION, V44, P57, DOI 10.1016/j.inffus.2017.12.003
   Fierrez J, 2018, INFORM FUSION, V44, P103, DOI 10.1016/j.inffus.2017.12.005
   Flynn P., 2003, P INT C AUD AND VID
   Fried O., ACM T GRAPH, V38, P1
   Gafni O., 2019, ARXIV191108348
   Galbally J, 2014, IEEE ACCESS, V2, P1530, DOI 10.1109/ACCESS.2014.2381273
   Galbally J, 2014, IEEE T IMAGE PROCESS, V23, P710, DOI 10.1109/TIP.2013.2292332
   Gironi A., 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P6226, DOI 10.1109/ICASSP.2014.6854801
   Gomez-Barrero M, 2017, I W BIOMETRIC FORENS
   Gong Sixue, 2019, ARXIV191108080
   Gonzalez-Sosa E, 2018, IEEE T INF FOREN SEC, V13, P2001, DOI 10.1109/TIFS.2018.2807791
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Gross R., 2006, P IEEE CVF C COMP VI
   Gross Ralph, 2009, PROTECTING PRIVACY V, P129, DOI [10.1007/978-1-84882-301-3_8, DOI 10.1007/978-1-84882-301-3_8]
   Guan H., 2019, P IEEE WINT APPL COM
   Guarnera L., 2020, P IEEE CVF C COMP VI
   Guera D., 2018, P INT C ADV VID SIGN
   Guo G., 2019, ARXIV190711418
   Guo S., 2018, P CHIN CONTR C
   Hadid A, 2015, IEEE SIGNAL PROC MAG, V32, P20, DOI 10.1109/MSP.2015.2437652
   Hara K., 2018, P IEEE CVF C COMP VI
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI 10.1007/978-3-319-10578-9_23
   He ZL, 2019, IEEE T IMAGE PROCESS, V28, P5464, DOI 10.1109/TIP.2019.2916751
   Hinton G.E., 2018, P INT C LEARN REPR W
   Hinton GE, 2011, LECT NOTES COMPUT SC, V6791, P44, DOI 10.1007/978-3-642-21735-7_6
   Hosler B.C., 2020, P IEEE CVF C COMP VI
   Huh M., 2018, P EUR C COMP VIS
   Hulzebosch N., 2020, P IEEE CVF C COMP VI, P2020
   Isola P., 2017, P IEEE CVF C COMP VI
   Jain A., 2020, P IEEE CVF C COMP VI
   Jain A, 2018, INT CONF BIOMETR THE
   Jung T, 2020, IEEE ACCESS, V8, P83144, DOI 10.1109/ACCESS.2020.2988660
   Kai Shu, 2017, ACM SIGKDD Explorations Newsletter, V19, P22, DOI 10.1145/3137597.3137600
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Karras T., 2019, P IEEE CVF C COMP VI
   Karras Tero., 2020, P IEEE CVF C COMP VI P IEEE CVF C COMP VI
   Khalid H., 2020, P IEEE CVF C COMP VI
   Kietzmann J, 2020, BUS HORIZONS, V63, P135, DOI 10.1016/j.bushor.2019.11.006
   Kim J, 2005, IEEE T PATTERN ANAL, V27, P1977, DOI 10.1109/TPAMI.2005.242
   Kim T., 2017, P INT C MACH LEARN
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Kingma DP, 2018, ADV NEUR IN, V31
   Korshunov P., 2018, P EUR SIGN PROC C
   Korshunov P., 2019, ARXIV191001933
   Korus P, 2017, DIGIT SIGNAL PROCESS, V71, P1, DOI 10.1016/j.dsp.2017.08.009
   Kose N., 2015, P INT C WORKSH AUT F
   Kraetzer C., P 5 ACM WORKSH INF H, P21, DOI [10.1145/3082031.3083244, DOI 10.1145/3082031.3083244]
   Lample G, 2017, ADV NEUR IN, V30
   Lazer DMJ, 2018, SCIENCE, V359, P1094, DOI 10.1126/science.aao2998
   Lehtinen J, 2018, P INT C LEARN REPR
   Li M., 2016, ARXIV161005586
   Li Y., 2020, P IEEE CVF C COMP VI
   Li Y., 2019, P IEEE CVF C COMP VI
   Li Y., 2019, P ACM WORKSH INF HID
   Li YZ, 2018, IEEE INT WORKS INFOR
   Lin ZC, 2009, PATTERN RECOGN, V42, P2492, DOI 10.1016/j.patcog.2009.03.019
   Liu M., 2019, P IEEE CVF C COMP VI
   Liu Z., 2015, P IEEE CVF INT C COM
   Majumdar P., 2019, P IEEE CVF C COMP VI
   Marcel S., 2019, HDB BIOMETRIC ANTISP
   Marcel Sebastien, 2018, ARXIV PREPRINT ARXIV
   Marra F., 2019, P IEEE INT WORKSH IN
   Marra F, 2019, 2019 2ND IEEE CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2019), P506, DOI 10.1109/MIPR.2019.00103
   Matern F., 2019, P IEEE WINT APPL COM
   Meden B, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20010060
   Meden B, 2017, IET SIGNAL PROCESS, V11, P1046, DOI 10.1049/iet-spr.2017.0049
   Milani S, 2012, APSIPA TRANS SIGNAL, V1, DOI 10.1017/ATSIP.2012.2
   Mirjalili V, 2019, IEEE ACCESS, V7, P99735, DOI 10.1109/ACCESS.2019.2924619
   Mirza M, 2014, ARXIV PREPRINT ARXIV
   Miyato T., 2018, P INT C LEARN REPR
   Montserrat D.M., 2020, P IEEE CVF C COMP VI
   Moon TK, 1996, IEEE SIGNAL PROC MAG, V13, P47, DOI 10.1109/79.543975
   Morales A., 2020, P IEEE COMP SOFTW AP P IEEE COMP SOFTW AP
   Morales A, 2019, ARXIV190200334
   Nataraj L., 2019, J ELECTRON IMAGING, V5, P1
   Neves J., 2020, IEEE J SEL TOP SIGNA
   Nguyen H., 2019, ARXIV190606876
   Nguyen Huy H, 2019, ARXIV191012467
   Pan Y.L., 2019, P INT C ADV VID SIGN
   Peng F, 2019, IEEE ACCESS, V7, P75122, DOI 10.1109/ACCESS.2019.2920713
   Perarnau G., 2016, P ADV NEURAL INFORM
   Perez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269
   Piva, 2013, ISRN SIGNAL PROCESS, V01, DOI [10.1155/2013/496701, DOI 10.1155/2013/496701]
   Popescu AC, 2005, IEEE T SIGNAL PROCES, V53, P3948, DOI 10.1109/TSP.2005.855406
   Qian C., 2020, ARXIV200105201
   Rahmouni N, 2017, IEEE INT WORKS INFOR
   Raja K., 2020, ARXIV200606458
   Raja K., 2020, IEEE WINT C APPL COM
   Ranjan R, 2019, IEEE T PATTERN ANAL, V41, P121, DOI 10.1109/TPAMI.2017.2781233
   Rathgeb C, 2020, IEEE ACCESS, V8, P106373, DOI 10.1109/ACCESS.2020.3000254
   Rathgeb C., 2020, IET BIOM
   Rathgeb C, 2019, IEEE ACCESS, V7, P152667, DOI 10.1109/ACCESS.2019.2948526
   Rebuffi S., 2017, P IEEE CVF C COMP VI
   Rocha A, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1978802.1978805
   Rossler A., 2019, P IEEE CVF INT C COM
   Rossler Andreas, 2018, ARXIV180309179
   Sabir E., 2019, P IEEE CVF C COMP VI
   Sabour S., 2017, NIPS, P3856
   Sanderson C., 2009, P INT C BIOM
   Scherhag U., 2018, P IEEE INT C IM SIGN
   Scherhag U., 2020, ARXIV200101202
   Scherhag U, 2019, IEEE ACCESS, V7, P23012, DOI 10.1109/ACCESS.2019.2899367
   Schroff F., 2015, P IEEE CVF C COMP VI
   Shen W., 2017, P IEEE CVF C COMP VI
   Shen Y., 2020, P IEEE CVF C COMP VI, P2020
   Shu K, 2019, COMPUT MATH ORGAN TH, V25, P60, DOI 10.1007/s10588-018-09280-3
   Simonyan K, 2015, ICLR 2015, DOI DOI 10.1109/CVPR.2015.7298594
   Simonyan K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.8
   Singh M, 2019, INFORM FUSION, V52, P187, DOI 10.1016/j.inffus.2018.12.003
   Song Y., 2019, P INT JOINT C ART IN
   Soukupova T., 2016, P COMP VIS WINT WORK
   Stamm MC, 2010, IEEE T INF FOREN SEC, V5, P492, DOI 10.1109/TIFS.2010.2053202
   Sun D., 2018, P IEEE CVF C COMP VI
   Sun Q., 2018, P IEEE CVF C COMP VI
   Suwajanakorn S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073640
   Swaminathan A, 2008, IEEE T INF FOREN SEC, V3, P101, DOI 10.1109/TIFS.2007.916010
   Szegedy C., 2015, P IEEE CVF C COMP VI
   Szegedy C., 2016, P IEEE CVF C COMP VI
   Tariq S, 2018, MPS'18: PROCEEDINGS OF THE 2ND INTERNATIONAL WORKSHOP ON MULTIMEDIA PRIVACY AND SECURITY, P81, DOI 10.1145/3267357.3267367
   Thies J., 2016, P IEEE CVF C COMP VI
   Thies J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323035
   Tolosana R., 2020, ARXIV200605327
   Tolosana R., 2020, ARXIV PREPRINT ARXIV
   Tursman E., 2020, P IEEE CVF C COMP VI
   Vaswani A, 2017, ADV NEUR IN, P5998
   Verdoliva L., 2019, ACM MULTIMEDIA
   Verdoliva L., 2020, IEEE J SEL TOP SIGNA
   Wang R, 2019, ARXIV PREPRINT ARXIV
   Wang S., 2019, P IEEE CVF INT C COM
   Wang Y, 2020, AMB EXPRESS, V10, DOI 10.1186/s13568-019-0940-0
   Welling M, 2013, P INT C LEARN REPR
   Wolberg G, 1998, VISUAL COMPUT, V14, P360, DOI 10.1007/s003710050148
   Xiao T., 2018, P EUR C COMP VIS
   Yang Q., 2020, P IEEE CVF C COMP VI
   Yang X., 2019, P INT C AC SPEECH SI
   Yerushalmy I, 2011, INT J COMPUT VISION, V92, P71, DOI 10.1007/s11263-010-0403-1
   Yi D., 2014, ARXIV14117923
   Yu N., 2019, P IEEE CVF INT C COM
   Yu Z., 2020, P IEEE CVF C COMP VI
   Yuxing Wu, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P2674, DOI 10.1109/ICASSP.2014.6854085
   Zakharov E., 2019, P IEEE CVF INT C COM
   Zhang L.B., 2018, P INT C MULT EXP
   Zhang X., 2019, P IEEE INT WORKSH IN
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
   Zhou H., 2019, P AAAI C ART INT
   Zhou P., 2018, P IEEE CVF C COMP VI
   Zhou P., 2017, P IEEE CVF C COMP VI
   Zhu J., 2017, P ADV NEUR INF PROC
   Zhu J., 2017, P IEEE CVF INT C COM
NR 198
TC 44
Z9 45
U1 14
U2 102
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1566-2535
EI 1872-6305
J9 INFORM FUSION
JI Inf. Fusion
PD DEC
PY 2020
VL 64
BP 131
EP 148
DI 10.1016/j.inffus.2020.06.014
PG 18
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NS3LH
UT WOS:000572166500010
OA Green Submitted
DA 2022-02-06
ER

PT J
AU Palani, B
   Elango, S
   Viswanathan, KV
AF Palani, Balasubramanian
   Elango, Sivasankar
   Viswanathan, Vignesh K.
TI CB-Fake: A multimodal deep learning framework for automatic fake news
   detection using capsule neural network and BERT
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Fake news detection; Deep learning; BERT; Capsule neural network;
   Routing-by-agreement
AB The progressive growth of today's digital world has made news spread exponentially faster on social media platforms like Twitter, Facebook, and Weibo. Unverified news is often disseminated in the form of multimedia content like text, picture, audio, or video. The dissemination of such false news deceives the public and leads to protests and creates troubles for the public and the government. Hence, it is essential to verify the authenticity of the news at an early stage before sharing it with the public. Earlier fake news detection (FND) approaches combined textual and visual features, but the semantic correlations between words were not addressed and many informative visual features were lost. To address this issue, an automated fake news detection system is proposed, which fuses textual and visual features to create a multimodal feature vector with high information content. The proposed work incorporates the bidirectional encoder representations from transformers (BERT) model to extract the textual features, which preserves the semantic relationships between words. Unlike the convolutional neural network (CNN), the proposed capsule neural network (CapsNet) model captures the most informative visual features from an image. These features are combined to obtain a richer data representation that helps to determine whether the news is fake or real. We investigated the performance of our model against different baselines using two publicly accessible datasets, Politifact and Gossipcop. Our proposed model achieves significantly better classification accuracy of 93% and 92% for the Politifact and Gossipcop datasets, respectively, compared to 84.6% and 85.6% for the SpotFake+ model.
C1 [Palani, Balasubramanian; Elango, Sivasankar] Natl Inst Technol, Dept Comp Sci & Engn, Tiruchirappalli, Tamil Nadu, India.
   [Viswanathan, Vignesh K.] Visa Inc, Bengaluru, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Tiruchirappalli
RP Palani, B (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Tiruchirappalli, Tamil Nadu, India.
EM balaiiits@gmail.com; sivasankar@nitt.edu; vigneshkvn2098@gmail.com
CR Ahmed H, 2017, LECT NOTES COMPUT SC, V10618, P127, DOI 10.1007/978-3-319-69155-8_9
   Akyol K, 2019, CMC-COMPUT MATER CON, V61, P69, DOI 10.32604/cmc.2019.08143
   Allcott H, 2017, J ECON PERSPECT, V31, P211, DOI 10.1257/jep.31.2.211
   Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   Faustini PHA, 2020, EXPERT SYST APPL, V158, DOI 10.1016/j.eswa.2020.113503
   Asghar MZ, 2021, J AMB INTEL HUM COMP, V12, P4315, DOI 10.1007/s12652-019-01527-4
   Bondielli A, 2019, INFORM SCIENCES, V497, P38, DOI 10.1016/j.ins.2019.05.035
   Chen T, 2018, LECT NOTES ARTIF INT, V11154, P40, DOI 10.1007/978-3-030-04503-6_4
   Devlin J, 2019, PROC C N AM CHAPTER, P4171, DOI DOI 10.18653/V1/N19-1423
   Goldani MH, 2021, APPL SOFT COMPUT, V101, DOI 10.1016/j.asoc.2020.106991
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Guo B, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3393880
   Guo CX, 2019, IEEE I CONF COMP VIS, P3908, DOI 10.1109/ICCV.2019.00401
   Han, 2012, SDM, P153
   Hinton G.E, 2018, INT C LEARN REPR, DOI DOI 10.2514/6.2003
   Hinton GE, 2011, LECT NOTES COMPUT SC, V6791, P44, DOI 10.1007/978-3-642-21735-7_6
   Jin ZW, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P795, DOI 10.1145/3123266.3123454
   Kai Shu, 2017, ACM SIGKDD Explorations Newsletter, V19, P22, DOI 10.1145/3137597.3137600
   Kaliyar RK, 2021, MULTIMED TOOLS APPL, V80, P11765, DOI 10.1007/s11042-020-10183-2
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Khattar D, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P2915, DOI 10.1145/3308558.3313552
   Kouzy R, 2020, CUREUS, V12, DOI 10.7759/cureus.7255
   Kumar A, 2019, MULTIMED TOOLS APPL, V78, P24083, DOI 10.1007/s11042-019-7398-6
   Li QZ, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1173
   Liu Y, 2018, THIRTY-SECOND AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTIETH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / EIGHTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P354
   Ma J., 2018, RUMOR DETECTION TWIT
   Ma J., 2016, P 25 INT JOINT C ART, P3818
   Ma J, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), P585, DOI 10.1145/3184558.3188729
   Marra F, 2018, IEEE 1ST CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2018), P384, DOI 10.1109/MIPR.2018.00084
   Nayak Pandu., 2019, UNDERSTANDING SEARCH
   Ozbay FA, 2020, PHYSICA A, V540, DOI 10.1016/j.physa.2019.123174
   Ozbay FA, 2019, ELEKTRON ELEKTROTECH, V25, P62, DOI 10.5755/j01.eie.25.4.23972
   Patrick MK, 2022, J KING SAUD UNIV-COM, V34, P1295, DOI 10.1016/j.jksuci.2019.09.014
   Perez-Rosas V, 2017, ARXIV PREPRINT ARXIV
   Qi P, 2019, IEEE DATA MINING, P518, DOI 10.1109/ICDM.2019.00062
   Rapoza K., 2017, FORBES
   Roger M, 2019, GOOGLES BERT ROLLS O
   Sabour S., 2017, NIPS, P3856
   Savyan PV, 2020, MULTIMED TOOLS APPL, V79, P19349, DOI 10.1007/s11042-020-08721-z
   Shu K, 2020, BIG DATA-US, V8, P171, DOI 10.1089/big.2020.0062
   Shu K, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P395, DOI 10.1145/3292500.3330935
   Singh SK, 2021, COMPUT SCI INF SYST, V18, P597, DOI 10.2298/CSIS200330012S
   Singhal S, 2020, AAAI CONF ARTIF INTE, V34, P13915
   Singhal S, 2019, 2019 IEEE FIFTH INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2019), P39, DOI [10.1109/BigMM.2019.00018, 10.1109/BigMM.2019.00-44]
   Vaswani A, 2017, ADV NEUR IN, V30
   Vesperini F, 2019, IEEE J-STSP, V13, P310, DOI 10.1109/JSTSP.2019.2902305
   Wang WY, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P422, DOI 10.18653/v1/P17-2067
   Wang YQ, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P849, DOI 10.1145/3219819.3219903
   Wang YW, 2020, FRONT PHARMACOL, V10, DOI 10.3389/fphar.2019.01631
   Wu K, 2015, PROC INT CONF DATA, P651, DOI 10.1109/ICDE.2015.7113322
   Wu L, 2018, WSDM'18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P637, DOI 10.1145/3159652.3159677
   Yang KH, 2020, CMC-COMPUT MATER CON, V64, P557, DOI 10.32604/cmc.2020.09907
   Yin LB, 2019, CMC-COMPUT MATER CON, V60, P275, DOI 10.32604/cmc.2019.05556
   Yu F., 2017, IJCAI 2017, P3901, DOI 10.24963/ijcai.2017/545
   Yu PS, 2018, ARXIV180600749, DOI DOI 10.1145/3070644
   Zeng JF, 2019, NEUROCOMPUTING, V366, P295, DOI 10.1016/j.neucom.2019.07.085
   Zhou P, 2018, PROC CVPR IEEE, P1053, DOI 10.1109/CVPR.2018.00116
   Zhou X., 2020, DIGITAL THREATS RES, DOI 10.1145/3377478
   Zhou XY, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3395046
   Zhou XY, 2019, PROCEEDINGS OF THE TWELFTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'19), P836, DOI 10.1145/3289600.3291382
NR 60
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
DI 10.1007/s11042-021-11782-3
EA DEC 2021
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XW0UJ
UT WOS:000735344900004
PM 34975284
OA Bronze, Green Published
DA 2022-02-06
ER

PT J
AU Mohawesh, R
   Xu, SX
   Tran, SN
   Ollington, R
   Springer, M
   Jararweh, Y
   Maqsood, S
AF Mohawesh, Rami
   Xu, Shuxiang
   Tran, Son N.
   Ollington, Robert
   Springer, Matthew
   Jararweh, Yaser
   Maqsood, Sumbal
TI Fake Reviews Detection: A Survey
SO IEEE ACCESS
LA English
DT Review
DE Feature extraction; Task analysis; Social networking (online); Deep
   learning; Companies; Licenses; Portable computers; Fake review; fake
   review detection; feature engineering; machine learning; deep learning
ID OPINION SPAM DETECTION; NEURAL-NETWORKS; ENSEMBLE MODEL; DECEPTION;
   INFORMATION; MESSAGES; CUES
AB In e-commerce, user reviews can play a significant role in determining the revenue of an organisation. Online users rely on reviews before making decisions about any product and service. As such, the credibility of online reviews is crucial for businesses and can directly affect companies' reputation and profitability. That is why some businesses are paying spammers to post fake reviews. These fake reviews exploit consumer purchasing decisions. Consequently, the techniques for detecting fake reviews have extensively been explored in the past twelve years. However, there still lacks a survey that can analyse and summarise the existing approaches. To bridge up the issue, this survey paper details the task of fake review detection, summing up the existing datasets and their collection methods. It analyses the existing feature extraction techniques. It also summarises and analyses the existing techniques critically to identify gaps based on two groups: traditional statistical machine learning and deep learning methods. Further, we conduct a benchmark study to investigate the performance of different neural network models and transformers that have not been used for fake review detection yet. The experimental results on two benchmark datasets show that RoBERTa performs about 7% better than the state-of-the-art methods in a mixed domain for the deception dataset with the highest accuracy of 91.2%, which can be used as a baseline for future studies. Finally, we highlight the current gaps in this research area and the possible future directions.
C1 [Mohawesh, Rami; Xu, Shuxiang; Tran, Son N.; Ollington, Robert; Springer, Matthew; Maqsood, Sumbal] Univ Tasmania, Sch Informat & Commun Technol, Hobart, Tas 7005, Australia.
   [Jararweh, Yaser] Jordan Univ Sci & Technol, Comp Sci Dept, Irbid 22110, Jordan.
C3 University of Tasmania; Jordan University of Science & Technology
RP Mohawesh, R (corresponding author), Univ Tasmania, Sch Informat & Commun Technol, Hobart, Tas 7005, Australia.
EM rami.mohawesh@utas.edu.au
RI Jararweh, Yaser/ABE-6543-2021; Xu, Shuxiang/H-1595-2013
OI Xu, Shuxiang/0000-0003-0597-7040; Jararweh, Yaser/0000-0002-4403-3846;
   Mohawesh, Rami/0000-0002-9332-3487
CR Achsas S., 2020, P 13 INT C INT SYST, P1
   Aghakhani H, 2018, 2018 IEEE SYMPOSIUM ON SECURITY AND PRIVACY WORKSHOPS (SPW 2018), P89, DOI 10.1109/SPW.2018.00022
   Akram AU, 2018, KSII T INTERNET INF, V12, P5120, DOI 10.3837/tiis.2018.10.026
   Al-Hawawreh M., 2019, P 3 INT C BIG DAT IN, P126
   Alberto TC, 2015, J INTELL ROBOT SYST, V80, pS245, DOI 10.1007/s10846-014-0105-y
   Algur S. P., 2017, INT J ADV RES COMPUT, V8
   Alharthi M., 2019, P 2019 MIL COMM INF, P1, DOI DOI 10.1109/MILCIS.2019.8930732
   Almeida F., 2019, ARXIV190109069
   [Anonymous], 2015, J BIG DATA-GER, DOI [10.1186/s40537-015-0029-9, DOI 10.1186/S40537-015-0029-9]
   [Anonymous], PROC 2014 C EMPIRICA, DOI [DOI 10.3115/V1/D14-1162, 10.3115/v1/d14-1162]
   Asadullah S. M., 2017, CLASSIFICATION TWITT
   Aslam U., 2019, INT J SCI TECHNOL RE, V8, P1
   Barbado R, 2019, INFORM PROCESS MANAG, V56, P1234, DOI 10.1016/j.ipm.2019.03.002
   Baroni M, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P238
   Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223
   Bethard S., 2013, P 2013 C EMP METH NA, P1393
   Biber Douglas, 2000, LONGMAN GRAMMAR SPOK
   Bo Pang, 2008, Foundations and Trends in Information Retrieval, V2, P1, DOI 10.1561/1500000001
   Bordes A., 2014, ARXIV14063676
   Cade W. L., 2010, P ANN C N AM CHAPT A, P669
   Cagnina L., 2015, P 6 WORKSH COMP APPR, P58
   Cao N, 2020, EXPERT SYST APPL, V156, DOI 10.1016/j.eswa.2020.113465
   Capuozzo P, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P1423
   Cardoso EF, 2018, NEUROCOMPUTING, V309, P106, DOI 10.1016/j.neucom.2018.04.074
   Chalapathy R., 2018, CORR
   Chan PPK, 2015, NEUROCOMPUTING, V155, P167, DOI 10.1016/j.neucom.2014.12.034
   Chen YR, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P173, DOI 10.1145/2736277.2741085
   Collobert R., 2008, P 25 INT C MACH LEAR, P160, DOI DOI 10.1145/1390156.1390177
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Deng HX, 2017, IEEE INT SYMP PARAL, P1278, DOI 10.1109/ISPA/IUCC.2017.00195
   DePaulo BM, 2003, PSYCHOL BULL, V129, P74, DOI 10.1037//0033-2909.129.1.74
   Desir C, 2013, PATTERN RECOGN, V46, P3490, DOI 10.1016/j.patcog.2013.05.022
   Devlin J, 2019, PROC C N AM CHAPTER, P4171, DOI DOI 10.18653/V1/N19-1423
   Dhamani N., 2019, ARXIV190510412
   Dong LY, 2018, EXPERT SYST APPL, V114, P210, DOI 10.1016/j.eswa.2018.07.005
   Eisenstein J., 2011, P 28 INT C MACH LEAR
   Elkan C., 2008, PROC 14 ACM SIGKDD I, DOI DOI 10.1145/1401890.1401920
   Fahfouh A, 2020, EXPERT SYST APPL, V157, DOI 10.1016/j.eswa.2020.113517
   Fei G., 2013, P 7 INT AAAI C WEBL, P1
   Feng S., 2012, P 50 ANN M ASS COMP, V50, P171
   Feng VW., 2013, P 6 INT JOINT C NAT, P338
   Fitzpatrick E., 2015, SYNTHESIS LECT HUMAN, V8, P1
   Fornaciari T., 2014, P 14 C EUR CHAPT ASS, P279, DOI DOI 10.3115/V1/E14-1030
   Ganin Y., 2014, UNSUPERVISED DOMAIN
   Ganin Y, 2015, PR MACH LEARN RES, V37, P1180
   Garcia-Duran Alberto, 2013, ADV NEURAL INFORM PR, V26, P2787
   Gieseke Fabian, 2012, Proceedings of the 1st International Conference on Pattern Recognition Applications and Methods. ICPRAM 2012, P45
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Grasser F, 2018, DH '18: PROCEEDINGS OF THE 2018 INTERNATIONAL CONFERENCE ON DIGITAL HEALTH, P121, DOI 10.1145/3194658.3194677
   Grover A, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P855, DOI 10.1145/2939672.2939754
   Guo ZW, 2021, FUTURE GENER COMP SY, V117, P205, DOI 10.1016/j.future.2020.11.028
   Hai Zhen, 2016, P 2016 C EMP METH NA, P1817
   Hammad A.A., 2013, INT ARAB J INFORM TE, V12, P9
   Hancock, 2011, P 49 ANN M ASS COMP, P309, DOI DOI 10.1145/2567948.2577293
   Hernandez-Castaneda A, 2017, SOFT COMPUT, V21, P585, DOI 10.1007/s00500-016-2409-2
   Heydari A, 2016, EXPERT SYST APPL, V58, P83, DOI 10.1016/j.eswa.2016.03.020
   Heydari A, 2015, EXPERT SYST APPL, V42, P3634, DOI 10.1016/j.eswa.2014.12.029
   Ho-Dac NN, 2013, J MARKETING, V77, P37, DOI 10.1509/jm.11.0011
   Hu M., 2004, P 10 ACM SIGKDD INT, P168
   Huang HH, 2017, WWW'17 COMPANION: PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P795, DOI 10.1145/3041021.3054233
   Jain N, 2019, LECT NOTES COMPUT SC, V11608, P79, DOI 10.1007/978-3-030-23281-8_7
   Ji SJ, 2020, INFORM SCIENCES, V536, P454, DOI 10.1016/j.ins.2020.05.084
   Jiang M, 2016, IEEE INTELL SYST, V31, P31, DOI 10.1109/MIS.2016.5
   Jindal N., 2008, P 2008 INT C WEB SEA, P219
   Jindal N., P 16 INT C WORLD WID, P1189, DOI DOI 10.1145/1242572.1242759
   Jing Y., 2014, RES DECEPTIVE OP SPA
   Joachims T, 1999, MACHINE LEARNING, PROCEEDINGS, P200
   Joulin Armand, 2016, ARXIV160701759
   Khan SS, 2014, KNOWL ENG REV, V29, P345, DOI 10.1017/S026988891300043X
   Khan SS, 2010, LECT NOTES ARTIF INT, V6206, P188
   Khurshid F., 2017, P 12 INT C INT SYST, P1
   Khurshid F, 2019, INT J COMPUT INT SYS, V12, P387, DOI 10.2991/ijcis.2019.125905655
   Kim S., 2015, P INT C INF KNOWL MA, P1131
   LAI S, 2015, P 29 AAAI C ART INT, P1
   Le Q., 2014, P 31 INT C INT C MAC
   Lei JZ, 2012, NEUROCOMPUTING, V75, P135, DOI 10.1016/j.neucom.2011.02.021
   Li CH, 2012, NEUROCOMPUTING, V92, P88, DOI 10.1016/j.neucom.2011.09.036
   Li F.H., 2011, P 22 INT JOINT C ART, P2488
   Li HY, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P1063, DOI 10.1145/3038912.3052582
   Li HY, 2014, IEEE DATA MINING, P899, DOI 10.1109/ICDM.2014.47
   Li J., 2013, P C EMP METH NAT LAN, P1933
   Li J., 2014, ARXIV14123714
   Li JD, 2021, EXPERT SYST APPL, V171, DOI 10.1016/j.eswa.2021.114585
   Li JW, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1566
   Li LY, 2017, NEUROCOMPUTING, V254, P33, DOI 10.1016/j.neucom.2016.10.080
   Li LY, 2015, LECT NOTES ARTIF INT, V9427, P393, DOI 10.1007/978-3-319-25816-4_32
   Li Q, 2019, LECT NOTES ARTIF INT, V11439, P222, DOI 10.1007/978-3-030-16148-4_18
   Li QY, 2019, PEER PEER NETW APPL, V12, P1673, DOI 10.1007/s12083-019-00753-z
   Li S, 2013, P 51 ANN M ASS COMP, V2, P217
   Li Y., 2015, IN PRESS, V12, P1615
   Li Z., P3539
   Ligthart A, 2021, APPL SOFT COMPUT, V101, DOI 10.1016/j.asoc.2020.107023
   Lin YM, 2014, WWW'14 COMPANION: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P341, DOI 10.1145/2567948.2577293
   Ling W., 2015, ARXIV150802096
   Liu B., 2012, SYNTHESIS LECT HUMAN, P1, DOI DOI 10.2200/S00416ED1V01Y201204HLT016
   Liu B., 2002, P INT C MACH LEARN I, P387
   Liu WT, 2020, COMPUTING, V102, P701, DOI 10.1007/s00607-019-00763-y
   Liu Y., 2019, ARXIV190711692
   Maas A, 2011, P 49 ANN M ASS COMP
   Mairesse F, 2007, J ARTIF INTELL RES, V30, P457, DOI 10.1613/jair.2349
   Maity SK, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), P63, DOI 10.1145/3184558.3186930
   Mani S, 2018, MACHINE LEARNING DAT
   Mikolov T., 2013, PROC INT C ADV NEURA, P3111
   Mohawesh R., 2021, EXPERT SYST APPL, V169
   Mukherjee A., 2012, P 21 INT C WORLD WID, P191
   Mukherjee A., 2013, UICCS032013
   Mukherjee A., 2013, 2013 INT C CONTR AUT, P1
   Mukherjee A, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P632
   Nanni L, 2006, NEUROCOMPUTING, V69, P842, DOI 10.1016/j.neucom.2005.09.007
   Nguyen V.-A., 2010, P 19 ACM INT C INF K, P939, DOI DOI 10.1145/1871437.1871557
   Nickel M, 2011, ICML, V11, P809
   Nilizadeh S, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P3108, DOI 10.1145/3308558.3313647
   Noekhah S, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102140
   Noekhah S, 2018, ADV SCI LETT, V24, P1437, DOI 10.1166/asl.2018.10765
   Ong T, 2014, ELECTRON COMMER R A, V13, P69, DOI 10.1016/j.elerap.2013.10.002
   Ott M, 2013, P NAACL HLT 2013, P497
   Pan ZQ, 2019, IEEE ACCESS, V7, P36322, DOI 10.1109/ACCESS.2019.2905015
   Patel N., 2018, 2018 4 INT C COMP CO, P1
   Penalver-Martinez I, 2014, EXPERT SYST APPL, V41, P5995, DOI 10.1016/j.eswa.2014.03.022
   Peng ML, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2505
   Perez-Rosas V, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P440
   Petrov S., 2015, ARXIV PREPRINT ARXIV
   Popescu A.-M., 2007, NATURAL LANGUAGE PRO, P9, DOI [DOI 10.1007/978-1-84628-754-1_2, 10. 1007/978-1-84628-754-1_2]
   Rastogi A, 2020, J DATA INFO SCI, V5, P76, DOI 10.2478/jdis-2020-0013
   Rayana S, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P985, DOI 10.1145/2783258.2783370
   Rayson P, 2002, LANG COMPUT, P295
   Ren Y., 2014, P C EMP METH NAT LAN, P488
   Ren YF, 2019, IEEE ACCESS, V7, P42934, DOI 10.1109/ACCESS.2019.2908495
   Ren YF, 2017, INFORM SCIENCES, V385, P213, DOI 10.1016/j.ins.2017.01.015
   Ren YF, 2016, THIRTIETH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P215
   Ren YF, 2016, INFORM SCIENCES, V369, P188, DOI 10.1016/j.ins.2016.06.040
   [任亚峰 Ren Yafeng], 2015, [计算机研究与发展, Journal of Computer Research and Development], V52, P639
   Ren Yafeng, 2014, Journal of Frontiers of Computer Science and Technology, V8, P313, DOI 10.3778/j.issn.1673-9418.1310040
   Rodriguez-Sanchez Jose Manuel, 2020, Psychol Med, P1, DOI 10.1017/S0033291720002408
   SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220
   SAMHA AK, 2014, ARXIV14041982
   Sanchez-Junquera J, 2020, PATTERN RECOGN LETT, V135, P122, DOI 10.1016/j.patrec.2020.04.020
   Sanchez-Junquera J, 2018, LECT NOTES COMPUT SC, V11018, P135, DOI 10.1007/978-3-319-98932-7_13
   Sanh V, 2019, 5 WORKSH EN EFF MACH
   Sedighi Z, 2017, 2017 3RD IRANIAN CONFERENCE ON SIGNAL PROCESSING AND INTELLIGENT SYSTEMS (ICSPIS), P74, DOI 10.1109/ICSPIS.2017.8311593
   Seneviratne S, 2017, ACM T WEB, V11, DOI 10.1145/3007901
   Serrano-Guerrero J, 2015, INFORM SCIENCES, V311, P18, DOI 10.1016/j.ins.2015.03.040
   Shan GH, 2021, DECIS SUPPORT SYST, V144, DOI 10.1016/j.dss.2021.113513
   Shojaee S, 2013, INT CONF INTELL SYST, P53, DOI 10.1109/ISDA.2013.6920707
   Silva RM, 2017, EXPERT SYST APPL, V83, P314, DOI 10.1016/j.eswa.2017.04.055
   Strapparava, 2009, P ACL IJCNLP 2009 C, P309, DOI DOI 10.3115/1667583.1667679
   Suess E. A., 2010, INTRO PROBABILITY SI, P219
   Tang XY, 2020, INFORM SCIENCES, V526, P274, DOI 10.1016/j.ins.2020.03.063
   Tang XY, 2019, LECT NOTES COMPUT SC, V11448, P324, DOI 10.1007/978-3-030-18590-9_38
   Tao DP, 2018, IEEE T IMAGE PROCESS, V27, P325, DOI 10.1109/TIP.2017.2762588
   Tao DP, 2016, IEEE T CYBERNETICS, V46, P756, DOI 10.1109/TCYB.2015.2414920
   Tian YJ, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102381
   Vidanagama DU, 2020, ARTIF INTELL REV, V53, P1323, DOI 10.1007/s10462-019-09697-5
   Vilone G., 2020, EXPLAINABLE ARTIFICI
   Visani Chirag, 2017, 2017 International Conference on Energy, Communication, Data Analytics and Soft Computing (ICECDS), P676, DOI 10.1109/ICECDS.2017.8389522
   Vrij A, 2007, LAW HUMAN BEHAV, V31, P499, DOI 10.1007/s10979-006-9066-4
   Wang C.-C., 2018, P 2 INT C E COMM E B, P16
   Wang G., 2011, 2011 IEEE 11 INT C D, P1242, DOI [10.1109/ICDM.2011.124, DOI 10.1109/ICDM.2011.124]
   Wang J., 2020, IEEE ACCESS, V8
   Wang X., 2016, P 26 INT C COMP LING, P2428
   Wang X, 2017, P NAT C NAT LANG PRO, P866
   Wang X., 2016, P 2016 C EMP METH NA, P866
   Wang XP, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P366, DOI 10.18653/v1/P17-1034
   Wang YY, 2016, KNOWL INF SYST, V49, P1071, DOI 10.1007/s10115-016-0927-y
   Wang Z, 2014, PROCEEDINGS OF THE TWENTY-EIGHTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1112
   Wu YY, 2020, DECIS SUPPORT SYST, V132, DOI 10.1016/j.dss.2020.113280
   Xia F, 2020, IEEE TETCI, V4, P95, DOI 10.1109/TETCI.2019.2952908
   Xu LD, 2014, IEEE T IND INFORM, V10, P2233, DOI 10.1109/TII.2014.2300753
   Xu R., 2008, LREC, V8, P26
   Yafeng R., 2016, P 26 INT C COMP LING, P140
   Yan X, 2011, ACM T INFORM SYST, V29, DOI 10.1145/1993036.1993039
   Yang  Z., 2016, HLT NAACL, P1480
   Yao JR, 2021, IEEE ACCESS, V9, P16914, DOI 10.1109/ACCESS.2021.3051174
   Yilmaz CM, 2018, 2018 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM), P306, DOI 10.1109/ASONAM.2018.8508314
   You L, 2020, FUTURE GENER COMP SY, V102, P163, DOI 10.1016/j.future.2019.07.044
   You Z., 2018, P 27 INT C COMP LING, p1884 1895
   Yuan CY, 2019, IEEE DATA MINING, P1444, DOI 10.1109/ICDM.2019.00188
   Zeng ZY, 2019, INFORMATION, V10, DOI 10.3390/info10070243
   Zhang W, 2018, INFORM PROCESS MANAG, V54, P576, DOI 10.1016/j.ipm.2018.03.007
   Zhang X., 2015, ARXIV150901626
   Zhang XY, 2013, ENG APPL ARTIF INTEL, V26, P2574, DOI 10.1016/j.engappai.2013.04.008
   Zhang Y., 2010, 26 C UNC ART INT CAT
   Zhao H., 2015, ARXIV150405070
   Zhao J, 2014, IEEE T VIS COMPUT GR, V20, P1773, DOI 10.1109/TVCG.2014.2346922
   Zhao S., 2017, ARXIV171109181
   Zhao ZY, 2015, INT J DATA WAREHOUS, V11, P98, DOI 10.4018/IJDWM.2015070105
   Zhu F, 2010, J MARKETING, V74, P133, DOI 10.1509/jmkg.74.2.133
NR 187
TC 1
Z9 1
U1 11
U2 16
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2021
VL 9
BP 65771
EP 65802
DI 10.1109/ACCESS.2021.3075573
PG 32
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering; Telecommunications
GA RX6BO
UT WOS:000647307100001
OA gold, Green Accepted
DA 2022-02-06
ER

PT J
AU Zervopoulos, A
   Alvanou, AG
   Bezas, K
   Papamichail, A
   Maragoudakis, M
   Kermanidis, K
AF Zervopoulos, Alexandros
   Alvanou, Aikaterini Georgia
   Bezas, Konstantinos
   Papamichail, Asterios
   Maragoudakis, Manolis
   Kermanidis, Katia
TI Deep learning for fake news detection on Twitter regarding the 2019 Hong
   Kong protests
SO NEURAL COMPUTING & APPLICATIONS
LA English
DT Article
DE Fake news detection; Natural language processing; Deep learning; Machine
   learning; Convolutional neural networks; Long short-term memory;
   XLM-RoBERTa; Twitter; Hong Kong protests
AB The dissemination of fake news on social media platforms is an issue of considerable interest, as it can be used to misinform people or lead them astray, which is particularly concerning when it comes to political events. The recent event of Hong Kong protests triggered an outburst of fake news posts that were identified on Twitter, which were then promptly removed and compiled into datasets to promote research. These datasets focusing on linguistic content were used in previous work to classify between tweets spreading fake and real news using traditional machine learning algorithms (Zervopoulos et al., in: IFIP international conference on artificial intelligence applications and innovations, Springer, Berlin, 2020). In this paper, the experimentation process on the previously constructed dataset is extended using deep learning algorithms along with a diverse set of input features, ranging from raw text to handcrafted features. Experiments showed that the deep learning algorithms outperformed the traditional approaches, reaching scores as high as 99.3% F1 Score, with the multilingual state-of-the-art model XLM-RoBERTa outperforming other algorithms using raw untranslated text. The combination of both traditional and deep learning algorithms allows for increased performance through the latter, while also gaining insight regarding tweet structure from the interpretability of the former.
C1 [Zervopoulos, Alexandros; Alvanou, Aikaterini Georgia; Bezas, Konstantinos; Papamichail, Asterios; Maragoudakis, Manolis; Kermanidis, Katia] Ionian Univ, Dept Informat, Corfu, Greece.
C3 Ionian University
RP Zervopoulos, A (corresponding author), Ionian Univ, Dept Informat, Corfu, Greece.
EM c19zerv@ionio.gr; c19alva@ionio.gr; c19beza@ionio.gr; c19papa@ionio.gr;
   mmarag@ionio.gr; kerman@ionio.gr
OI Zervopoulos, Alexandros/0000-0003-1951-6149
CR Abadi Martin, 2016, arXiv
   Afroz S, 2019, ARXIV190504749
   Ahmed Hadeer, 2018, Security and Privacy, V1, DOI 10.1002/spy2.9
   Amara A, 2021, APPL INTELL, V51, P3052, DOI 10.1007/s10489-020-02033-3
   Faustini PHA, 2020, EXPERT SYST APPL, V158, DOI 10.1016/j.eswa.2020.113503
   Bajaj S., 2017, TECHNICAL REPORT
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Conneau A., 2020, P 58 ANN M ASS COMP, P8440, DOI DOI 10.18653/V1/2020.ACL-MAIN.747
   Conneau Alexis, 2019, ARXIV191102116
   Devlin J, 2019, PROC C N AM CHAPTER, P4171, DOI DOI 10.18653/V1/N19-1423
   Fang Y, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0222713
   Hamdi T, 2020, LECT NOTES COMPUT SC, V11969, P266, DOI 10.1007/978-3-030-36987-3_17
   Helmstetter S, 2018, 2018 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM), P274, DOI 10.1109/ASONAM.2018.8508520
   Huang CR, 2017, P 8 INT JOINT C NAT, V2, P252
   Kai Shu, 2017, ACM SIGKDD Explorations Newsletter, V19, P22, DOI 10.1145/3137597.3137600
   Kaliyar RK, 2020, COGN SYST RES, V61, P32, DOI 10.1016/j.cogsys.2019.12.005
   Kermanidis, 2020, IFIP INT C ART INT A, P408
   Maragoudakis, 2020, IFIP INT C ART INT A, P177
   Parmelee J. H., 2011, POLITICS TWITTER REV
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Pennington J., 2014, EMNLP, P1532, DOI [10.3115/v1/D14-1162, DOI 10.3115/V1/D14-1162]
   Purbrick M, 2020, ASIAN AFF, V50, P465, DOI 10.1080/03068374.2019.1672397
   Singhal S, 2019, 2019 IEEE FIFTH INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2019), P39, DOI [10.1109/BigMM.2019.00018, 10.1109/BigMM.2019.00-44]
   Stolee J., 2015, P 53 ANN M ASS COMP, P489
   Vosoughi S, 2018, SCIENCE, V359, P1146, DOI 10.1126/science.aap9559
   Wang, 2018, ARXIV181100770
   Wang WY, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P422, DOI 10.18653/v1/P17-2067
   Wang Y, 2020, DATA INF MANAG, V5, P100
   Wang YQ, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P849, DOI 10.1145/3219819.3219903
   Wolf Thomas, 2020, HUGGINGFACES TRANSFO, P38, DOI DOI 10.18653/V1/2020.EMNLP-DEMOS.6
   Yu PS, 2018, ARXIV180600749, DOI DOI 10.1145/3070644
   Zhang, 2019, ARXIV190810818
   Zhou XY, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3395046
NR 34
TC 0
Z9 0
U1 4
U2 6
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0941-0643
EI 1433-3058
J9 NEURAL COMPUT APPL
JI Neural Comput. Appl.
PD JAN
PY 2022
VL 34
IS 2
SI SI
BP 969
EP 982
DI 10.1007/s00521-021-06230-0
EA JUL 2021
PG 14
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA YK9QP
UT WOS:000669289700001
DA 2022-02-06
ER

PT J
AU Li, X
   Lu, PX
   Hu, LT
   Wang, XG
   Lu, L
AF Li, Xin
   Lu, Peixin
   Hu, Lianting
   Wang, XiaoGuang
   Lu, Long
TI A novel self-learning semi-supervised deep learning network to detect
   fake news on social media
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Fake&#8201; news; Social &#8201; media; Semi-supervised&#8201;
   deep&#8201; learning&#8201; network; Confidence values
AB Social media has become a popular means for people to consume and share news. However, it also enables the extensive spread of fake news, that is, news that deliberately provides false information, which has a significant negative impact on society. Especially recently, the false information about the new coronavirus disease 2019 (COVID-19) has spread like a virus around the world. The state of the Internet is forcing the world's tech giants to take unprecedented action to protect the "information health" of the public. Despite many existing fake news datasets, comprehensive and effective algorithms for detecting fake news have become one of the major obstacles. In order to address this issue, we designed a self-learning semi-supervised deep learning network by adding a confidence network layer, which made it possible to automatically return and add correct results to help the neural network to accumulate positive sample cases, thus improving the accuracy of the neural network. Experimental results indicate that our network is more accurate than the existing mainstream machine learning methods and deep learning methods.
C1 [Li, Xin; Lu, Peixin; Hu, Lianting; Wang, XiaoGuang; Lu, Long] Wuhan Univ, Sch Informat Management, Wuhan, Peoples R China.
C3 Wuhan University
RP Lu, L (corresponding author), Wuhan Univ, Sch Informat Management, Wuhan, Peoples R China.
EM XinLi2020@whu.edu.cn; Lupx@whu.edu.cn; LiantingHu@whu.edu.cn;
   whu_wxg@126.com; lulong@whu.edu.cn
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61772375, 61936013, 71921002]; National
   Social Science Fund of China [18ZDA325]; National Key R&D Program of
   China [2019YFC0120003]; Natural Science Foundation of Hubei Province of
   ChinaNatural Science Foundation of Hubei Province [2019CFA025];
   Independent Research Project of School of Information Management Wuhan
   University [413100032]
FX This research was funded by National Natural Science Foundation of China
   (61772375, 61936013, 71921002), The National Social Science Fund of
   China (18ZDA325), National Key R&D Program of China (2019YFC0120003),
   Natural Science Foundation of Hubei Province of China (2019CFA025); and
   Independent Research Project of School of Information Management Wuhan
   University (413100032).
CR Ahmed H, 2017, LECT NOTES COMPUT SC, V10618, P127, DOI 10.1007/978-3-319-69155-8_9
   Boididou C, 2018, MULTIMED TOOLS APPL, V77, P15545, DOI 10.1007/s11042-017-5132-9
   Granik M, 2017, 2017 IEEE FIRST UKRAINE CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING (UKRCON), P900, DOI 10.1109/UKRCON.2017.8100379
   Huang YF, 2020, EXPERT SYST APPL, V159, DOI 10.1016/j.eswa.2020.113584
   Jwa H, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9194062
   Kai Shu, 2017, ACM SIGKDD Explorations Newsletter, V19, P22, DOI 10.1145/3137597.3137600
   Kawintiranon K., 2020, ARXIV200313907
   Mitra T, 2015, ICWSM 15
   Okoro EM., 2018, NIGERIAN J TECHNOLOG, V37, P454, DOI [10.4314/njt.v37i2.22, DOI 10.4314/NJT.V37I2.22]
   Papanastasiou Y, 2017, SSRN ELECT J
   Rashed KAN, 2014, MULTIMED TOOLS APPL, V70, P1069, DOI 10.1007/s11042-012-1103-3
   Reis JCS, 2019, P 10 ACM C WEB SCI A, P17, DOI [10.1145/3292522.3326027, DOI 10.1145/3292522.3326027]
   Ruchansky N, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P797, DOI 10.1145/3132847.3132877
   Santia GC, 2018, ICWSM 18
   Shu K, 2017, ARXIV171207709
   TACCHINI Eugenio, 2017, ARXIV170407506
   Wang, 2018, ARXIV180901286
   Wang WY, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P422, DOI 10.18653/v1/P17-2067
   Wang YQ, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P849, DOI 10.1145/3219819.3219903
   Yang Y., 2018, ARXIV180600749
   Yu, 2018, ARXIV180508751
NR 21
TC 2
Z9 2
U1 7
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
DI 10.1007/s11042-021-11065-x
EA JUN 2021
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SL9CN
UT WOS:000657212500001
PM 34093070
OA Bronze, Green Published
DA 2022-02-06
ER

PT J
AU Sipitanos, K
AF Sipitanos, Konstantinos
TI Raising awareness against fake news to protect democracy: the myth of
   Islamophobia in Trump's speech
SO SOCIAL SEMIOTICS
LA English
DT Article; Early Access
DE Fake news; democracy; disinformation; fake news; myths; media literacy
ID CRITICAL DISCOURSE ANALYSIS
AB Fake news is being disseminated rapidly and it is discussed constantly on social media through "likes", sharing and comments. Fake news undermined the contribution of media and gives space to powerful institution and specific parties to promote their policies as given. In this paper, I discuss that in order to understand in depth the fake news/disinformation, a phenomenon that threats democracy, each citizen should have the ability to connect the context, the words, the image and the extralinguistic features in order to "read" behind the lines and identify the intentions that are hidden. To support this claim, a specific excerpt from fake news by Donald Trump is being analysed thoroughly with the combination of Critical Discourse Analysis (CDA) and Social Semiotics (SS). From the analysis it is shown that not fake news merely, but rather elaborated myths are being constructed which attribute characteristics in social groups, in order to serve specific goals.
C1 [Sipitanos, Konstantinos] Univ Crete, Dept Philosophy & Social Sci, Iraklion, Greece.
C3 University of Crete
RP Sipitanos, K (corresponding author), Univ Crete, Dept Philosophy & Social Sci, Iraklion, Greece.
EM sipitanos@uoc.gr
OI Sipitanos, Konstantinos/0000-0001-5193-8187
CR Allcott H, 2017, J ECON PERSPECT, V31, P211, DOI 10.1257/jep.31.2.211
   Austermuehl F, 2020, SOC SEMIOT, V30, P528, DOI 10.1080/10350330.2020.1766205
   Bennett WL, 2018, EUR J COMMUN, V33, P122, DOI 10.1177/0267323118760317
   Bignell J, 2002, MEDIA SEMIOTICS INTR
   Breeze R, 2011, PRAGMATICS, V21, P493, DOI 10.1075/prag.21.4.01bre
   Brooke Erin Duffy, 2017, INT J COMMINICATION, V11, P4652
   Butler J., 1997, PSYCHIC LIFE POWER T
   Daghigh AJ, 2020, J MUSLIM MINOR AFF, V40, P179, DOI 10.1080/13602004.2020.1773099
   De Saussure Ferdinard., 1959, COURSE GEN LINGUISTC
   Devereux E, 2019, CRIT DISCOURSE STUD, V16, P347, DOI 10.1080/17405904.2019.1568898
   Edelman M, 1998, SOCIETY, V35, P131, DOI 10.1007/BF02838136
   European Commission, 2018, MULT APPR DIS REP IN
   European Parliamentary Research Service (EPRS), 2019, POL US TECHN POL CAM
   GEORGAKOPOULOU A, 2004, DISCOURSE ANAL INTRO
   Hall S., 1982, CULTURE SOC MEDIA, P56
   Halliday M. A. K., 2014, INTRO FUNCTIONAL GRA, VFourth
   Hendricks VincentF., 2019, REALITY LOST MARKETS
   Horkheimer M., 2002, CRITICAL THEORY SELE
   Jakowski Bartosz., 2018, ONLINE J MODELLING Q, V26Q, P52, DOI [10.24193/OJMNE.2018.26.05, DOI 10.24193/OJMNE.2018.26.05]
   Karim KH., 2000, ISLAMIC PERIL MEDIA
   Khan MH, 2019, RELIGIONS, V10, DOI 10.3390/rel10020115
   Kress G., 2006, READING IMAGES GRAMM, V2
   Lazer DMJ, 2018, SCIENCE, V359, P1094, DOI 10.1126/science.aao2998
   Levi-Strauss Claude, 1978, MYTH MEANING CRACKIN
   Lischka JA, 2019, JOURNALISM STUD, V20, P287, DOI 10.1080/1461670X.2017.1375385
   Machin D., 2012, DO CRITICAL DISCOURS
   Noack R., 2017, WASHINGTON POST
   Paradelle Muriel, 2000, J LAW RELIG, V15, P611, DOI [10.2307/1051577, DOI 10.2307/1051577]
   Poole Elizabeth., 2002, MEDIA REPRESENTATION
   Poorebrahim F., 2013, INT J FOREIGN LANGUA, V1, P57
   Richardson John E., 2007, ANAL NEWSPAPERS APPR, DOI DOI 10.1007/978-0-230-20968-8_7
   Royce Terry., 1999, THESIS
   Said EdwardW., 1978, ORIENTALISM
   Silverman C., 2016, BUZZFEED NEWS 0125
   Spence PR, 2016, COMMUN Q, V64, P55, DOI 10.1080/01463373.2015.1100644
   Tamul DJ, 2020, MASS COMMUN SOC, V23, P301, DOI 10.1080/15205436.2019.1652760
   Tandoc EC, 2018, NEW MEDIA SOC, V20, P1679, DOI 10.1177/1461444817702398
   Vamanu I., 2019, OPEN INFORM SCI, V3, P197, DOI DOI 10.1515/opis-2019-0014
   van Leeuwen T, 2018, CRIT DISCOURSE STUD, V15, P140, DOI 10.1080/17405904.2018.1427120
   Van Leeuwen Theo, 2008, DISCOURSE PRACTICE N
   Wang JY, 2014, CRIT ARTS, V28, P264, DOI 10.1080/02560046.2014.906344
   Wardle C., 2017, FAKE NEWS ITS COMPLI
   Weaver R. M., 1953, ETHICS RHETORIC
   Zywietz Bernd., 2018, FAKE NEWS HASHTAGS S, P98
NR 44
TC 0
Z9 0
U1 5
U2 6
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 1035-0330
EI 1470-1219
J9 SOC SEMIOT
JI Soc. Semiot.
DI 10.1080/10350330.2021.1929147
EA MAY 2021
PG 17
WC Humanities, Multidisciplinary; Communication; Linguistics
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Arts & Humanities - Other Topics; Communication; Linguistics
GA SI4FU
UT WOS:000654782400001
DA 2022-02-06
ER

PT J
AU Al-Adhaileh, MH
   Alsaade, FW
AF Al-Adhaileh, Mosleh Hmoud
   Alsaade, Fawaz Waselallah
TI Detecting and Analysing Fake Opinions Using Artificial Intelligence
   Algorithms
SO INTELLIGENT AUTOMATION AND SOFT COMPUTING
LA English
DT Article
DE Fake opinions; product reviews; fraudulent; e-business; deep learning
ID WORD-OF-MOUTH; SPAM DETECTION; LSTM
AB In e-commerce and on social media, identifying fake opinions has become a tremendous challenge. Such opinions are widely generated on the internet by fake viewers, also called fraudsters. They write deceptive reviews that purport to reflect actual user experience either to promote some products or to defame others. They also target the reputations of e-businesses. Their aim is to mislead customers to make a wrong purchase decision by selecting undesired products. Such reviewers are often paid by rival e-business companies to compose positive reviews of their products and/or negative reviews of other companies' products. The main objective of this paper is to detect, analyze and calculate the difference between fake and truthful product reviews. To do this, the methodology has planned to have seven phases: reviewing online products, analyzing features through linguistic enquiry and word count (LIWC), preprocessing the data to clean and normalize them, embedding words (Word2Vec) and analyzing performance using artificial deep-learning algorithms for classifying fake and truthful reviews. Two deep-learning neural network models have been evaluated based on standard Yelp product reviews. These models are bidirectional long-short term memory (BiLSTM) and convolutional neural network (CNN). The results from comparing the performance of the two models showed that the BiLSTM model provided higher accuracy for detecting fake reviews than the CNN model.
C1 [Al-Adhaileh, Mosleh Hmoud] King Faisal Univ, Deanship E Learning & Distance Educ, Al Hasa, Saudi Arabia.
   [Alsaade, Fawaz Waselallah] King Faisal Univ, Coll Comp Sci & Informat Technol, Al Hasa, Saudi Arabia.
C3 King Faisal University; King Faisal University
RP Alsaade, FW (corresponding author), King Faisal Univ, Coll Comp Sci & Informat Technol, Al Hasa, Saudi Arabia.
EM falsaade@kfu.edu.sa
FU Deanship of Scientific Research at King Faisal University [216017]
FX This research and the APC were funded by the Deanship of Scientific
   Research at King Faisal University for the financial support under grant
   No. 216017.
CR Ahmed Hadeer, 2018, Security and Privacy, V1, DOI 10.1002/spy2.9
   Akoglu L., 2013, P 7 INT AAAI C WEBL, V7
   Aldhyani THH, 2021, CMC-COMPUT MATER CON, V67, P2141, DOI 10.32604/cmc.2021.014498
   Alsubari S. N., 2020, INT J ADV SCI TECHNO, V29, P3846
   Alsubari SN, 2021, APPL BIONICS BIOMECH, V2021, DOI 10.1155/2021/5522574
   [Anonymous], 2012, P 18 ACM SIGKDD INT, DOI DOI 10.1145/2339530.2339662
   Asghar MZ, 2020, SOFT COMPUT, V24, P3475, DOI 10.1007/s00500-019-04107-y
   Barbado R, 2019, INFORM PROCESS MANAG, V56, P1234, DOI 10.1016/j.ipm.2019.03.002
   Chakraborty U., 2018, J PROMOTION MANAGEME, V24, P57
   Chan YYY, 2011, MARK INTELL PLAN, V29, P488, DOI 10.1108/02634501111153692
   Goswami Kunal, 2017, Journal of Big Data, V4, DOI 10.1186/s40537-017-0075-6
   Hancock, 2011, P 49 ANN M ASS COMP, P309, DOI DOI 10.1145/2567948.2577293
   Hussain N, 2020, IEEE ACCESS, V8, P53801, DOI 10.1109/ACCESS.2020.2979226
   Jindal N., 2008, P 2008 INT C WEB SEA, P219
   Li H., 2015, 9 INT AAAI C WEB SOC
   Liu G, 2019, NEUROCOMPUTING, V337, P325, DOI 10.1016/j.neucom.2019.01.078
   Luca M, 2016, MANAGE SCI, V62, P3412, DOI 10.1287/mnsc.2015.2304
   Narayan R, 2018, ADV INTELL SYST, V719, P281, DOI 10.1007/978-981-10-3376-6_31
   Newman ML, 2003, PERS SOC PSYCHOL B, V29, P665, DOI 10.1177/0146167203029005010
   Park DH, 2008, ELECTRON COMMER R A, V7, P399, DOI 10.1016/j.elerap.2007.12.001
   Ren YF, 2017, INFORM SCIENCES, V385, P213, DOI 10.1016/j.ins.2017.01.015
   Riegner C, 2007, J ADVERTISING RES, V47, P436, DOI 10.2501/S0021849907070456
   Rosso P, 2014, INFORM PROCESS MANAG, V51, P1
   Savage D, 2015, EXPERT SYST APPL, V42, P8650, DOI 10.1016/j.eswa.2015.07.019
   Toke P. S., 2016, INT J ADV RES COMPUT, V5, P793
   Vidanagama DU, 2020, ARTIF INTELL REV, V53, P1323, DOI 10.1007/s10462-019-09697-5
   Wang Y, 2020, CMC-COMPUT MATER CON, V65, P355, DOI 10.32604/cmc.2020.09835
   Xiang LY, 2020, INTELL AUTOM SOFT CO, V26, P1375, DOI 10.32604/iasc.2020.013382
   Xiang LY, 2020, MATH BIOSCI ENG, V17, P1041, DOI 10.3934/mbe.2020055
   Xiong ZY, 2018, CMC-COMPUT MATER CON, V55, P213, DOI 10.3970/cmc.2018.01762
   Yan X, 2011, ACM T INFORM SYST, V29, DOI 10.1145/1993036.1993039
   Zeng ZY, 2019, INFORMATION, V10, DOI 10.3390/info10070243
NR 32
TC 0
Z9 0
U1 8
U2 8
PU TECH SCIENCE PRESS
PI HENDERSON
PA 871 CORONADO CENTER DR, SUTE 200, HENDERSON, NV 89052 USA
SN 1079-8587
EI 2326-005X
J9 INTELL AUTOM SOFT CO
JI Intell. Autom. Soft Comput.
PY 2022
VL 32
IS 1
BP 643
EP 655
DI 10.32604/iasc.2022.021225
PG 13
WC Automation & Control Systems; Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Automation & Control Systems; Computer Science
GA WN8OB
UT WOS:000712025300016
OA hybrid
DA 2022-02-06
ER

PT J
AU de Seta, G
AF de Seta, Gabriele
TI Huanlian, or changing faces: Deepfakes on Chinese digital media
   platforms
SO CONVERGENCE-THE INTERNATIONAL JOURNAL OF RESEARCH INTO NEW MEDIA
   TECHNOLOGIES
LA English
DT Article
DE Artificial intelligence; Bilibili; China; deepfakes; machine vision;
   media manipulation; synthetic media; vernacular creativity; ZAO
AB In China, deepfakes are commonly known as huanlian, which literally means "changing faces." Huanlian content, including face-swapped images and video reenactments, has been circulating in China since at least 2018, at first through amateur users experimenting with machine learning models and then through the popularization of audiovisual synthesis technologies offered by digital platforms. Informed by a wealth of interdisciplinary research on media manipulation, this article aims at historicizing, contextualizing, and disaggregating huanlian in order to understand how synthetic media is domesticated in China. After briefly summarizing the global emergence of deepfakes and the local history of huanlian, I discuss three specific aspects of their development: the launch of the ZAO app in 2019 with its societal backlash and regulatory response; the commercialization of deepfakes across formal and informal markets; and the communities of practice emerging around audiovisual synthesis on platforms like Bilibili. Drawing on these three cases, the conclusion argues for the importance of situating specific applications of deep learning in their local contexts.
C1 [de Seta, Gabriele] Univ Bergen, Bergen, Norway.
C3 University of Bergen
RP de Seta, G (corresponding author), Univ Bergen, Dept Linguist Literary & Aesthet Studies, Postboks 7805, N-5020 Bergen, Norway.
EM gabriele.seta@uib.no
RI de Seta, Gabriele/Q-8340-2019
OI de Seta, Gabriele/0000-0003-0497-2811
FU European Research Council (ERC) under the European Union's Horizon 2020
   research and innovation programmeEuropean Research Council (ERC)
   [771800]
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: This
   research is supported by the Machine Vision in Everyday Life project,
   which has received funding from the European Research Council (ERC)
   under the European Union's Horizon 2020 research and innovation
   programme (Grant Agreement No. 771800).
CR Ai Q., 2019, HUANLIAN APP ZOUHONG
   [Anonymous], 2019, GUONEI SHOUGE JIANGU
   Boneh D, 2019, IEEE SECUR PRIV, V17, P64, DOI 10.1109/MSEC.2019.2934193
   Brock Andrew, 2019, INT C LEARN REPR
   Burgess, 2006, CONTINUUM, V20, P201, DOI [DOI 10.1080/10304310600641737, 10.1080/10304310600641737]
   Cavalli F., 2019, STATE DEEPFAKES LAND, P27
   Chen L., 2019, S CHINA MORNING POST
   Chesney B, 2019, CALIF LAW REV, V107, P1753, DOI 10.15779/Z38RV0D15J
   CHEUNG A, 2009, J MEDIA LAW, V1, P191, DOI DOI 10.1080/17577632.2009.11427341
   Cole S., 2017, MOTHERBOARD TECH VIC
   Coleman, 2019, BBC NEWS
   Constine J, 2020, TECHCRUNCH
   Cyberspace Administration of China Ministry of Culture and Tourism & National Radio and Television Administration, 2019, GUAN YINF WANGL YINS
   de Miaoer Kong, 2020, DAME DA NE XIONGMAOT
   de Seta G, 2016, LEXIA RIV SEMIOTICA, V25, P463, DOI [10.4399/978882550315926, DOI 10.4399/978882550315926]
   DeSeta G., 2018, 1 MONDAY, V23
   Donovan J., 2019, DEEPFAKES CHEAP FAKE, P50
   Fallis Don, 2020, Philos Technol, P1, DOI 10.1007/s13347-020-00419-2
   Fikse TD., 2018, THESIS U OSLO OSLO
   Fletcher J, 2018, THEATRE J, V70, P455, DOI 10.1353/tj.2018.0097
   Floridi L., 2018, PHILOS TECHNOLOGY, V31, P317, DOI [10.1007/s13347-018-0325-3, DOI 10.1007/S13347-018-0325-3]
   Fu, 2019, WEI RENGONG ZHINENG
   Gershgorn D., 2020, MEDIUM
   Global Times, 2019, GLOBAL TIMES
   Hao K., 2020, MIT TECHNOL REV
   Harris D., 2019, DUKE LAW TECHNOLOGY, V17, P99
   HsLotus, 2020, JIAO NI QINGSONG ZUO
   Hu X., 2020, TWITTER
   Huang, 2019, CHINA DAILY
   Huanyu yingshi fenxiang, 2021, SANQIAN YASHA ZHEGE
   Hwang T., 2020, DEEPFAKES GROUNDED T, P38
   Jacobs K, 2012, PEOPLE'S PORNOGRAPHY: SEX AND SURVEILLANCE ON THE CHINESE INTERNET, P1
   Jiang LM, 2020, PROC CVPR IEEE, P2886, DOI 10.1109/CVPR42600.2020.00296
   Jie S., 2019, PAPER
   Kietzmann J, 2020, BUS HORIZONS, V63, P135, DOI 10.1016/j.bushor.2019.11.006
   Li L, 2019, INFORM POL, P1
   Li LZ, 2020, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR42600.2020.00505
   Liang, 2019, CHINESE DEEPFAKE CRE
   Liao C., 2019, RENMINWANG
   Lin Y, 2021, J CONTEMP CHINA, V30, P85, DOI 10.1080/10670564.2020.1766911
   McDaniel P., 2020, PREPARING AGE DEEPFA, P5
   Meng BC, 2011, GLOB MEDIA COMMUN, V7, P33, DOI 10.1177/1742766510397938
   Mirsky Y, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3425780
   Mo H, 2019, FACE SWAP APP ACCUSE
   People's Daily, 2019, PEOPLES DAILY
   Rea C.G., 2013, HUMOUR CHINESE LIFE, P149, DOI DOI 10.5790/HONGKONG/9789888139231.003.0007
   Rini R, 2020, PHILOS IMPRINT, V20, P1
   Shen X., 2019, S CHINA MORNING POST
   Siarohin Aliaksandr, 2020, ARXIV200300196
   Siyuetian, 2020, SANQIAN YASHA AL HUA
   Suwajanakorn S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073640
   Tencent, 2020, QINGSONG HUASHEN HEP
   Tencent Research Institute, 2020, FANZ ZHIN 2020 TENGX, P39
   Thies J, 2016, PROC CVPR IEEE, P2387, DOI 10.1109/CVPR.2016.262
   UFO Shang de Shuchong, 2020, WEI TEL YU PENGP XIA
   Vaccari C, 2020, SOC MEDIA SOC, V6, DOI 10.1177/2056305120903408
   Xia, 2019, SPINOFF
   Xiaoxi, 2020, B DAMEDANE B ZHAN SH
   Xie Echo., 2019, S CHINA MORNING POST
   Xu, 2020, GUONEI WANGJU AI HUA
   Xu W., 2019, ZAO HUOBAO QUE ZHUDI
   Ye J., 2019, S CHINA MORNING POST
   Yuli, 2020, AI HUANLIAN DAXING C
   yuwen Yang Axing jiang, 2020, HAHA BU ZHIDAO SHEI
   Zhang, 2019, HAOWAN DE AI HUANLIA
   Zhang J., 2019, FAZHAN RENGONG ZHINE
   Zhang Y., 2019, ZHONGYANG WANGXIN BA
   Zhao E. J., 2019, DIGITAL CHINAS INFOR
NR 68
TC 0
Z9 0
U1 6
U2 6
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 1354-8565
EI 1748-7382
J9 CONVERGENCE-US
JI Convergence
PD AUG
PY 2021
VL 27
IS 4
SI SI
BP 935
EP 953
AR 13548565211030185
DI 10.1177/13548565211030185
EA JUL 2021
PG 19
WC Communication
WE Social Science Citation Index (SSCI)
SC Communication
GA UK7UP
UT WOS:000679713900001
OA hybrid, Green Published
DA 2022-02-06
ER

PT J
AU Sharma, DK
   Garg, S
AF Sharma, Dilip Kumar
   Garg, Sonal
TI IFND: a benchmark dataset for fake news detection
SO COMPLEX & INTELLIGENT SYSTEMS
LA English
DT Article; Early Access
DE Deep-learning; Fake news detection; Indian dataset; LDA topic modelling;
   Machine learning
AB Spotting fake news is a critical problem nowadays. Social media are responsible for propagating fake news. Fake news propagated over digital platforms generates confusion as well as induce biased perspectives in people. Detection of misinformation over the digital platform is essential to mitigate its adverse impact. Many approaches have been implemented in recent years. Despite the productive work, fake news identification poses many challenges due to the lack of a comprehensive publicly available benchmark dataset. There is no large-scale dataset that consists of Indian news only. So, this paper presents IFND (Indian fake news dataset) dataset. The dataset consists of both text and images. The majority of the content in the dataset is about events from the year 2013 to the year 2021. Dataset content is scrapped using the Parsehub tool. To increase the size of the fake news in the dataset, an intelligent augmentation algorithm is used. An intelligent augmentation algorithm generates meaningful fake news statements. The latent Dirichlet allocation (LDA) technique is employed for topic modelling to assign the categories to news statements. Various machine learning and deep-learning classifiers are implemented on text and image modality to observe the proposed IFND dataset's performance. A multi-modal approach is also proposed, which considers both textual and visual features for fake news detection. The proposed IFND dataset achieved satisfactory results. This study affirms that the accessibility of such a huge dataset can actuate research in this laborious exploration issue and lead to better prediction models.
C1 [Sharma, Dilip Kumar; Garg, Sonal] GLA Univ, Mathura, India.
C3 GLA University
RP Sharma, DK (corresponding author), GLA Univ, Mathura, India.
EM dilip.sharma@gla.ac.in; sonal.garg@gla.ac.in
OI Sharma, Dilip Kumar/0000-0002-3860-7997
FU Council of Science and Technology, Lucknow, UP, India in Department of
   Computer Engineering and Applications, GLA University Mathura
FX The authors generously acknowledge the funding from the Council of
   Science and Technology, Lucknow, UP, India in Department of Computer
   Engineering and Applications, GLA University Mathura. The title of the
   research project is "Identification of unreliability and fakeness in
   Social Media posts".
CR Abonizio HQ, 2020, FUTURE INTERNET, V12, DOI 10.3390/fi12050087
   Ahmed Hadeer, 2018, Security and Privacy, V1, DOI 10.1002/spy2.9
   Ahmed H, 2017, LECT NOTES COMPUT SC, V10618, P127, DOI 10.1007/978-3-319-69155-8_9
   Alrubaian M, 2018, IEEE T DEPEND SECURE, V15, P661, DOI 10.1109/TDSC.2016.2602338
   Amjad M, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P2537
   [Anonymous], BBC NEWS
   [Anonymous], ALT NEWS
   [Anonymous], INDIATODAY
   [Anonymous], DNAINDIA
   [Anonymous], TEEKHIMIRCHI
   [Anonymous], Boomlive
   [Anonymous], NDTV
   [Anonymous], ThelogicalIndian
   [Anonymous], Timesnownews
   [Anonymous], DAPAANNEWS
   [Anonymous], Tribuneindia
   [Anonymous], Thestatesman
   [Anonymous], INDIANEXPRESS
   Arooj A, 2021, ARCH COMPUT METHOD E, DOI 10.1007/s11831-021-09590-x
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Boididou C, 2016, VERIFYING MULTIMEDIA
   BOIDIDOU C, 2015, MEDIAEVAL
   Bonet-Jover A, 2021, EXPERT SYST APPL, V169, DOI 10.1016/j.eswa.2020.114340
   Castillo C., 2011, WWW, P675
   Fernandez-Delgado M, 2014, J MACH LEARN RES, V15, P3133
   Garg Sonal, 2020, Proceedings of the 2020 9th International Conference System Modeling and Advancement in Research Trends (SMART), P17, DOI 10.1109/SMART50582.2020.9337152
   Gravanis G, 2019, EXPERT SYST APPL, V128, P201, DOI 10.1016/j.eswa.2019.03.036
   Hira S, 2021, APPL INTELL, V51, P2864, DOI 10.1007/s10489-020-02010-w
   Hossain MZ, 2020, BANFAKENEWS DATASET
   Jin ZW, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P795, DOI 10.1145/3123266.3123454
   Jindal S, 2020, NEWSBAG MULTIMODAL B
   Kai Shu, 2017, ACM SIGKDD Explorations Newsletter, V19, P22, DOI 10.1145/3137597.3137600
   Kaliyar RK, 2021, MULTIMED TOOLS APPL, V80, P11765, DOI 10.1007/s11042-020-10183-2
   Kaliyar RK, 2020, COGN SYST RES, V61, P32, DOI 10.1016/j.cogsys.2019.12.005
   Karadzhov G, 2018, WE BUILT FAKE NEWS
   Khattar D, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P2915, DOI 10.1145/3308558.3313552
   Li X, 2021, MULTIMED TOOLS APPL, DOI 10.1007/s11042-021-11065-x
   Liu Y, 2021, WIRELESS PERS COMMUN, DOI 10.1007/s11277-021-08272-y
   Long Y, 2017, FAKE NEWS DETECTION
   Loukadakis M, 2018, ACCELERATING DEEP NE
   Nasir J. A., 2021, INT J INF MANAGE DAT, V1, DOI DOI 10.1016/J.JJIMEI.2020.100007
   Ong T, 2014, ELECTRON COMMER R A, V13, P69, DOI 10.1016/j.elerap.2013.10.002
   Ru L, 2021, WIREL COMMUN MOB COM, V2021, DOI 10.1155/2021/5592454
   Sahoo SR, 2021, APPL SOFT COMPUT, V100, DOI 10.1016/j.asoc.2020.106983
   Santia G., 2018, INT AAAI C WEB SOC M
   Santos RLS, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P1404
   Shahi GK., 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.36190/2020.14
   Sharma A, 2021, INT J CIV ENG, V19, P653, DOI [10.1007/s40999-020-00597-2, 10.1109/JSYST.2021.3052072]
   Sharma Dilip Kumar, 2021, 2021 International Conference on Innovative Practices in Technology and Management (ICIPTM), P227, DOI 10.1109/ICIPTM52218.2021.9388356
   Shojaee S, 2013, INT CONF INTELL SYST, P53, DOI 10.1109/ISDA.2013.6920707
   Shrivastava G, 2020, IEEE T COMPUT SOC SY, V7, P1159, DOI 10.1109/TCSS.2020.3014135
   Shu K, 2020, BIG DATA-US, V8, P171, DOI 10.1089/big.2020.0062
   Singh Bhuvanesh, 2021, Proceedings of the 2021 8th International Conference on Computing for Sustainable Global Development (INDIACom), P705, DOI 10.1109/INDIACom51348.2021.00125
   Singh B, 2021, NEURAL COMPUT APPL, DOI 10.1007/s00521-021-06086-4
   Singhal S, 2019, 2019 IEEE FIFTH INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2019), P39, DOI [10.1109/BigMM.2019.00018, 10.1109/BigMM.2019.00-44]
   Tacchini E., 2017, ARXIV170407506, DOI DOI 10.1257/JEP.31.2.211
   Trueman TE, 2021, APPL SOFT COMPUT
   Verma PK, 2021, IEEE T COMPUT SOC SY, V8, P881, DOI 10.1109/TCSS.2021.3068519
   Wang WY, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P422, DOI 10.18653/v1/P17-2067
   Wu L, 2018, WSDM'18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P637, DOI 10.1145/3159652.3159677
   Xu K, 2018, LECT NOTES COMPUT SC, V10874, P521, DOI 10.1007/978-3-319-94268-1_43
   Yu PS, 2018, ARXIV180600749, DOI DOI 10.1145/3070644
   Zhou X., 2020, ADV KNOWL DISCOV DAT, V354, P12085
NR 63
TC 0
Z9 0
U1 7
U2 7
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 2199-4536
EI 2198-6053
J9 COMPLEX INTELL SYST
JI COMPLEX INTELL. SYST.
DI 10.1007/s40747-021-00552-1
EA OCT 2021
PG 21
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WH4YC
UT WOS:000707684200002
PM 34777983
OA gold, Green Published
DA 2022-02-06
ER

PT J
AU Ilie, VI
   Truica, CO
   Apostol, ES
   Paschke, A
AF Ilie, Vlad-Iulian
   Truica, Ciprian-Octavian
   Apostol, Elena-Simona
   Paschke, Adrian
TI Context-Aware Misinformation Detection: A Benchmark of Deep Learning
   Architectures Using Word Embeddings
SO IEEE ACCESS
LA English
DT Article
DE Fake news; Deep learning; Task analysis; Benchmark testing; Feature
   extraction; Entertainment industry; Biological system modeling;
   Misinformation detection; deep learning; multi-class text
   classification; word embeddings; text preprocessing; benchmarking
ID FAKE NEWS
AB New mass media paradigms for information distribution have emerged with the digital age. With new digital-enabled mass media, the communication process is centered around the user, while multimedia content is the new identity of news. Thus, the media landscape has shifted from mass media to personalized social media. While this progress brings advantages, it also carries the risk of being detrimental to society through the emergence of misinformation (false or inaccurate information) and disinformation (intentionally spreading misinformation) in the form of fake news. Fake news is a tool used to manipulate public opinion on particular topics, distort public perceptions, and generate social unrest while lacking the rigor of traditional journalism. Driven by this current and real-world problem, in this paper, we train multiple Deep Learning architectures for multi-class classification and compare their performance in detecting the veracity of the news articles. To achieve accurate models in detecting misinformation, we employ a large dataset containing 100 000 news articles labeled with ten classes (one with real news and the rest with different types of fake news). We use two preprocessing techniques, i.e., one simple and another very aggressive, to clean the dataset. We also employ three word embeddings that preserve the word context, i.e., Word2Vec, FastText, and GloVe, pre-trained and trained on our dataset to vectorize the preprocessed dataset. For the misinformation task, we train a Logistic Regression as a baseline and compare its results with the performance of ten Deep Learning architectures. We obtain the best results using a Recurrent Convolutional Neural Network based architecture. The experimental results show that the models are highly dependable on text preprocessing and the word embedding employed.
C1 [Ilie, Vlad-Iulian; Truica, Ciprian-Octavian; Apostol, Elena-Simona] Univ Politehn Bucuresti, Fac Automat Control & Comp, Comp Sci & Engn Dept, Bucharest 060042, Romania.
   [Paschke, Adrian] Fraunhofer Inst Open Commun Syst FOKUS, D-10589 Berlin, Germany.
C3 Polytechnic University of Bucharest; Fraunhofer Gesellschaft; Fraunhofer
   Institute Center Schloss Birlinghoven
RP Truica, CO; Apostol, ES (corresponding author), Univ Politehn Bucuresti, Fac Automat Control & Comp, Comp Sci & Engn Dept, Bucharest 060042, Romania.
EM ciprian.truica@upb.ro; elena.apostol@upb.ro
RI APOSTOL, Elena-Simona/AAG-9392-2021; Truica,
   Ciprian-Octavian/J-9536-2014
OI APOSTOL, Elena-Simona/0000-0001-6397-4951; Truica,
   Ciprian-Octavian/0000-0001-7292-4462
FU German Academic Exchange Service (DAAD) through the Project "AWAKEN:
   content-Aware and netWork-Aware faKE News mitigation''Deutscher
   Akademischer Austausch Dienst (DAAD) [91809005]; German Federal Ministry
   of Education and Research (BMBF) Project "PANQURA-a technology platform
   for more information transparency in times of crisis''Federal Ministry
   of Education & Research (BMBF) [03COV03F]; European Union Project
   "FAST-LISA-Fighting hAte Speech Through a Legal, ICT and Sociolinguistic
   Approach'' [101049342]; German Academic Exchange Service (DAAD) through
   Project "Deep-Learning Anomaly Detection for Human and Automated Users
   Behavior''Deutscher Akademischer Austausch Dienst (DAAD) [91809358]
FX This work was supported in part by the German Academic Exchange Service
   (DAAD) through the Project ``AWAKEN: content-Aware and netWork-Aware
   faKE News mitigation'' under Grant 91809005 and Project "Deep-Learning
   Anomaly Detection for Human and Automated Users Behavior'' under Grant
   91809358, in part by the German Federal Ministry of Education and
   Research (BMBF) Project ``PANQURA-a technology platform for more
   information transparency in times of crisis'' under Grant 03COV03F, and
   in part by the European Union Project "FAST-LISA-Fighting hAte Speech
   Through a Legal, ICT and Sociolinguistic Approach'' under Grant
   101049342.
CR Ajao Oluwaseun, 2018, P 9 INT C SOC MED SO, DOI 10.1145/3217804.3217917
   Aramaki E, 2020, ARXIV200714013
   Assent I, 2012, WIRES DATA MIN KNOWL, V2, P340, DOI 10.1002/widm.1062
   Bastos MT, 2019, SOC SCI COMPUT REV, V37, P38, DOI 10.1177/0894439317734157
   Bojanowski P., 2017, TACL, V5, P135, DOI [DOI 10.1162/TACL_A_00051, 10.1162/tacl_a_00051]
   Bovet A, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-018-07761-2
   Calvillo DP, 2020, SOC PSYCHOL PERS SCI, V11, P1119, DOI 10.1177/1948550620940539
   Chao Liu, 2019, Knowledge Science, Engineering and Management. 12th International Conference, KSEM 2019. Proceedings: Lecture Notes in Artificial Intelligence (LNAI 11776), P172, DOI 10.1007/978-3-030-29563-9_17
   Choras R, 2020, C COMPL INT SOFTW IN, P239
   Choudhary A, 2021, EXPERT SYST APPL, V169, DOI 10.1016/j.eswa.2020.114171
   Collell G, 2018, NEUROCOMPUTING, V275, P330, DOI 10.1016/j.neucom.2017.08.035
   Conroy NJ, 2015, P ASS INF SCI TECHN, V51, P1, DOI [10.1002/pra2.2015.145052010082, DOI 10.1002/PRA2.2015.145052010082]
   Devlin J, 2019, PROC C N AM CHAPTER, P4171, DOI DOI 10.18653/V1/N19-1423
   Feldman Vitaly, 2019, P MACHINE LEARNING R, V97, P1892
   Gautam A. E. A, P CONSTRAINT SHAR TA, V2021, P189
   Gelfert A, 2018, INFORMAL LOG, V38, P84, DOI 10.22329/il.v38i1.5068
   Ghanem B, 2020, ACM T INTERNET TECHN, V20, DOI 10.1145/3381750
   Gravanis G, 2019, EXPERT SYST APPL, V128, P201, DOI 10.1016/j.eswa.2019.03.036
   Hardalov M, 2016, LECT NOTES ARTIF INT, V9883, P172, DOI 10.1007/978-3-319-44748-3_17
   Hartmann J, 2019, INT J RES MARK, V36, P20, DOI 10.1016/j.ijresmar.2018.09.009
   Helmstetter S, 2018, 2018 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM), P274, DOI 10.1109/ASONAM.2018.8508520
   Higgins K, 2016, NATURE, V540, P9, DOI 10.1038/540009a
   Hua JL, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17072309
   Kai Shu, 2017, ACM SIGKDD Explorations Newsletter, V19, P22, DOI 10.1145/3137597.3137600
   Kaliyar RK, 2020, COGN SYST RES, V61, P32, DOI 10.1016/j.cogsys.2019.12.005
   Khan J. Y., 2021, MACH LEARN APPL, V4
   Lai SW, 2015, PROCEEDINGS OF THE TWENTY-NINTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2267
   Li Q, 2020, PERS UBIQUIT COMPUT, V24, P259, DOI 10.1007/s00779-019-01289-y
   Li Y, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1715, DOI 10.1145/3219819.3219956
   Linzen T., 2016, ARXIV160607736ABS CO, P13, DOI 10.18653/v1/W16-2503
   Liu Y., 2019, CORR
   Mihailescu R.-C, 2020, P 19 IEEE INT C MACH, P775
   Mikolov T., 2013, ARXIV13013781, P1
   Mikolov T, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P52
   Mishra R, 2019, PROCEEDINGS OF THE 2019 ACM SIGIR INTERNATIONAL CONFERENCE ON THEORY OF INFORMATION RETRIEVAL (ICTIR'19), P196, DOI 10.1145/3341981.3344229
   Pennington J., 2014, EMNLP, P1532, DOI [10.3115/v1/D14-1162, DOI 10.3115/V1/D14-1162]
   Piktus A., 2019, P 2019 C N AM CHAPT, P3226, DOI [DOI 10.18653/V1/N19-, DOI 10.18653/V1/N19-1326]
   Potts C., 2018, P 2018 C N AM CHAPT, V2, P212
   Przybyla P, 2020, AAAI CONF ARTIF INTE, V34, P490
   Rogers A, 2020, T ASSOC COMPUT LING, V8, P842, DOI 10.1162/tacl_a_00349
   Roozenbeek J, 2019, J RISK RES, V22, P570, DOI 10.1080/13669877.2018.1443491
   Rubin V., 2016, P 2 WORKSH COMP APPR, P7, DOI DOI 10.18653/V1/W16-0802
   Ruths D, 2019, SCIENCE, V363, P348, DOI 10.1126/science.aaw1315
   Shu K., 2020, ARXIV200401732
   Shu K, 2019, PROCEEDINGS OF THE TWELFTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'19), P312, DOI 10.1145/3289600.3290994
   Teoh Deanna, 2019, Am Soc Clin Oncol Educ Book, V39, P75, DOI 10.1200/EDBK_239363
   Umer M, 2020, IEEE ACCESS, V8, P156695, DOI 10.1109/ACCESS.2020.3019735
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Yi D, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11070942
   Zannettou S, 2019, ACM J DATA INF QUAL, V11, DOI 10.1145/3309699
   Zhang YM, 2021, CONNECT SCI, V33, P81, DOI 10.1080/09540091.2020.1783640
   Zhou XY, 2019, PROCEEDINGS OF THE TWELFTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'19), P836, DOI 10.1145/3289600.3291382
NR 52
TC 0
Z9 0
U1 1
U2 1
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2021
VL 9
BP 162122
EP 162146
DI 10.1109/ACCESS.2021.3132502
PG 25
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering; Telecommunications
GA XO8TU
UT WOS:000730452100001
OA gold
DA 2022-02-06
ER

PT J
AU Raj, C
   Meel, P
AF Raj, Chahat
   Meel, Priyanka
TI ConvNet frameworks for multi-modal fake news detection
SO APPLIED INTELLIGENCE
LA English
DT Article
DE Fake news detection; Multimodal combination; Weighted average fusion;
   Convolutional neural networks; Deep learning
AB An upsurge of false information revolves around the internet. Social media and websites are flooded with unverified news posts. These posts are comprised of text, images, audio, and videos. There is a requirement for a system that detects fake content in multiple data modalities. We have seen a considerable amount of research on classification techniques for textual fake news detection, while frameworks dedicated to visual fake news detection are very few. We explored the state-of-the-art methods using deep networks such as CNNs and RNNs for multi-modal online information credibility analysis. They show rapid improvement in classification tasks without requiring pre-processing. To aid the ongoing research over fake news detection using CNN models, we build textual and visual modules to analyze their performances over multi-modal datasets. We exploit latent features present inside text and images using layers of convolutions. We see how well these convolutional neural networks perform classification when provided with only latent features and analyze what type of images are needed to be fed to perform efficient fake news detection. We propose a multi-modal Coupled ConvNet architecture that fuses both the data modules and efficiently classifies online news depending on its textual and visual content. We thence offer a comparative analysis of the results of all the models utilized over three datasets. The proposed architecture outperforms various state-of-the-art methods for fake news detection with considerably high accuracies.
C1 [Raj, Chahat; Meel, Priyanka] Delhi Technol Univ, Dept Informat Technol, Delhi, India.
C3 Delhi Technological University
RP Meel, P (corresponding author), Delhi Technol Univ, Dept Informat Technol, Delhi, India.
EM chahatraj58@gmail.com; priyankameel86@gmail.com
RI Raj, Chahat/AAL-9102-2021
OI Raj, Chahat/0000-0003-0083-6812
CR Ajao Oluwaseun, 2018, P 9 INT C SOC MED SO, DOI 10.1145/3217804.3217917
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   Bayar B., 2016, P 4 ACM WORKSH INF H, P5, DOI DOI 10.1145/2909827.2930786
   Boididou C., 2016, MEDIAEVAL
   BOIDIDOU C, 2015, MEDIAEVAL
   Bourgonje Peter, 2017, P 2017 EMNLP WORKSHO, P84, DOI 10.18653/v1/W17-4215
   Chen T, 2018, LECT NOTES ARTIF INT, V11154, P40, DOI 10.1007/978-3-030-04503-6_4
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Conforti C., 2018, P 1 WORKSH FACT EXTR, P40
   Cui LM, 2019, PROCEEDINGS OF THE 2019 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2019), P41, DOI 10.1145/3341161.3342894
   Ferreira W., 2016, P 2016 C N AM CHAPTE, P1163
   Gaurav K, 2019, INT J COMPUT INTELL, V2
   Guera D, 2018, 2018 15TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P127
   He K., 2016, DEEP RESIDUAL LEARNI, DOI DOI 10.1109/CVPR.2016.90
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Hutchinson, 2019, P INT AAAI C WEB SOC, P659
   Jin ZW, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P795, DOI 10.1145/3123266.3123454
   Jin ZW, 2017, IEEE T MULTIMEDIA, V19, P598, DOI 10.1109/TMM.2016.2617078
   Jindal S, 2020, NEWSBAG MULTIMODAL B
   Khattar D, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P2915, DOI 10.1145/3308558.3313552
   Lago F, 2019, SECUR COMMUN NETW, DOI 10.1155/2019/9236910
   Liu Y, 2018, THIRTY-SECOND AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTIETH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / EIGHTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P354
   Ma J., 2016, P 25 INT JOINT C ART, P3818
   Ma J, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P3049, DOI 10.1145/3308558.3313741
   Maigrot C., 2016, MEDIAEVAL 2016 MULTI
   Marra F, 2018, IEEE 1ST CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2018), P384, DOI 10.1109/MIPR.2018.00084
   Papadopoulou O., 2017, P 2 INT WORKSH MULT, P6, DOI DOI 10.1145/3078897.3080535
   Pomari T, 2018, IEEE IMAGE PROC, P3788, DOI 10.1109/ICIP.2018.8451227
   Qi P, 2019, IEEE DATA MINING, P518, DOI 10.1109/ICDM.2019.00062
   Rahmouni N, 2017, IEEE INT WORKS INFOR
   Sabir E, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1337, DOI 10.1145/3240508.3240707
   Sabir Ekraam, 2019, INTERFACES GUI, P80
   Singhal S, 2019, 2019 IEEE FIFTH INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2019), P39, DOI [10.1109/BigMM.2019.00018, 10.1109/BigMM.2019.00-44]
   Szegedy C, 2015, ARXIV14094842, P1, DOI [10.1109/CVPR.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tariq S, 2018, MPS'18: PROCEEDINGS OF THE 2ND INTERNATIONAL WORKSHOP ON MULTIMEDIA PRIVACY AND SECURITY, P81, DOI 10.1145/3267357.3267367
   Thorne J., 2017, P 2017 EMNLP WORKSH, P80
   Uliyan DM, 2016, EXPERT SYST APPL, V64, P1, DOI 10.1016/j.eswa.2016.07.026
   Uliyan DM, 2015, IEEE CONF OPEN SYST, P7, DOI 10.1109/ICOS.2015.7377269
   Wang YQ, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P849, DOI 10.1145/3219819.3219903
   Wu K, 2015, PROC INT CONF DATA, P651, DOI 10.1109/ICDE.2015.7113322
   Yang Y., 2018, TI CNN CONVOLUTIONAL
   Zhou P, 2017, IEEE COMPUT SOC CONF, P1831, DOI 10.1109/CVPRW.2017.229
NR 42
TC 0
Z9 0
U1 9
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0924-669X
EI 1573-7497
J9 APPL INTELL
JI Appl. Intell.
PD NOV
PY 2021
VL 51
IS 11
BP 8132
EP 8148
DI 10.1007/s10489-021-02345-y
EA MAR 2021
PG 17
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WD2YI
UT WOS:000633276500001
DA 2022-02-06
ER

PT J
AU Liu, QJ
   Jackson, PJB
   Wang, WW
AF Liu, Qingju
   Jackson, Philip J. B.
   Wang, Wenwu
TI A Speech Synthesis Approach for High Quality Speech Separation and
   Generation
SO IEEE SIGNAL PROCESSING LETTERS
LA English
DT Article
DE Deep learning; speech separation; speech synthesis; WaveNet; hourglass;
   high quality
ID NETWORKS
AB We propose a new method for source separation by synthesizing the source froma speech mixture corrupted by various environmental noise. Unlike traditional source separation methods which estimate the source from the mixture as a replica of the original source (e.g. by solving an inverse problem), our proposed method is a synthesis-based approachwhich aims to generate a new signal (i.e. "fake" source) that sounds similar to the original source. The proposed system has an encoder-decoder topology, where the encoder predicts intermediate-level features from the mixture, i.e. Mel-spectrum of the target source, using a hybrid recurrent and hourglass network, while the decoder is a state-of-the-artWaveNet speech synthesis network conditioned on the Mel-spectrum, which directly generates time-domain samples of the sources. Both objective and subjective evaluations were performed on the synthesized sources, and show great advantages of our proposed method for high-quality speech source separation and generation.
C1 [Liu, Qingju; Jackson, Philip J. B.; Wang, Wenwu] Univ Surrey, Ctr Vis Speech & Signal Proc, Guildford GU2 7XH, Surrey, England.
   [Wang, Wenwu] Qingdao Univ Sci & Technol, Qingdao 266061, Peoples R China.
C3 University of Surrey; Qingdao University of Science & Technology
RP Liu, QJ (corresponding author), Univ Surrey, Ctr Vis Speech & Signal Proc, Guildford GU2 7XH, Surrey, England.
EM q.liu@surrey.ac.uk; p.jackson@surrey.ac.uk; w.wang@surrey.ac.uk
OI LIU, Qingju/0000-0003-0778-2992; Wang, Wenwu/0000-0002-8393-5703
FU EPSRC Programme Grant S3A: Future Spatial Audio for an Immersive
   Listener Experience at HomeUK Research & Innovation (UKRI)Engineering &
   Physical Sciences Research Council (EPSRC) [EP/L000539/1]; BBC as part
   of the BBC Audio Research Partnership; EPSRCUK Research & Innovation
   (UKRI)Engineering & Physical Sciences Research Council (EPSRC)
   [EP/L000539/1] Funding Source: UKRI
FX This work was supported by the EPSRC Programme Grant S3A: Future Spatial
   Audio for an Immersive Listener Experience at Home (EP/L000539/1) and
   the BBC as part of the BBC Audio Research Partnership. The associate
   editor coordinating the review of this manuscript and approving it for
   publication was Prof. Rosangela Coelho
CR Arik S. O., 2017, CORR
   Chandna P., 2017, P IEEE INT C LAT VAR
   Dall R., 2014, P INT C SPEECH PROS
   GRIFFIN DW, 1984, IEEE T ACOUST SPEECH, V32, P236, DOI 10.1109/TASSP.1984.1164317
   Hershey JR, 2016, INT CONF ACOUST SPEE, P31, DOI 10.1109/ICASSP.2016.7471631
   Huang PS, 2015, IEEE-ACM T AUDIO SPE, V23, P2136, DOI 10.1109/TASLP.2015.2468583
   Ito K., 2017, LJ SPEECH DATASET
   Jin ZY, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2251, DOI 10.1109/ICASSP.2018.8462431
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Kavukcuoglu K., 2016, ARXIV160903499
   Kingma DP, 2015, 3 INT C LEARN REPR I, DOI DOI 10.1145/1830483.1830503
   Liu Q., 2017, P EUR SIGN PROC C AU
   Liu QJ, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P541, DOI 10.1109/ICASSP.2018.8462603
   Maiti S, 2019, INT CONF ACOUST SPEE, P6995, DOI 10.1109/ICASSP.2019.8683130
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Pascual S, 2017, INTERSPEECH, P3642, DOI 10.21437/Interspeech.2017-1428
   Piczak KJ, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1015, DOI 10.1145/2733373.2806390
   Qian K., 2017, P C INT SPEECH COMM
   Rethage D, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5069, DOI 10.1109/ICASSP.2018.8462417
   Rix AW, 2001, INT CONF ACOUST SPEE, P749, DOI 10.1109/ICASSP.2001.941023
   Shen J, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4779, DOI 10.1109/ICASSP.2018.8461368
   Taal CH, 2010, INT CONF ACOUST SPEE, P4214, DOI 10.1109/ICASSP.2010.5495701
   Vincent E, 2006, IEEE T AUDIO SPEECH, V14, P1462, DOI 10.1109/TSA.2005.858005
NR 23
TC 0
Z9 0
U1 1
U2 7
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1070-9908
EI 1558-2361
J9 IEEE SIGNAL PROC LET
JI IEEE Signal Process. Lett.
PD DEC
PY 2019
VL 26
IS 12
BP 1872
EP 1876
DI 10.1109/LSP.2019.2951894
PG 5
WC Engineering, Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA KC0KI
UT WOS:000506875800006
DA 2022-02-06
ER

PT J
AU Yu, PP
   Xia, ZH
   Fei, JW
   Lu, YJ
AF Yu, Peipeng
   Xia, Zhihua
   Fei, Jianwei
   Lu, Yujiang
TI A Survey on Deepfake Video Detection
SO IET BIOMETRICS
LA English
DT Review
ID IMAGES
AB Recently, deepfake videos, generated by deep learning algorithms, have attracted widespread attention. Deepfake technology can be used to perform face manipulation with high realism. So far, there have been a large amount of deepfake videos circulating on the Internet, most of which target at celebrities or politicians. These videos are often used to damage the reputation of celebrities and guide public opinion, greatly threatening social stability. Although the deepfake algorithm itself has no attributes of good or evil, this technology has been widely used for negative purposes. To prevent it from threatening human society, a series of research have been launched, including developing detection methods and building large-scale benchmarks. This review aims to demonstrate the current research status of deepfake video detection, especially, generation process, several detection methods and existing benchmarks. It has been revealed that current detection methods are still insufficient to be applied in real scenes, and further research should pay more attention to the generalization and robustness.
C1 [Yu, Peipeng; Fei, Jianwei; Lu, Yujiang] Nanjing Univ Informat Sci & Technol, Engn Res Ctr Digital Forens, Jiangsu Engn Ctr Network Monitoring, Minist Educ,Sch Comp & Software,Jiangsu Collabora, Nanjing, Jiangsu, Peoples R China.
   [Xia, Zhihua] Jinan Univ, Coll Cyber Secur, Guangzhou 510632, Guangdong, Peoples R China.
   [Xia, Zhihua] Nanjing Univ Informat Sci & Technol, Engn Res Ctr Digital Forens, Nanjing, Peoples R China.
C3 Nanjing University of Information Science & Technology; Jinan
   University; Nanjing University of Information Science & Technology
RP Xia, ZH (corresponding author), Jinan Univ, Coll Cyber Secur, Guangzhou 510632, Guangdong, Peoples R China.
EM xia_zhihua@163.com
OI Yu, Peipeng/0000-0003-0056-4300
FU Collaborative Innovation Centre of Atmospheric Environment and Equipment
   Technology (CICAEET) fund, China; Priority Academic Programme
   Development of Jiangsu Higher Education Institutions; '333' project of
   Jiangsu ProvinceNatural Science Foundation of Jiangsu Province; Qinglan
   Project of Jiangsu Province; National Natural Science Foundation of
   ChinaNational Natural Science Foundation of China (NSFC) [61702276,
   61772283, U1936118, 61601236, 61602253, 61672294, U1836208]; National
   Key R&D Programme of China [2018YFB1003205]; Ministry of Education of
   Korea; Jiangsu Basic Research Programs-Natural Science Foundation
   [BK20181407]; Six peak talent project of Jiangsu Province [R2016L13]
FX Collaborative Innovation Centre of Atmospheric Environment and Equipment
   Technology (CICAEET) fund, China.; Priority Academic Programme
   Development of Jiangsu Higher Education Institutions; '333' project of
   Jiangsu Province; Qinglan Project of Jiangsu Province; National Natural
   Science Foundation of China, Grant/Award Numbers: 61702276, 61772283,
   U1936118, 61601236, 61602253, 61672294, U1836208; National Key R&D
   Programme of China, Grant/Award Number: 2018YFB1003205; BK21+ programme
   from the Ministry of Education of Korea; Jiangsu Basic Research
   Programs-Natural Science Foundation, Grant/Award Number: BK20181407; Six
   peak talent project of Jiangsu Province, Grant/Award Number: R2016L13
CR Afchar D., 2018, 2018 IEEE INT WORKSH, P1, DOI DOI 10.1109/WIFS.2018.8630761
   Amerini I, 2019, IEEE INT CONF COMP V, P1205, DOI 10.1109/ICCVW.2019.00152
   [Anonymous], 2019, KERAS VGGFACE VGGFAC
   [Anonymous], 2018, FACESWAP GAN
   Bitouk D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360638
   Bonettini E.D.C., 2020, ARXIV PREPRINT ARXIV
   Carlini N., 2020, P IEEE CVF C COMP VI, P2804
   Chen C, 2020, PROC CVPR IEEE, P2947, DOI 10.1109/CVPR42600.2020.00302
   Chen M, 2008, IEEE T INF FOREN SEC, V3, P74, DOI 10.1109/TIFS.2007.916285
   Chen T. Q., 2018, ADV NEURAL INFORM PR, P6571
   Chen WX, 2018, LECT NOTES COMPUT SC, V11206, P356, DOI 10.1007/978-3-030-01216-8_22
   Chesney B, 2019, CALIF LAW REV, V107, P1753, DOI 10.15779/Z38RV0D15J
   Chesney R, 2019, FOREIGN AFF, V98, P147
   Chierchia G, 2014, IEEE T INF FOREN SEC, V9, P554, DOI 10.1109/TIFS.2014.2302078
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Ciftci U.A., 2020, IEEE T PATTERN ANAL, V1
   Cozzolino D., 2019, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPRW47913.2019
   Cozzolino D, 2020, IEEE T INF FOREN SEC, V15, P144, DOI 10.1109/TIFS.2019.2916364
   Cozzolino Davide, 2018, ARXIV181202510
   Dale K., 2011, VIDEO FACE REPLACEME
   Dang H, 2020, PROC CVPR IEEE, P5780, DOI 10.1109/CVPR42600.2020.00582
   Delfino RA, 2019, FORDHAM LAW REV, V88, P887
   Dixon H.B, 2019, JUDGES J, V58, P35
   Dolhansky B., 2019, DEEPFAKE DETECTION C
   Dolhansky B., 2020, DEEPFAKE DETECTION C
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Dong SK, 2017, IEEE GLOB COMM CONF
   Dufour, 2019, DEEPFAKES DETECTION
   Feldstein Steven, 2019, CONVERSATION 0422
   Feng LT, 2015, IEEE T CIRC SYST VID, V25, P879, DOI 10.1109/TCSVT.2014.2364415
   Fernandes S, 2019, IEEE INT CONF COMP V, P1721, DOI 10.1109/ICCVW.2019.00213
   Frank J, 2020, PR MACH LEARN RES, V119
   Fried O, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323028
   Gandhi A, 2020, IEEE IJCNN
   Guera D, 2018, 2018 15TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P127
   Nguyen HD, 2019, PROCEEDINGS OF THE 2019 FIFTH INTERNATIONAL WORKSHOP ON SERVERLESS COMPUTING (WOSC '19), P1, DOI 10.1145/3366623.3368133
   Hernandez-Ortega Javier, 2020, ARXIV PREPRINT ARXIV
   Huang Yuheng, 2020, ARXIV PREPRINT ARXIV
   Jaiswal Ayush, 2019, ARXIV190500582
   Jia Yunpei, 2020, P IEEE CVF C COMP VI, P8484
   Jiang LM, 2020, PROC CVPR IEEE, P2886, DOI 10.1109/CVPR42600.2020.00296
   Kermany DS, 2018, CELL, V172, P1122, DOI 10.1016/j.cell.2018.02.010
   KIM HYEON-ZOO, 2018, [ASSOCIATION CULTURELLE FRANC0-COREENNE, 프랑스 문화 연구], V37, P1, DOI 10.18022/acfco.2018.37.1.001
   Koopman M, 2018, P IR MACH VIS IM PRO, P133
   Korshunov P., 2019, 12 IAPR INT C BIOM I, P1
   Korshunov P., 2018, DEEPFAKES NEW THREAT
   Korshunova I, 2017, IEEE I CONF COMP VIS, P3697, DOI 10.1109/ICCV.2017.397
   Korus P, 2017, IEEE T INF FOREN SEC, V12, P809, DOI 10.1109/TIFS.2016.2636089
   Li LZ, 2020, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR42600.2020.00505
   Li LJ, 2019, IEEE I CONF COMP VIS, P10312, DOI 10.1109/ICCV.2019.01041
   Li XR, 2020, WWW'20: COMPANION PROCEEDINGS OF THE WEB CONFERENCE 2020, P88, DOI 10.1145/3366424.3382711
   [李艳歌 Li Yange], 2018, [高分子通报, Polymer Bulletin], P46
   Li YJ, 2019, IEEE INT C BIOINFORM, P303, DOI 10.1109/BIBM47256.2019.8982964
   Li Yuezun, 2018, 2018 IEEE INT WORKSH, P1, DOI DOI 10.1109/WIFS.2018.8630787
   Liu Zhengzhe, 2020, P IEEE CVF C COMP VI, P8060, DOI DOI 10.1109/CVPR42600.2020.00808
   Lukas J, 2006, IEEE T INF FOREN SEC, V1, P205, DOI 10.1109/TIFS.2006.873602
   Lundberg SM., 2017, ADV NEURALINFOR MATI, DOI DOI 10.5555/3295222.3295230
   Masi Iacopo, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12352), P667, DOI 10.1007/978-3-030-58571-6_39
   Mittal Trisha, 2020, MM '20: Proceedings of the 28th ACM International Conference on Multimedia, P2823, DOI 10.1145/3394171.3413570
   Montserrat Daniel Mas, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW). Proceedings, P2851, DOI 10.1109/CVPRW50498.2020.00342
   Muller, 2017, ARXIV PREPRINT ARXIV, DOI DOI 10.21037/jmai.2018.07.01
   Neekhara P., 2020, ARXIV PREPRINT ARXIV
   Nguyen HH, 2019, INT CONF ACOUST SPEE, P2307, DOI 10.1109/ICASSP.2019.8682602
   Olszewski K, 2017, IEEE I CONF COMP VIS, P5439, DOI 10.1109/ICCV.2017.580
   Petrov Ivan, 2020, ARXIV PREPRINT ARXIV
   Prakash SKA, 2018, BIOMED OPT EXPRESS, V9, P873, DOI 10.1364/BOE.9.000873
   Qi H., 2020, P 28 ACM INT C MULT, P4318
   Rossler A, 2019, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2019.00009
   Ruff L, 2018, PR MACH LEARN RES, V80
   Sabir Ekraam, 2019, INTERFACES GUI, P80
   Simonyan K, 2015, ICLR 2015, DOI DOI 10.1109/CVPR.2015.7298594
   Stehouwer Joel, 2019, ARXIV191001717
   Suwajanakorn S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073640
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tarasiou M, 2020, IEEE IMAGE PROC, P1821, DOI 10.1109/ICIP40778.2020.9190714
   Thies J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323035
   Thies J, 2016, PROC CVPR IEEE, P2387, DOI 10.1109/CVPR.2016.262
   Vlasic Daniel, 2006, ACM SIGGRAPH 2006 C, P24
   Wang R., 2020, P INT JOINT C ART IN, P3444
   Wu X, 2020, INT CONF ACOUST SPEE, P2952, DOI 10.1109/ICASSP40776.2020.9053969
   Xiong RQ, 2017, IEEE T IMAGE PROCESS, V26, DOI 10.1109/TIP.2016.2621478
   Yang X, 2019, INT CONF ACOUST SPEE, P8261, DOI 10.1109/ICASSP.2019.8683164
   Yuan L., 2012, ACM INT C MULT ACM N, P1249
   Zhang Xin, 2014, Instrument Technique and Sensor, P95
   Zhao CC, 2018, IEEE COMPUT SOC CONF, P1380, DOI 10.1109/CVPRW.2018.00177
   Zhao Y., 2019, INT C INF COMM SEC, P630
NR 87
TC 2
Z9 2
U1 18
U2 27
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 2047-4938
EI 2047-4946
J9 IET BIOMETRICS
JI IET Biom.
PD NOV
PY 2021
VL 10
IS 6
BP 607
EP 624
DI 10.1049/bme2.12031
EA APR 2021
PG 18
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA WF9IR
UT WOS:000639386500001
OA gold
DA 2022-02-06
ER

PT J
AU Jang, Y
   Park, CH
   Lee, DG
   Seo, YS
AF Jang, Yonghun
   Park, Chang-Hyeon
   Lee, Dong-Gun
   Seo, Yeong-Seok
TI Fake News Detection on Social Media: A Temporal-Based Approach
SO CMC-COMPUTERS MATERIALS & CONTINUA
LA English
DT Article
DE Artificial inteligence; deep learning; fake&nbsp; news; rumor; smart
   city data analysis
AB Following the development of communication techniques and smart devices, the era of Artificial Intelligence (AI) and big data has arrived. The increased connectivity, referred to as hyper-connectivity, has led to the development of smart cities. People in these smart cities can access numerous online contents and are always connected. These developments, however, also lead to a lack of standardization and consistency in the propagation of information throughout communities due to the consumption of information through social media channels. Information cannot often be verified, which can confuse the users. The increasing influence of social media has thus led to the emergence and increasing prevalence of fake news. In this study, we propose a methodology to classify and identify fake news emanating from social channels. We collected content from Twitter to detect fake news and statistically verified that the temporal propagation pattern of quote retweets is effective for the classification of fake news. To verify this, we trained the temporal propagation pattern to a two-phases deep learning model based on convolutional neural networks and long short-term memory. The fake news classifier demonstrates the ability for its early detection. Moreover, it was verified that the temporal propagation pattern was the most influential feature compared to other feature groups discussed in this paper.
C1 [Jang, Yonghun; Park, Chang-Hyeon; Lee, Dong-Gun; Seo, Yeong-Seok] Yeungnam Univ, Dept Comp Engn, Gyongsan 38541, South Korea.
C3 Yeungnam University
RP Seo, YS (corresponding author), Yeungnam Univ, Dept Comp Engn, Gyongsan 38541, South Korea.
EM ysseo@yu.ac.kr
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [NRF-2020R1I1A3073313]
FX This research was supported by the Basic Science Research Program
   through the National Research Foundation of Korea (NRF) funded by the
   Ministry of Education (NRF-2020R1I1A3073313) .
CR Allam Z, 2018, SMART CITIES-BASEL, V1, P4, DOI 10.3390/smartcities1010002
   Baird S., 2017, FAKE NEWS CHALLENGE
   Bovet A, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-018-07761-2
   Castillo C., 2011, WWW, P675
   Chandrasekaran D., 2021, ACM CSUR, V54, P1
   Flanagin AJ, 2000, JOURNALISM MASS COMM, V77, P515, DOI 10.1177/107769900007700304
   Fuchs C, 2017, SOCIAL MEDIA CRITICA, V2nd, P33
   Garimella K, 2016, PROCEEDINGS OF THE 2016 ACM WEB SCIENCE CONFERENCE (WEBSCI'16), P200, DOI 10.1145/2908131.2908170
   Ghanem B., 2018, P 1 WORKSH FACT EXTR, P66
   Hanselowski A., 2018, ARXIV180605180
   Hermida A, 2010, JOURNAL PRACT, V4, P297, DOI 10.1080/17512781003640703
   Huh JH, 2017, HUM-CENTRIC COMPUT I, V7, DOI 10.1186/s13673-017-0101-x
   Imran M, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2771588
   Jang Y, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8121377
   Jeong S. S., 2019, J AMB INTEL HUM COMP, V6, P1, DOI DOI 10.1007/S12652-019-01347-6
   Jin ZW, 2016, THIRTIETH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2972
   Johnson TJ, 2007, J COMPUT-MEDIAT COMM, V13, P100, DOI 10.1111/j.1083-6101.2007.00388.x
   Kim SK, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12104021
   Kwak HG, 2010, INT CONF ADV COMMUN, P591
   Kwon S, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0168344
   Kwon S, 2013, IEEE DATA MINING, P1103, DOI 10.1109/ICDM.2013.61
   Laufs J, 2020, SUSTAIN CITIES SOC, V55, DOI 10.1016/j.scs.2020.102023
   Lillie A. E., 2019, ARXIV PREPRINT ARXIV
   Lukasik M, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P393
   Lytras MD, 2018, SUSTAINABILITY-BASEL, V10, DOI 10.3390/su10061998
   Maddock J, 2015, PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON COMPUTER-SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING (CSCW'15), P228, DOI 10.1145/2675133.2675280
   Marsh A., 2016, P 10 INT WORKSH SEM, P458, DOI DOI 10.18653/V1/S16-1074
   Mason, 2013, ICONFERENCE 2014, DOI DOI 10.9776/14308
   Mavridis IN, 2018, PHARM NANOTECHNO, P1, DOI 10.1016/B978-0-12-813667-6.00001-2
   Mendoza Marcelo, 2010, P 1 WORKSH SOC MED A, DOI DOI 10.1145/1964858.1964869
   Pamungkas E. W., 2019, ARXIV PREPRINT ARXIV
   Park JH, 2021, HUM-CENT COMPUT INFO, V11, DOI 10.22967/HCIS.2021.11.003
   Phuvipadawat S, 2010, Proceedings of the 2010 IEEE/ACM International Conference on Web Intelligence-Intelligent Agent Technology - Workshops (WI-IAT 2010), P120, DOI 10.1109/WI-IAT.2010.205
   Procter R, 2013, POLIC SOC, V23, P413, DOI 10.1080/10439463.2013.780223
   Procter R, 2013, INT J SOC RES METHOD, V16, P197, DOI 10.1080/13645579.2013.774172
   Sakaki T, 2013, IEEE T KNOWL DATA EN, V25, P919, DOI 10.1109/TKDE.2012.29
   Sang Ki Kim, 2020, 2020 International Conference on Artificial Intelligence in Information and Communication (ICAIIC), P657, DOI 10.1109/ICAIIC48513.2020.9065226
   Schwarz J, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1245
   Singh S. K., 2021, HUM-CENT COMPUT INFO, V11, P1
   Van Dijck J, 2013, CULTURE CONNECTIVITY, P3
   Van-Hoang Nguyen, 2020, CIKM '20: Proceedings of the 29th International Conference on Information & Knowledge Management, P1165, DOI 10.1145/3340531.3412046
   Yang R., 2019, P 13 INT WORKSH SEM, P1090
   Yates D, 2011, INT J INFORM MANAGE, V31, P6, DOI 10.1016/j.ijinfomgt.2010.10.001
   Yin CY, 2020, J SUPERCOMPUT, V76, P5161, DOI 10.1007/s11227-019-02751-7
   Yin CY, 2019, HUM-CENT COMPUT INFO, V9, DOI 10.1186/s13673-019-0177-6
   Yin J, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P4234, DOI 10.1109/MIS.2012.6
   Yu J, 2020, IEEE CONSUM ELECTR M, V9, P34, DOI 10.1109/MCE.2019.2953737
   Zubiaga A, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3161603
   Zubiaga A, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0150989
NR 49
TC 0
Z9 0
U1 11
U2 11
PU TECH SCIENCE PRESS
PI HENDERSON
PA 871 CORONADO CENTER DR, SUTE 200, HENDERSON, NV 89052 USA
SN 1546-2218
EI 1546-2226
J9 CMC-COMPUT MATER CON
JI CMC-Comput. Mat. Contin.
PY 2021
VL 69
IS 3
BP 3563
EP 3579
DI 10.32604/cmc.2021.018901
PG 17
WC Computer Science, Information Systems; Materials Science,
   Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Materials Science
GA UF2NE
UT WOS:000688414800002
OA gold
DA 2022-02-06
ER

PT J
AU Liang, LY
   Zhang, XL
AF Liang, Lingyu
   Zhang, Xinglin
TI Adaptive Label Propagation for Facial Appearance Transfer
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Image editing; face appearance transfer; label propagation; face
   replacement; face blending
ID IMAGE; RECOGNITION
AB Facial appearance transfer (FAT) is a critical component of various facial editing tasks. It aims to transfer the facial appearance of a reference into a target with good visual consistency. When there are considerable visual differences between a reference and a target, however, it may introduce visual artifacts into the results. To tackle this problem, we propose a facial appearance map with illumination-aware and region-aware properties that allows seamless FAT. We formulate the appearance-map generation as label propagation (LP) on a similarity graph, and propose a new regularization structure to facilitate the adaptive appearance-map diffusion. Solving the original LP model of appearance map in general requires on the order O(kn(2)) time for an n-nodes graph where each node has k neighbors. It may be computationally prohibitive for an image with a large spatial resolution. To tackle this problem, we mathematically analyze the graph-based LP model and propose a fast algorithm with smart subset sampling. It selects a subset with m nodes of the graph with n nodes (m << n) to approximate the solution to the original system, which significantly reduces its computational requirements from O(kn(2)) to O(m(2)n). Based on the adaptive LP-based appearance map, we construct a framework to achieve various editing effects with FAT, including face replacement, face dubbing, face swapping, and transfiguring. Comparisons with related methods show the effectiveness of the adaptive LP model for FAT. Qualitative and quantitative evaluations verify the computational improvements of the approximation algorithm.
C1 [Liang, Lingyu] South China Univ Technol, Sch Elect & Informat Engn, Guangzhou 510641, Guangdong, Peoples R China.
   [Zhang, Xinglin] South China Univ Technol, Sch Comp Sci & Engn, Guangzhou 510006, Peoples R China.
C3 South China University of Technology; South China University of
   Technology
RP Zhang, XL (corresponding author), South China Univ Technol, Sch Comp Sci & Engn, Guangzhou 510006, Peoples R China.
EM lianglysky@gmail.com; zhxlinsc@gmail.com
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61502176, 61872149, 61602184, 61872151];
   Natural Science Foundation of Guangdong ProvinceNational Natural Science
   Foundation of Guangdong Province [2018B030306010, 2017A030313376];
   Guangdong Special Support Program [2017TQ04X482]; Pearl River S&T Nova
   Program of Guangzhou [201806010088]; Science and Technology Program of
   Guangzhou [201707010147]; Fundamental Research Funds for the Central
   UniversitiesFundamental Research Funds for the Central Universities
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 61502176, 61872149, 61602184, and
   61872151, in part by Natural Science Foundation of Guangdong Province
   under Grants 2018B030306010 (Distinguished Young Scholar) and
   2017A030313376, in part by the Guangdong Special Support Program under
   Grant 2017TQ04X482, in part by the Pearl River S&T Nova Program of
   Guangzhou underGrant 201806010088, in part by Science and Technology
   Program of Guangzhou under Grant 201707010147, and in part by
   Fundamental Research Funds for the Central Universities. The associate
   editor coordinating the reviewof thismanuscript and approving it for
   publicationwas Dr. Lei Zhang.
CR Agarwala A, 2004, ACM T GRAPHIC, V23, P294, DOI 10.1145/1015706.1015718
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Aksoy Y, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201275
   An XB, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360639
   Atkinson K, 2005, THEORETICAL NUMERICA, V39
   Barron JT, 2015, IEEE T PATTERN ANAL, V37, P1670, DOI 10.1109/TPAMI.2014.2377712
   Bhat P, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1731047.1731048
   Billinghurst Mark, 2015, Foundations and Trends in Human-Computer Interaction, V8, P73, DOI 10.1561/1100000049
   Bitouk D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360638
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   Brahnam S., 2014, LOCAL BINARY PATTERN
   Burgos-Artizzu XP, 2013, IEEE I CONF COMP VIS, P1513, DOI 10.1109/ICCV.2013.191
   Chapelle O., 2006, SEMISUPERVISED LEARN
   Chen BC, 2015, IEEE T MULTIMEDIA, V17, P804, DOI 10.1109/TMM.2015.2420374
   Chen XW, 2013, IEEE T IMAGE PROCESS, V22, P4249, DOI 10.1109/TIP.2013.2271548
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Dale K, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024164
   Dou H, 2017, IEEE T MULTIMEDIA, V19, P1718, DOI 10.1109/TMM.2017.2689327
   Fowlkes C, 2004, IEEE T PATTERN ANAL, V26, P214, DOI 10.1109/TPAMI.2004.1262185
   Garrido P, 2014, PROC CVPR IEEE, P4217, DOI 10.1109/CVPR.2014.537
   Guo D, 2009, PROC CVPR IEEE, P73, DOI 10.1109/CVPRW.2009.5206833
   Guo GD, 2011, IEEE I CONF COMP VIS, P2510, DOI 10.1109/ICCV.2011.6126537
   Henriquez P, 2017, IEEE T MULTIMEDIA, V19, P1467, DOI 10.1109/TMM.2017.2666545
   Huang GQ, 2009, INT J COMPUT INTEG M, V22, P579, DOI 10.1080/09511920701724934
   Huang GS, 2007, 2007 7TH IEEE CONFERENCE ON NANOTECHNOLOGY, VOL 1-3, P7, DOI 10.1109/NANO.2007.4601129
   Jia JY, 2006, ACM T GRAPHIC, V25, P631, DOI 10.1145/1141911.1141934
   Joachims Thorsten, 2003, P 20 INT C MACH LEAR, DOI DOI 10.1145/2612669.2612699
   Kemelmacher-Shlizerman I, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925871
   KEMELMACHERSHLIZER, 2014, PROC CVPR IEEE, P3334, DOI DOI 10.1109/CVPR.2014.426
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Korshunova I, 2017, IEEE I CONF COMP VIS, P3697, DOI 10.1109/ICCV.2017.397
   KRISHNAN D., 2013, ACM T GRAPHIC, V32, P142
   Learned-Miller E., 2016, ADV FACE DETECTION F, P189, DOI [10.1007/978-3-319-25958-1_8, DOI 10.1007/978-3-319-25958-1_8]
   Lee S, 1997, IEEE T VIS COMPUT GR, V3, P228, DOI 10.1109/2945.620490
   Liang JQ, 2017, IEEE T MULTIMEDIA, V19, P1077, DOI 10.1109/TMM.2016.2644862
   Liang LY, 2017, IEEE T CIRC SYST VID, V27, P125, DOI 10.1109/TCSVT.2016.2602812
   Liang LY, 2013, IEICE T INF SYST, VE96D, P2904, DOI 10.1587/transinf.E96.D.2904
   Liang X, 2018, PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: IOT AND SMART CITY (ICIT 2018), P173, DOI 10.1145/3301551.3301555
   Ling HB, 2017, IEEE MULTIMEDIA, V24, P10, DOI 10.1109/MMUL.2017.3051517
   Liu JY, 2018, IEEE T MULTIMEDIA, V20, P1724, DOI 10.1109/TMM.2017.2780761
   Liu SF, 2015, PROC CVPR IEEE, P3451, DOI 10.1109/CVPR.2015.7298967
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lukac R., 2010, COMPUTATIONAL PHOTOG
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Nguyen MH, 2008, COMPUT GRAPH FORUM, V27, P627, DOI 10.1111/j.1467-8659.2008.01160.x
   Nirkin Y, 2018, IEEE INT CONF AUTOMA, P98, DOI 10.1109/FG.2018.00024
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ortega A, 2018, P IEEE, V106, P808, DOI 10.1109/JPROC.2018.2820126
   Paszke A., 2016, ENET DEEP NEURAL NET
   Peers P, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239503
   Perez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269
   Reinhard E, 2013, P IEEE, V101, P1998, DOI 10.1109/JPROC.2013.2260711
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Saad Y., 2003, ITERATIVE METHODS SP, V2nd
   Shashua A, 2001, IEEE T PATTERN ANAL, V23, P129, DOI 10.1109/34.908964
   Shih YC, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601137
   Shuman DI, 2013, IEEE SIGNAL PROC MAG, V30, P83, DOI 10.1109/MSP.2012.2235192
   Sun WT, 2017, IEEE T MULTIMEDIA, V19, P1870, DOI 10.1109/TMM.2017.2688929
   Szummer M., 2001, NIPS, P945
   Tai YW, 2007, IEEE T PATTERN ANAL, V29, P1520, DOI 10.1109/TPAMI.2007.1168
   THIES J, 2016, PROC CVPR IEEE, P2387, DOI DOI 10.1109/CVPR.2016.262
   Thies J, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818056
   Thomaz CE, 2010, IMAGE VISION COMPUT, V28, P902, DOI 10.1016/j.imavis.2009.11.005
   Tong WS, 2007, PACIFIC GRAPHICS 2007: 15TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, P211, DOI 10.1109/PG.2007.31
   Tran AT, 2017, PROC CVPR IEEE, P1493, DOI 10.1109/CVPR.2017.163
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Williams CKI, 2001, ADV NEUR IN, V13, P682
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423
   Yang S, 2017, INT CONF ACOUST SPEE, P1353, DOI 10.1109/ICASSP.2017.7952377
   Yang SM, 2015, AER ADV ENG RES, V8, P1, DOI 10.1109/PESGM.2015.7285904
   Zhang R, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073703
   Zhang Z., 2018, ARXIV181204202
   Zhou DY, 2004, ADV NEUR IN, V16, P321
   Zhou P, 2017, IEEE COMPUT SOC CONF, P1831, DOI 10.1109/CVPRW.2017.229
   Zhu X., 2003, P 20 INT C MACH LEAR, V20, P912
   Zhu X., 2002, LEARNING LABELED UNL
NR 77
TC 0
Z9 0
U1 2
U2 11
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD DEC
PY 2019
VL 21
IS 12
BP 3068
EP 3082
DI 10.1109/TMM.2019.2918717
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA KJ8ZS
UT WOS:000512345200008
DA 2022-02-06
ER

PT J
AU Chintha, A
   Thai, B
   Sohrawardi, SJ
   Bhatt, K
   Hickerson, A
   Wright, M
   Ptucha, R
AF Chintha, Akash
   Thai, Bao
   Sohrawardi, Saniat Javid
   Bhatt, Kartavya
   Hickerson, Andrea
   Wright, Matthew
   Ptucha, Raymond
TI Recurrent Convolutional Structures for Audio Spoof and Video Deepfake
   Detection
SO IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING
LA English
DT Article
DE Information integrity; Videos; Face; Feature extraction; Convolution;
   Computer architecture; Forgery; Convolution; deep learning; deepfake;
   entropy; spoof
ID NETWORKS
AB Deepfakes, or artificially generated audiovisual renderings, can be used to defame a public figure or influence public opinion. With the recent discovery of generative adversarial networks, an attacker using a normal desktop computer fitted with an off-the-shelf graphics processing unit can make renditions realistic enough to easily fool a human observer. Detecting deepfakes is thus becoming important for reporters, social media platforms, and the general public. In this work, we introduce simple, yet surprisingly efficient digital forensic methods for audio spoof and visual deepfake detection. Our methods combine convolutional latent representations with bidirectional recurrent structures and entropy-based cost functions. The latent representations for both audio and video are carefully chosen to extract semantically rich information from the recordings. By feeding these into a recurrent framework, we can detect both spatial and temporal signatures of deepfake renditions. The entropy-based cost functions work well in isolation as well as in context with traditional cost functions. We demonstrate our methods on the FaceForensics++ and Celeb-DF video datasets and the ASVSpoof 2019 Logical Access audio datasets, achieving new benchmarks in all categories. We also perform extensive studies to demonstrate generalization to new domains and gain further insight into the effectiveness of the new architectures.
C1 [Chintha, Akash; Thai, Bao; Ptucha, Raymond] Rochester Inst Technol, Dept Comp Engn, Rochester, NY 14623 USA.
   [Sohrawardi, Saniat Javid; Bhatt, Kartavya; Wright, Matthew] Rochester Inst Technol, Dept Comp Secur, Rochester, NY 14623 USA.
   [Hickerson, Andrea] Univ South Carolina, Sch Journalism & Mass Commun, Columbia, SC 29208 USA.
C3 Rochester Institute of Technology; Rochester Institute of Technology;
   University of South Carolina System; University of South Carolina
   Columbia
RP Chintha, A (corresponding author), Rochester Inst Technol, Dept Comp Engn, Rochester, NY 14623 USA.
EM ac1864@rit.edu; baothai120708@gmail.com; js8365@rit.edu;
   kb8077@g.rit.edu; hickera@mailbox.sc.edu; matthew.wright@rit.edu;
   rwpeec@rit.edu
OI Hickerson, Andrea/0000-0002-6854-8027; BHATT,
   KARTAVYA/0000-0001-8455-6353; Chintha, Akash/0000-0003-1816-8111;
   Sohrawardi, Saniat/0000-0002-4707-7035
FU Miami Foundation through the Ethics and Governance of the Artificial
   Intelligence Initiative
FX This effort was funded in part by the Miami Foundation through the
   Ethics and Governance of the Artificial Intelligence Initiative.
CR Afchar D., 2018, 2018 IEEE INT WORKSH, P1, DOI DOI 10.1109/WIFS.2018.8630761
   Agarwal S., 2019, P CVPR WORKSH LONG B, P38
   Allaire G, 2004, J COMPUT PHYS, V194, P363, DOI 10.1016/j.jcp.2003.09.032
   Alzantot M., 2019, P 20 ANN C INT SPEEC, P1078, DOI DOI 10.21437/INTERSPEECH.2019-3174
   Andreas R <spacing, 2019, INT C COMP VIS ICCV, DOI DOI 10.1109/ICCV.2019.00009
   Arik SO, 2018, ADV NEURAL INFORM PR, P10019
   Bradski G, 2000, DR DOBBS J, V25, P120
   Cao Q, 2018, IEEE INT CONF AUTOMA, P67, DOI 10.1109/FG.2018.00020
   Chettri B., 2019, P INTERSPEECH, DOI DOI 10.21437/INTERSPEECH.2019-2505
   Chettri B, 2018, IEEE W SP LANG TECH, P92, DOI 10.1109/SLT.2018.8639666
   Chintala S, 2015, ARXIV151106434
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Ciftci U.A., 2019, ARXIV190102212
   Cozzolino Davide, 2018, ARXIV181202510
   Das RK, 2019, 2019 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU 2019), P1018, DOI 10.1109/ASRU46091.2019.9003845
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dieleman S., 2016, ISCA SPEECH SYNTH WO, P125, DOI DOI 10.1109/ICASSP.2009.4960364
   Dolhansky B., 2019, DEEPFAKE DETECTION C
   Fletcher J, 2018, THEATRE J, V70, P455, DOI 10.1353/tj.2018.0097
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   GRIFFIN DW, 1984, IEEE T ACOUST SPEECH, V32, P236, DOI 10.1109/TASSP.1984.1164317
   Guera David, 2018, 15 IEEE INT C ADV VI, P1, DOI [DOI 10.1109/AVSS.2018.8639163, 10.1109/AVSS.2018.8639163]
   Ha Sungjoo, 2019, ARXIV191108139
   Nguyen HD, 2019, PROCEEDINGS OF THE 2019 FIFTH INTERNATIONAL WORKSHOP ON SERVERLESS COMPUTING (WOSC '19), P1, DOI 10.1145/3366623.3368133
   He K., 2016, DEEP RESIDUAL LEARNI, DOI DOI 10.1109/CVPR.2016.90
   Hinton GE, 2011, LECT NOTES COMPUT SC, V6791, P44, DOI 10.1007/978-3-642-21735-7_6
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Kameoka H, 2018, IEEE W SP LANG TECH, P266, DOI 10.1109/SLT.2018.8639535
   Karras T., 2017, ARXIV171010196
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Kim HS, 2019, ADDICT RES THEORY, V27, P95, DOI [10.1155/2018/2365414, 10.1080/16066359.2018.1455188]
   Kim T., 2017, P IEEE WIR POW TRANS, V70, P1857, DOI DOI 10.1109/WPT.2017.7953894
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Kingma D., 2013, ARXIV13126114
   Kingma DP, 2015, 3 INT C LEARN REPR I, DOI DOI 10.1145/1830483.1830503
   Kinnunen T, 2017, INTERSPEECH, P2, DOI 10.21437/Interspeech.2017-1111
   Korshunov P., 2018, DEEPFAKES NEW THREAT
   Korshunov P., 2019, HDB BIOMETRIC ANTISP
   Korshunova I, 2017, IEEE I CONF COMP VIS, P3697, DOI 10.1109/ICCV.2017.397
   Kowalski M., FACESWAP
   Li YJ, 2019, IEEE INT C BIOINFORM, P303, DOI 10.1109/BIBM47256.2019.8982964
   Li Yuezun, 2018, CVPR
   Lin K.W.E., 2019, ARXIV 1905 12439
   Liu MY, 2019, IEEE I CONF COMP VIS, P10550, DOI 10.1109/ICCV.2019.01065
   Lorenzo-Trueba J., 2018, P OD 2018 SPEAK LANG, P195
   Lu S.-A., FACESWAP GAN
   Lu YY, 2018, LECT NOTES COMPUT SC, V11216, P293, DOI 10.1007/978-3-030-01258-8_18
   Matern F, 2019, IEEE WINT CONF APPL, P83, DOI 10.1109/WACVW.2019.00020
   Matrouf D, 2007, INTERSPEECH 2007: 8TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION, VOLS 1-4, P2624
   Nguyen H.H., 2018, ARXIV181011215
   Ovadya A., 2019, ARXIV190711274V2
   Perarnau Guim, 2016, ARXIV161106355
   Reed S, 2016, PR MACH LEARN RES, V48
   Reynolds DA, 2000, DIGIT SIGNAL PROCESS, V10, P19, DOI 10.1006/dspr.1999.0361
   Sabir Ekraam, 2019, INTERFACES GUI, P80
   Sabour S., 2017, NIPS, P3856
   Sanderson C, 2009, LECT NOTES COMPUT SC, V5558, P199, DOI 10.1007/978-3-642-01793-3_21
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Shen Y., 2019, INTERPRETING LATENT
   Simonyan K, 2015, ICLR 2015, DOI DOI 10.1109/CVPR.2015.7298594
   Sohrawardi SJ, 2019, PROCEEDINGS OF THE 2019 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'19), P2613, DOI 10.1145/3319535.3363269
   SOONG FK, 1987, AT&T TECH J, V66, P14, DOI 10.1002/j.1538-7305.1987.tb00198.x
   Suwajanakorn S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073640
   SZEGEDY C, 2016, PROC CVPR IEEE, P2818, DOI DOI 10.1109/CVPR.2016.308
   Tanaka K, 2019, INT CONF ACOUST SPEE, P6805, DOI 10.1109/ICASSP.2019.8683282
   Thies J., 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.262
   Thies J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323035
   Todisco M., 2016, ODYSSEY 2016, V45, P283, DOI DOI 10.21437/ODYSSEY.2016-41
   Todisco M., 2019, INTERSPEECH 2019
   Tom F, 2018, INTERSPEECH, P681, DOI 10.21437/Interspeech.2018-2279
   Wang TC, 2019, ADV NEUR IN, V32
   Wu QQ, 2010, 2011 INTERNATIONAL CONFERENCE ON COMPUTERS, COMMUNICATIONS, CONTROL AND AUTOMATION (CCCA 2011), VOL I, P288, DOI 10.1109/DICTA.2010.57
   Wu ZZ, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P2037
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yang X, 2019, INT CONF ACOUST SPEE, P8261, DOI 10.1109/ICASSP.2019.8683164
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu Jun-Yan, 2017, IEEE INT C COMP VIS, DOI [DOI 10.1109/ICCV.2017.244, DOI 10.1109/ICCV.2017.244:2242-2251]
NR 78
TC 5
Z9 5
U1 5
U2 28
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1932-4553
EI 1941-0484
J9 IEEE J-STSP
JI IEEE J. Sel. Top. Signal Process.
PD AUG
PY 2020
VL 14
IS 5
BP 1024
EP 1037
DI 10.1109/JSTSP.2020.2999185
PG 14
WC Engineering, Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA NG8BM
UT WOS:000564205000010
DA 2022-02-06
ER

PT J
AU Kim, S
   Jung, SJ
   Seo, K
   Ribera, RBI
   Noh, J
AF Kim, Seonghyeon
   Jung, Sunjin
   Seo, Kwanggyoon
   Blanco i Ribera, Roger
   Noh, Junyong
TI Deep Learning-Based Unsupervised Human Facial Retargeting
SO COMPUTER GRAPHICS FORUM
LA English
DT Article
AB Traditional approaches to retarget existing facial blendshape animations to other characters rely heavily on manually paired data including corresponding anchors, expressions, or semantic parametrizations to preserve the characteristics of the original performance. In this paper, inspired by recent developments in face swapping and reenactment, we propose a novel unsupervised learning method that reformulates the retargeting of 3D facial blendshape-based animations in the image domain. The expressions of a source model is transferred to a target model via the rendered images of the source animation. For this purpose, a reenactment network is trained with the rendered images of various expressions created by the source and target models in a shared latent space. The use of shared latent space enable an automatic cross-mapping obviating the need for manual pairing. Next, a blendshape prediction network is used to extract the blendshape weights from the translated image to complete the retargeting of the animation onto a 3D target model. Our method allows for fully unsupervised retargeting of facial expressions between models of different configurations, and once trained, is suitable for automatic real-time applications.
C1 [Kim, Seonghyeon; Jung, Sunjin; Seo, Kwanggyoon; Noh, Junyong] Korea Adv Inst Sci & Technol, Visual Media Lab, Daejeon, South Korea.
   [Blanco i Ribera, Roger] C JeS Gulliver Studios, Goyang, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST)
RP Kim, S (corresponding author), Korea Adv Inst Sci & Technol, Visual Media Lab, Daejeon, South Korea.
OI Kim, Seonghyeon/0000-0001-8027-8261
FU Institute of Information & communications Technology Planning &
   Evaluation (IITP) - Korea government (MSIT) [2020-0-00450]
FX We thank the anonymous reviewers for their invaluable comments; Haemin
   Kim for providing the voice-over. This work was supported by Institute
   of Information & communications Technology Planning & Evaluation (IITP)
   grant funded by the Korea government(MSIT) (No.2020-0-00450, A Deep
   Learning Based Immersive AR Content Creation Platform for Generating
   Interactive, Context and Geometry Aware Movement from a Single Image).
CR Aneja D, 2018, IEEE WINT CONF APPL, P160, DOI 10.1109/WACV.2018.00024
   Bao JM, 2018, PROC CVPR IEEE, P6713, DOI 10.1109/CVPR.2018.00702
   Ribera RBI, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073674
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Cao C, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601204
   Cao C, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2462012
   Deng Z., 2006, P S INT 3D GRAPH GAM, P43, DOI DOI 10.1145/1111411.1111419]
   Ekman P., 1978, MANUAL FACIAL ACTION
   Gao L, 2018, SIGGRAPH ASIA'18: SIGGRAPH ASIA 2018 TECHNICAL PAPERS
   Jianzhu Guo, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12364), P152, DOI 10.1007/978-3-030-58529-7_10
   Kim H, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201283
   King DB, 2015, ACS SYM SER, V1214, P1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Laine S, 2017, ACM SIGGRAPH / EUROGRAPHICS SYMPOSIUM ON COMPUTER ANIMATION (SCA 2017), DOI 10.1145/3099564.3099581
   Lewis J. P., 2014, EUROGRAPHICS STATE A, V1, P2
   Liu MY, 2017, ADV NEUR IN, V30
   Mones B., 2016, P AS C COMP VIS, P136
   Naruniec J, 2020, COMPUT GRAPH FORUM, V39, P173, DOI 10.1111/cgf.14062
   Natsume Ryota, 2018, ARXIV180403447, DOI DOI 10.1145/3230744.3230818
   Natsume Ryota, 2018, P AS C COMP VIS, P117
   Nirkin Y, 2019, IEEE I CONF COMP VIS, P7183, DOI 10.1109/ICCV.2019.00728
   Noh JY, 2001, COMP GRAPH, P277
   Petrov Ivan, 2020, ARXIV PREPRINT ARXIV
   PHONG BT, 1975, COMMUN ACM, V18, P311, DOI 10.1145/360825.360839
   Ravi Nikhila, 2020, ARXIV200708501
   Seol Y., 2014, ACM SIGGRAPH 2014 TA, P1
   Seol Y., 2016, P S DIG PROD, P13
   Seol Y, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2159516.2159519
   Siarohin A., 2021, CVPR
   Siarohin A, 2019, ADV NEUR IN, V32
   Simonyan K, 2015, ICLR 2015, DOI DOI 10.1109/CVPR.2015.7298594
   Song J, 2011, COMPUT ANIMAT VIRT W, V22, P187, DOI 10.1002/cav.414
   Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736
   Tewari A, 2019, PROC CVPR IEEE, P10804, DOI 10.1109/CVPR.2019.01107
   Tewari A, 2020, IEEE T PATTERN ANAL, V42, P357, DOI 10.1109/TPAMI.2018.2876842
   Thies J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323035
   Thies J, 2016, PROC CVPR IEEE, P2387, DOI 10.1109/CVPR.2016.262
   Thies J, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818056
   Tolosana R, 2020, INFORM FUSION, V64, P131, DOI 10.1016/j.inffus.2020.06.014
   Tran L, 2019, PROC CVPR IEEE, P1126, DOI 10.1109/CVPR.2019.00122
   Zhang J., 2020, IEEE T VIS COMPUT GR
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
NR 42
TC 0
Z9 0
U1 1
U2 1
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0167-7055
EI 1467-8659
J9 COMPUT GRAPH FORUM
JI Comput. Graph. Forum
PD OCT
PY 2021
VL 40
IS 7
BP 45
EP 55
DI 10.1111/cgf.14400
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XD8KV
UT WOS:000722952000006
DA 2022-02-06
ER

PT J
AU Cheng, JW
   Mitomo, H
   Kamplean, A
   Seo, Y
AF Cheng, John W.
   Mitomo, Hitoshi
   Kamplean, Artima
   Seo, Youngkyoung
TI Lesser evil? Public opinion on regulating fake news in Japan, South
   Korea, and Thailand-A three-country comparison
SO TELECOMMUNICATIONS POLICY
LA English
DT Article
DE Fake news; Fake news regulation; Public opinion; Lesser evil;
   Third-person effect; Multi-group SEM
ID OF-FIT INDEXES; FACT-CHECKING; FREE SPEECH; GOODNESS; MEDIA; CENSORSHIP;
   DISCOURSE; DEMOCRACY; OTHERS
AB This study quantitatively examines and compares public opinion on regulating fake news, and factors affecting the opinion in three Asian countries: Japan, South Korea, and Thailand. Based on the third-person effect, it is hypothesised that the perceived harm of fake news on society increases people's support for fake news regulation. In parallel, according to the lesser evil principle, it is also anticipated that people will be less supportive of regulating fake news if they are aware that there are other non-regulatory counter fake news solutions such as fact-checking. Using original survey data collected from the three countries (n = 5218) and multi-group SEM, it is found that while the first hypothesis holds for all three countries, the second one holds only for Japan and South Korea (the two mature democracies), but not for Thailand (the semidemocratic country). This finding implies that the lesser evil principle also applies in Asian countries, but only in mature democracies where freedom of speech is protected.
C1 [Cheng, John W.] Tsuda Univ, Coll Liberal Arts, Dept English, 2-1-1 Tsuda Machi, Kodaira, Tokyo 1878577, Japan.
   [Mitomo, Hitoshi; Kamplean, Artima; Seo, Youngkyoung] Waseda Univ, Grad Sch Asia Pacific Studies, Shinjuku Ku, Nishi Waseda Bldg,1-21-1 Nishi Waseda, Tokyo 1690051, Japan.
C3 Waseda University
RP Cheng, JW (corresponding author), Tsuda Univ, Coll Liberal Arts, Dept English, 2-1-1 Tsuda Machi, Kodaira, Tokyo 1878577, Japan.
EM cwljwc@tsuda.ac.jp; mitomo@waseda.jp; artima10654@ruri.waseda.jp;
   seo.young.k@fuji.waseda.jp
RI Cheng, John William/U-6752-2019
OI Cheng, John William/0000-0001-9149-4891
FU Mitomo Lab at Waseda University
FX The survey in this study was a part of a research project funded and
   conducted by Mitomo Lab at Waseda University. An earlier version of this
   paper was presented under the title `The lesser evil? Public opinion
   towards regulating fake news in three Asian countries' at the
   International Telecommunications Society (ITS) Europe 2020 Conference
   held online on 14-17 June 2020 (Cheng, Mitomo, Seo, & Kamplean, 2020).
   We would like to express our gratitude for all the comments we received
   in the conference. We would also like to thank the anonymous reviewers
   for their constructive comments, and Dr Nicholas A. R. Fraser for
   proofreading the manuscript of this paper.
CR Abe K, 2004, INT SOCIOL, V19, P215, DOI 10.1177/0268580904042901
   Albritton R. B., 2008, PUBLIC OPINION POLIT
   Allen J, 2020, SCI ADV, V6, DOI 10.1126/sciadv.aay3539
   Azarian R., 2011, INT J HUMANITIES SOC, V1, P113
   Baek YM, 2019, MASS COMMUN SOC, V22, P301, DOI 10.1080/15205436.2018.1562076
   BAER WS, 1993, TELECOMMUN POLICY, V17, P3, DOI 10.1016/0308-5961(93)90022-U
   Barthel M, 2016, MANY AM BELIEVE FAKE
   BOLLEN KA, 1992, SOCIOL METHOD RES, V21, P205, DOI 10.1177/0049124192021002004
   Brown N. I., 2018, SYRACUSE L REV, V68, P521
   Burstein P, 2003, POLIT RES QUART, V56, P29, DOI 10.1177/106591290305600103
   Cage M, 2019, WASHINGTON POST 0830
   Calvert C., 2017, 1 AMENDMENT LAW REV, V16, P153
   Campan A, 2017, IEEE INT CONF BIG DA, P4453, DOI 10.1109/BigData.2017.8258484
   Chen FF, 2007, STRUCT EQU MODELING, V14, P464, DOI 10.1080/10705510701301834
   Cheng J. W., 2020, ITS EUR 2020 C
   Cheng Y, 2020, MASS COMMUN SOC, V23, P705, DOI 10.1080/15205436.2020.1750656
   Cheung GW, 2002, STRUCT EQU MODELING, V9, P233, DOI 10.1207/S15328007SEM0902_5
   Choe S.-H., 2018, NEW YORK TIMES
   Corbu N, 2020, EUR J COMMUN, V35, P165, DOI 10.1177/0267323120903686
   Cui D, 2016, TELECOMMUN POLICY, V40, P265, DOI 10.1016/j.telpol.2015.11.010
   DAVISON WP, 1983, PUBLIC OPIN QUART, V47, P1, DOI 10.1086/268763
   FactCheck Initiative Japan, FACTCHECK INITIATIVE
   Freedom House, THAILAND
   Freeman M, 1996, PAC REV, V9, P352, DOI 10.1080/09512749608719191
   GO SEON-GYU, 2020, The Asian Journal for Public Opinion Research, V8, P105
   Graves L., 2016, REUTERS I DIGITAL NE
   Graves L, 2018, JOURNALISM STUD, V19, P613, DOI 10.1080/1461670X.2016.1196602
   Graves L, 2017, COMMUN CULT CRIT, V10, P518, DOI 10.1111/cccr.12163
   Guo L, 2020, SOC MEDIA SOC, V6, DOI 10.1177/2056305120923003
   Haciyakupoglu G., 2018, COUNTERING FAKE NEWS
   Hair JF., 2018, MULTIVARIATE DATA AN, V8th edn.
   Hildebrandt M, 2018, PRIMITIVES LEGAL PRO, DOI [10.2139/ssrn.3140594, DOI 10.2139/SSRN.3140594]
   Hoffner C, 1999, COMMUN RES, V26, P726, DOI 10.1177/009365099026006004
   Howard JW, 2019, ANNU REV POLIT SCI, V22, P93, DOI 10.1146/annurev-polisci-051517-012343
   Human Rights Watch, 2016, SIL CRIT
   Ignatieff M., 2013, LESSER EVIL POLITICA
   ITU, 2017, MEASURING INFORM SOC
   Jang SM, 2018, COMPUT HUM BEHAV, V80, P295, DOI 10.1016/j.chb.2017.11.034
   Japan Press Research Institute, 2020, DAI ROK KAI SHO GAIK
   Jarman JW, 2016, COMMUN RES REP, V33, P9, DOI 10.1080/08824096.2015.1117436
   Jo H, 2019, INFORM DISORDER ASIA, P39
   Jones-Jang SM, 2021, AM BEHAV SCI, V65, P371, DOI 10.1177/0002764219869406
   Kajimoto M, 2019, INFORM DISORDER ASIA, P16
   Kenny D.A., 2020, MEASURING MODEL FIT
   Kshetri N, 2017, IT PROF, V19, P8, DOI 10.1109/MITP.2017.4241459
   Lee BK, 2005, J COMMUN, V55, P292, DOI 10.1111/j.1460-2466.2005.tb02673.x
   Lee N. Y, 2008, JAPANESE J ELECTORAL, V23, P127, DOI [10.14854/jaes1986.23.127, DOI 10.14854/JAES1986.23.127]
   Lee S, 2018, INT J COMMUN-US, V12, P1523
   Lee T., 2019, PUBLIC ADMIN POLICY, V22, P15, DOI 10.1108/PAP-04-2019-0008
   Lees C, 2018, INDEX CENSORSHIP, V47, P88, DOI 10.1177/0306422018769578
   Lysaker O, 2016, NORD J HUMAN RIGHTS, V34, P104, DOI 10.1080/18918131.2016.1212691
   Maida A., 2019, SPEAK OUT IS DANGERO
   Mantzarlis Alexios, 2018, JOURNALISM FAKE NEWS, P85
   Manzi DC, 2019, FORDHAM LAW REV, V87, P2623
   Marsden C, 2020, COMPUT LAW SECUR REV, V36, DOI 10.1016/j.clsr.2019.105373
   Mastroianni R., 2019, SW J INT LAW, V25, P42
   McCargo D., 2019, ASIA POLICY, V26, P89
   McIntyre L, 2018, MIT PRESS ESSENT, P1
   MCNAIR Brian, 2018, FAKE NEWS FALSEHOOD
   MIC, 2019, PUR SAB NI SEK KENK
   Mitchell A., 2019, MANY AM SAY MADE UP
   Mitchell A., 2021, NEWS USE SOCIAL MEDI
   Murakami S., 2018, THE JAPAN TIMES
   Napoli P. M., 2018, FED COMMUN LAW J, V70, P55
   NARS, 2020, JE 21DAE GUK JUY IPB
   Neo R, 2020, INT POLITICS, V57, P724, DOI 10.1057/s41311-019-00198-4
   Newman N., 2017, REUTERS I DIGITAL NE
   Niklewicz K., 2017, EUROPEAN VIEW, V16, P335, DOI DOI 10.1007/S12290-017-0468-0
   Nyhan B, 2010, POLIT BEHAV, V32, P303, DOI 10.1007/s11109-010-9112-2
   Pew Research Center, 2017, SPRING 2017 GLOB ATT
   Poynter, GUID ANT MIS ACT AR
   Public Media Alliance, 2019, RIS FAK NEWS LAWS AC
   Putnick DL, 2016, DEV REV, V41, P71, DOI 10.1016/j.dr.2016.06.004
   Rojas H, 1996, INT J PUBLIC OPIN R, V8, P163
   Rosuck M., 2018, SMU SCI TECH L REV, V21, P319
   Schetzer A., 2019, CONVERSATION 1223
   Schnellenbach J., 2017, ORDO JAHRBUCH ORDNUN
   Shahbaz A, 2019, FREEDOM NET 2019 THE
   Shin DC, 2009, JPN J POLIT SCI, V10, P59, DOI 10.1017/S146810990800337X
   Shin JE, 2017, J COMMUN, V67, P233, DOI 10.1111/jcom.12284
   Silverman Craig, 2016, BUZZFEED NEWS
   Smith R., 2020, ATHENS J LAW, V6, P243, DOI [10.30958/ajl.6-3-3, DOI 10.30958/AJL.6-3-3]
   Stone A., 2019, OXFORD HDB CONSTITUT
   Tanakasempipat P, 2019, THAILAND UNVEILS ANT
   Tardaguila C., 2019, OBSCENE CONTENT IS F
   Tayor A., 2019, WASHINGTON POST 0209
   Thai News Agency, 2017, THAI NEWS AGENCY
   The Economist Intelligence Unit [EIU], 2019, DEM IND 2019 YEAR DE
   The Law Library of Congress, 2019, IN COUNT FAK NEWS SE
   Van de Vijver F., 2019, 201 OECD, V201, DOI DOI 10.1787/254738DD-EN
   Van Duyn E, 2019, MASS COMMUN SOC, V22, P29, DOI 10.1080/15205436.2018.1511807
   Vasu N., 2018, FAKE NEWS NATL SECUR
   Vosoughi S, 2018, SCIENCE, V359, P1146, DOI 10.1126/science.aap9559
   Walter N, 2020, POLIT COMMUN, V37, P350, DOI 10.1080/10584609.2019.1668894
   Wardle C., 2018, JOURNALISM FAKE NEWS, P32
   Yoon Sung Ock, 2019, [Journal of Media Law, Ethics and Policy, 언론과 법], V18, P103, DOI 10.26542/JML.2019.4.18.1.103
   Young DG, 2018, J MASS COMMUN Q, V95, P49, DOI 10.1177/1077699017710453
NR 97
TC 0
Z9 0
U1 8
U2 8
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 0308-5961
EI 1879-3258
J9 TELECOMMUN POLICY
JI Telecommun. Policy
PD OCT
PY 2021
VL 45
IS 9
AR 102185
DI 10.1016/j.telpol.2021.102185
PG 14
WC Communication; Information Science & Library Science; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Communication; Information Science & Library Science; Telecommunications
GA UU0RJ
UT WOS:000698512300010
DA 2022-02-06
ER

PT J
AU Bondielli, A
   Marcelloni, F
AF Bondielli, Alessandro
   Marcelloni, Francesco
TI A survey on fake news and rumour detection techniques
SO INFORMATION SCIENCES
LA English
DT Article
DE Fake news; Rumours; Natural language processing; Data mining; Text
   mining; Classification; Machine learning; Deep learning
AB False or unverified information spreads just like accurate information on the web, thus possibly going viral and influencing the public opinion and its decisions. Fake news and rumours represent the most popular forms of false and unverified information, respectively, and should be detected as soon as possible for avoiding their dramatic effects. The interest in effective detection techniques has been therefore growing very fast in the last years. In this paper we survey the different approaches to automatic detection of fake news and rumours proposed in the recent literature. In particular, we focus on five main aspects. First, we report and discuss the various definitions of fake news and rumours that have been considered in the literature. Second, we highlight how the collection of relevant data for performing fake news and rumours detection is problematic and we present the various approaches, which have been adopted to gather these data, as well as the publicly available datasets. Third, we describe the features that have been considered in fake news and rumour detection approaches. Fourth, we provide a comprehensive analysis on the various techniques used to perform rumour and fake news detection. Finally, we identify and discuss future directions. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Bondielli, Alessandro; Marcelloni, Francesco] Univ Pisa, Dipartimento Ingn Informaz, Largo Lucio Lazzarino 1, Pisa, Italy.
   [Bondielli, Alessandro] Univ Florence, Dipartimento Ingn Informaz, Florence, Italy.
C3 University of Pisa; University of Florence
RP Marcelloni, F (corresponding author), Univ Pisa, Dipartimento Ingn Informaz, Largo Lucio Lazzarino 1, Pisa, Italy.
EM alessandro.bondielli@unifi.it; francesco.marcelloni@unipi.it
RI Marcelloni, Francesco/AAA-4495-2021
OI Marcelloni, Francesco/0000-0002-5895-876X
FU University of Pisa [PRA_2017_37]; MIT-UNIPI Project; Tuscany
   RegionRegione Toscana
FX This work was partially supported by the University of Pisa [grant
   number PRA_2017_37] in the context of the project "IoT e Big Data:
   metodologie e tecnologie per la raccolta e l'elaborazione di grosse moli
   di dati", by Tuscany Region in the context of the projects "Talent" and
   "Sibilla" in the framework of regional program FESR 2014-2020", and by
   the MIT-UNIPI Project "Event Extraction for Fake News Detection".
CR Afroz S, 2012, P IEEE S SECUR PRIV, P461, DOI 10.1109/SP.2012.34
   Ajao Oluwaseun, 2018, P 9 INT C SOC MED SO, DOI 10.1145/3217804.3217917
   Aker A., 2017, P INT C REC ADV NAT, P31, DOI 10.26615/978-954-452-049-6_005
   Allcott H, 2017, TECHNICAL REPORT
   Allport GW, 1946, PUBLIC OPIN QUART, V10, P501, DOI 10.1086/265813
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Bodnar T, 2014, IEEE INT CONF BIG DA, P636, DOI 10.1109/BigData.2014.7004286
   Bradtke SJ, 1996, MACH LEARN, V22, P33, DOI 10.1007/BF00114723
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Breiman L., 2017, CLASSIFICATION REGRE
   Briscoe EJ, 2014, P ANN HICSS, P1435, DOI 10.1109/HICSS.2014.186
   Burgoon JK, 2003, LECT NOTES COMPUT SC, V2665, P91
   Cai GY, 2014, 2014 PROCEEDINGS OF THE IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2014), P912, DOI 10.1109/ASONAM.2014.6921694
   Castillo C., 2011, WWW, P675
   Chakraborty A, 2016, PROCEEDINGS OF THE 2016 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING ASONAM 2016, P9, DOI 10.1109/ASONAM.2016.7752207
   Chang K, 2016, I C INF COMM TECH CO, P751, DOI 10.1109/ICTC.2016.7763286
   Chen WL, 2017, MICROSYST TECHNOL, V23, P2485, DOI 10.1007/s00542-016-2989-x
   Chen Y., 2015, P 2015 ACM WORKSH MU, P15, DOI DOI 10.1145/2823465.2823467
   Chen Y., 2017, P 11 INT WORKSH SEM, P465
   Cho K., 2014, EMNLP, DOI DOI 10.3115/V1/D14-1179
   Chua Alton Y. K., 2016, International Multiconference of Engineers and Computer Scientists 2016 (IMECS). Proceedings, P387
   Ciampaglia GL, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0128193
   Conroy NJ, 2015, P ASS INF SCI TECHN, V51, P1, DOI [10.1002/pra2.2015.145052010082, DOI 10.1002/PRA2.2015.145052010082]
   D'Andrea E, 2019, EXPERT SYST APPL, V116, P209, DOI 10.1016/j.eswa.2018.09.009
   de Alfaro L., 2015, P 3 AAAI C HUM COMP, P42
   Della Vedova M., 2018, P 22 C OP INN ASS FR
   Derczynski L., 2014, P 10 JOINT ACL ISO W, V1181
   Diakopoulos Nicholas, 2012, MAY P SIGCHI C HUM F, V2451, DOI [DOI 10.1145/2207676.2208409, 10.1145/2207676.2208409]
   DiFonzo N, 2007, DIOGENES, V54, P19, DOI 10.1177/0392192107073433
   Enayet O., 2017, SEMEVAL ACL 2017, P470, DOI 10.18653/v1/S17-2082
   Farajtabar M, 2017, PR MACH LEARN RES, V70
   Feng VW., 2013, P 6 INT JOINT C NAT, P338
   Ferreira W., 2016, P 2016 C N AM CHAPTE, P1163
   Giasemidis Georgios, 2016, Social Informatics. 8th International Conference, SocInfo 2016. Proceedings: LNCS 10046, P185, DOI 10.1007/978-3-319-47880-7_12
   Guacho G. B., ABS180409088 CORR
   Gupta A, 2014, LECT NOTES COMPUT SC, V8851, P228, DOI 10.1007/978-3-319-13734-6_16
   Hamidian S., 2015, P 5 INT C SOC MED TE, P71
   Hardalov M, 2016, LECT NOTES ARTIF INT, V9883, P172, DOI 10.1007/978-3-319-44748-3_17
   Harshman R., 1970, UCLA WORKING PAPERS, V16
   HAWKES AG, 1971, BIOMETRIKA, V58, P83, DOI 10.1093/biomet/58.1.83
   Hermida A, 2010, JOURNAL PRACT, V4, P297, DOI 10.1080/17512781003640703
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735
   Horne B., 2017, THIS JUST FAKE NEWS
   Hosseinzadeh S, 2019, POLYM BULL, V76, P4827, DOI 10.1007/s00289-018-2618-1
   Hu X, 2014, PROCEEDINGS OF THE TWENTY-EIGHTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P59
   Hu Zhang, 2012, Journal of Networks, V7, P1811, DOI 10.4304/jnw.7.11.1811-1816
   Ito J, 2015, WWW'15 COMPANION: PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P953, DOI 10.1145/2740908.2742569
   Jacovi Alon, 2018, ARXIV180908037, P56, DOI DOI 10.18653/V1/W18-5408
   Jin ZW, 2016, THIRTIETH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2972
   Jin ZW, 2017, IEEE T MULTIMEDIA, V19, P598, DOI 10.1109/TMM.2016.2617078
   Kai Shu, 2017, ACM SIGKDD Explorations Newsletter, V19, P22, DOI 10.1145/3137597.3137600
   Kang C., 2016, WASHINGTON PIZZERIA, V5
   Knapp RH, 1944, PUBLIC OPIN QUART, V8, P22, DOI 10.1086/265665
   Kochkina E., 2018, COLING 2018, P3402
   Kumar KPK, 2014, HUM-CENT COMPUT INFO, V4, DOI 10.1186/s13673-014-0014-x
   Kwon S, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0168344
   Kwon S, 2013, IEEE DATA MINING, P1103, DOI 10.1109/ICDM.2013.61
   Lafferty J. D., 2001, P INT C MACH LEARN, P282, DOI DOI 10.1038/NPROT.2006.61
   Le Q., 2014, P 31 INT C INT C MAC, V32
   LeCun Y, 2010, IEEE INT SYMP CIRC S, P253, DOI 10.1109/ISCAS.2010.5537907
   Lee YJ, 2013, IEEE T KNOWL DATA EN, V25, P1460, DOI 10.1109/TKDE.2012.99
   Li T, 2015, INT C ELECTR MACH SY, P1752, DOI 10.1109/ICEMS.2015.7385324
   Liao Y, 2016, ASIA-PAC INT SYM ELE, P101, DOI 10.1109/APEMC.2016.7522938
   Ma J., 2016, P 25 INT JOINT C ART, P3818
   Ma J, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P708, DOI 10.18653/v1/P17-1066
   Magdy A., 2010, P 2 INT WORKSH SEARC, P103, DOI 10.1145/1871985.1872002
   Mikolov T., 2013, NIPS, V26, P3111
   Mitra T., 2015, ICWSM, P258
   Mitra T, 2017, CSCW'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING, P126, DOI 10.1145/2998181.2998351
   Newman N, 2012, INT J INTERNET SCI, V7, P6
   Page L., 1999, TECHNICAL REPORT
   Perez Veronica, 2015, P 2015 C EMP METH NA, P1120
   Postman L., 1947, ANN ACAD POLITICAL S, V257, P240
   Potthast Martin, 2016, Advances in Information Retrieval. 38th European Conference on IR Research, ECIR 2016. Proceedings; LNCS 9626, P810, DOI 10.1007/978-3-319-30671-1_72
   Procter R., 2017, SEMEVAL 2017 TASK 8, P69
   Procter R, 2013, INT J SOC RES METHOD, V16, P197, DOI 10.1080/13645579.2013.774172
   Qazvinian V., 2011, P 2011 C EMP METH NA, P1589
   Quinlan J.R., 2014, C4 5 PROGRAMS MACHIN
   Rubin V., 2016, P 2 WORKSH COMP APPR, P7, DOI DOI 10.18653/V1/W16-0802
   Rubin V.L., 2015, P ASS INFORM SCI TEC, V52, P1, DOI [https://doi.org/10.1002/pra2.2015.145052010083, DOI 10.1002/PRA2.2015.145052010083]
   Rubin VL, 2015, J ASSOC INF SCI TECH, V66, P905, DOI 10.1002/asi.23216
   Ruchansky N, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P797, DOI 10.1145/3132847.3132877
   SANTIA G., 2018, P 12 INT AAAI C WEB
   Shu K, 2018, FAKENEWSNET DATA REP
   Silverman C., 2015, LIES DAMN LIES VIRAL, V168
   Song C., 2018, CED CREDIBLE EARLY D
   Song SR, 2017, PROC CVPR IEEE, P190, DOI 10.1109/CVPR.2017.28
   Tacchini E, 2017, SOME IT HOAX AUTOMAT
   Tang C., 2016, SPOTTING RUMORS VIA
   Thorne J., 2018, FEVER LARGE SCALE DA, P809, DOI 10.18653/v1/N18-1074
   Tolmie P., 2018, ACM T SOC COMPUTING, V1, P1
   Tolmie P, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3632, DOI 10.1145/3025453.3025892
   Trabelsi A, 2014, IEEE DATA MINING, P550, DOI 10.1109/ICDM.2014.120
   Vieweg S., 2010, P 2010 ACM C COMP SU, P241
   Vlachos A, 2014, ACL, P18, DOI DOI 10.3115/V1/W14-2508
   Volkova S, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P647, DOI 10.18653/v1/P17-2102
   Vosoughi S., 2015, THESIS
   Vosoughi S, 2017, ACM T KNOWL DISCOV D, V11, DOI 10.1145/3070644
   Wang SH, 2017, P INT COMP SOFTW APP, P654, DOI 10.1109/COMPSAC.2017.115
   Wang SH, 2015, PROCEEDINGS 2015 IEEE INTERNATIONAL CONFERENCE ON BIG DATA, P2709, DOI 10.1109/BigData.2015.7364071
   Wang WY, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P422, DOI 10.18653/v1/P17-2067
   Widmer G, 1996, MACH LEARN, V23, P69, DOI 10.1007/BF00116900
   Wu K, 2015, PROC INT CONF DATA, P651, DOI 10.1109/ICDE.2015.7113322
   Wu Y., 2017, P 11 INT WORKSH SEM, P491
   Wu Y, 2014, PROC VLDB ENDOW, V7, P589, DOI 10.14778/2732286.2732295
   Xiao G, 2012, ASIAN RESPONSES TO THE GLOBAL FINANCIAL CRISIS: THE IMPACT OF REGIONALISM AND THE ROLE OF THE G20, P13
   Zeng L., 2016, P 10 INT AAAI C WEB
   Zhang Y, 2015, INT CONF COMP SCI ED, P186, DOI 10.1109/ICCSE.2015.7250240
   Zhao Z, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P1395, DOI 10.1145/2736277.2741637
   Zhou L., 2003, 36th Hawaii International Conference on Systems Sciences
   Zubiaga A, 2017, INT C SOC INF, P109
   Zubiaga A., 2016, LEARNING REPORTING D
   Zubiaga A., 2015, AAAI WORKSH, P35
   Zubiaga A, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3161603
   Zubiaga A, 2018, INFORM PROCESS MANAG, V54, P273, DOI 10.1016/j.ipm.2017.11.009
   Zubiaga A, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0150989
NR 116
TC 94
Z9 98
U1 32
U2 181
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 0020-0255
EI 1872-6291
J9 INFORM SCIENCES
JI Inf. Sci.
PD SEP
PY 2019
VL 497
BP 38
EP 55
DI 10.1016/j.ins.2019.05.035
PG 18
WC Computer Science, Information Systems
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IF5LN
UT WOS:000473122400003
DA 2022-02-06
ER

PT J
AU Huang, YF
   Chen, PH
AF Huang, Yin-Fu
   Chen, Po-Hong
TI Fake news detection using an ensemble learning model based on
   Self-Adaptive Harmony Search algorithms
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Deep learning; Fake news; Natural language processing; Harmony search
   algorithm
AB In general, the features of fake news are almost the same as those of real news, so it is not easy to identify them. In this paper, we propose a fake news detection system using a deep learning model. First, news articles are preprocessed and analyzed based on different training models. Then, an ensemble learning model combining four different models called embedding LSTM, depth LSTM, LIWC CNN, and N-gram CNN is proposed for fake news detection. Besides, to achieve higher accuracy in fake news detection, the optimized weights of the ensemble learning model are determined using the Self-Adaptive Harmony Search (SAHS) algorithm. In the experiments, we verify that the proposed model is superior to the state-of-the-art methods, with the highest accuracy of 99.4%. Furthermore, we also investigate the cross-domain intractability issue and achieve the highest accuracy of 72.3%. Finally, we believe there is still room for improving the ensemble learning model in addressing the cross-domain intractability issue. (C) 2020 Elsevier Ltd. All rights reserved.
C1 [Huang, Yin-Fu; Chen, Po-Hong] Natl Yunlin Univ Sci & Technol, Dept Comp Sci & Informat Engn, Touliu, Yunlin, Taiwan.
C3 National Yunlin University Science & Technology
RP Huang, YF (corresponding author), Natl Yunlin Univ Sci & Technol, Dept Comp Sci & Informat Engn, Touliu, Yunlin, Taiwan.
EM huangyf@yuntech.edu.tw
OI Huang, Yin-Fu/0000-0001-6665-0135
CR Aderghal K, 2017, PROCEEDINGS OF THE 15TH INTERNATIONAL WORKSHOP ON CONTENT-BASED MULTIMEDIA INDEXING (CBMI), DOI 10.1145/3095713.3095749
   Ahmed H., 2017, P INT C INT SEC DEP
   Britzky H., 2017, FAKE NEWS
   Camgoz N.C., 2016, P 23 INT C PATT REC
   Cavnar W, 1994, P 3 ANN S DOC AN INF
   Ceylan H, 2012, TRANSPORT RES C-EMER, V25, P152, DOI 10.1016/j.trc.2012.05.007
   Fiegerman S, 2017, FACEBOOK GOOGLE TWIT
   Fourie J, 2010, IMAGE VISION COMPUT, V28, P1702, DOI 10.1016/j.imavis.2010.05.006
   Gao J, 2018, P 24 ACM SIGKDD INT
   Geem ZW, 2001, SIMULATION, V76, P60, DOI 10.1177/003754970107600201
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735
   Jruvika, 2017, FAKE NEWS DETECTION
   Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X
   Liu R, 2019, CHINA GEOL, V2, P8, DOI 10.31035/cg2018069
   Liu Yang, 2018, P 32 AAAI C ART INT
   Ma J., 2016, P 25 INT JOINT C ART
   Mazzola M., 2017, SNOPES FAKE LEGIT NE
   McIntire G., 2017, BUILDING FAKE NEWS C
   Monti F., 2019, ARXIV190206673V1, P2
   Olivieri A., 2019, P 52 HAW INT C SYST
   Perez-Rosas V., 2017, ARXIV170807104V1, P8
   Potthast M., 2017, ARXIV PREPRINT ARXIV
   Pradhan R, 2018, IEEE T IMAGE PROCESS, V27, P692, DOI 10.1109/TIP.2017.2766358
   Qian F., 2018, P 27 INT JOINT C ART
   Rashkin H., 2017, P C EMP METH NAT LAN
   Reis JCS, 2019, IEEE INTELL SYST, V34, P76, DOI 10.1109/MIS.2019.2899143
   Risdal M., 2016, GETTING REAL FAKE NE
   Rubin V. L., 2016, P 15 ANN C N AM CHAP
   Schuster S, 2016, PROCEEDINGS OF THE 7TH INTERNATIONAL WORKSHOP ON FEATURE-ORIENTED SOFTWARE DEVELOPMENT (FOSD'16), P11, DOI 10.1145/3001867.3001869
   Shi L, 2011, EXPERT SYST APPL, V38, P6300, DOI 10.1016/j.eswa.2010.11.069
   Shu Kai, 2019, AAAI
   Subramanian S., 2017, INSIDE MACEDONIAN FA
   Tausczik YR, 2010, J LANG SOC PSYCHOL, V29, P24, DOI 10.1177/0261927X09351676
   Venugopalan S., 2015, P IEEE INT C COMP VI
   Vosoughi S, 2017, ACM T KNOWL DISCOV D, V11, DOI 10.1145/3070644
   Wang CM, 2010, EXPERT SYST APPL, V37, P2826, DOI 10.1016/j.eswa.2009.09.008
   Wang SL, 2015, NEUROCOMPUTING, V149, P708, DOI 10.1016/j.neucom.2014.07.059
   Yang Y., 2018, ARXIV180600749V1, P6
   Zoph B., 2016, ARXIV160100710V1, P1
NR 39
TC 11
Z9 11
U1 4
U2 19
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD NOV 30
PY 2020
VL 159
AR 113584
DI 10.1016/j.eswa.2020.113584
PG 17
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic; Operations Research & Management Science
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Operations Research & Management Science
GA NZ0JV
UT WOS:000576778900001
DA 2022-02-06
ER

PT J
AU Kim, G
   Ko, Y
AF Kim, Gihwan
   Ko, Youngjoong
TI Effective fake news detection using graph and summarization techniques
SO PATTERN RECOGNITION LETTERS
LA English
DT Article
DE Fake news detection; Graph neural networks; Summarization; Deep neural
   networks
AB Nowadays, fake news is widely spreading in various media, and this fake information is causing serious damage in many areas. Therefore, there is an increasing need to accurately detect fake news to prevent such damage. In this paper, we propose a novel method that uses graph and summarization techniques for fake news detection. Our proposed method represents the relationship of all sentences in a graph structure to accurately understand the context information of the document. Accordingly, the relationship between sentences in the graph is calculated as a score through the attention mechanism. Then, the summarization technique is used to reflect the sentence subject information in the graph update process. Our proposed method shows better performance than Karimi's and BERT based models by approximately 10.34%p and 3.72%p, respectively. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Kim, Gihwan; Ko, Youngjoong] Sungkyunkwan Univ, Dept Comp Sci & Engn, 2066 Seobu Ro, Suwon, Gyeonggi Do, South Korea.
C3 Sungkyunkwan University (SKKU)
RP Ko, Y (corresponding author), Sungkyunkwan Univ, Dept Comp Sci & Engn, 2066 Seobu Ro, Suwon, Gyeonggi Do, South Korea.
EM yjko@skku.edu
FU Institute of Information & Communications Technology Planning &
   Evaluation (IITP) - Korea Government (MSIT) [2020-0-00368]; National
   Research Foundation of Korea (NRF) - Korea government (MSIT)
   [NRF-2020R1A2C2100362]; MSIT (Ministry of Science and ICT), Korea, under
   the ICT Creative Consilience program [IITP-2020-0-01821]
FX This work was supported in part by Institute of Information &
   Communications Technology Planning & Evaluation (IITP) grant funded by
   the Korea Government (MSIT) (No. 2020-0-00368, A Neural-Symbolic Model
   for Knowledge Acquisition and Inference Techniques), in part by the
   National Research Foundation of Korea (NRF) grant funded by the Korea
   government (MSIT) (NRF-2020R1A2C2100362), and in part by the MSIT
   (Ministry of Science and ICT), Korea, under the ICT Creative Consilience
   program (IITP-2020-0-01821) supervised by the IITP.
CR Castillo C., 2011, WWW, P675
   Cui LM, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P2961, DOI 10.1145/3357384.3357862
   Cui LM, 2019, PROCEEDINGS OF THE 2019 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2019), P41, DOI 10.1145/3341161.3342894
   Devlin J, 2019, PROC C N AM CHAPTER, P4171, DOI DOI 10.18653/V1/N19-1423
   Dozat T, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P484
   Jeong H, 2016, EXPERT SYST APPL, V60, P222, DOI 10.1016/j.eswa.2016.05.001
   Karimi Hamid, 2019, ARXIV190307389, V1, P3432
   King DB, 2015, ACS SYM SER, V1214, P1
   Levi O., 2019, P 2 WORKSH NAT LANG, P31, DOI 10.18653/v1/D19-5004
   Lu YJ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P505
   Mikolov T., 2013, ARXIV13013781
   Monti F., 2019, ARXIV 190206673
   Pan JZ, 2018, LECT NOTES COMPUT SC, V11136, P669, DOI 10.1007/978-3-030-00671-6_39
   Potthast M, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P231
   Qian F., NEURAL USER RESPONSE
   Ruchansky N, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P797, DOI 10.1145/3132847.3132877
   Silva A., EMBRACING DOMAIN DIF
   Silvaa A., EMBEDDING PARTIAL PR
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang YQ, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P849, DOI 10.1145/3219819.3219903
   Yan R, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P1318
   Yang F., P MDS 12 ACM SIGKDD, DOI [10.1145/2350190.2350203, DOI 10.1145/2350190.2350203]
NR 22
TC 0
Z9 0
U1 8
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0167-8655
EI 1872-7344
J9 PATTERN RECOGN LETT
JI Pattern Recognit. Lett.
PD NOV
PY 2021
VL 151
BP 135
EP 139
DI 10.1016/j.patrec.2021.07.020
PG 5
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UW6SN
UT WOS:000700283100020
DA 2022-02-06
ER

PT J
AU Jain, V
   Kaliyar, RK
   Goswami, A
   Narang, P
   Sharma, Y
AF Jain, Vidit
   Kaliyar, Rohit Kumar
   Goswami, Anurag
   Narang, Pratik
   Sharma, Yashvardhan
TI AENeT: an attention-enabled neural architecture for fake news detection
   using contextual features
SO NEURAL COMPUTING & APPLICATIONS
LA English
DT Article
DE Fake News; Social Media; Contextualized Features; Deep learning; Neural
   Network
AB In the current era of social media, the popularity of smartphones and social media platforms has increased exponentially. Through these electronic media, fake news has been rising rapidly with the advent of new sources of information, which are highly unreliable. Checking off a particular news article is genuine or fake is not easy for any end user. Search engines like Google are also not capable of telling about the fakeness of any news article due to its restriction with limited query keywords. In this paper, our end goal is to design an efficient deep learning model to detect the degree of fakeness in a news statement. We propose a simple network architecture that combines the use of contextual embedding as word embedding and uses attention mechanisms with relevant metadata available. The efficacy and efficiency of our models are demonstrated on several real-world datasets. Our model achieved 46.36% accuracy on the LIAR dataset, which outperforms the current state of the art by 1.49%.
C1 [Kaliyar, Rohit Kumar; Goswami, Anurag] Bennett Univ, Dept Comp Sci Engn, Greater Noida, India.
   [Jain, Vidit; Narang, Pratik; Sharma, Yashvardhan] BITS, Dept CSIS, Pilani, Rajasthan, India.
C3 Birla Institute of Technology & Science Pilani (BITS Pilani)
RP Narang, P (corresponding author), BITS, Dept CSIS, Pilani, Rajasthan, India.
EM f2016064@pilani.bits-pilani.ac.in; rk5370@bennett.edu.in;
   anurag.goswami@bennett.edu.in; pratik.narang@pilani.bits-pilani.ac.in;
   yash@pilani.bits-pilani.ac.in
CR Ahmed H, 2017, LECT NOTES COMPUT SC, V10618, P127, DOI 10.1007/978-3-319-69155-8_9
   Bhattacharyya P., 2018, DEEP ENSEMBLE FRAMEW
   Caliskan A, 2017, SCIENCE, V356, DOI 10.1126/science.aal4230
   Camacho-Collados J, 2016, ARTIF INTELL, V240, P36, DOI 10.1016/j.artint.2016.07.005
   Cerisara C, 2018, COMPUT SPEECH LANG, V47, P175, DOI 10.1016/j.csl.2017.07.009
   Conroy NJ, 2015, P ASS INF SCI TECHN, V51, P1, DOI [10.1002/pra2.2015.145052010082, DOI 10.1002/PRA2.2015.145052010082]
   Dougherty J., 1995, Machine Learning. Proceedings of the Twelfth International Conference on Machine Learning, P194
   Feng S., 2012, P 50 ANN M ASS COMP, V50, P171
   Huang CR, 2017, P 8 INT JOINT C NAT, V2, P252
   Iyyer M, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1681
   Kai Shu, 2017, ACM SIGKDD Explorations Newsletter, V19, P22, DOI 10.1145/3137597.3137600
   Kaliyar RK, 2021, CODS-COMAD 2021: PROCEEDINGS OF THE 3RD ACM INDIA JOINT INTERNATIONAL CONFERENCE ON DATA SCIENCE & MANAGEMENT OF DATA (8TH ACM IKDD CODS & 26TH COMAD), P437, DOI 10.1145/3430984.3431064
   Kaliyar RK, 2021, NEURAL COMPUT APPL, V33, P8597, DOI 10.1007/s00521-020-05611-1
   Kaliyar RK, 2020, COGN SYST RES, V61, P32, DOI 10.1016/j.cogsys.2019.12.005
   Kamkarhaghighi M, 2017, EXPERT SYST APPL, V90, P241, DOI 10.1016/j.eswa.2017.08.021
   Le, 2019, U.S. Patent, Patent No. [10,521,729, 10521729]
   Mikolov T., 2013, P INT C LEARN REPR I, DOI DOI 10.5555/2999792.2999959
   Neil S., 2018, FALSE INFORM WEB SOC
   Pennington J., 2014, EMNLP, P1532, DOI [10.3115/v1/D14-1162, DOI 10.3115/V1/D14-1162]
   Perez-Rosas V, 2018, P 27 INT C COMPUTATI, P3391
   Persily N, 2017, J DEMOCR, V28, P63, DOI 10.1353/jod.2017.0025
   Peters M.E., 2018, P C N AM CHAPT ASS C, P2227, DOI [10.18653/v1/n18-1202, DOI 10.18653/V1/N18-1202]
   Qi C, 2021, KNOWL-BASED SYST, V211, DOI 10.1016/j.knosys.2020.106561
   Ren YX, 2020, IEEE DATA MINING, P452, DOI 10.1109/ICDM50108.2020.00054
   Ruchansky N, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P797, DOI 10.1145/3132847.3132877
   Sharma K, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3305260
   Shu K, 2020, BIG DATA-US, V8, P171, DOI 10.1089/big.2020.0062
   Shu K, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P395, DOI 10.1145/3292500.3330935
   Shu K, 2019, PROCEEDINGS OF THE TWELFTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'19), P312, DOI 10.1145/3289600.3290994
   Tang DY, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1555
   Vaswani A., 2017, ADV NEURAL INFORM PR, P5998, DOI DOI 10.5555/3295222.3295349
   Wang WY, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P422, DOI 10.18653/v1/P17-2067
   Wang YQ, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P849, DOI 10.1145/3219819.3219903
   Youze Wang, 2020, ICMR '20: Proceedings of the 2020 International Conference on Multimedia Retrieval, P540, DOI 10.1145/3372278.3390713
   Zhang JW, 2020, PROC INT CONF DATA, P1826, DOI 10.1109/ICDE48307.2020.00180
   Zhang T, 2020, IEEE IJCNN
   Zhang Y, 2017, ADV SOC SCI EDUC HUM, V185, P253
   Zhong BT, 2019, ADV ENG INFORM, V40, P46, DOI 10.1016/j.aei.2019.02.009
NR 38
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0941-0643
EI 1433-3058
J9 NEURAL COMPUT APPL
JI Neural Comput. Appl.
PD JAN
PY 2022
VL 34
IS 1
SI SI
BP 771
EP 782
DI 10.1007/s00521-021-06450-4
EA AUG 2021
PG 12
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA YE3WM
UT WOS:000690860800002
PM 34483493
OA Green Published, Bronze
DA 2022-02-06
ER

PT J
AU Jiang, T
   Li, JP
   Ul Haq, A
   Saboor, A
   Ali, A
AF Jiang, Tao
   Li, Jian Ping
   Ul Haq, Amin
   Saboor, Abdus
   Ali, Amjad
TI A Novel Stacking Approach for Accurate Detection of Fake News
SO IEEE ACCESS
LA English
DT Article
DE Support vector machines; Machine learning; Social networking (online);
   Deep learning; Feature extraction; Stacking; Neural networks; Deception
   detection; deep learning; fake news; machine learning; McNemar&#8217; s
   test; performance evaluation; stacking
AB With the increasing popularity of social media, people has changed the way they access news. News online has become the major source of information for people. However, much information appearing on the Internet is dubious and even intended to mislead. Some fake news are so similar to the real ones that it is difficult for human to identify them. Therefore, automated fake news detection tools like machine learning and deep learning models have become an essential requirement. In this paper, we evaluated the performance of five machine learning models and three deep learning models on two fake and real news datasets of different size with hold out cross validation. We also used term frequency, term frequency-inverse document frequency and embedding techniques to obtain text representation for machine learning and deep learning models respectively. To evaluate models' performance, we used accuracy, precision, recall and F1-score as the evaluation metrics and a corrected version of McNemar's test to determine if models' performance is significantly different. Then, we proposed our novel stacking model which achieved testing accuracy of 99.94% and 96.05 % respectively on the ISOT dataset and KDnugget dataset. Furthermore, the performance of our proposed method is high as compared to baseline methods. Thus, we highly recommend it for fake news detection.
C1 [Jiang, Tao; Li, Jian Ping; Ul Haq, Amin; Saboor, Abdus] Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu 611731, Peoples R China.
   [Ali, Amjad] Univ Swat, Dept Comp Sci & Software Technol, Mingora 19200, Pakistan.
C3 University of Electronic Science & Technology of China
RP Jiang, T; Li, JP; Ul Haq, A (corresponding author), Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu 611731, Peoples R China.
EM tao1024@yahoo.com; jpli2222@uestc.edu.cn; khan.amin50@yahoo.com
RI HAQ, AMIN Ul/Z-2201-2019
OI HAQ, AMIN Ul/0000-0002-7774-5604; Ali, Amjad/0000-0001-9117-3692; ,
   Tao/0000-0002-0686-7612
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61370073]; National High Technology Research
   and Development Program of ChinaNational High Technology Research and
   Development Program of China [2007AA01Z423]; Science and Technology
   Department of Sichuan Province
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61370073, in part by the National High
   Technology Research and Development Program of China under Grant
   2007AA01Z423, and in part by the project of the Science and Technology
   Department of Sichuan Province.
CR Aceto G, 2019, COMPUT NETW, V165, DOI 10.1016/j.comnet.2019.106944
   Ahmed Hadeer, 2018, Security and Privacy, V1, DOI 10.1002/spy2.9
   Ajao Oluwaseun, 2018, P 9 INT C SOC MED SO, DOI 10.1145/3217804.3217917
   Amjad M, 2020, J INTELL FUZZY SYST, V39, P2457, DOI 10.3233/JIFS-179905
   Faustini PHA, 2020, EXPERT SYST APPL, V158, DOI 10.1016/j.eswa.2020.113503
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen HL, 2011, EXPERT SYST APPL, V38, P9014, DOI 10.1016/j.eswa.2011.01.120
   Cho K., 2014, EMNLP, DOI DOI 10.3115/V1/D14-1179
   Cristianini N., 2000, INTRO SUPPORT VECTOR, DOI [10.1017/CBO9780511801389, DOI 10.1017/CBO9780511801389]
   Das Bhattacharjee S, 2017, IEEE INT CONF BIG DA, P556, DOI 10.1109/BigData.2017.8257971
   Della Vedova ML, 2018, PROC CONF OPEN INNOV, P272, DOI 10.23919/FRUCT.2018.8468301
   EDWARDS AL, 1948, PSYCHOMETRIKA, V0013, P00185
   Gilda S, 2017, IEEE ST CONF RES DEV, P110, DOI 10.1109/SCORED.2017.8305411
   Goldani M. H., 2020, ARXIV 2002 01030
   Gupta AK, 2019, P INT C ISS CHALL IN, V1, P1, DOI 10.1109/ICICT46931.2019.8977659
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735
   Kaliyar RK, 2020, COGN SYST RES, V61, P32, DOI 10.1016/j.cogsys.2019.12.005
   Kaliyar RK, 2019, INT CONF ADV COMPU, P103, DOI 10.1109/IACC48062.2019.8971579
   Kula Sebastian, 2020, Computational Science - ICCS 2020. 20th International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12140), P653, DOI 10.1007/978-3-030-50423-6_49
   Kumar S, 2020, T EMERG TELECOMMUN T, V31, DOI 10.1002/ett.3767
   Long Y., 2017, TECH REP, V2
   Ma J., 2016, P 25 INT JOINT C ART, P3818
   McNemar Q, 1947, PSYCHOMETRIKA, V12, P153, DOI 10.1007/BF02295996
   MONTI F, 2019, ARXIV 1902 06673
   Montieri A, 2020, IEEE T NETW SCI ENG, V7, P1043, DOI 10.1109/TNSE.2019.2901994
   Oshikawa R., 2018, ARXIV 1811 00770
   Ozbay FA, 2020, PHYSICA A, V540, DOI 10.1016/j.physa.2019.123174
   Posadas-Duran JP, 2019, J INTELL FUZZY SYST, V36, P4869, DOI 10.3233/JIFS-179034
   Rasool T, 2019, INT CONF COMPUT AUTO, P73, DOI 10.1145/3313991.3314008
   Reis JCS, 2019, P 10 ACM C WEB SCI A, P17, DOI [10.1145/3292522.3326027, DOI 10.1145/3292522.3326027]
   Reis JCS, 2019, IEEE INTELL SYST, V34, P76, DOI 10.1109/MIS.2019.2899143
   Agudelo GER, 2018, LECT NOTES COMPUT SC, V11195, P596, DOI 10.1007/978-3-030-02131-3_52
   Roy A., 2018, ARXIV 1811 04670
   Ruchansky N, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P797, DOI 10.1145/3132847.3132877
   Shabani S, 2018, 2018 4TH IEEE INTERNATIONAL CONFERENCE ON COLLABORATION AND INTERNET COMPUTING (CIC 2018), P299, DOI 10.1109/CIC.2018.00048
   Singhania S, 2017, LECT NOTES COMPUT SC, V10635, P572, DOI 10.1007/978-3-319-70096-0_59
   Ul Haq A, 2020, J INTELL FUZZY SYST, V38, P2383, DOI 10.3233/JIFS-191461
   Ul Haq A, 2019, IEEE ACCESS, V7, P37718, DOI 10.1109/ACCESS.2019.2906350
   Ul Haq A, 2018, I COMP CONF WAVELET, P101, DOI 10.1109/ICCWAMTIP.2018.8632613
   Umer M, 2020, IEEE ACCESS, V8, P156695, DOI 10.1109/ACCESS.2020.3019735
   Wagacha P. W., 2003, FDN LEARNING ADAPTIV, V12, P1
   Wang W. Y., 2017, ARXIV 1705 00648
   WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1
   Wu XD, 2008, KNOWL INF SYST, V14, P1, DOI 10.1007/s10115-007-0114-2
   Zhang XC, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.03.004
NR 45
TC 3
Z9 3
U1 3
U2 9
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2021
VL 9
BP 22626
EP 22639
DI 10.1109/ACCESS.2021.3056079
PG 14
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA QG1PK
UT WOS:000617362500001
OA gold
DA 2022-02-06
ER

PT J
AU Kong, CQ
   Chen, BL
   Yang, WH
   Li, HL
   Chen, PL
   Wang, SQ
AF Kong, Chenqi
   Chen, Baoliang
   Yang, Wenhan
   Li, Haoliang
   Chen, Peilin
   Wang, Shiqi
TI Appearance Matters, So Does Audio: Revealing the Hidden Face via
   Cross-Modality Transfer
SO IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS FOR VIDEO TECHNOLOGY
LA English
DT Article
DE Faces; Videos; Information integrity; Face recognition; Training;
   Generative adversarial networks; Testing; Deepfake; cross modality; face
   reconstruction; face revealing; fake face
ID HEAD POSE; IDENTITY; SPEECH; VOICE
AB Recently, there has been an exponential increase in the security concerns raised by faking face (e.g., deepfake), which automatically changes the identity with a specifically learned deep generative model. With numerous approaches proposed to identify the fake content, much less work has been dedicated to automatically revealing the authentic one that is originally acquired. Here, we propose a new paradigm that seeks to reveal the authentic face hidden behind the fake one by leveraging the joint information of face and audio. More specifically, given the fake face as well as the audio segment, the cross-modality transferable capability is exploited by learning to generate the feature of the authentic face, based on the underlying clues from the audio as well as the fake face appearance. The effectiveness of the proposed scheme is validated through a series of evaluations, and experimental results show that the proposed model achieves promising face reconstruction performance in revealing the hidden faces, in terms of reconstruction quality, as well as identity and face attribute inference accuracy.
C1 [Kong, Chenqi; Chen, Baoliang; Yang, Wenhan; Chen, Peilin] City Univ Hong Kong, Dept Comp & Sci, Hong Kong, Peoples R China.
   [Li, Haoliang] Nanyang Technol Univ, Rapid Rich Object Search Lab, Singapore 639798, Singapore.
   [Wang, Shiqi] City Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China.
   [Wang, Shiqi] City Univ Hong Kong, Shenzhen Res Inst, Shenzhen 518057, Peoples R China.
C3 City University of Hong Kong; Nanyang Technological University &
   National Institute of Education (NIE) Singapore; Nanyang Technological
   University; City University of Hong Kong; City University of Hong Kong
RP Wang, SQ (corresponding author), City Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China.; Wang, SQ (corresponding author), City Univ Hong Kong, Shenzhen Res Inst, Shenzhen 518057, Peoples R China.
EM cqkong2-c@my.cityu.edu.hk; blchen6-c@my.cityu.edu.hk;
   wyang34@cityu.edu.hk; hli016@e.ntu.edu.sg; plchen3-c@my.cityu.edu.hk;
   shiqwang@cityu.edu.hk
FU Science, Technology, and Innovation Commission of Shenzhen Municipality
   [JCYJ20180307123934031]; National Natural Science Foundation of
   ChinaNational Natural Science Foundation of China (NSFC) [62022002];
   Hong Kong Research Grants Council, Early Career SchemeHong Kong Research
   Grants Council [21211018]; General Research Fund [11203220]
FX This work was supported in part by the Science, Technology, and
   Innovation Commission of Shenzhen Municipality under Project
   JCYJ20180307123934031, in part by the National Natural Science
   Foundation of China under Grant 62022002, in part by the Hong Kong
   Research Grants Council, Early Career Scheme under Grant 21211018, and
   in part by the General Research Fund under Grant 11203220. This article
   was recommended by Associate Editor W. Liu.
CR Abdal R, 2019, IEEE I CONF COMP VIS, P4431, DOI 10.1109/ICCV.2019.00453
   Afchar D, 2018, IEEE INT WORKS INFOR
   Alharbi Y, 2019, PROC CVPR IEEE, P1458, DOI 10.1109/CVPR.2019.00155
   Andrew G., 2013, INT C MACHINE LEARNI, P1247
   Arandjelovic R, 2017, IEEE I CONF COMP VIS, P609, DOI 10.1109/ICCV.2017.73
   Bahari M. H., 2011, P IEEE WORKSH BIOM M, P1
   Bao JM, 2018, PROC CVPR IEEE, P6713, DOI 10.1109/CVPR.2018.00702
   Bau D, 2019, IEEE I CONF COMP VIS, P4501, DOI 10.1109/ICCV.2019.00460
   Bau D, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323023
   Bian S, 2014, IEEE T CIRC SYST VID, V24, P2144, DOI 10.1109/TCSVT.2014.2334031
   Bregler C., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P353
   Brock A., 2018, INT C LEARN REPR
   Cao Q, 2018, IEEE INT CONF AUTOMA, P67, DOI 10.1109/FG.2018.00020
   Chung JS, 2018, INTERSPEECH, P1086
   Duarte A, 2019, INT CONF ACOUST SPEE, P8633, DOI 10.1109/ICASSP.2019.8682970
   Ephrat A, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201357
   Feld M, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4, P2838
   Feng CH, 2017, IEEE T CIRC SYST VID, V27, P2543, DOI 10.1109/TCSVT.2016.2593612
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Greenwood D, 2018, INTERSPEECH, P2484, DOI 10.21437/Interspeech.2018-2587
   Greenwood D, 2017, INTERSPEECH, P3991, DOI 10.21437/Interspeech.2017-894
   Guera D, 2018, 2018 15TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P127
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hensel M, 2017, ADV NEUR IN, V30
   Hinton GE, 2011, LECT NOTES COMPUT SC, V6791, P44, DOI 10.1007/978-3-642-21735-7_6
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Kamachi M, 2003, CURR BIOL, V13, P1709, DOI 10.1016/j.cub.2003.09.005
   Kameoka H., 2019, ARXIV190404540
   Karras T., 2017, ARXIV171010196
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   King DB, 2015, ACS SYM SER, V1214, P1
   Krause Y., 2018, INT C MACH LEARN, V80, P5072
   Li HD, 2018, IEEE T CIRC SYST VID, V28, P31, DOI 10.1109/TCSVT.2016.2599849
   Li HL, 2020, PATTERN RECOGN, V108, DOI 10.1016/j.patcog.2020.107536
   Li HL, 2019, THIRTY-THIRD AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTY-FIRST INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / NINTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P8602
   Li HL, 2020, IEEE T NEUR NET LEAR, V31, P984, DOI 10.1109/TNNLS.2019.2913723
   Li H, 2020, LEUKEMIA, V34, P1503, DOI 10.1038/s41375-020-0848-3
   Li JA, 2017, PROC CVPR IEEE, P1951, DOI 10.1109/CVPR.2017.211
   Li LZ, 2020, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR42600.2020.00505
   [李艳歌 Li Yange], 2018, [高分子通报, Polymer Bulletin], P46
   Li YZ, 2018, IEEE INT WORKS INFOR
   Liu QZ, 2019, IEEE T CIRC SYST VID, V29, P1907, DOI 10.1109/TCSVT.2018.2859633
   Matern F, 2019, IEEE WINT CONF APPL, P83, DOI 10.1109/WACVW.2019.00020
   Meagher M, 2007, IEEE INT CONF INF VI, P601
   Meishvili G., 2019, ARXIV190912780
   NAZZARO JR, 1970, J EXP PSYCHOL, V84, P477, DOI 10.1037/h0020861
   Ngiam J., 2011, PROC 28 INT C MACH L, P689
   Nguyen HV, 2019, 2019 2ND INTERNATIONAL CONFERENCE ON APPLIED INFORMATION TECHNOLOGY AND INNOVATION (ICAITI2019), P1, DOI 10.1109/ICAITI48442.2019.8982119
   Nguyen HH, 2019, INT CONF ACOUST SPEE, P2307, DOI 10.1109/ICASSP.2019.8682602
   Nguyen Huy H, 2019, ARXIV191012467
   Nguyen T., 2019, DEEP LEARNING DEEPFA
   Oh TH, 2019, PROC CVPR IEEE, P7531, DOI 10.1109/CVPR.2019.00772
   Park T, 2019, PROC CVPR IEEE, P2332, DOI 10.1109/CVPR.2019.00244
   Rossler A, 2019, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2019.00009
   Roh Y, 2021, IEEE T KNOWL DATA EN, V33, P1328, DOI 10.1109/TKDE.2019.2946162
   Sabir Ekraam, 2019, INTERFACES GUI, P80
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Shu XB, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P35, DOI 10.1145/2733373.2806216
   Smith HMJ, 2016, ATTEN PERCEPT PSYCHO, V78, P868, DOI 10.3758/s13414-015-1045-8
   Sugiyama M, 2008, ANN I STAT MATH, V60, P699, DOI 10.1007/s10463-008-0197-x
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tang JH, 2016, ACM T MULTIM COMPUT, V12, DOI 10.1145/2998574
   Thies J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323035
   Wang JW, 2019, IEEE T CIRC SYST VID, V29, P2775, DOI 10.1109/TCSVT.2018.2867786
   Wang W, 2014, PROC VLDB ENDOW, V7, P649, DOI 10.14778/2732296.2732301
   Wang XL, 2017, PROC CVPR IEEE, P3039, DOI 10.1109/CVPR.2017.324
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
   Wen YD, 2019, ADV NEUR IN, V32
   Weston N, 2016, ARXIV160907093
   Yang X, 2019, INT CONF ACOUST SPEE, P8261, DOI 10.1109/ICASSP.2019.8683164
   Zazo R, 2018, IEEE ACCESS, V6, P22524, DOI 10.1109/ACCESS.2018.2816163
   Zhao J., 2019, P INT JOINT C ART IN, P4397
   Zhao J, 2019, THIRTY-THIRD AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTY-FIRST INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / NINTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P9251
   Zhao J, 2018, PROC CVPR IEEE, P2207, DOI 10.1109/CVPR.2018.00235
   Zhao J, 2019, IEEE T PATTERN ANAL, V41, P2380, DOI 10.1109/TPAMI.2018.2858819
   Zhao Jian, 2017, ADV NEURAL INFORM PR
   Zhu Jiapeng, 2019, ARXIV190608090
   Zhu JY, 2016, LECT NOTES COMPUT SC, V9909, P597, DOI 10.1007/978-3-319-46454-1_36
   Zhuang FZ, 2021, P IEEE, V109, P43, DOI 10.1109/JPROC.2020.3004555
NR 81
TC 0
Z9 0
U1 0
U2 0
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1051-8215
EI 1558-2205
J9 IEEE T CIRC SYST VID
JI IEEE Trans. Circuits Syst. Video Technol.
PD JAN
PY 2022
VL 32
IS 1
BP 423
EP 436
DI 10.1109/TCSVT.2021.3057457
PG 14
WC Engineering, Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA YG0JD
UT WOS:000742183600037
DA 2022-02-06
ER

PT J
AU Wanda, P
   Jie, HJ
AF Wanda, Putra
   Jie, Huang Jin
TI DeepProfile: Finding fake profile in online social network using dynamic
   CNN
SO JOURNAL OF INFORMATION SECURITY AND APPLICATIONS
LA English
DT Article
DE Dynamic CNN; Fake profile; Online social network; Features
   classification
AB Online Social Networks (OSN) are popular applications for sharing various data, including text, photos, and videos. However, fake account problems are one of the obstacles in the current OSN systems. Attacker exploits fake accounts to distribute misleading information such as malware, virus, or malicious URLs. Inspired by the big successes of deep learning in computer vision, mainly in automatic feature extraction and representation, we propose DeepProfile, a deep neural network (DNN) algorithm to deal with fake account issues. Instead of using standard machine learning, we construct a dynamic CNN to train a learning model in fake profile classification. Notably, we propose a novel pooling layer to optimize the neural network performance in the training process. Demonstrated by the experiments, we harvest a promising result with better accuracy and small loss than common learning algorithms in a malicious account classification task. (C) 2020 Elsevier Ltd. All rights reserved.
C1 [Wanda, Putra; Jie, Huang Jin] Harbin Univ Sci & Technol, Sch Comp Sci & Technol, Harbin, Peoples R China.
   [Wanda, Putra] Univ Respati Yogyakarta, Yogyakarta, Indonesia.
C3 Harbin University of Science & Technology
RP Jie, HJ (corresponding author), Harbin Univ Sci & Technol, Sch Comp Sci & Technol, Harbin, Peoples R China.
EM wpwawan@gmail.com; huangjinjie163@163.com
RI Wanda, Putra/AAD-7516-2019
OI Wanda, Putra/0000-0003-0130-3196
FU Institute of Research in Information Processing Laboratory, Harbin
   University of Science and Technology under CSC Scholarship
FX This paper is conducted in the Institute of Research in Information
   Processing Laboratory, Harbin University of Science and Technology under
   CSC Scholarship.
CR Al-Qurishi M, 2017, IEEE ACCESS, V5, P1200, DOI 10.1109/ACCESS.2017.2656635
   Anglano C, 2017, DIGIT INVEST, V23, P31, DOI 10.1016/j.diin.2017.09.002
   Arshad H, 2017, INT J COMMUN SYST, V30, DOI 10.1002/dac.3361
   Baingana B, 2016, IEEE T SIGNAL PROCES, V64, P2013, DOI 10.1109/TSP.2015.2510971
   Bindu PV, 2016, J NETW COMPUT APPL, V68, P213, DOI 10.1016/j.jnca.2016.02.021
   Blunsom Phil, 2014, P 52 ANN M ASS COMP
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Castillo C, 2011, WWW C
   Chhabra P, 2008, IEEE INFOCOM SER, P2378
   Chiluka N., 2015, P 10 ACM S INF COMP, P507
   Clark D.B., 2015, BOT BUBBLE CLICK FAR
   Creese, 2015, J INTERNET SERVICES, V5, P70
   Durst S., 2016, DARPA TWITTER BOT CH
   Egele M, 2017, IEEE T DEPEND SECURE, V14, P447, DOI 10.1109/TDSC.2015.2479616
   Gang Wang, 2019, International Journal of High Performance Computing and Networking, V13, P436
   Goodfellow BengioCourville, 2016, DEEP LEARNING, P184
   HANLEY JA, 1982, RADIOLOGY, V143, P29, DOI 10.1148/radiology.143.1.7063747
   Hastie T., 2001, SPRINGER SERIES STAT
   Hemalatha, 2016, INT J APPL ENG RES, V11-12, P7672
   Hudson B, 2016, BIG DATA SOC
   Kokciyan N, 2016, IEEE T KNOWL DATA EN, V28, P2724, DOI 10.1109/TKDE.2016.2583425
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li C, 2018, INT J CLOUD APPL COM, V8, P32, DOI 10.4018/IJCAC.2018070103
   Li GY, 2019, FRONT CELL NEUROSCI, V13, DOI 10.3389/fncel.2019.00153
   Li MZ, 2018, INT J COMMUN SYST, V31, DOI 10.1002/dac.3387
   Liu BH, 2014, INT J COMMUN SYST, V27, P4481, DOI 10.1002/dac.2630
   Miller S., 2016, INT J INTERNET TECHN, V5, P474, DOI [10.20533/jitst.2046.3723.2016.0060, DOI 10.20533/JITST.2046.3723.2016.0060]
   Mohaisen A, 2013, 14 INT WORKSH INF SE, P8267
   Mohammadrezaei M, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/5923156
   Ni XD, 2016, SECUR COMMUN NETW, V9, P1890, DOI 10.1002/sec.926
   Qin Y, 2016, IEEE ACM T NETWORK, V24, P1989, DOI 10.1109/TNET.2015.2437955
   Ruan X, 2016, IEEE T INF FOREN SEC, V11, P176, DOI 10.1109/TIFS.2015.2482465
   Sharma V, 2017, IEEE ACCESS, V5, P3284, DOI 10.1109/ACCESS.2017.2666823
   Shu Kai, 2017, ACM SIGKDD EXPLOR NE, V18, P5, DOI [10.1145/3068777.3068781, DOI 10.1145/3068777.3068781]
   Soule A., 2005, P 5 ACM SIGCOMM C IN, P331, DOI DOI 10.1145/1330107.1330147
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Swets John A., 1996, SIGNAL DETECTION THE
   Tan ZH, 2016, IEEE ACCESS, V4, P6105, DOI 10.1109/ACCESS.2016.2612298
   Theodoridis S, 2010, INTRO PATTERN RECOGN
   Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Van Der Walt E, 2018, IEEE ACCESS, V6, P6540, DOI 10.1109/ACCESS.2018.2796018
   Vigliotti MG, 2015, SOC NETWORKS, V41, P18, DOI 10.1016/j.socnet.2014.12.001
   Wanda Putra, 2014, 2014 1st International Conference on Information Technology, Computer and Electrical Engineering (ICITACEE). Proceedings, P245, DOI 10.1109/ICITACEE.2014.7065750
   Wanda P., 2018, TELKOMNIKA J, V16
   Wanda P, 2014, 2014 INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY SYSTEMS AND INNOVATION (ICITSI), P81, DOI 10.1109/ICITSI.2014.7048242
   Zhang ZY, 2017, MULTIMED TOOLS APPL, V76, P18513, DOI 10.1007/s11042-016-4162-z
   Zhang ZY, 2018, FUTURE GENER COMP SY, V86, P914, DOI 10.1016/j.future.2016.10.007
   Zhou F, 2018, IEEE INFOCOM SER, P1313, DOI 10.1109/INFOCOM.2018.8486231
NR 48
TC 2
Z9 2
U1 2
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2214-2126
EI 2214-2134
J9 J INF SECUR APPL
JI J. Inf. Secur. Appl.
PD JUN
PY 2020
VL 52
AR 102465
DI 10.1016/j.jisa.2020.102465
PG 13
WC Computer Science, Information Systems
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA LT2ZK
UT WOS:000536940000007
DA 2022-02-06
ER

PT J
AU Low, JF
   Fung, BCM
   Iqbal, F
   Huang, SC
AF Low, Jwen Fai
   Fung, Benjamin C. M.
   Iqbal, Farkhund
   Huang, Shih-Chia
TI Distinguishing between fake news and satire with transformers
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Fake news; Satire; Sarcasm; Deep learning; Transformers; BERT;
   DistilBERT; Classification
ID IMPACT
AB Indiscriminate elimination of harmful fake news risks destroying satirical news, which can be benign or even beneficial, because both types of news share highly similar textual cues. In this work we applied a recent development in neural network architecture, transformers, to the task of separating satirical news from fake news. Transformers have hitherto not been applied to this specific problem. Our evaluation results on a publicly available and carefully curated dataset show that the performance from a classifier framework built around a DistilBERT architecture performed better than existing machine-learning approaches. Additional improvement over baseline DistilBERT was achieved through the use of non-standard tokenization schemes as well as varying the pre-training and text pre-processing strategies. The improvement over existing approaches stands at 0.0429 (5.2%) in F1 and 0.0522 (6.4%) in accuracy. Further evaluation on two additional datasets shows our framework's ability to generalize across datasets without diminished performance.
C1 [Low, Jwen Fai; Fung, Benjamin C. M.] McGill Univ, Sch Informat Studies, Montreal, PQ H3A 1X1, Canada.
   [Iqbal, Farkhund] Zayed Univ, Coll Technol Innovat, Abu Dhabi, U Arab Emirates.
   [Huang, Shih-Chia] Natl Taipei Univ Technol, Dept Elect Engn, Taipei, Taiwan.
C3 McGill University; Zayed University; National Taipei University of
   Technology
RP Fung, BCM (corresponding author), McGill Univ, Sch Informat Studies, Montreal, PQ H3A 1X1, Canada.; Huang, SC (corresponding author), Natl Taipei Univ Technol, Dept Elect Engn, Taipei, Taiwan.
EM jwen.low@mail.mcgill.ca; ben.fung@mcgill.ca; farkhund.iqbal@zu.ac.ae;
   schuang@ntut.edu.tw
OI Low, Jwen Fai/0000-0001-6618-7443; Iqbal, Farkhund/0000-0001-9081-3598;
   Huang, Shih-Chia/0000-0002-6896-3415
FU Natural Sciences and Engineering Research Council of Canada
   (NSERC)Natural Sciences and Engineering Research Council of Canada
   (NSERC) [RGPIN2018-03872]; Canada Research Chairs ProgramCanada Research
   Chairs [950230623]; Cluster project from Zayed University, United Arab
   Emirates [R16083]; Zayed University, United Arab Emirates [R20093]
FX The second author is supported by the Discovery Grants (RGPIN2018-03872)
   from the Natural Sciences and Engineering Research Council of Canada
   (NSERC) and Canada Research Chairs Program (950230623). The third author
   is supported by Cluster project (#R16083) and Provost Research
   Fellowship grant (#R20093) from Zayed University, United Arab Emirates.
CR Adali S., 2017, 11 INT AAAI C WEB SO, P759
   Aggarwal A, 2020, EAI ENDORSED TRANS S, V7, DOI 10.4108/eai.13-7-2018.163973
   Ahmed Hadeer, 2018, Security and Privacy, V1, DOI 10.1002/spy2.9
   Ahmed W, 2020, J MED INTERNET RES, V22, DOI 10.2196/19458
   Alkhodair SA, 2021, ACM TRANS MANAG INF, V12, DOI 10.1145/3416703
   Alkhodair SA, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.02.016
   Allcott H, 2017, J ECON PERSPECT, V31, P211, DOI 10.1257/jep.31.2.211
   Becker AB, 2018, INFORM COMMUN SOC, V21, P612, DOI 10.1080/1369118X.2017.1301517
   Beltagy I., 2019, P 2019 C EMPIRICAL M, P3615, DOI DOI 10.18653/V1/D19-1371
   Brewer PR, 2013, INT J PUBLIC OPIN R, V25, P323, DOI 10.1093/ijpor/edt015
   Burfoot C., P ACL IJCNLP 2009 C, P161
   Chao Liu, 2019, Knowledge Science, Engineering and Management. 12th International Conference, KSEM 2019. Proceedings: Lecture Notes in Artificial Intelligence (LNAI 11776), P172, DOI 10.1007/978-3-030-29563-9_17
   Chen HT, 2017, INT J COMMUN-US, V11, P3011
   Chomsky N., 2015, NOAM CHOMSKY NEW YOR
   Coenen A, 2019, ADV NEUR IN, V32
   Das D, 2019, 2019 FIRST INTERNATIONAL CONFERENCE ON TRANSDISCIPLINARY AI (TRANSAI 2019), P22, DOI 10.1109/TransAI46475.2019.00012
   De Morais J. I., 2019, ACM INT C P SERIES, DOI [10.1145/3330204.3330231, DOI 10.1145/3330204.3330231]
   De Sarkar Sohan, 2018, 27 INT C COMP LING C, P3371
   Devlin J, 2019, PROC C N AM CHAPTER, P4171, DOI DOI 10.18653/V1/N19-1423
   Ghosh Souvick, 2018, Proceedings of the Association for Information Science and Technology, V55, DOI 10.1002/pra2.2018.14505501125
   Giachanou A, 2020, PR INT CONF DATA SC, P647, DOI 10.1109/DSAA49011.2020.00091
   Golbeck J, 2018, WEBSCI'18: PROCEEDINGS OF THE 10TH ACM CONFERENCE ON WEB SCIENCE, P17, DOI 10.1145/3201064.3201100
   Hassan F. M., 2021, ADV INTELLIGENT SYST, P218, DOI [10.1007/978-3-030-57805-3_21, DOI 10.1007/978-3-030-57805-3_21]
   Herman E., 2010, MANUFACTURING CONSEN
   Jennen B, 2021, BLOOMBERG
   Jones MO, 2017, COMMUN PUBLIC, V2, P136, DOI 10.1177/2057047317706372
   Jwa H, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9194062
   Kaliyar RK, 2021, MULTIMED TOOLS APPL, V80, P11765, DOI 10.1007/s11042-020-10183-2
   Le H., 2020, ARXIV191205372CS
   Liu Y., 2019, CORR
   Liu Y, 2019, CORR 2019 ABS19080
   LIU Z., 2019, 2019 28 INT C COMP C, P1, DOI 10.1109/VTCSpring.2019.8746624
   Lloret E, 2013, DATA KNOWL ENG, V88, P164, DOI 10.1016/j.datak.2013.08.005
   Jeronimo CLM, 2019, IIWAS2019: THE 21ST INTERNATIONAL CONFERENCE ON INFORMATION INTEGRATION AND WEB-BASED APPLICATIONS & SERVICES, P15, DOI 10.1145/3366030.3366039
   Mukurunge T., 2019, J PSYCHOL RES, V9, DOI [10.17265/2159-5542/2019.09.004, DOI 10.17265/2159-5542/2019.09.004]
   News F. D., 2020, 1 DRAFT
   Norregaard Jeppe, 2019, P 13 INT C WEB SOC M, V13, P630
   Rashkin Hannah, 2017, P 2017 C EMPIRICAL M, P2931
   Rubin V., 2016, P 2 WORKSH COMP APPR, P7, DOI DOI 10.18653/V1/W16-0802
   Sanh V., 2020, ARXIV13013781
   Shabani S, 2018, 2018 4TH IEEE INTERNATIONAL CONFERENCE ON COLLABORATION AND INTERNET COMPUTING (CIC 2018), P299, DOI 10.1109/CIC.2018.00048
   Singhal S, 2019, 2019 IEEE FIFTH INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2019), P39, DOI [10.1109/BigMM.2019.00018, 10.1109/BigMM.2019.00-44]
   Sun C, 2019, LECT NOTES ARTIF INT, V11856, P194, DOI 10.1007/978-3-030-32381-3_16
   Sutskever I., 2018, IMPROVING LANGUAGE U
   Tandoc EC, 2018, DIGIT JOURNAL, V6, P137, DOI 10.1080/21670811.2017.1360143
   Vaibhav V., 2019, ARXIV PREPRINT ARXIV
   Vaswani A., 2017, ADV NEURAL INFORM PR, P5998, DOI DOI 10.5555/3295222.3295349
   Volkova S, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P647, DOI 10.18653/v1/P17-2102
   Vosoughi S, 2018, SCIENCE, V359, P1146, DOI 10.1126/science.aap9559
   Wardle C., 2017, FAKE NEWS ITS COMPLI
   Wu Y, 2016, GOOGLES NEURAL MACHI, DOI DOI 10.20944/PREPRINTS201608.0137.V1
   Xie B, 2020, J ASSOC INF SCI TECH, V71, P1419, DOI 10.1002/asi.24357
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Zannettou S, 2019, ACM J DATA INF QUAL, V11, DOI 10.1145/3309699
   Zimdars M., 2016, FALSE MISLEADING CLI
   Zimdars M, 2016, WASH POST
NR 56
TC 0
Z9 0
U1 9
U2 9
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD JAN
PY 2022
VL 187
AR 115824
DI 10.1016/j.eswa.2021.115824
PG 13
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic; Operations Research & Management Science
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Operations Research & Management Science
GA WB8XO
UT WOS:000703850500011
DA 2022-02-06
ER

PT J
AU Chen, BY
   Tan, SQ
AF Chen, Baoying
   Tan, Shunquan
TI FeatureTransfer: Unsupervised Domain Adaptation for Cross-Domain
   Deepfake Detection
SO SECURITY AND COMMUNICATION NETWORKS
LA English
DT Article
AB Recently, various Deepfake detection methods have been proposed, and most of them are based on convolutional neural networks (CNNs). These detection methods suffer from overfitting on the source dataset and do not perform well on cross-domain datasets which have different distributions from the source dataset. To address these limitations, a new method named FeatureTransfer is proposed in this paper, which is a two-stage Deepfake detection method combining with transfer learning. Firstly, The CNN model pretrained on a third-party large-scale Deepfake dataset can be used to extract the more transferable feature vectors of Deepfake videos in the source and target domains. Secondly, these feature vectors are fed into the domain-adversarial neural network based on backpropagation (BP-DANN) for unsupervised domain adaptive training, where the videos in the source domain have real or fake labels, while the videos in the target domain are unlabelled. The experimental results indicate that the proposed method FeatureTransfer can effectively solve the overfitting problem in Deepfake detection and greatly improve the performance of cross-dataset evaluation.
C1 [Chen, Baoying; Tan, Shunquan] Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen 518060, Peoples R China.
   [Chen, Baoying; Tan, Shunquan] Guangdong Key Lab Intelligent Informat Proc, Shenzhen, Peoples R China.
   [Chen, Baoying; Tan, Shunquan] Shenzhen Key Lab Media Secur, Shenzhen, Peoples R China.
   [Chen, Baoying; Tan, Shunquan] Shenzhen Inst Artificial Intelligence & Robot Soc, Shenzhen, Peoples R China.
C3 Shenzhen University
RP Tan, SQ (corresponding author), Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen 518060, Peoples R China.; Tan, SQ (corresponding author), Guangdong Key Lab Intelligent Informat Proc, Shenzhen, Peoples R China.; Tan, SQ (corresponding author), Shenzhen Key Lab Media Secur, Shenzhen, Peoples R China.; Tan, SQ (corresponding author), Shenzhen Inst Artificial Intelligence & Robot Soc, Shenzhen, Peoples R China.
EM 1900271059@email.szu.edu.cn; tansq@szu.edu.cn
FU Key-Area Research and Development Program of Guangdong Province
   [2019B010139003]; NSFCNational Natural Science Foundation of China
   (NSFC) [61772349, U19B2022, 61872244]; Guangdong Basic and Applied Basic
   Research Foundation [2019B151502001]; Shenzhen RD Program
   [JCYJ20180305124325555]; Alibaba Group through Alibaba Innovative
   Research (AIR) Program
FX This work was supported in part by the Key-Area Research and Development
   Program of Guangdong Province (2019B010139003), NSFC (61772349,
   U19B2022, and 61872244), Guangdong Basic and Applied Basic Research
   Foundation (2019B151502001), and Shenzhen R&D Program
   (JCYJ20180305124325555). This work was also supported by Alibaba Group
   through Alibaba Innovative Research (AIR) Program.
CR Abbasi R, 2021, SOFTWARE PRACT EXPER, V51, P645, DOI 10.1002/spe.2884
   Afchar D, 2018, IEEE INT WORKS INFOR
   Azad MA, 2020, FUTURE GENER COMP SY, V105, P297, DOI 10.1016/j.future.2019.11.007
   Chen P, 2020, IEEE INT CON MULTI
   Ciftci Umur Aybars, 2020, IEEE Trans Pattern Anal Mach Intell, VPP, DOI 10.1109/TPAMI.2020.3009287
   Cozzolino D., 2018, FORENSICTRANSFER WEA
   Dolhansky B., 2020, DEEPFAKE DETECTION C
   Dolhansky Brian, 2019, DEEPFAKE DETECTION C
   Dufour N., 2020, CONTRIBUTING DATA DE
   Ganin Y, 2015, PR MACH LEARN RES, V37, P1180
   Guera D, 2018, 2018 15TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P127
   Hakak Saqib, 2020, Computational Data and Social Networks. 9th International Conference, CSoNet 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12575), P345, DOI 10.1007/978-3-030-66046-8_28
   Hakak S, 2021, FUTURE GENER COMP SY, V117, P47, DOI 10.1016/j.future.2020.11.022
   Huang D, 2012, LECT NOTES COMPUT SC, V7573, P144, DOI 10.1007/978-3-642-33709-3_11
   Javed AR, 2021, IEEE T NETW SCI ENG, V8, P1456, DOI 10.1109/TNSE.2021.3059881
   Javed A, 2020, IEEE INT SYMP CIRC S
   Jie H., 2020, CVPR, V42, P2011, DOI 10.1109/TPAMI.2019.2913372
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Korshunov P., 2018, DEEPFAKES NEW THREAT
   Li LZ, 2020, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR42600.2020.00505
   Li Y, 2018, EXPOSING DEEPFAKE VI
   Li YZ, 2018, IEEE INT WORKS INFOR
   Li YZ, 2020, PROC CVPR IEEE, P3204, DOI 10.1109/CVPR42600.2020.00327
   Lin H, 2021, IEEE INTERNET THINGS, V8, P15683, DOI 10.1109/JIOT.2020.3033129
   Long MS, 2015, PR MACH LEARN RES, V37, P97
   Matern F, 2019, IEEE WINT CONF APPL, P83, DOI 10.1109/WACVW.2019.00020
   Nguyen HV, 2019, 2019 2ND INTERNATIONAL CONFERENCE ON APPLIED INFORMATION TECHNOLOGY AND INNOVATION (ICAITI2019), P1, DOI 10.1109/ICAITI48442.2019.8982119
   Nirkin Y, 2019, IEEE I CONF COMP VIS, P7183, DOI 10.1109/ICCV.2019.00728
   Pei ZY, 2018, THIRTY-SECOND AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTIETH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / EIGHTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P3934
   Petrov I., 2020, DEEPFACELAB SIMPLE F
   Rossler A, 2019, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2019.00009
   Sagar R, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9010097
   Sanderson C, 2009, LECT NOTES COMPUT SC, V5558, P199, DOI 10.1007/978-3-642-01793-3_21
   Shaoanlu, 2020, **NON-TRADITIONAL**
   Sun BC, 2016, LECT NOTES COMPUT SC, V9915, P443, DOI 10.1007/978-3-319-49409-8_35
   Yang X, 2019, INT CONF ACOUST SPEE, P8261, DOI 10.1109/ICASSP.2019.8683164
   Yin X, 2018, IEEE T IMAGE PROCESS, V27, P964, DOI 10.1109/TIP.2017.2765830
   Yu CH, 2019, IEEE DATA MINING, P778, DOI 10.1109/ICDM.2019.00088
   Yuyang Qian, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P86, DOI 10.1007/978-3-030-58610-2_6
   Zakharov E, 2019, IEEE I CONF COMP VIS, P9458, DOI 10.1109/ICCV.2019.00955
   Zhang HL, 2019, IEEE ACCESS, V7, P159081, DOI 10.1109/ACCESS.2019.2949741
   Zhang XJ, 2019, 2019 IEEE 18TH INTERNATIONAL SYMPOSIUM ON NETWORK COMPUTING AND APPLICATIONS (NCA), P229
NR 42
TC 0
Z9 0
U1 8
U2 9
PU WILEY-HINDAWI
PI LONDON
PA ADAM HOUSE, 3RD FL, 1 FITZROY SQ, LONDON, WIT 5HE, ENGLAND
SN 1939-0114
EI 1939-0122
J9 SECUR COMMUN NETW
JI Secur. Commun. Netw.
PD JUN 7
PY 2021
VL 2021
AR 9942754
DI 10.1155/2021/9942754
PG 8
WC Computer Science, Information Systems; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA SY4RJ
UT WOS:000665877000005
OA gold
DA 2022-02-06
ER

PT J
AU Shim, JS
   Lee, Y
   Ahn, H
AF Shim, Jae-Seung
   Lee, Yunju
   Ahn, Hyunchul
TI A link2vec-based fake news detection model using web search results
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Fake news detection; Link2vec; Web search result; Feature selection;
   Deep learning
AB Today, the world is under siege from various kinds of fake news ranging from politics to COVID-19. Thus, many scholars have been researching automatic fake news detection based on artificial intelligence and machine learning (AI/ML) to prevent the spread of fake news. The mainstream research on detecting fake news so far has been text-based detection approaches, but they have inherent limitations such as the difficulty of short text processing and language dependency. Thus, as an alternative to the text-based approach, the context-based approach is emerging. The most common context-based approach the use of distributors' network information in social media. However, such information is difficult to obtain, and only propagation within a single social media can be traced. Under this background, we propose the use of composition pattern of web links containing news content as a new source of information for fake news detection. To properly vectorize the composition pattern of web links, this study proposes a novel embedding technique, which is called link2vec, an extension of word2vec. To test the effectiveness and language independency of our link2vec-based model, we applied it to two real-world fake news datasets in different languages (English and Korean). As comparison models, we adopted the conventional text-based model and a hybrid model that combined text and whitelist-based link information proposed by a prior study. Results revealed that in the datasets in two languages, the link2vec-based detection models outperformed all the comparison models with statistical significance. Our research is expected to contribute to suggesting a completely new path for effective fake news detection.
C1 [Shim, Jae-Seung; Lee, Yunju; Ahn, Hyunchul] Kookmin Univ, Grad Sch Business IT, 77 Jeongneung Ro, Seoul 02707, South Korea.
C3 Kookmin University
RP Ahn, H (corresponding author), Kookmin Univ, Grad Sch Business IT, 77 Jeongneung Ro, Seoul 02707, South Korea.
EM simsoni7@kookmin.ac.kr; mmlas0ui@kookmin.ac.kr; hcahn@kookmin.ac.kr
CR Alizadeh R, 2020, RES ENG DES, V31, P275, DOI 10.1007/s00163-020-00336-7
   Alizadeh R, 2019, AI EDAM, V33, P484, DOI 10.1017/S089006041900026X
   Alkhodair SA, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.02.016
   Amin S. H., 2019, KAGGLE V1
   Apuke OD, 2021, TELEMAT INFORM, V56, DOI 10.1016/j.tele.2020.101475
   Asgari E, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0141287
   Baly R., 2018, P 2018 C EMP METH NA, DOI [10.18653/v1/D18-1389, DOI 10.18653/V1/D18-1389, 10.18653/v1/d18-1389]
   Banerjee I, 2018, J BIOMED INFORM, V77, P11, DOI 10.1016/j.jbi.2017.11.012
   Berghel H, 2017, COMPUTER, V50, P80, DOI 10.1109/MC.2017.56
   Bondielli A, 2019, INFORM SCIENCES, V497, P38, DOI 10.1016/j.ins.2019.05.035
   Buntain C, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON SMART CLOUD (SMARTCLOUD), P208, DOI 10.1109/SmartCloud.2017.40
   Castelo S, 2019, COMPANION OF THE WORLD WIDE WEB CONFERENCE (WWW 2019 ), P975, DOI 10.1145/3308560.3316739
   Castillo C., 2011, WWW, P675
   Choi J. J., 2018, P KOR I INF SCI ENG, P982
   Choi S., 2016, P 28 ANN C HUM COGN, P252
   Choras M, 2018, LECT NOTES COMPUT SC, V11127, P130, DOI 10.1007/978-3-319-99954-8_12
   Cochran WC, 1989, STAT METHODS, Veighth
   DAncona M., 2017, POSTTRUTH NEW WAR TR
   Das Bhattacharjee S, 2017, IEEE INT CONF BIG DA, P556, DOI 10.1109/BigData.2017.8257971
   Della Vedova ML, 2018, PROC CONF OPEN INNOV, P272, DOI 10.23919/FRUCT.2018.8468301
   Goldani MH, 2021, APPL SOFT COMPUT, V101, DOI 10.1016/j.asoc.2020.106991
   Hamidian S., 2019, ARXIV191208926
   Hussain MG, 2020, 2020 INTERNATIONAL CONFERENCE ON COMPUTING, ELECTRONICS & COMMUNICATIONS ENGINEERING (ICCECE, P81, DOI 10.1109/iCCECE49321.2020.9231167
   Jia LY, 2020, ADV ENG INFORM, V45, DOI 10.1016/j.aei.2020.101123
   Kiely E., 2016, SPOT FAKE NEWS, P18
   Kim Changsook, 2020, [Journal of Communication Research, 언론정보연구], V57, P286, DOI 10.22174/jcr.2020.57.3.286
   Kwon S, 2013, IEEE DATA MINING, P1103, DOI 10.1109/ICDM.2013.61
   Lau JH, 2016, P 1 WORKSH REPR LEAR, P78, DOI DOI 10.18653/V1/W16-1609
   Lazer DMJ, 2018, SCIENCE, V359, P1094, DOI 10.1126/science.aao2998
   Le Q., 2014, P 31 INT C INT C MAC
   Li LF, 2014, BEHAV INFORM TECHNOL, V33, P1136, DOI 10.1080/0144929X.2013.875221
   Liu WS, 2016, 2016 2ND IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATIONS (ICCC), P1195, DOI 10.1109/CompComm.2016.7924894
   Ma J, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P708, DOI 10.18653/v1/P17-1066
   Masciari E., 2020, DEEP LEARNING APPROA, P113, DOI [10.1007/978-3-030-59491-6_11, DOI 10.1007/978-3-030-59491-6_11]
   Meel P, 2020, EXPERT SYST APPL, V153, DOI 10.1016/j.eswa.2019.112986
   Mikolov T., 2013, NIPS, V26, P3111
   Ng P., 2017, DNA2VEC CONSISTENT V
   Okoro EM., 2018, NIGERIAN J TECHNOLOG, V37, P454, DOI [10.4314/njt.v37i2.22, DOI 10.4314/NJT.V37I2.22]
   Oshikawa R., 2018, ARXIV PREPRINT ARXIV
   Park Sung Soo, 2019, [Journal of Digital Convergence, 디지털융복합연구], V17, P137, DOI 10.14400/JDC.2019.17.5.137
   Pathak A, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019:): STUDENT RESEARCH WORKSHOP, P357
   Penaforte MA Jr., 2009, PERFIL PRODUTORES LE, P1
   Poddar K., 2019, 2019 INN POW ADV COM, V1, P1
   Qi P, 2019, IEEE DATA MINING, P518, DOI 10.1109/ICDM.2019.00062
   Qin YM, 2018, CHINESE J ELECTRON, V27, P514, DOI 10.1049/cje.2018.03.008
   Rodriguez I., 2019, ARXIV PREPRINT ARXIV
   Rubin V., 2016, P 2 WORKSH COMP APPR, P7, DOI DOI 10.18653/V1/W16-0802
   Ruchansky N, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P797, DOI 10.1145/3132847.3132877
   Schulz A., 2020, DIGITAL NEWS REPORT
   Sitaula N., 2020, DISINFORMATION MISIN, P163
   Thorne J., 2017, P 2017 EMNLP WORKSH, P80
   Tschiatschek S, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), P517, DOI 10.1145/3184558.3188722
   van Der Linden S, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.566790
   Vishwakarma DK, 2019, COGN SYST RES, V58, P217, DOI 10.1016/j.cogsys.2019.07.004
   Wang WY, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P422, DOI 10.18653/v1/P17-2067
   심재승, 2019, [Journal of Intelligence and Information Systems, 지능정보연구], V25, P201
   Yun Tae-Uk, 2018, Journal of Information Technology Applications & Management, V25, P19, DOI 10.21219/jitam.2018.25.1.019
   Zhang JW, 2020, PROC INT CONF DATA, P1826, DOI 10.1109/ICDE48307.2020.00180
   Zhang XC, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.03.004
   Zhou XY, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3395046
NR 60
TC 1
Z9 1
U1 12
U2 12
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD DEC 1
PY 2021
VL 184
AR 115491
DI 10.1016/j.eswa.2021.115491
PG 15
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic; Operations Research & Management Science
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Operations Research & Management Science
GA UR8OP
UT WOS:000697001800015
DA 2022-02-06
ER

PT J
AU Choudhary, A
   Arora, A
AF Choudhary, Anshika
   Arora, Anuja
TI Linguistic feature based learning model for fake news detection and
   classification
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Fake news; Syntactic; Readability; Neural network; Deep learning;
   Machine learning; LSTM
AB Social media is used as a dominant source of news distribution among users. The world's preeminent decisions such as politics are acclaimed by social media to influence users for enclosing users' decisions in their favor. However, the adoption of social media is much needed for awareness but the authenticity of content is an unknown factor in the current scenario. Therefore, this research work finds it imperative to propose a solution to fake news detection and classification. In the case of fake news, content is the prime entity that captures the human mind towards trust for specific news. Therefore, a linguistic model is proposed to find out the properties of content that will generate language-driven features. This linguistic model extracts syntactic, grammatical, sentimental, and readability features of particular news. Language driven model requires an approach to handle time-consuming and handcrafted features problems in order to deal with the curse of dimensionality problem. Therefore, the neural-based sequential learning model is used to achieve superior results for fake news detection. The results are drawn to validate the importance of the linguistic model extracted features and finally combined linguistic feature-driven model is able to achieve the average accuracy of 86% for fake news detection and classification. The sequential neural model results are compared with machine learning based models and LSTM based word embedding based fake news detection model as well. Comparative results show that features based sequential model is able to achieve comparable evaluation performance in discernable less time.
C1 [Choudhary, Anshika; Arora, Anuja] Jaypee Inst Informat Technol, Dept Comp Sci & Engn, Noida, India.
C3 Jaypee Institute of Information Technology (JIIT)
RP Choudhary, A (corresponding author), Jaypee Inst Informat Technol, Dept Comp Sci & Engn, Noida, India.
EM anshika.ch412@gmail.com; anuja.arora@jiit.ac.in
CR Alkhodair SA, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.02.016
   Bauskar S., 2019, INT J INFORM ENG ELE, V11, P1
   Bondielli A, 2019, INFORM SCIENCES, V497, P38, DOI 10.1016/j.ins.2019.05.035
   Chen X., 2020, ARXIV200102731, V39, P1
   Conroy NJ, 2015, P ASS INF SCI TECHN, V51, P1, DOI [10.1002/pra2.2015.145052010082, DOI 10.1002/PRA2.2015.145052010082]
   Danielson KE, 1987, READING HORIZONS J L, V27, P4
   Feng Lijun, 2010, P 23 INT C COMP LING, P276
   Flesch R., 1951, TEST READABILITY
   Girgis S, 2018, PROCEEDINGS OF 2018 13TH INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING AND SYSTEMS (ICCES), P93, DOI 10.1109/ICCES.2018.8639198
   Gravanis G, 2019, EXPERT SYST APPL, V128, P201, DOI 10.1016/j.eswa.2019.03.036
   Horne BD, 2017, THIS JUST FAKE NEWS, P9
   Jain L, 2020, EXPERT SYST APPL, V142, DOI 10.1016/j.eswa.2019.113016
   Kai Shu, 2017, ACM SIGKDD Explorations Newsletter, V19, P22, DOI 10.1145/3137597.3137600
   KLARE GR, 1976, J READING BEHAV, V8, P129, DOI 10.1080/10862967609547171
   Kogan S., 2019, FAKE NEWS EVIDENCE F
   Li Q., 2019, ARXIV191107199, V1, P1
   Lillie A. E., 2019, ARXIV190700181, V1, P1
   Liu ZL, 2020, DRY TECHNOL, V38, P1869, DOI 10.1080/07373937.2019.1675077
   Mahanta J., 2017, DATA SCI, V13
   Meel P, 2020, EXPERT SYST APPL, V153, DOI 10.1016/j.eswa.2019.112986
   Mohseni S., 2019, ARXIV190403016, V1, P1
   Pe rez-Rosas V, 2017, ARXIV170807104
   Reyes J., 2019, DETECTION FAKE NEWS
   Sharma K, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3305260
   Shen H, 2017, NEUROCOMPUTING, V225, P49, DOI 10.1016/j.neucom.2016.11.013
   Shu K., 2017, ARXIV171207709, V1, P1
   Shu Kai, 2017, ACM SIGKDD EXPLOR NE, V18, P5, DOI [10.1145/3068777.3068781, DOI 10.1145/3068777.3068781]
   Wang WY, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P422, DOI 10.18653/v1/P17-2067
   Wang YQ, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P849, DOI 10.1145/3219819.3219903
   Wu L, 2018, WSDM'18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P637, DOI 10.1145/3159652.3159677
   Xinyi Zhou, 2020, ACM Digital Threats: Research Practice, V1, DOI 10.1145/3377478
   Yu PS, 2018, ARXIV180600749, DOI DOI 10.1145/3070644
   Zhang JW, 2020, PROC INT CONF DATA, P1826, DOI 10.1109/ICDE48307.2020.00180
   Zhang X., 2020, INFORM PROCESS MANAG, V57
NR 34
TC 4
Z9 4
U1 7
U2 9
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD MAY 1
PY 2021
VL 169
AR 114171
DI 10.1016/j.eswa.2020.114171
PG 15
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic; Operations Research & Management Science
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Operations Research & Management Science
GA SV3FJ
UT WOS:000663708000002
DA 2022-02-06
ER

PT J
AU Kumari, R
   Ashok, N
   Ghosal, T
   Ekbal, A
AF Kumari, Rina
   Ashok, Nischal
   Ghosal, Tirthankar
   Ekbal, Asif
TI What the fake? Probing misinformation detection standing on the shoulder
   of novelty and emotion
SO INFORMATION PROCESSING & MANAGEMENT
LA English
DT Article
DE Fake news detection; Novelty prediction; Emotion prediction; Deep
   learning
ID CLASSIFICATION; RUMORS
AB One of the most time-critical challenges for the Natural Language Processing (NLP) community is to combat the spread of fake news and misinformation. Existing approaches for misinformation detection use neural network models, statistical methods, linguistic traits, fact-checking strategies, etc. However, the menace of fake news seems to grow more vigorous with the advent of humongous and unusually creative language models. Relevant literature reveals that one major characteristic of the virality of fake news is the presence of an element of surprise in the story, which attracts immediate attention and invokes strong emotional stimulus in the reader. In this work, we leverage this idea and propose textual novelty detection and emotion prediction as the two tasks relating to automatic misinformation detection. We re-purpose textual entailment for novelty detection and use the models trained on large-scale datasets of entailment and emotion to classify fake information. Our results correlate with the idea as we achieve state-of-the-art (SOTA) performance (7.92%, 1.54%, 17.31% and 8.13% improvement in terms of accuracy) on four large-scale misinformation datasets. We hope that our current probe will motivate the community to explore further research on misinformation detection along this line. The source code is available at the GitHub.(2)
C1 [Kumari, Rina; Ashok, Nischal; Ghosal, Tirthankar; Ekbal, Asif] Indian Inst Technol Patna, Dept Comp Sci & Engn, Patna 801106, Bihar, India.
C3 Indian Institute of Technology (IIT) - Patna; Indian Institute of
   Technology System (IIT System)
RP Ashok, N (corresponding author), Indian Inst Technol Patna, Dept Comp Sci & Engn, Patna 801106, Bihar, India.
EM rina_1921cs13@iitp.ac.in; 1801cs33@iitp.ac.in; ghosal@ufal.mff.cuni.cz;
   asif@iitp.ac.in
OI Kumari, Rina/0000-0002-1590-4673
CR Abdul-Mageed M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P718, DOI 10.18653/v1/P17-1067
   Ajit Rajasekharan A. L, 2020, WHAT ARE MAIN DIFFER
   Akhtar MS, 2018, IEEE INTELL SYST, V33, P8, DOI 10.1109/MIS.2018.2877279
   Alhindi T., 2018, P 1 WORKSH FACT EXTR, P85
   Alkhodair SA, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.02.016
   Amplayo RK, 2018, INFORM SCIENCES, V422, P542, DOI 10.1016/j.ins.2017.09.037
   An X., 2020, BIOMEDICAL INFORM TE, P369
   Attardi G., 2020, LANG RESOUR EVAL
   Barr R. A., 2019, FAKE NEWS GRABS OUR
   Becker K, 2017, INFORM PROCESS MANAG, V53, P684, DOI 10.1016/j.ipm.2016.12.008
   Bostan L.-A.-M., 2018, P 27 INT C COMP LING, P2104
   Brady WJ, 2017, P NATL ACAD SCI USA, V114, P7313, DOI 10.1073/pnas.1618923114
   Breja M, 2015, INT J COMPUTER SCI I
   Bro R, 2014, ANAL METHODS-UK, V6, P2812, DOI 10.1039/c3ay41907j
   Chaudhry A. K., 2017, CS224N NATURAL LANGU
   Chen Q, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2406
   Claire Wardle H. D, 2017, ONE YEAR WERE STILL
   Devlin J., 2019, LONG SHORT PAPERS, P4171
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   Gang R, 2019, INFORM PROCESS MANAG, V56, P1425, DOI 10.1016/j.ipm.2018.04.003
   Ghanem B., 2021, P 16 C EUR CHAPT ASS, P679
   Ghanem B, 2020, ACM T INTERNET TECHN, V20, DOI 10.1145/3381750
   Ghosal T, 2021, NAT LANG ENG, V27, P427, DOI 10.1017/S1351324920000194
   Giachanou A, 2021, J ASSOC INF SCI TECH, V72, P1117, DOI 10.1002/asi.24480
   Giachanou A, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P877, DOI 10.1145/3331184.3331285
   Guo CX, 2019, IEEE I CONF COMP VIS, P3908, DOI 10.1109/ICCV.2019.00401
   Hanselowski A., 2018, ARXIV180605180
   He XJ, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102258
   Hsu C.-C., 2019, THEORY MISINFORMATIO
   Imtiaz Z, 2020, IEEE ACCESS, V8, P21932, DOI 10.1109/ACCESS.2020.2969041
   Jain G, 2019, ANN MATH ARTIF INTEL, V85, P21, DOI 10.1007/s10472-018-9612-z
   Jose S.-D. J., 2020, NEW TRENDS USE ARTIF
   Kerner HR, 2019, THIRTY-THIRD AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTY-FIRST INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / NINTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P9484
   Kouzy R, 2020, CUREUS, V12, DOI 10.7759/cureus.7255
   Kumar S, 2020, SN APPL SCI, V2, DOI 10.1007/s42452-020-2082-z
   Kumari R, 2021, IEEE IJCNN, DOI 10.1109/IJCNN52387.2021.9534218
   Kumari R, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2021.102631
   Lee S., 2015, P 2015 C EMP METH NA, P567
   Liew J.S.Y., 2016, P NAACL STUD RES WOR, P73
   Liu S., 2019, P 12 ACM INT C WEB S, P11
   Liu YH, 2019, INFORM PROCESS MANAG, V56, P1457, DOI 10.1016/j.ipm.2018.11.003
   LIU Z., 2019, 2019 28 INT C COMP C, P1, DOI 10.1109/VTCSpring.2019.8746624
   Lu YJ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P505
   Mazumder, 2020, IMPACT RUMORS MISINF
   Mutlu EC, 2020, DATA BRIEF, V33, DOI 10.1016/j.dib.2020.106401
   Nakov P., 2019, P 2019 C EMP METH NA, P5640, DOI DOI 10.18653/V1/D19
   Pennycook G, 2020, PSYCHOL SCI, V31, P770, DOI 10.1177/0956797620939054
   Pennycook G, 2019, COGNITION, V188, P39, DOI 10.1016/j.cognition.2018.06.011
   Pham L., 2019, P 12 ACM INT C WEB S, P11
   Pisner DA., 2020, MACH LEARN, P101, DOI [10.1016/B978-0-12-815739-8.00006-7, DOI 10.1016/B978-0-12-815739-8.00006-7]
   Preslav N, 2020, ARXIV PREPRINT ARXIV
   Qin Y., 2016, ARXIV PREPRINT ARXIV
   Rohit W., 2018, INT J SCI RES COMPUT
   Saikh T., 2017, P 14 INT C NAT LANG P 14 INT C NAT LANG, P131
   Scheufele DA, 2019, P NATL ACAD SCI USA, V116, P7662, DOI 10.1073/pnas.1805871115
   Shu K, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P395, DOI 10.1145/3292500.3330935
   Shu K, 2019, PROCEEDINGS OF THE TWELFTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'19), P312, DOI 10.1145/3289600.3290994
   Simon Felix, 2020, REUTERS I
   Slovikovskaya V, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P1211
   Sotthisopha N, 2018, 2018 19TH IEEE/ACIS INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, ARTIFICIAL INTELLIGENCE, NETWORKING AND PARALLEL/DISTRIBUTED COMPUTING (SNPD), P182, DOI 10.1109/SNPD.2018.8441072
   Vaswani A, 2017, ADV NEUR IN, V30
   Vosoughi S, 2018, SCIENCE, V359, P1146, DOI 10.1126/science.aap9559
   Wang WY, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P422, DOI 10.18653/v1/P17-2067
   Wang YC, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P996
   Xiaoye S, 2019, THESIS SWISS FEDERAL
   Xiong X, 2020, KNOWL-BASED SYST, V194, DOI 10.1016/j.knosys.2020.105544
   Yang K.-C., 2019, P 12 ACM INT C WEB S
   Yang RQ, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4699
   Cuan-Baltazar JY, 2020, JMIR PUBLIC HLTH SUR, V6, P176, DOI 10.2196/18444
   Zarrabian S., 2020, BASIC CLIN NEUROSCI, P189
   Zhou D., 2016, PROF 21 C EMP METH N
   Zubiaga A, 2018, INFORM PROCESS MANAG, V54, P273, DOI 10.1016/j.ipm.2017.11.009
NR 72
TC 0
Z9 0
U1 17
U2 17
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 0306-4573
EI 1873-5371
J9 INFORM PROCESS MANAG
JI Inf. Process. Manage.
PD JAN
PY 2022
VL 59
IS 1
AR 102740
DI 10.1016/j.ipm.2021.102740
PG 18
WC Computer Science, Information Systems; Information Science & Library
   Science
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Information Science & Library Science
GA WN5TS
UT WOS:000711830600005
OA Bronze
DA 2022-02-06
ER

PT J
AU Taylor, BC
AF Taylor, Bryan C.
TI Defending the state from digital Deceit: the reflexive securitization of
   deepfake
SO CRITICAL STUDIES IN MEDIA COMMUNICATION
LA English
DT Article
DE Digital media; securitization; mimesis; ontological security; satire
AB Recent revelation of disinformation campaigns conducted by external adversaries on social media platforms has triggered anxiety among western liberal democracies. One focus of this anxiety has been the emerging technology known as deepfake. In examining related controversy, I use the theoretical lens of securitization to establish how communicative reflexivity shapes the attribution of threat to digital media. Next, focusing on the case of the U.S. government, I critique deepfake's securitization by applying two theories of media and state (in-) security. I argue that deepfake sustains the liberal state's conventional dread of mimetic threats posed to its ontological security. I then challenge this narrative by exploring satire as an alternate configuration of deepfake's capabilities. I conclude by summarizing the implications of this case for ongoing study of digital media, conflict, and politics.
C1 [Taylor, Bryan C.] Univ Colorado, Dept Commun, UCB 270, Boulder, CO 80309 USA.
C3 University of Colorado System; University of Colorado Boulder
RP Taylor, BC (corresponding author), Univ Colorado, Dept Commun, UCB 270, Boulder, CO 80309 USA.
EM bryan.taylor@colorado.edu
CR Ajder H., 2019, DEEPTRACE
   Andersen RS, 2017, SECUR DIALOGUE, V48, P354, DOI 10.1177/0967010617709875
   [Anonymous], 2019, WASHINGTON POST
   [Anonymous], 2019, REP US SEN COMM HOM
   [Anonymous], 2019, WASHINGTON POST
   [Anonymous], 2019, **NON-TRADITIONAL**
   Beavers O, 2019, HILL
   Bijker WE., 2008, INT ENCY COMMUNICATI, DOI [10.1002/9781405186407.wbiect025, DOI 10.1002/9781405186407.WBIECT025]
   Braddock K, 2019, ICA HANDB SER, P247
   Bradshaw S., 2019, GLOBAL DISINFORMATIO
   Brandom R., 2019, THE VERGE       0305
   Brown N. I., 2019, US TODAY
   Browning CS, 2017, COOP CONFL, V52, P31, DOI 10.1177/0010836716653161
   Chandler Simon, 2020, FORBES
   Chesney B., 2018, DEEP FAKES
   Christian J., 2018, THE OUTLINE
   Croft S, 2012, CONTEMP SECUR POL, V33, P219, DOI 10.1080/13523260.2012.693776
   Currie P. M., 2012, TERRORISM AFFORDANCE, P33
   Downing J., 2020, J GLOB SECUR STUD, P1
   Edenborg E, 2017, POSTCOLONIAL STUD-UK, V20, P294, DOI 10.1080/13688790.2017.1378086
   Feenberg A., 2002, TRANSFORMING TECHNOL
   Feldman B., 2019, NEW YORK MAGAZINE
   Foley J., 2019, 9 DEEPFAKE EXAMPLES
   Glass M., 1993, CITIZENS MX
   Hall I, 2014, EUR J INT RELAT, V20, P217, DOI 10.1177/1354066112445187
   Hansen L, 2011, EUR J INT RELAT, V17, P51, DOI 10.1177/1354066110388593
   HAO K, 2018, MIT
   Harrington S, 2012, JOURNALISM, V13, P38, DOI 10.1177/1464884911400847
   Hart C, 2014, INT J COMMUN-US, V8, P2860
   Hartnett SJ, 2011, Q J SPEECH, V97, P411, DOI 10.1080/00335630.2011.608705
   Hasian Marouf A., 2015, RHETORICAL INVENTION
   Hicks K., 2019, OTHER MEANS 1
   Holland EC, 2018, POP COMMUN, V16, P182, DOI 10.1080/15405702.2017.1397674
   Horowitz M.C., 2018, ARTIFICIAL INTELLIGE
   Hsu Jeremy, 2019, IEEE SPECTRUM
   Jones MO, 2017, COMMUN PUBLIC, V2, P136, DOI 10.1177/2057047317706372
   Karpf D., 2017, ANN INT COMMUNICATIO, V41, P198, DOI DOI 10.1080/23808985.2017.1316675
   Katz J. E., 2002, PERPETUAL CONTACT
   Kearns M., 2019, NATL REV
   Kwok O. J., 2020, CURR ISSUES TOUR, P1, DOI [10.1080/13683500.2020.1738357?needAccess=true, DOI 10.1080/13683500.2020.1738357?NEEDACCESS=TRUE]
   Lacy Mark, 2018, GLOBAL DISCOURSE, V8, P100, DOI DOI 10.1080/23269995.2017.1415082
   Lawson S, 2019, ICA HANDB SER, P262
   Lawson S, 2014, CAMB REV INT AFF, V27, P226, DOI 10.1080/09557571.2012.734787
   Littell J., 2019, WAR ROCKS
   Marvin C., 1988, OLD TECHNOLOGIES WER
   Meinrath SD, 2014, CRIT STUD MEDIA COMM, V31, P123, DOI 10.1080/15295036.2014.921320
   Metz Rachel, 2019, CNN
   Mirghani S, 2011, CRIT STUD MEDIA COMM, V28, P113, DOI 10.1080/15295036.2010.514933
   MISKIMMON ALISTER, 2014, STRATEGIC NARRATIVES
   Mitzen J, 2006, EUR J INT RELAT, V12, P341, DOI 10.1177/1354066106067346
   Paris B., 2019, DATA SOC, V47
   Parkin S., 2019, GUARDIAN GUARDIAN
   Parkinson H. J., 2019, GUARDIAN
   Payne R, 2013, PAST PRESENT, P3, DOI 10.1093/pastj/gtt008
   Payne RA, 2017, INT STUD PERSPECT, V18, P211, DOI 10.1093/isp/ekv026
   Potzsch H., 2017, ROUTLEDGE HDB MEDIA, P36
   Rees G., 2019, HERES DEEPFAKE TECHN
   Reid J, 2009, CAMB REV INT AFF, V22, P607, DOI 10.1080/09557570903325520
   Rice R. M., 2018, TAMARA, V16, P25
   Rothkopf J., 2020, NY TIMES
   Rumaner M, 2019, MICROMACHINES-BASEL, V10, DOI 10.3390/mi10070481
   Satter R, 2019, AP NEWS         0613
   Sayler K.M., 2019, ARTIFICIAL INTELLIGE
   Schwarzenegger C, 2018, SCM STUD COMM MEDIA, V7, P473, DOI 10.5771/2192-4007-2018-4-473
   SILVERSTONE R, 1993, MEDIA CULT SOC, V15, P573, DOI 10.1177/016344393015004004
   Silvestri L. E., 2015, FRIENDED FRONT
   Simonite Tom, 2020, WIRED
   Singer P. W., 2018, LIKEWAR
   Slack J. D., 2005, CULTURE TECHNOLOGY
   Stahl R, 2016, Q J SPEECH, V102, P376, DOI 10.1080/00335630.2016.1208365
   Stankiewicz K., 2019, CNBC
   Stanton C., 2019, CARNEGIE ENDOWMENT I
   Steele B., 2008, ONTOLOGICAL SECURITY
   Steele B. J., 2012, DEFACING POWER
   Summerville A., 2019, DEEPFAKES TRIGGER RA
   Taylor BC, 2017, COMMUN THEOR, V27, P48, DOI 10.1111/comt.12104
   Taylor PM, 2007, PLACE BRANDING PUBLI, V3, P196, DOI 10.1057/palgrave.pb.6000064
   von Boemcken M, 2019, CRIT STUD SECUR, V7, P91, DOI 10.1080/21624887.2019.1644049
   Vultee F, 2010, JOURNAL PRACT, V4, P33, DOI 10.1080/17512780903172049
   Vuori J.A., 2017, ROUTLEDGE HDB SECURI, P64
   Waddell Kaveh, 2019, AXIOS
   Waever O., 1995, SECURITY, P46
   Walsh L, 2006, J COMPUT-MEDIAT COMM, V12, P189, DOI 10.1111/j.1083-6101.2006.00321.x
   Warner Bernhard, 2019, FORTUNE
   Woods H. S., 2019, MAKE AM MEME AGAIN
   Wright M., 2019, HILL
NR 86
TC 1
Z9 1
U1 3
U2 27
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 1529-5036
EI 1479-5809
J9 CRIT STUD MEDIA COMM
JI Crit. Stud. Media Comm.
PD JAN 1
PY 2021
VL 38
IS 1
BP 1
EP 17
DI 10.1080/15295036.2020.1833058
EA OCT 2020
PG 17
WC Communication
WE Social Science Citation Index (SSCI)
SC Communication
GA QU9GN
UT WOS:000582345500001
DA 2022-02-06
ER

PT J
AU Bhattacharya, P
   Patel, SB
   Gupta, R
   Tanwar, S
   Rodrigues, JJPC
AF Bhattacharya, Pronaya
   Patel, Shivani Bharatbhai
   Gupta, Rajesh
   Tanwar, Sudeep
   Rodrigues, Joel J. P. C.
TI SaTYa: Trusted Bi-LSTM-Based Fake News Classification Scheme for Smart
   Community
SO IEEE TRANSACTIONS ON COMPUTATIONAL SOCIAL SYSTEMS
LA English
DT Article; Early Access
DE Fake news; Social networking (online); Data models; Distributed ledger;
   Stakeholders; Semantics; Security; Bi-directional long short-term memory
   (Bi-LSTM); blockchain (BC); deep learning (DL); fake news identification
ID SOCIAL MEDIA; BLOCKCHAIN
AB This article proposes a SaTya scheme that leverages a blockchain (BC)-based deep learning (DL)-assisted classifier model that forms a trusted chronology in fake news classification. The news collected from newspapers, social handles, and e-mails are web-scrapped, prepossessed, and sent to a proposed Q-global vector for word representations (Q-GloVe) model that captures the fine-grained linguistic semantics in the data. Based on the Q-GloVe output, the data are trained through a proposed bi-directional long short-term memory (Bi-LSTM) model, and the news is classified as real-or-fake news. This reduces the vanishing gradient problem, which optimizes the weights of the model and reduces bias. Once the news is classified, it is stored as a transaction, and the news stakeholders can execute smart contracts (SCs) and trace the news origin. However, only verified trusted news sources are added to the BC network, ensuring credibility in the system. For security evaluation, we propose the associated cost of the Bi-LSTM classifier and propose vulnerability analysis through the smart check tool for potential vulnerabilities. The scheme is compared against discourse-structure analysis, linguistic natural language framework, and entity-based recognition for different performance metrics. The scheme achieves an accuracy of 99.55% compared to 93.62% against discourse structure analysis. Also, it shows an average improvement of 18.76% against other approaches, which indicates its viability against fake-classifier-based models.
C1 [Bhattacharya, Pronaya; Patel, Shivani Bharatbhai; Gupta, Rajesh; Tanwar, Sudeep] Nirma Univ, Inst Technol, Dept Comp Sci & Engn, Gota 382481, Gujarat, India.
   [Rodrigues, Joel J. P. C.] Senac Fac Ceara, BR-60160194 Fortaleza, Ceara, Brazil.
   [Rodrigues, Joel J. P. C.] Inst Telecomunicacoes, P-6201001 Covilha, Portugal.
C3 Nirma University
RP Tanwar, S (corresponding author), Nirma Univ, Inst Technol, Dept Comp Sci & Engn, Gota 382481, Gujarat, India.
EM pronoya.bhattatharya@nirmauni.ac.in; 17bcc117@nirmauni.ac.in;
   18ftvphde31@nirmauni.ac.in; sudeep.tanwar@nirmauni.ac.in;
   joeljr@ieee.org
RI Tanwar, Sudeep/AAI-6709-2020; Gupta, Rajesh/AAC-8353-2020
OI Tanwar, Sudeep/0000-0002-1776-4651; Gupta, Rajesh/0000-0003-3298-4238;
   Bhattacharya, Pronaya/0000-0002-1206-2298; Rodrigues,
   Joel/0000-0001-8657-3800
FU FCT/MCTESPortuguese Foundation for Science and TechnologyEuropean
   Commission; EU funds [UIDB/50008/2020]; Brazilian National Council for
   Scientific and Technological Development (CNPq)Conselho Nacional de
   Desenvolvimento Cientifico e Tecnologico (CNPQ) [313036/2020-9]
FX This work was supported in part by FCT/MCTES through national funds and
   when applicable co-funded EU funds under Project UIDB/50008/2020 and in
   part by the Brazilian National Council for Scientific and Technological
   Development (CNPq) under Grant 313036/2020-9.
CR Ahn YC, 2019, INT JOINT CONF COMP, P289, DOI 10.1109/JCSSE.2019.8864171
   Akyol K, 2019, CMC-COMPUT MATER CON, V61, P69, DOI 10.32604/cmc.2019.08143
   Bahad P, 2019, PROCEDIA COMPUT SCI, V165, P74, DOI 10.1016/j.procs.2020.01.072
   Bodkhe U, 2020, IEEE ACCESS, V8, P54371, DOI 10.1109/ACCESS.2020.2981415
   Choudhary M, 2021, APPL SOFT COMPUT, V110, DOI 10.1016/j.asoc.2021.107614
   de Oliveira NR, 2021, INFORMATION, V12, DOI 10.3390/info12010038
   Devlin J, 2019, PROC C N AM CHAPTER, P4171, DOI DOI 10.18653/V1/N19-1423
   Dey A, 2018, 2018 JOINT 7TH INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS & VISION (ICIEV) AND 2018 2ND INTERNATIONAL CONFERENCE ON IMAGING, VISION & PATTERN RECOGNITION (ICIVPR), P305, DOI 10.1109/ICIEV.2018.8641018
   Fraga-Lamas P, 2020, IT PROF, V22, P53, DOI 10.1109/MITP.2020.2977589
   He YQ, 2020, MICROPROCESS MICROSY, V75, DOI 10.1016/j.micpro.2020.103058
   Ishida Y, 2018, PROCEDIA COMPUT SCI, V126, P2228, DOI 10.1016/j.procs.2018.07.226
   Kaliyar RK, 2020, COGN SYST RES, V61, P32, DOI 10.1016/j.cogsys.2019.12.005
   Kesarwani A, 2020, PROCEEDINGS OF THE 2020 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING AND COMMUNICATION ENGINEERING (ICACCE-2020)
   Kian Long Tan, 2021, 2021 9th International Conference on Information and Communication Technology (ICoICT), P331, DOI 10.1109/ICoICT52021.2021.9527500
   Kim KH, 2019, INT JOINT CONF COMP, P209, DOI 10.1109/JCSSE.2019.8864154
   Leonardi S, 2021, INFORMATION, V12, DOI 10.3390/info12060248
   Nyow NX, 2019, 2019 IEEE CONFERENCE ON APPLICATION, INFORMATION AND NETWORK SECURITY (AINS), P24, DOI 10.1109/AINS47559.2019.8968706
   Ozbay FA, 2020, PHYSICA A, V540, DOI 10.1016/j.physa.2019.123174
   Patel SB, 2021, IEEE T NETW SCI ENG, V8, P1044, DOI 10.1109/TNSE.2020.3005678
   Paul S, 2019, 2019 7TH INTERNATIONAL CONFERENCE ON SMART COMPUTING & COMMUNICATIONS (ICSCC), P250
   Shae ZY, 2019, INT CON DISTR COMP S, P1610, DOI 10.1109/ICDCS.2019.00160
   Singh S. K., IEEE CONSUM ELECTR M, DOI [10.1109/MCE.2021.3089992, DOI 10.1109/MCE.2021.3089992]
   Singh SK, 2021, HUM-CENT COMPUT INFO, V11, DOI 10.22967/HCIS.2021.11.012
   Sureshbhai PN, 2020, IEEE INT CONF COMM
   Traylor T, 2019, IEEE INT C SEMANT CO, P445, DOI [10.1109/ICOSC.2019.8665593, 10.1109/ICSC.2019.00086]
   Uppal A, 2020, PROCEEDINGS OF THE CONFLUENCE 2020: 10TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE & ENGINEERING, P751, DOI 10.1109/Confluence47617.2020.9058106
   Vishwakarma DK, 2019, COGN SYST RES, V58, P217, DOI 10.1016/j.cogsys.2019.07.004
   Vivar AL, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22020203
   Xiang LY, 2020, INTELL AUTOM SOFT CO, V26, P1375, DOI 10.32604/iasc.2020.013382
   Xu K, 2020, TSINGHUA SCI TECHNOL, V25, P20, DOI 10.26599/TST.2018.9010139
   Yin LB, 2019, CMC-COMPUT MATER CON, V60, P275, DOI 10.32604/cmc.2019.05556
   Zhang CW, 2019, EUR J OPER RES, V279, P1036, DOI 10.1016/j.ejor.2019.06.022
NR 32
TC 0
Z9 0
U1 1
U2 1
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2329-924X
J9 IEEE T COMPUT SOC SY
JI IEEE Trans. Comput. Soc. Syst.
DI 10.1109/TCSS.2021.3131945
EA DEC 2021
PG 10
WC Computer Science, Cybernetics; Computer Science, Information Systems
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XT3KN
UT WOS:000733491000001
DA 2022-02-06
ER

PT J
AU Meel, P
   Vishwakarma, DK
AF Meel, Priyanka
   Vishwakarma, Dinesh Kumar
TI HAN, image captioning, and forensics ensemble multimodal fake news
   detection
SO INFORMATION SCIENCES
LA English
DT Article
DE Fake news detection; Hierarchical attention network; Image captioning;
   Ensemble; Multimodal data analysis
ID CREDIBILITY; INFORMATION
AB Nowadays, news publication, propagation, and consumption have been diverted to online social media networks and web portals, which has given rise to falsified and fabricated news articles containing both textual and visual information formats. Most of the research to date is centered on textual fake news detection using machine learning approaches, where multimedia data forgery is hardly addressed. Hence, a multimodal fake news detection framework is proposed, which unitedly exploits hidden pattern extraction capabilities from text using Hierarchical Attention Network (HAN) and visual image features using image captioning and forensic analysis. We specifically focused on four different techniques of multimodal data analysis, such as HAN deep model for text, generating image caption and headline matching with news text (CHM), Noise Variance Inconsistency (NVI), and Error Level Analysis (ELA). All these algorithms have been tested, first independently and then collectively using the max voting Ensemble method on three different datasets. The experimental results and comparisons with contemporary techniques put forward the fact that the proposed method outperforms state-of-the-art with 95.90% highest accuracy on the Fake News Samples dataset. The achieved results also prove that the combined model beats individual methods' capabilities in classifying fake news accurately.
   (c) 2021 Elsevier Inc. All rights reserved.
C1 [Meel, Priyanka; Vishwakarma, Dinesh Kumar] Delhi Technol Univ, Dept Informat Technol, Biometr Res Lab, New Delhi 110042, India.
C3 Delhi Technological University
RP Vishwakarma, DK (corresponding author), Delhi Technol Univ, Dept Informat Technol, Biometr Res Lab, New Delhi 110042, India.
EM priyankameel@dtu.ac.in; dinesh@dtu.ac.in
RI Vishwakarma, Dinesh/L-3815-2018
OI Vishwakarma, Dinesh/0000-0002-1026-0047
CR Agarwalla K., 2019, INT J RECENT TECHNOL, V7, P844
   Ajao O., 2018, P 9 INT C SOC MED SO P 9 INT C SOC MED SO
   AMRITKAR C, 2018, 2018 4 INT C COMP, pNI153
   Bian JW, 2015, IEEE T MULTIMEDIA, V17, P216, DOI 10.1109/TMM.2014.2384912
   Bondielli A, 2019, INFORM SCIENCES, V497, P38, DOI 10.1016/j.ins.2019.05.035
   Del Vicario M, 2019, ACM T WEB, V13, DOI 10.1145/3316809
   Gao J, 2018, P 24 ACM SIGKDD INT
   Huh M, 2018, LECT NOTES COMPUT SC, V11215, P106, DOI 10.1007/978-3-030-01252-6_7
   Indu V, 2019, J NETW COMPUT APPL, V125, P28, DOI 10.1016/j.jnca.2018.10.003
   Jin ZW, 2017, IEEE T MULTIMEDIA, V19, P598, DOI 10.1109/TMM.2016.2617078
   Kaufhold MA, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102132
   Krawetz, 2007, PICTURES WORTH DIGIT
   Kudugunta S, 2018, INFORM SCIENCES, V467, P312, DOI 10.1016/j.ins.2018.08.019
   Lago F., 2019, SECUR COMMUN NETWORK, P1
   Li CL, 2019, INFORM SCIENCES, V504, P61, DOI 10.1016/j.ins.2019.06.060
   Li F.-F, 2013, AUTOMATED IMAGE CAPT
   Li J, 2019, IEEE INT C DATA MINI
   Luo J, 2017, P 25 ACM INT C MULT
   Meel P, 2020, EXPERT SYST APPL, V153, DOI 10.1016/j.eswa.2019.112986
   Mossie Z, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102087
   Pandian V. A., 2018, INT J PURE APPL MATH, V118, P3787
   Pasi G, 2019, INFORM SCIENCES, V503, P574, DOI 10.1016/j.ins.2019.07.037
   Qiu JT, 2019, INFORM SCIENCES, V489, P274, DOI 10.1016/j.ins.2019.03.041
   Reis JCS, 2019, IEEE INTELL SYST, V34, P76, DOI 10.1109/MIS.2019.2899143
   Saad S, 2018, SECUR PRIVACY, P1
   Sharma K, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3305260
   Singhal S, 2019, 2019 IEEE FIFTH INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2019), P39, DOI [10.1109/BigMM.2019.00018, 10.1109/BigMM.2019.00-44]
   Tang J, 2019, 2019 C N AM CHAPT AS
   Tutorials D, 2020, WEB SCRAPPING PYTHON
   Varma V, 2019, WORLD WID WEB C SA
   Vishwakarma DK, 2019, COGN SYST RES, V58, P217, DOI 10.1016/j.cogsys.2019.07.004
   Wu LW, 2020, INFORM SCIENCES, V516, P453, DOI 10.1016/j.ins.2019.12.040
   Yang CF, 2016, IEEE IC COMP COM NET
   Zahra K, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102107
   Zannettou S, 2019, ACM J DATA INF QUAL, V11, DOI 10.1145/3309699
   Zhang XC, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.03.004
NR 36
TC 2
Z9 2
U1 8
U2 14
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 0020-0255
EI 1872-6291
J9 INFORM SCIENCES
JI Inf. Sci.
PD AUG
PY 2021
VL 567
BP 23
EP 41
DI 10.1016/j.ins.2021.03.037
PG 19
WC Computer Science, Information Systems
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA SP7WP
UT WOS:000659875500002
DA 2022-02-06
ER

PT J
AU Kiruthika, S
   Masilamani, V
AF Kiruthika, S.
   Masilamani, V
TI Image quality assessment based fake face detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image forgery; Image quality assessment; Random forest; Deepfake; Face
   forensics; Face detection
ID STATISTICS
AB The tremendous growth of data in social media and other platforms has raised an interesting question of authenticity. It has led to an active research area named Digital Forensics. Especially, the face manipulation has become a major issue in character assassination. The image forgery tools are improving everyday thereby posing a challenge in detection systems. The current detection systems provide deep learning based solutions which do not bring the reliability and also have chance to fail when different forgery tool is developed to synthesise or edit the face image. Therefore, an efficient system is required which gives explainability along with efficacy. In this paper, we propose a novel method to detect the forged faces using Image Quality Assessment(IQA) based features. As far as we know IQA has not been used for detecting AI generated images. Despite the visual appearance being same for original and fake images, most of the discriminative information will be available in the frequency domain of those images. With that intuition we have extracted image quality based features from frequency domain and also spatial domain. The proposed method has achieved the highest accuracy of 99% when different types of experiments were performed on standard datasets. The generalisation and explainability of the proposed model have also been discussed.
C1 [Kiruthika, S.; Masilamani, V] Indian Inst Informat Technol Design & Mfg, Kancheepuram, India.
RP Kiruthika, S (corresponding author), Indian Inst Informat Technol Design & Mfg, Kancheepuram, India.
EM coe18d003@iiitdm.ac.in; masila@iiitdm.ac.in
CR Akhtar Z, 2019, 2019 IEEE INT S TECH, P1
   Amerini I, 2019, IEEE INT CONF COMP V, P1205, DOI 10.1109/ICCVW.2019.00152
   Bakshi A, 2020, MULTIMED TOOLS APPL, DOI 10.1007/s11042-020-10045-x
   Bappy JH, 2017, IEEE I CONF COMP VIS, P4980, DOI 10.1109/ICCV.2017.532
   Cao Q, 2018, IEEE INT CONF AUTOMA, P67, DOI 10.1109/FG.2018.00020
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Cristin R, 2018, IET IMAGE PROCESS, V12, P1439, DOI 10.1049/iet-ipr.2017.1120
   Dang H, 2020, PROC CVPR IEEE, P5780, DOI 10.1109/CVPR42600.2020.00582
   De K, 2017, MULTIMED TOOLS APPL, V76, P18641, DOI 10.1007/s11042-016-4335-9
   De K, 2013, PROCEDIA ENGINEER, V64, P149, DOI 10.1016/j.proeng.2013.09.086
   Fei JW, 2021, MULTIMED TOOLS APPL, V80, P30789, DOI 10.1007/s11042-020-09147-3
   Fernando T, 2019, ARXIV191107844
   Fourati E, 2020, MULTIMED TOOLS APPL, V79, P865, DOI 10.1007/s11042-019-08115-w
   Galbally J, 2014, IEEE ACCESS, V2, P1530, DOI 10.1109/ACCESS.2014.2381273
   Galbally J, 2014, IEEE T IMAGE PROCESS, V23, P710, DOI 10.1109/TIP.2013.2292332
   Galbally J, 2012, FUTURE GENER COMP SY, V28, P311, DOI 10.1016/j.future.2010.11.024
   Guan HY, 2019, IEEE WINT CONF APPL, P63, DOI 10.1109/WACVW.2019.00018
   Guera D, 2018, 2018 15TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P127
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hsu CC, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10010370
   Karras Tero, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8107, DOI 10.1109/CVPR42600.2020.00813
   Khalid Hasam, 2020, P IEEE CVF C COMP VI, P656
   Korshunova I, 2017, IEEE I CONF COMP VIS, P3697, DOI 10.1109/ICCV.2017.397
   Korus P, 2017, DIGIT SIGNAL PROCESS, V71, P1, DOI 10.1016/j.dsp.2017.08.009
   Li J, 2019, ARXIV191205790
   Li LZ, 2020, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR42600.2020.00505
   Li XR, 2020, WWW'20: COMPANION PROCEEDINGS OF THE WEB CONFERENCE 2020, P88, DOI 10.1145/3366424.3382711
   [李艳歌 Li Yange], 2018, [高分子通报, Polymer Bulletin], P46
   Liu LX, 2014, SIGNAL PROCESS-IMAGE, V29, P494, DOI 10.1016/j.image.2014.02.004
   Lundberg SM, 2017, ADV NEUR IN, V30
   Matern F, 2019, IEEE WINT CONF APPL, P83, DOI 10.1109/WACVW.2019.00020
   McCloskey Scott, 2018, ARXIV181208247
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mo HX, 2018, PROCEEDINGS OF THE 6TH ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY (IH&MMSEC'18), P43, DOI 10.1145/3206004.3206009
   Nataraj L, 2019, ELECT IMAGING, V2019, P532, DOI DOI 10.2352/ISSN.2470-1173.2019.5.MWSF-532
   Neves JC, 2019, ARXIV191105351
   Nguyen HH, 2019, INT CONF ACOUST SPEE, P2307, DOI 10.1109/ICASSP.2019.8682602
   Nhu T, 2018, P 2018 INT S INF TEC
   Rana MS, 2020, 2020 7TH IEEE INTERNATIONAL CONFERENCE ON CYBER SECURITY AND CLOUD COMPUTING (CSCLOUD 2020)/2020 6TH IEEE INTERNATIONAL CONFERENCE ON EDGE COMPUTING AND SCALABLE CLOUD (EDGECOM 2020), P70, DOI 10.1109/CSCloud-EdgeCom49738.2020.00021
   Kiruthika S, 2021, IET IMAGE PROCESS, DOI 10.1049/ipr2.12209
   Simonyan K, 2015, ICLR 2015, DOI DOI 10.1109/CVPR.2015.7298594
   Tariq S, 2018, MPS'18: PROCEEDINGS OF THE 2ND INTERNATIONAL WORKSHOP ON MULTIMEDIA PRIVACY AND SECURITY, P81, DOI 10.1145/3267357.3267367
   Thies J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323035
   Thies J, 2016, PROC CVPR IEEE, P2387, DOI 10.1109/CVPR.2016.262
   Wang R, 2019, ARXIV PREPRINT ARXIV
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P4850, DOI 10.1109/TIP.2014.2355716
   Yang X, 2019, INT CONF ACOUST SPEE, P8261, DOI 10.1109/ICASSP.2019.8683164
   Yeh CH, 2018, IEEE WINT CONF APPL, P49, DOI 10.1109/WACV.2018.00012
   Yi D., 2014, ARXIV14117923
   Zhang Y, 2017, 2017 IEEE 2ND INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP), P15, DOI 10.1109/SIPROCESS.2017.8124497
NR 50
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
DI 10.1007/s11042-021-11493-9
EA JAN 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XZ6EB
UT WOS:000737741900014
DA 2022-02-06
ER

PT J
AU Mihailova, M
AF Mihailova, Mihaela
TI To Dally with Dali: Deepfake (Inter)faces in the Art Museum
SO CONVERGENCE-THE INTERNATIONAL JOURNAL OF RESEARCH INTO NEW MEDIA
   TECHNOLOGIES
LA English
DT Article
DE curatorial studies; emerging media; James Coupe; museum studies;
   Salvador Dali; deepfakes; Gillian Wearing; algorithmic culture
AB This essay focuses on the nascent symbiotic relationship between deepfakes and art museums and galleries, as demonstrated by three case studies. The first one, housed at the Dali Museum in St Petersburg, Florida, is a life-size talking avatar of the artist generated from archival footage. The second one, Warriors by James Coupe, revisits Walter Hill's 1979 film of the same name using deepfake algorithms to insert visitors' faces into key scenes, sorting them into gangs based on data-driven analysis of their demographic and economic markers. Finally, Gillian Wearing's fake ad, Wearing Gillian, uses deepfake technology to enable a series of actors to appear on screen with the artist's face as a way of interrogating questions of identity in a networked digital world. Based on these works, my article examines museums' employment of deepfakes for advertising, audience engagement, and educational outreach, and the curatorial, ethical, and creative opportunities and challenges involved therein. While deepfake esthetics will be discussed wherever relevant, this is not a formalist analysis; my goal is not to focus on close readings of the deepfake pieces themselves, however fascinating their esthetics. Instead, I will look at the promotional and critical discourse around them in order to unpack the ways in which the acquisition of creative deepfake works by cultural institutions functions as a legitimizing force that is already shifting the narrative regarding the artistic value and social functions of this technology.
C1 [Mihailova, Mihaela] San Francisco State Univ, Sch Cinema, 1010 Catherine St,Apt 404, San Francisco, CA 48104 USA.
C3 California State University System; San Francisco State University
RP Mihailova, M (corresponding author), San Francisco State Univ, Sch Cinema, 1010 Catherine St,Apt 404, San Francisco, CA 48104 USA.
EM mihaela.mihailova88@gmail.com
OI Mihailova, Mihaela/0000-0002-3083-946X
CR Ames M., 2020, NATL NEWS 0303
   Anderson, 2014, PRESERVING COMPLEX D, P73
   Antonelli P., 2012, INSIDE OUT 1129
   Baraniuk C, 2016, BBC 0406
   Beer, 2018, FAST CO
   Belting Hans, 2017, FACE MASK DOUBLE HIS
   BLEWER A., 2019, OPEN INFORM SCI, V3, P32, DOI DOI 10.1515/OPIS-2019-0003
   Cooke, 2020, ROUTLEDGE INT HDB NE, P319
   Cooke, 2020, ROUTLEDGE INT HDB NE, P68
   Cooper M., 2020, INT CTR PHOTOGR 0113
   Coupe J., 2020, WITNESS MEDIA L 0924
   Debruge, 2016, VARIETY
   Dunne JE., 2018, CINCINNATI ART 0723
   Eadicicco, 2019, BUSINESS INSIDER
   Faber T., 2014, FINANCIAL TIMES 0819
   Farago J, 2020, NEW YORK TIMES
   Ferranto M, 2015, DES CULT, V7, P203, DOI 10.1080/17547075.2015.1051827
   Griffiths, 2008, SHIVERS YOUR SPINE C
   Henning, 2020, MUSEUM MEDIA, P69
   Henning, 2020, MUSEUM MEDIA, P603
   Henning, 2006, MUSEUMS MEDIA CULTUR
   Henning M., 2020, MUSEUM MEDIA, P235
   Kietzmann TC., 2020, CONVERSATION 0212
   Kneese T., 2020, SLATE MAGAZINE 1102
   Kozinn, 2012, NEW YORK TIMES
   Kuhn S, 2019, MOL PSYCHIATR, V24, P1220, DOI 10.1038/s41380-018-0031-7
   Lanson K., 2020, ROUTLEDGE COMPANION, P174
   Lee D., 2019, VERGE 0510
   Merritt E., 2019, AM ALLIANCE MUS 0510
   Museum of Jewish Heritage, 2021, DIM TEST
   Richtel M., 2021, NEW YORK TIMES
   Saarikoski P., 2013, MAKING HIST COMPUTIN, V416, P226
   Savenije GM, 2017, INT J HERIT STUD, V23, P832, DOI 10.1080/13527258.2017.1339108
   Schroder KC., 2018, ROUTLEDGE HDB MUSEUM, P31
   Smith A., 2020, INDEPENDENT
   Stroud, 2019, ETHICS COMPUTER GENE
   The Dal? Museum, 2019, YOUTUBE
   Toews, 2020, FORBES
   Uchida M., 2019, AI MORE HUMAN, P125
   Waite T., 2019, DAZED DIGITAL
   Wang H., 2018, PRIMER
   Watson S., 2010, MUSEUM MAT, P204
   Yerebakan OC., 2018, BROOKLYN RAIL 1108
   Zhou, 2018, CNET
NR 44
TC 0
Z9 0
U1 4
U2 4
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 1354-8565
EI 1748-7382
J9 CONVERGENCE-US
JI Convergence
PD AUG
PY 2021
VL 27
IS 4
SI SI
BP 882
EP 898
AR 13548565211029401
DI 10.1177/13548565211029401
EA JUL 2021
PG 17
WC Communication
WE Social Science Citation Index (SSCI)
SC Communication
GA UK7UP
UT WOS:000677802000001
DA 2022-02-06
ER

PT J
AU Rodrigues, UM
   Xu, J
AF Rodrigues, Usha M.
   Xu, Jian
TI Regulation of COVID-19 fake news infodemic in China and India
SO MEDIA INTERNATIONAL AUSTRALIA
LA English
DT Article
DE China; COVID-19; fake news; free speech; government regulation; India;
   social media
ID SOCIAL MEDIA
AB During the recent outbreak of coronavirus, the concern about proliferation of misleading information, rumours and myths has caused governments across the world to institute various interventionist steps to stem their flow. Each government has had to balance the dichotomy between freedom of expression and people's right to be safe from the adverse impact of inaccurate information. Governments across the world have implemented a number of strategies to manage COVID-19 including issuing public advisories, advertising campaigns, holding press conferences and instituting punitive regulations to combat the distribution of false and misleading information. We examine the two most populous countries' governments' response to the scourge of fake news during COVID-19. China and India are the most challenging nations to govern in terms of their sheer size and diversity of their population. Each country's government has taken several steps to minimise the impact of fake news during COVID, within its own political system.
C1 [Rodrigues, Usha M.; Xu, Jian] Deakin Univ, Melbourne Burwood Campus,221 Burwood Highway, Burwood, Vic 3125, Australia.
C3 Deakin University
RP Rodrigues, UM (corresponding author), Deakin Univ, Melbourne Burwood Campus,221 Burwood Highway, Burwood, Vic 3125, Australia.
EM usha.rodrigues@deakin.edu.au
RI Rodrigues, Usha/AAT-1094-2021
OI Rodrigues, Usha/0000-0003-4688-4625; Xu, Jian/0000-0003-2798-0996
CR AccessNow, 2019, CIV SOC WHO LETS END
   Berger Miriam, 2019, WASH POST
   Chilappa M, 2020, SLATE
   Chinanews.com, 2020, CHINANEWS       0130
   CNNIC, 2020, 45 STAT REP CHIN INT
   Coronavirus.jhu.edu, 2020, COVID 19 DASHB CTR S
   CPJ.org, 2020, IND SUPR COURT DEN G
   Datareportal, 2020, DIG 2020 IND
   Figoureux M, 2020, CRIT STUD TERROR, V13, P237, DOI 10.1080/17539153.2020.1714415
   Funke D., 2019, GUIDE ANTIMISINFORMA
   Gunther R, 2018, TRUMP MAY OWE HIS 20
   Lewis SC, 2018, MEDIA COMMUN-LISBON, V6, P11, DOI 10.17645/mac.v6i4.1562
   Mohan R., 2020, STRAITS TIMES
   Nazmi S, 2019, BBC NEWS
   Paul K., 2019, GUARDIAN
   PTI, 2020, EC TIMES
   Qianlong.com, 2020, QIANLONG        0502
   Qiu S, 2018, CHINA LAUNCHES PLATF
   Rochefort A, 2020, COMMUN LAW POLICY, V25, P225, DOI 10.1080/10811680.2020.1735194
   Rodrigues UM, 2019, INT J MEDIA CULT POL, V15, P361, DOI 10.1386/macp_00006_1
   Rodrigues UM, 2019, GLOB MEDIA COMMUN, V15, P151, DOI 10.1177/1742766519848266
   RSF, 2020, WORLD PRESS FREED IN
   Sina.com, 2020, SINA            0206
   SINGH Manish, 2020, TECHCRUNCH
   Statista.com, 2020, DIG POP IND JAN 2020
   Statista.com, 2020, LEAD APPS MONTHL ACT
   Tkacheva Olesya, 2013, INTERNET FREEDOM POL
   TRAI.gov.in, 2020, HIGHL TEL SUBSCR DAT
   UNDP.org, 2020, UNDP GOV MUST LEAD F
   Vaidhyanathan Siva., 2018, ANTISOCIAL MEDIA FAC
   Xinhuanet.com, 2019, MULT STAK COLL CRACK
   Xu J., 2018, CHINESE SOCIAL MEDIA, P221
   Xu Jian, 2016, MEDIA EVENTS WEB 2 0
   Zakrzewski C., 2020, WASHINGTON POST
NR 34
TC 13
Z9 14
U1 8
U2 31
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 1329-878X
EI 2200-467X
J9 MEDIA INT AUST
JI Media Int. Aust.
PD NOV
PY 2020
VL 177
IS 1
SI SI
BP 125
EP 131
AR 1329878X20948202
DI 10.1177/1329878X20948202
EA AUG 2020
PG 7
WC Communication
WE Social Science Citation Index (SSCI)
SC Communication
GA OC4ND
UT WOS:000560422100001
OA hybrid
DA 2022-02-06
ER

PT J
AU Kumari, R
   Ekbal, A
AF Kumari, Rina
   Ekbal, Asif
TI AMFB: Attention based multimodal Factorized Bilinear Pooling for
   multimodal Fake News Detection
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Multimodal fake news detection; Deep learning; Attention mechanism;
   Multimodal Feature fusion; Multimodal Factorized Bilinear Pooling
ID FEATURES
AB Fake news is the information or stories that are intentionally created to deceive or mislead the readers. In recent times, Fake news detection has attracted the attention of researchers and practitioners due to its many-fold benefits, including bringing in preventive measures to tackle the dissemination of misinformation that could otherwise disturb the social fabrics. Social media in recent times are heavily loaded with multimedia news and information. People prefer online news reading and find it more informative and convenient if they have access to multimedia content in the forms of text, images, audio, and videos. In early studies, researchers have proposed several fake news detection mechanisms that mostly utilize the textual features and not proper to learn multimodal (textual + visual) shared representation. To overcome these limitations, in this paper, we propose a multimodal fake news detection framework with appropriate multimodal feature fusion that leverages information from text and image and tries to maximize the correlation between them to get the efficient multimodal shared representation. We empirically show that text, when combined with the image, can improve the performance of the model. The model detects the post once it is introduced into the network in an early stage. At the early stage of a news post's introduction into the network, the model takes the text and image of the post as input and decides whether this is fake or genuine. Since this model only analyzes news contents, It does not require any prior information regarding the user and network details. This framework has four different sub-modules viz. Attention Based Stacked Bidirectional Long Short Term Memory (ABS-BiLSTM) for textual feature representation, Attention Based Multilevel Convolutional Neural Network-Recurrent Neural Network (ABM-CNN-RNN) for visual feature extraction, multimodal Factorized Bilinear Pooling (MFB) for feature fusion and finally Multi-Layer Perceptron (MLP) for the classification. We perform experiments on two publicly available datasets, viz. Twitter and Weibo. Evaluation results show the efficacy of our proposed approach that performs significantly better compared to the state-of-the-art models. It shows to outperform the current state-of-the-art by approximately 10 points for the Twitter dataset. In contrast, the Weibo dataset achieves an overall better performance with balanced F1-scores between fake and real classes. Furthermore, the complexity of our proposed model is significantly lower than the state-of-the-art.
C1 [Kumari, Rina; Ekbal, Asif] Indian Inst Technol Patna, Dept Comp Sci & Engn, Bihta, India.
C3 Indian Institute of Technology (IIT) - Patna
RP Kumari, R (corresponding author), Indian Inst Technol Patna, Dept Comp Sci & Engn, Bihta, India.
EM rina_1921cs13@iitp.ac.in; asif@iitp.ac.in
OI Kumari, Rina/0000-0002-1590-4673
FU Wipro
FX The authors gratefully acknowledge the project "HELIOS-Hate,
   Hyperpartisan, and Hyperpluralism Elicitation and Observer System",
   sponsored by Wipro.
CR Alkhodair SA, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.02.016
   Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   Faustini PHA, 2020, EXPERT SYST APPL, V158, DOI 10.1016/j.eswa.2020.113503
   BOIDIDOU C, 2015, MEDIAEVAL
   Castillo C., 2011, WWW, P675
   Chauhan D. S., 2019, P 2019 C EMP METH NA, P5651
   Chauhan H, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5437
   Church KW, 2017, NAT LANG ENG, V23, P155, DOI 10.1017/S1351324916000334
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Devlin J, 2019, PROC C N AM CHAPTER, P4171, DOI DOI 10.18653/V1/N19-1423
   Fukui Akira, 2016, ARXIV160601847, P457, DOI DOI 10.18653/V1/D16-1044
   Ghosal D., 2018, P 2018 C EMP METH NA, P3454, DOI DOI 10.18653/V1/D18-1382
   Gilda S, 2017, IEEE ST CONF RES DEV, P110, DOI 10.1109/SCORED.2017.8305411
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Gravanis G, 2019, EXPERT SYST APPL, V128, P201, DOI 10.1016/j.eswa.2019.03.036
   Huang SJ, 2018, CANCER GENOM PROTEOM, V15, P41, DOI 10.21873/cgp.20063
   Huang YF, 2020, EXPERT SYST APPL, V159, DOI 10.1016/j.eswa.2020.113584
   Jin ZW, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P795, DOI 10.1145/3123266.3123454
   Jin ZW, 2017, IEEE T MULTIMEDIA, V19, P598, DOI 10.1109/TMM.2016.2617078
   Jin ZW, 2014, IEEE DATA MINING, P230, DOI 10.1109/ICDM.2014.91
   Jun SH, 2017, ICEC'17: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON ELECTRONIC COMMERCE, DOI 10.1145/3154943.3154947
   Karimi H., P 27 INT C COMP LING, P1546
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Khanzadi P, 2017, 2017 IEEE 4TH INTERNATIONAL CONFERENCE ON KNOWLEDGE-BASED ENGINEERING AND INNOVATION (KBEI), P440, DOI 10.1109/KBEI.2017.8325017
   Khattar D, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P2915, DOI 10.1145/3308558.3313552
   Kwon S, 2013, IEEE DATA MINING, P1103, DOI 10.1109/ICDM.2013.61
   Liu YH, 2019, INFORM PROCESS MANAG, V56, P1457, DOI 10.1016/j.ipm.2018.11.003
   Liu YC, 2019, NEUROCOMPUTING, V366, P276, DOI 10.1016/j.neucom.2019.08.013
   Ma J., 2016, P 25 INT JOINT C ART, P3818
   Potthast M, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P231
   Rashkin Hannah, 2017, P 2017 C EMPIRICAL M, P2931
   Reiter E., 1997, Natural Language Engineering, P57, DOI 10.1017/S1351324997001502
   Rish I., 2001, IJCAI 2001 WORKSHOP, V3, P41
   Rubin V., 2016, P 2 WORKSH COMP APPR, P7, DOI DOI 10.18653/V1/W16-0802
   Ruchansky N, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P797, DOI 10.1145/3132847.3132877
   Shaha Manali, 2018, 2018 Second International Conference on Electronics, Communication and Aerospace Technology (ICECA), P656, DOI 10.1109/ICECA.2018.8474802
   Shen H, 2017, NEUROCOMPUTING, V225, P49, DOI 10.1016/j.neucom.2016.11.013
   Shu K, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P395, DOI 10.1145/3292500.3330935
   Shu K, 2019, PROCEEDINGS OF THE TWELFTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'19), P312, DOI 10.1145/3289600.3290994
   Singhal S, 2019, 2019 IEEE FIFTH INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2019), P39, DOI [10.1109/BigMM.2019.00018, 10.1109/BigMM.2019.00-44]
   Song Yan-Yan, 2015, Shanghai Arch Psychiatry, V27, P130, DOI 10.11919/j.issn.1002-0829.215044
   Tian D.P., 2013, INT J MULTIMEDIA UBI, V8, P385
   Wang YQ, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P849, DOI 10.1145/3219819.3219903
   Wu LW, 2020, INFORM SCIENCES, V516, P453, DOI 10.1016/j.ins.2019.12.040
   Yang J., 2018, 32 AAAI C ART INT
   Yang Z., 2016, NAACL HLT, P1480
   Yu Z, 2017, IEEE I CONF COMP VIS, P1839, DOI 10.1109/ICCV.2017.202
   Zhang HW, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1942, DOI 10.1145/3343031.3350850
   Zhang PP, 2017, IEEE I CONF COMP VIS, P202, DOI 10.1109/ICCV.2017.31
   Zhang ZH, 2016, ANN TRANSL MED, V4, DOI 10.21037/atm.2016.03.37
   Zhong ZL, 2017, INT GEOSCI REMOTE SE, P1824, DOI 10.1109/IGARSS.2017.8127330
   Zubiaga A, 2018, INFORM PROCESS MANAG, V54, P273, DOI 10.1016/j.ipm.2017.11.009
NR 52
TC 1
Z9 1
U1 18
U2 18
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD DEC 1
PY 2021
VL 184
AR 115412
DI 10.1016/j.eswa.2021.115412
PG 12
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic; Operations Research & Management Science
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Operations Research & Management Science
GA UR7VO
UT WOS:000696952300006
DA 2022-02-06
ER

PT J
AU Pavis, M
AF Pavis, Mathilde
TI Rebalancing our regulatory response to Deepfakes with performers' rights
SO CONVERGENCE-THE INTERNATIONAL JOURNAL OF RESEARCH INTO NEW MEDIA
   TECHNOLOGIES
LA English
DT Article
DE Deepfakes; performers' rights; intellectual property; law; performer;
   performance synthetisation; digital avatars; United Kingdom
ID DEEP FAKES; LEGAL; PROTECTION
AB Law experts have been actively looking for solutions within the law to control Deepfakes since their emergence in 2017. This article puts forward performers' rights as a suitable regulatory tool for Deepfakes, defined as synthetic performances produced using artificial intelligence systems. In many respects, performers' rights represent a more sophisticated response to the challenges posed by Deepfake technology compared to existing legal remedies and reform proposals introduced to regulate Deepfakes. In making its case for performers' rights as suitable regulatory response to Deepfakes, this article uncovers a tension: performers' rights are an attractive solution to regulate Deepfakes but this technology challenges their scope of application. This is because Deepfakes uses content protected by performers' rights (performances) in a way unforeseen by intellectual property policy-makers at the time these rights were introduced into law. Despite this limitation, performers' rights remain one of the most attractive legal remedies in regulating Deepfakes, if adequately reformed. This article proposes two routes for the reform of performers' rights to address this gap. The first involves an ad hoc modification of performers' rights to ensure that performances manipulated by Deepfakes are covered. The second and preferred recommendation replaces the regime of performers' rights with a regime of performers' copyright. This small, yet important, change in legal regimes can be the difference between piecemeal, uneven and, therefore, ineffective protection against unauthorized Deepfakes and a harmonized international approach to the technology.
C1 [Pavis, Mathilde] Univ Exeter, Amory Bldg,Rennes Dr,Streatham Campus, Exeter EX4 4RJ, Devon, England.
C3 University of Exeter
RP Pavis, M (corresponding author), Univ Exeter, Amory Bldg,Rennes Dr,Streatham Campus, Exeter EX4 4RJ, Devon, England.
EM m.pavis@exeter.ac.uk
CR Arnold, 2016, PERFORMERS RIGHTS
   Bliss L, 2019, J CRIM LAW, V83, P217, DOI 10.1177/0022018319829262
   Blythe SM, 2019, EUR INTELL PROP R, V41, P70
   Bode L, 2021, CONVERGENCE-US, V27, P919, DOI 10.1177/13548565211030454
   Caldera E, 2019, SETON HALL LAW REV, V50, P177
   Carty H., 2012, IPQ, V2, P106
   Chesney B, 2019, CALIF LAW REV, V107, P1753, DOI 10.15779/Z38RV0D15J
   Citron Danielle Keats, 2019, MARYLAND LAW REV, V78, P883
   Coors C, 2015, COMMS L, V20, P72
   Deazley, 2017, COPYRIGHT DIGITAL CU
   Deazley R, 2003, NORTH IREL LEG Q, V54, P99
   Defaux T, 2018, EUR INTELL PROP R, V40, P539
   Delfino RA, 2020, ACTUAL PROBLEMS EC L, V1, P150
   Edwards L, 2013, HUM-COMPUT INT-SPRIN, P115, DOI 10.1007/978-3-319-01631-3_7
   Ekaratne SC, 2020, EUR INTELL PROP R, V42, P353
   Farish, 2020, PRACTICE NOTES LEXIS
   Farish K, 2020, J INTELLET PROP LAW, V15, P40, DOI 10.1093/jiplp/jpz139
   Fletcher J, 2018, THEATRE J, V70, P455, DOI 10.1353/tj.2018.0097
   Gibson J, 2020, QUEEN MARY J INTELLE, V10, P1, DOI 10.4337/qmjip.2020.01.00
   Gieseke AP, 2020, VANDERBILT LAW REV, V73, P1479
   Gomery, 2007, LEGAL STUDIES, V27, P404
   Greenberg D., 2021, WESTLAW EDGE UK 0226
   Griffiths J, 2013, OXFORD J LEGAL STUD, V33, P767, DOI 10.1093/ojls/gqt017
   Harbinja E., 2017, INT REV LAW COMPUTER, V31, P26
   Helm RK, 2021, HUM RIGHTS LAW REV, V21, P302, DOI 10.1093/hrlr/ngaa060
   Ice J, 2019, CASE W RESERVE LAW R, V70, P417
   Jacques, 2019, PARODY EXCEPTION COP
   James B, 2020, INT FAMILY LAW, V23, P43
   Kirchengast T, 2020, INF COMMUN TECHNOL L, V29, P308, DOI 10.1080/13600834.2020.1794615
   Kwok AOJ, 2021, CURR ISSUES TOUR, V24, P1798, DOI 10.1080/13683500.2020.1738357
   Lees, 2021, SIGHT SOUND RUSHES T, V2021, P1
   McDonagh, 2021, PERFORMING COPYRIGHT
   Meskys E, 2020, J INTELLET PROP LAW, V15, P24, DOI 10.1093/jiplp/jpz167
   Mirsky Y, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3425780
   Monteiro R, 2016, IEEE INT CONF MULTI
   O'Connell A, 2020, LEGAL STUD, V40, P442, DOI 10.1017/lst.2020.17
   O'Connell A, 2020, J INTELLET PROP LAW, V15, P55, DOI 10.1093/jiplp/jpz150
   Oke EK, 2020, J INTELLET PROP LAW, V15, P49, DOI 10.1093/jiplp/jpz143
   Pace C., 2021, NW PUBLIC LAW RES PA
   Pavis, 2020, SUBMISSION UK IPO AR, P1, DOI [10.5281/zenodo.4298854, DOI 10.5281/ZENODO.4298854]
   Pavis, 2016, THESIS U EXTER UK
   Pavis, 2021, PROTECTION PERFORMAN, P21
   Pavis, 2019, EIPR, V41, P347
   Pavis M., 2021, INTERNET NEWSLETTER
   Pavis M, 2018, J INTELLET PROP LAW, V13, P867, DOI 10.1093/jiplp/jpy118
   Pavis M, 2016, J WORLD INTELLECT PR, V19, P99, DOI 10.1111/jwip.12056
   Perot E, 2020, J INTELLET PROP LAW, V15, P32, DOI 10.1093/jiplp/jpz164
   Pihlajarinne T, 2017, IIC-INT REV INTELL P, V48, P953, DOI 10.1007/s40319-017-0654-2
   Plangger K, 2020, INT J ADVERT, V40, P1
   Polanski P, 2019, EUR INTELL PROP R, V41, P155
   Ramanan D., 2020, ARXIV200104463
   Rothman J., 2018, RIGHT PUBLICITY PRIV
   Rudkin T, 2014, ENTERTAINMENT LAW RE, V25, P201
   Saied A, 2020, ENTERTAINMENT LAW RE, V31, P171
   Silbey J., 2019, MARYLAND LAW REV, V78, P960
   Simone D, 2019, COPYRIGHT COLLECTIVE
   Smith M., 2020, MALICIOUS FALSEHOOD
   Tan D, 2017, CAM INTELLECT PROP, P1, DOI 10.1017/9781316488744
   UK Intellectual Property office, 2021, BEIJ TREAT AUD PERF
   UK Intellectual Property Office, 2020, ARTIFICIAL INTELLIGE
   Wadlow C., 2016, LAW PASSING OFF UNFA
   Waldman Ari Ezra, 2019, MD L REV, V78, P892
   Walsh K, 2021, IIC-INT REV INTELL P, V52, P379, DOI 10.1007/s40319-021-01041-1
   Westerlund M, 2019, TECHNOL INNOV MANAG, V9, P39, DOI 10.22215/timreview/1282
   Whyte Christopher, 2020, Journal of Cyber Policy, V5, P199, DOI 10.1080/23738871.2020.1797135
   Wragg, 2020, COMP PRIVACY DEFAMAT, P65
   Wragg, 2020, COMP PRIVACY DEFAMAT, P9
   Wragg, 2020, COMP PRIVACY DEFAMAT, P243
   Yamaoka-Enkerlin A, 2020, NEW YORK U J LEGISLA, V22, P725
   Zakharov E, 2019, IEEE I CONF COMP VIS, P9458, DOI 10.1109/ICCV.2019.00955
   Zhou T., 2018, ARXIV180807371V1CSGR, P1
NR 71
TC 0
Z9 0
U1 8
U2 8
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 1354-8565
EI 1748-7382
J9 CONVERGENCE-US
JI Convergence
PD AUG
PY 2021
VL 27
IS 4
SI SI
BP 974
EP 998
AR 13548565211033418
DI 10.1177/13548565211033418
EA AUG 2021
PG 25
WC Communication
WE Social Science Citation Index (SSCI)
SC Communication
GA UK7UP
UT WOS:000685844200001
OA Green Published
DA 2022-02-06
ER

PT J
AU Ni, SW
   Li, JW
   Kao, HY
AF Ni, Shiwen
   Li, Jiawen
   Kao, Hung-Yu
TI MVAN: Multi-View Attention Networks for Fake News Detection on Social
   Media
SO IEEE ACCESS
LA English
DT Article
DE Social networking (online); Feature extraction; Deep learning; Blogs;
   Neural networks; Mathematical model; Logic gates; Fake news detection;
   graph attention networks; attention; deep learning; social media
AB Fake news on social media is a widespread and serious problem in today's society. Existing fake news detection methods focus on finding clues from Long text content, such as original news articles and user comments. This paper solves the problem of fake news detection in more realistic scenarios. Only source shot-text tweet and its retweet users are provided without user comments. We develop a novel neural network based model, Multi-View Attention Networks (MVAN) to detect fake news and provide explanations on social media. The MVAN model includes text semantic attention and propagation structure attention, which ensures that our model can capture information and clues both of source tweet content and propagation structure. In addition, the two attention mechanisms in the model can find key clue words in fake news texts and suspicious users in the propagation structure. We conduct experiments on two real-world datasets, and the results demonstrate that MVAN can significantly outperform state-of-the-art methods by 2.5% in accuracy on average, and produce a reasonable explanation.
C1 [Ni, Shiwen; Li, Jiawen; Kao, Hung-Yu] Natl Cheng Kung Univ, Dept Comp Sci & Informat Engn, Tainan 701401, Taiwan.
C3 National Cheng Kung University
RP Kao, HY (corresponding author), Natl Cheng Kung Univ, Dept Comp Sci & Informat Engn, Tainan 701401, Taiwan.
EM hykao@mail.ncku.edu.tw
OI , SHIWEN NI/0000-0002-4986-4446; Li, Jiawen/0000-0003-3684-4785
FU Qualcomm through the Taiwan University Research Collaboration Project;
   Ministry of Science and Technology, TaiwanMinistry of Science and
   Technology, Taiwan [MOST 109-2221-E-006-173, NCKU B109-K027D]
FX This work was supported in part by Qualcomm through the Taiwan
   University Research Collaboration Project, and in part by the Ministry
   of Science and Technology, Taiwan, under Grant MOST 109-2221-E-006-173
   and Grant NCKU B109-K027D.
CR Ajao Oluwaseun, 2018, P 9 INT C SOC MED SO, DOI 10.1145/3217804.3217917
   Augenstein I., 2016, ARXIV160605464
   Bahdanau D., 2014, ARXIV PREPRINT ARXIV
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223
   Bian T, 2020, AAAI CONF ARTIF INTE, V34, P549
   Castillo C., 2011, WWW, P675
   Chen T, 2018, LECT NOTES ARTIF INT, V11154, P40, DOI 10.1007/978-3-030-04503-6_4
   Chen Y., 2017, P 11 INT WORKSH SEM, P465
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Guo H, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P943, DOI 10.1145/3269206.3271709
   Hochreiter S, 1997, ADV NEUR IN, V9, P473
   Huang YJ, 2019, IEEE TRUST BIG, P678, DOI 10.1109/TrustCom/BigDataSE.2019.00096
   Jin Fang, 2013, P 7 WORKSH SOC NETW, V8, p[1, 3], DOI DOI 10.1145/2501025.2501027
   Li J., 2020, P 28 INT C COMP LING P 28 INT C COMP LING, P5420
   Li J., ARXIV210710747
   Li JW, 2020, IEEE ACCESS, V8, P212865, DOI 10.1109/ACCESS.2020.3040263
   Liu Y, 2018, THIRTY-SECOND AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTIETH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / EIGHTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P354
   Lu YJ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P505
   Ma J., 2018, RUMOR DETECTION TWIT
   Ma J., 2016, P 25 INT JOINT C ART, P3818
   Ma J, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P708, DOI 10.18653/v1/P17-1066
   Medsker L. R., 2001, DESIGN APPL, V5, P64
   Mnih V, 2014, P 27 INT C NEURAL IN, V2, P2204
   Monti F., ARXIV190206673
   Nguyen T. T., 2019, GRAPH BASED RUMOR DE GRAPH BASED RUMOR DE
   Ni S., 2020, P AS C MACH LEARN, P769
   Ozbay FA, 2020, PHYSICA A, V540, DOI 10.1016/j.physa.2019.123174
   Popat K, 2017, WWW'17 COMPANION: PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P735, DOI 10.1145/3041021.3053379
   Qazvinian V., 2011, P 2011 C EMP METH NA, P1589
   Rath B., 2017, P 2017 IEEE ACM INT, P179
   Ruchansky N, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P797, DOI 10.1145/3132847.3132877
   Sampson J, 2016, CIKM'16: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P2377, DOI 10.1145/2983323.2983697
   Shu K, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P395, DOI 10.1145/3292500.3330935
   Song C.-H., 2019, INT J RADIAT BIOL, V95, P1498, DOI [10.1080/09553002.2019.1642535, DOI 10.1080/09553002.2019.1642535]
   Vaswani A, 2017, ADV NEUR IN, P5998
   Velickovic P., 2018, P ICLR, P1
   Wu K, 2015, PROC INT CONF DATA, P651, DOI 10.1109/ICDE.2015.7113322
   Wu ZH, 2021, IEEE T NEUR NET LEAR, V32, P4, DOI 10.1109/TNNLS.2020.2978386
   Yan SJ, 2018, THIRTY-SECOND AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTIETH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / EIGHTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P7444
   Yang F., P MDS 12 ACM SIGKDD, DOI [10.1145/2350190.2350203, DOI 10.1145/2350190.2350203]
   Yu F., 2017, P 26 INT JOINT C ART P 26 INT JOINT C ART, P3901
   Yu F, 2019, COMPUT SECUR, V83, P106, DOI 10.1016/j.cose.2019.02.003
   Zhou J., ARXIV181208434
   Zhou ZH, 2019, NATL SCI REV, V6, P74, DOI 10.1093/nsr/nwy108
NR 45
TC 0
Z9 0
U1 7
U2 7
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2021
VL 9
BP 106907
EP 106917
DI 10.1109/ACCESS.2021.3100245
PG 11
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA TU6EI
UT WOS:000681127000001
OA gold
DA 2022-02-06
ER

PT J
AU Kumar, S
   Asthana, R
   Upadhyay, S
   Upreti, N
   Akbar, M
AF Kumar, Sachin
   Asthana, Rohan
   Upadhyay, Shashwat
   Upreti, Nidhi
   Akbar, Mohammad
TI Fake news detection using deep learning models: A novel approach
SO TRANSACTIONS ON EMERGING TELECOMMUNICATIONS TECHNOLOGIES
LA English
DT Article
AB With the ever increase in social media usage, it has become necessary to combat the spread of false information and decrease the reliance of information retrieval from such sources. Social platforms are under constant pressure to come up with efficient methods to solve this problem because users' interaction with fake and unreliable news leads to its spread at an individual level. This spreading of misinformation adversely affects the perception about an important activity, and as such, it needs to be dealt with using a modern approach. In this paper, we collect 1356 news instances from various users via Twitter and media sources such as PolitiFact and create several datasets for the real and the fake news stories. Our study compares multiple state-of-the-art approaches such as convolutional neural networks (CNNs), long short-term memories (LSTMs), ensemble methods, and attention mechanisms. We conclude that CNN + bidirectional LSTM ensembled network with attention mechanism achieved the highest accuracy of 88.78%, whereas Ko et al tackled the fake news identification problem and achieved a detection rate of 85%.
C1 [Kumar, Sachin; Asthana, Rohan; Upreti, Nidhi; Akbar, Mohammad] Ajay Kumar Garg Engn Coll, Dept Comp Sci & Engn, Ghaziabad 201009, India.
   [Upadhyay, Shashwat] Ajay Kumar Garg Engn Coll, Dept Informat Technol, Ghaziabad, India.
RP Kumar, S (corresponding author), Ajay Kumar Garg Engn Coll, Dept Comp Sci & Engn, Ghaziabad 201009, India.
EM imsachingupta@rediffmail.com
CR Allcott H, 2017, J ECON PERSPECT, V31, P211, DOI 10.1257/jep.31.2.211
   Bengio Y, 2017, ARXIV170908568CSLG
   Donald B, 2016, STANFORD RES FIND HA
   Fawaz HI, 2019, ARXIV190306602CSLG
   Friggeri A., 2014, 8 INT AAAI C WEBL SO
   Gilda, 2017, 2017 IEEE 15 STUD C
   Granik Mykhailo, 2017, 2017 IEEE 1 UKR C EL
   Hassan A, 2017, 2017 IEEE LONG ISLAND SYSTEMS, APPLICATIONS AND TECHNOLOGY CONFERENCE (LISAT)
   Kai Shu, 2017, ACM SIGKDD Explorations Newsletter, V19, P22, DOI 10.1145/3137597.3137600
   Kim Y., 2014, ARXIV14085882V2CSCL
   Ko H, 2019, COGN SYST RES, V55, P77, DOI 10.1016/j.cogsys.2018.12.018
   Lipton Zachary C., 2015, ARXIV150600019V4CSLG
   Lohr S, 2018, ITS TRUE FALSE NEWS
   Lyons T., 2018, HARD QUESTIONS WHATS
   Mele Nicco, 2017, COMBATING FAKE NEWS
   Pennington J., 2014, P EMPIRICAL METHODS
   Python Software Foundation, PYTH LIB REF BEAUTIF
   RUCHANSKY N, 2017, P 2017 ACM C INF KNO
   Severyn A., 2015, P 38 INT ACM SIGIR C
   Shao C, 2018, ARXIV170707592V4CSSI
   Shelke Sushila, 2019, Online Social Networks and Media, V9, P30, DOI 10.1016/j.osnem.2018.12.001
   Shu K, 2018, ARXIV171207709V2CSSI
   Shu K, 2019, ARXIV180901286V3CSSI
   Stojanovski D, 2018, MULTIMED TOOLS APPL, V77, P32213, DOI 10.1007/s11042-018-6168-1
   Tao S, 2019, ARXIV190405488CSLG
   Vaswani Ashish, 2017, ARXIV170603762V5CSCL
   Wang C., 2018, IEEE ACCESS, V7, P2161
   Young T, 2018, ARXIV170802709V8CSCL
   Zhang L, 2018, ARXIV180107883V2CSCL
   Zhao Z., 2015, P 24 INT C WORLD WID
   Zheng L, 2016, IEEE C ELECTR PERFOR, P25, DOI 10.1109/EPEPS.2016.7835410
NR 31
TC 14
Z9 15
U1 4
U2 29
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 2161-3915
J9 T EMERG TELECOMMUN T
JI Trans. Emerg. Telecommun. Technol.
PD FEB
PY 2020
VL 31
IS 2
AR e3767
DI 10.1002/ett.3767
EA NOV 2019
PG 23
WC Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Telecommunications
GA LH3GT
UT WOS:000494269400001
DA 2022-02-06
ER

PT J
AU Qian, SS
   Hu, J
   Fang, Q
   Xu, CS
AF Qian, Shengsheng
   Hu, Jun
   Fang, Quan
   Xu, Changsheng
TI Knowledge-aware Multi-modal Adaptive Graph Convolutional Networks for
   Fake News Detection
SO ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS
LA English
DT Article
DE Fake news detection; graph convolutional network; multi-modal learning
AB In this article, we focus on fake news detection task and aim to automatically identify the fake news from vast amount of social media posts. To date, many approaches have been proposed to detect fake news, which includes traditional learning methods and deep learning-based models. However, there are three existing challenges: (i) How to represent social media posts effectively, since the post content is various and highly complicated; (ii) how to propose a data-driven method to increase the flexibility of the model to deal with the samples in different contexts and news backgrounds; and (iii) how to fully utilize the additional auxiliary information (the background knowledge and multi-modal information) of posts for better representation learning. To tackle the above challenges, we propose a novel Knowledge-aware Multi-modal Adaptive Graph Convolutional Networks (KMAGCN) to capture the semantic representations by jointly modeling the textual information, knowledge concepts, and visual information into a unified framework for fake news detection. We model posts as graphs and use a knowledge-aware multi-modal adaptive graph learning principal for the effective feature learning. Compared with existing methods, the proposed KMAGCN addresses challenges from three aspects: (1) It models posts as graphs to capture the non-consecutive and long-range semantic relations; (2) it proposes a novel adaptive graph convolutional network to handle the variability of graph data; and (3) it leverages textual information, knowledge concepts and visual information jointly for model learning. We have conducted extensive experiments on three public real-world datasets and superior results demonstrate the effectiveness of KMAGCN compared with other state-of-the-art algorithms.
C1 [Qian, Shengsheng; Hu, Jun; Fang, Quan; Xu, Changsheng] Chinese Acad Sci, Natl Lab Pattern Recognit, Inst Automat, Beijing, Peoples R China.
   [Qian, Shengsheng; Hu, Jun; Fang, Quan] Univ Chinese Acad Sci, 95 ZhongGuanChun East Rd, Beijing 100190, Peoples R China.
   [Xu, Changsheng] Univ Chinese Acad Sci, Sch Artificial Intelligence, Beijing, Peoples R China.
   [Xu, Changsheng] Peng Cheng Lab, 95 ZhongGuanChun East Rd, Beijing 100190, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Automation, CAS; Chinese
   Academy of Sciences; University of Chinese Academy of Sciences, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS
RP Qian, SS (corresponding author), Chinese Acad Sci, Natl Lab Pattern Recognit, Inst Automat, Beijing, Peoples R China.; Qian, SS (corresponding author), Univ Chinese Acad Sci, 95 ZhongGuanChun East Rd, Beijing 100190, Peoples R China.
EM shengsheng.qian@nlpr.ia.ac.cn; hujunxianligong@gmail.com;
   qfang@nlpr.ia.ac.cn; csxu@nlpr.ia.ac.cn
FU National Key Research and Development Program of China [2017YFB1002804];
   National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [62036012, 61721004, 61720106006, 61802405,
   62072456, 61832002, 61936005, U1705262]; Key Research Program of
   Frontier Sciences, CAS [QYZDJSSWJSC039]; K.C.Wong Education Foundation
FX This work was supported by National Key Research and Development Program
   of China (No. 2017YFB1002804), National Natural Science Foundation of
   China (No. 62036012, 61721004, 61720106006, 61802405, 62072456,
   61832002, 61936005 and U1705262), the Key Research Program of Frontier
   Sciences, CAS, Grant NO. QYZDJSSWJSC039, and the K.C.Wong Education
   Foundation.
CR Allcott H, 2017, J ECON PERSPECT, V31, P211, DOI 10.1257/jep.31.2.211
   Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS)
   Castillo C., 2011, WWW, P675
   Chen LH, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P457, DOI 10.1145/3269206.3271809
   Cho K., 2014, EMNLP, DOI DOI 10.3115/V1/D14-1179
   Cui LM, 2019, PROCEEDINGS OF THE 2019 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2019), P41, DOI 10.1145/3341161.3342894
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Ganea OE, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16), P927, DOI 10.1145/2872427.2882988
   Globerson A, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P621
   Guo ZC, 2018, SEMANT WEB, V9, P459, DOI 10.3233/SW-170273
   Gupta A, 2014, LECT NOTES COMPUT SC, V8851, P228, DOI 10.1007/978-3-319-13734-6_16
   Han, 2012, SDM, P153
   Hu GY, 2019, LECT NOTES ARTIF INT, V11838, P698, DOI 10.1007/978-3-030-32233-5_54
   Hu Jun, 2021, ABS210111552 CORR
   IkuyaYamada Hiroyuki Shindo, 2017, T ASSOC COMPUT LING, V5, P397
   Ji RR, 2019, IEEE T MULTIMEDIA, V21, P1062, DOI 10.1109/TMM.2018.2867718
   Jin ZW, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P795, DOI 10.1145/3123266.3123454
   Jin ZW, 2017, IEEE T MULTIMEDIA, V19, P598, DOI 10.1109/TMM.2016.2617078
   Kai Shu, 2017, ACM SIGKDD Explorations Newsletter, V19, P22, DOI 10.1145/3137597.3137600
   Kalamaras I, 2014, IEEE T MULTIMEDIA, V16, P1460, DOI 10.1109/TMM.2014.2316473
   Khattar D, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P2915, DOI 10.1145/3308558.3313552
   Kingma DP, 2015, 3 INT C LEARN REPR I, DOI DOI 10.1145/1830483.1830503
   Kipf T. N., 2017, ICLR, P1, DOI DOI 10.1051/0004-6361/201527329
   Kolitsas N, 2018, P 22 C COMPUTATIONAL, P519
   Kwon S, 2013, IEEE DATA MINING, P1103, DOI 10.1109/ICDM.2013.61
   Lazic N., 2015, T ASSOC COMPUT LING, V3, P503, DOI DOI 10.1162/tacl_a_00154
   Le Phong, 2018, ARXIV180410637
   Ma J., 2015, P 24 ACM INT C INF K, V19-23, P1751, DOI DOI 10.1145/2806416.2806607
   Ma J., 2016, P 25 INT JOINT C ART, P3818
   Man Wu, 2020, 2020 IEEE International Conference on Data Mining (ICDM), P681, DOI 10.1109/ICDM50108.2020.00077
   Man Wu, 2020, WWW '20: Proceedings of The Web Conference 2020, P1457, DOI 10.1145/3366423.3380219
   Marcheggiani Diego, 2018, P NAACL, V2, P486, DOI 1804.08313
   Mikolov T., 2013, NIPS, V26, P3111
   Milne David N., 2008, P 17 ACM C INFORM KN
   Potthast M, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P231
   Qi P, 2019, IEEE DATA MINING, P518, DOI 10.1109/ICDM.2019.00062
   Rousseau F, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1702
   Shen W, 2015, IEEE T KNOWL DATA EN, V27, P443, DOI 10.1109/TKDE.2014.2327028
   Shi BX, 2016, KNOWL-BASED SYST, V104, P123, DOI 10.1016/j.knosys.2016.04.015
   Simaan, 2017, P 2017 C EMP METH NA, DOI [DOI 10.18653/V1/D17-1209, 10.18653/v1/d17-1209]
   Simonyan K, 2015, ICLR 2015, DOI DOI 10.1109/CVPR.2015.7298594
   Singhal S, 2020, AAAI CONF ARTIF INTE, V34, P13915
   Singhal S, 2019, 2019 IEEE FIFTH INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2019), P39, DOI [10.1109/BigMM.2019.00018, 10.1109/BigMM.2019.00-44]
   Song Liu, 2020, SIGIR '20: Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval, P1379, DOI 10.1145/3397271.3401086
   Suchanek FM, 2008, J WEB SEMANT, V6, P203, DOI 10.1016/j.websem.2008.06.001
   Tian D.P., 2013, INT J MULTIMEDIA UBI, V8, P385
   Tong S, 2002, J MACH LEARN RES, V2, P45, DOI 10.1162/153244302760185243
   Udandarao Vishaal, 2020, ARXIVCSLG200503687
   Velickovic P., 2017, 6 INT C LEARN REPR
   Wang YQ, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P849, DOI 10.1145/3219819.3219903
   Wu Wentao, 2012, P 2012 ACM SIGMOD IN, P481, DOI DOI 10.1145/2213836.2213891
   Wu X, 2008, IEEE T MULTIMEDIA, V10, P188, DOI 10.1109/TMM.2007.911778
   Wu ZH, 2021, IEEE T NEUR NET LEAR, V32, P4, DOI 10.1109/TNNLS.2020.2978386
   Yang XS, 2015, IEEE T MULTIMEDIA, V17, P64, DOI 10.1109/TMM.2014.2375793
   Yang Z, 2019, NEURIPS, P5754
   Yao L., 2018, AAAI
   Yao L, 2019, THIRTY-THIRD AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTY-FIRST INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / NINTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P7370
   Youze Wang, 2020, ICMR '20: Proceedings of the 2020 International Conference on Multimedia Retrieval, P540, DOI 10.1145/3372278.3390713
   Yu F., 2017, IJCAI 2017, P3901, DOI 10.24963/ijcai.2017/545
   Zhang HW, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1942, DOI 10.1145/3343031.3350850
   Zhang YY, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1089, DOI 10.1145/3343031.3351033
   Zhao L, 2015, IEEE T MULTIMEDIA, V17, P1936, DOI 10.1109/TMM.2015.2477058
   Zhou XY, 2020, LECT NOTES ARTIF INT, V12085, P354, DOI 10.1007/978-3-030-47436-2_27
   Zisserman A, 2014, CORR
   Zubiaga A, 2017, INT C SOC INF, P109
NR 65
TC 0
Z9 0
U1 15
U2 15
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1551-6857
EI 1551-6865
J9 ACM T MULTIM COMPUT
JI ACM Trans. Multimed. Comput. Commun. Appl.
PD AUG
PY 2021
VL 17
IS 3
AR 98
DI 10.1145/3451215
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UC5SO
UT WOS:000686585400022
DA 2022-02-06
ER

PT J
AU Wang, JD
   Kan, HT
   Meng, FQ
   Mu, QZ
   Shi, GH
   Xiao, XX
AF Wang, Jingdong
   Kan, Haitao
   Meng, Fanqi
   Mu, Qizi
   Shi, Genhua
   Xiao, Xixi
TI Fake Review Detection Based on Multiple Feature Fusion and Rolling
   Collaborative Training
SO IEEE ACCESS
LA English
DT Review
DE Fake review detection; machine learning; multiple feature fusion;
   feature extraction; rolling collaborative training
ID IDENTIFICATION
AB Fake reviews may mislead consumers. A large number of fake reviews will even cause huge property losses and public opinion crises. Therefore, it is necessary to detect and filter fake reviews. However, most existing methods have lower accuracy in detecting fake reviews due to they just use single features and lack of labeled experimental data. To solve this problem, we propose a novelty method to detect fake reviews based on multiple feature fusion and rolling collaborative training. First, the method requires an initial index system with multiple features such as text features, sentiment features of reviews and behavior features of reviewers. Second, the method needs an initial training sample set. Thus, we designed related algorithms to extract all the features of a review. Then the classification of the review is labeled manually. Finally, the method uses the initial sample set to train 7 classifiers, and the most accurate classifier will be selected to classify new reviews. The novelty of the method lies in that the features and the classification labels of the new reviews will be added into the initial sample set as new samples. So the size of the sample set will increase automatically. The experimental results in the reviews of yelp shopping website show that the accuracy of the proposed method for detecting fake reviews is 84.45%, which is 3.5% higher than the baseline methods. And compared with the latest deep learning model, its baseline precision has increased by 5.3%. According to the Friedman test, the support vector machine (SVM) classifier and random forest (RF) classifier has been proven to be the best one by statistical means. It means our method which uses multiple features has higher accuracy than the baseline models. Meanwhile, it also resolves the problem of lacking labeled training samples in fake reviews detection.
C1 [Wang, Jingdong; Kan, Haitao; Meng, Fanqi; Mu, Qizi; Shi, Genhua; Xiao, Xixi] Northeast Elect Power Univ, Sch Comp Sci, Jilin 132012, Jilin, Peoples R China.
C3 Northeast Electric Power University
RP Kan, HT; Meng, FQ (corresponding author), Northeast Elect Power Univ, Sch Comp Sci, Jilin 132012, Jilin, Peoples R China.
EM 1145758763@qq.com; mengfanqi@neepu.edu.cn
OI han, hai tao/0000-0002-6493-4668
FU Science and Technology Development Plan of Jilin Province (Network
   Public Opinion Analysis and Dynamic Evolution Mechanism Research for
   Public Crisis Early Warning) [20190303107SF]
FX This work was supported by the Science and Technology Development Plan
   of Jilin Province (Network Public Opinion Analysis and Dynamic Evolution
   Mechanism Research for Public Crisis Early Warning) under Grant
   20190303107SF.
CR Ahmed Hadeer, 2018, Security and Privacy, V1, DOI 10.1002/spy2.9
   [Anonymous], 2015, J BIG DATA-GER, DOI [10.1186/s40537-015-0029-9, DOI 10.1186/S40537-015-0029-9]
   [Anonymous], 2012, P 18 ACM SIGKDD INT, DOI DOI 10.1145/2339530.2339662
   Balakrishnama S., 1998, I SIGNAL INF PROCESS, V18, P1
   Barbado R, 2019, INFORM PROCESS MANAG, V56, P1234, DOI 10.1016/j.ipm.2019.03.002
   Beeri C., 1989, READINGS ARTIFICIAL, P468
   Blewitt ME, 2008, NAT GENET, V40, P663, DOI 10.1038/ng.142
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Chen YR, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P173, DOI 10.1145/2736277.2741085
   Chung Y., 2018, ARXIV180808294
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   Demsar J, 2006, J MACH LEARN RES, V7, P1
   Deng HX, 2017, IEEE INT SYMP PARAL, P1278, DOI 10.1109/ISPA/IUCC.2017.00195
   Deng Song, 2015, Journal of Chinese Computer Systems, V36, P2498
   Eimurrigi E, 2017, 2017 SEVENTH INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING TECHNOLOGY (INTECH 2017), P107, DOI 10.1109/INTECH.2017.8102442
   Elliot-Gibson V, 2019, SECONDARY FRACTURE PREVENTION: AN INTERNATIONAL PERSPECTIVE, P79, DOI 10.1016/B978-0-12-813136-7.00005-3
   Feng S., 2012, P 50 ANN M ASS COMP, V50, P171
   Jindal N., 2008, P 2008 INT C WEB SEA, P219
   Kim SM, 2009, PROCEEDINGS OF THE 2009 SIXTH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: NEW GENERATIONS, VOLS 1-3, P376, DOI 10.1109/ITNG.2009.119
   Kostyra DS, 2016, INT J RES MARK, V33, P11, DOI 10.1016/j.ijresmar.2014.12.004
   LACKERMAIR G, 2013, ADV EC BUSINESS, V1, P1, DOI DOI 10.13189/AEB.2013.010101
   Le Q., 2014, P 31 INT C INT C MAC
   Li HY, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P1063, DOI 10.1145/3038912.3052582
   Li LY, 2017, NEUROCOMPUTING, V254, P33, DOI 10.1016/j.neucom.2016.10.080
   Li S, 2013, P 51 ANN M ASS COMP, V2, P217
   Liu Y, 2019, WORLD ENVIRONMENTAL AND WATER RESOURCES CONGRESS 2019: GROUNDWATER, SUSTAINABILITY, HYDRO-CLIMATE/CLIMATE CHANGE, AND ENVIRONMENTAL ENGINEERING, P226
   Masood F, 2019, IEEE ACCESS, V7, P68140, DOI 10.1109/ACCESS.2019.2918196
   McCallum A., 1998, AAAI 98 WORKSH LEARN, V752, P41
   Nguyen V.-A., 2010, P 19 ACM INT C INF K, P939, DOI DOI 10.1145/1871437.1871557
   Norsigian CJ, 2020, NAT PROTOC, V15, P1, DOI 10.1038/s41596-019-0254-3
   Oliveira R. de Castro, 2020, REV BRASILEIRA PESQU, V14, P1
   Ott M., 2011, ARXIV11074557
   Radovanovic D., 2018, 23 INT SCI PROF C IN, P1
   Rastogi A, 2018, PROCEEDINGS OF THE 2018 SECOND INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS), P852, DOI 10.1109/ICCONS.2018.8662912
   Rayana S, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P985, DOI 10.1145/2783258.2783370
   Ren YF, 2017, INFORM SCIENCES, V385, P213, DOI 10.1016/j.ins.2017.01.015
   [任亚峰 Ren Yafeng], 2015, [计算机研究与发展, Journal of Computer Research and Development], V52, P639
   Rout JK, 2017, IEEE ACCESS, V5, P1319, DOI 10.1109/ACCESS.2017.2655032
   Sun W, 2017, PROCEEDINGS OF 2017 3RD IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATIONS (ICCC), P1510, DOI 10.1109/CompComm.2017.8322792
   Tang CY, 2015, MARKET LETT, V26, P67, DOI 10.1007/s11002-013-9268-8
   Ullrich S, 2015, J PROD BRAND MANAG, V24, P66, DOI 10.1108/JPBM-05-2014-0611
   Venkataraman V., 2013, P INT AAAI C WEBL SO, V7, P409
   Wang G., 2011, 2011 IEEE 11 INT C D, P1242, DOI [10.1109/ICDM.2011.124, DOI 10.1109/ICDM.2011.124]
   Wang X, 2017, P NAT C NAT LANG PRO, P866
   Wang Z, 2018, KNOWL INF SYST, V55, P571, DOI 10.1007/s10115-017-1068-7
   Wright RE, 1995, READING UNDERSTANDIN, P217
   Wu FZ, 2016, NEUROCOMPUTING, V201, P51, DOI 10.1016/j.neucom.2016.03.036
   Yanfang C., 2014, DATA ANAL KNOWL DISC, V30, P81
   You Z., 2018, P 27 INT C COMP LING, p1884 1895
   Zhang W, 2018, INFORM PROCESS MANAG, V54, P576, DOI 10.1016/j.ipm.2018.03.007
NR 51
TC 1
Z9 1
U1 8
U2 14
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2020
VL 8
BP 182625
EP 182639
DI 10.1109/ACCESS.2020.3028588
PG 15
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA OD0WP
UT WOS:000579575200001
OA gold
DA 2022-02-06
ER

PT J
AU Haggar, E
AF Haggar, Ellen
TI Fighting fake news: exploring George Orwell's relationship to
   information literacy
SO JOURNAL OF DOCUMENTATION
LA English
DT Article
DE Information literacy; Information; News; Misinformation; Fake news;
   George Orwell
AB Purpose The purpose of this paper is to analyse George Orwell's diaries through an information literacy lens. Orwell is well known for his dedication to freedom of speech and objective truth, and his novel Nineteen Eighty-Four is often used as a lens through which to view the fake news phenomenon. This paper will examine Orwell's diaries in relation to UNESCO's Five Laws of Media and Information Literacy to examine how information literacy concepts can be traced in historical documents. Design/methodology/approach This paper will use a content analysis method to explore Orwell's relationship to information literacy. Two of Orwell's political diaries from the period 1940-42 were coded for key themes related to the ways in which Orwell discusses and evaluates information and news. These themes were then compared to UNESCO Five Laws of Media and Information Literacy. Textual analysis software NVivo 12 was used to perform keyword searches and word frequency queries in the digitised diaries. Findings The findings show that while Orwell's diaries and the Five Laws did not share terminology, they did share ideas on bias and access to information. They also extend the history of information literacy research and practice by illustrating how concerns about the need to evaluate information sources are represented within historical literature. Originality/value This paper combines historical research with textual analysis to bring a unique historical perspective to information literacy, demonstrating that "fake news" is not a recent phenomenon, and that the tools to fight it may also lie in historical research.
C1 [Haggar, Ellen] UCL, Dept Informat Studies, London, England.
   [Haggar, Ellen] Inst Mech Engineers, London, England.
C3 University of London; University College London
RP Haggar, E (corresponding author), UCL, Dept Informat Studies, London, England.; Haggar, E (corresponding author), Inst Mech Engineers, London, England.
EM e.haggar.17@alumni.ucl.ac.uk
CR ACRL, 2015, FRAM INF LIT HIGH ED
   Allcott H, 2017, J ECON PERSPECT, V31, P211, DOI 10.1257/jep.31.2.211
   ANDERSON P, 2006, ORWELL TRIBUNE
   [Anonymous], 2014, BBC
   [Anonymous], 2018, CHANNEL 4 NEWS
   [Anonymous], 1941, COMMUNICATION
   Biggam John., 2015, SUCCEEDING YOUR MAST, V3rd
   Blackwell A., 2017, THIS IS NOT FAK C LO
   Blakeslee S., 2004, LOEX Q, V31
   Caulfield M., 2018, RECOGNITION IS FUTIL
   Caulfield M., 2017, WEB LITERACY STUDENT
   Holiday R., 2016, NEW YORK OBSERVER
   Ireland S, 2017, REF USER SERV Q, V57, P12, DOI 10.5860/rusq.57.1.6436
   Irving H., 2014, CHAOS CENSORSHIP SEC
   Jones J., 2018, G ORWELL IDENTIFIES
   Leetaru K., 2019, FORBES
   Lenart B., 2014, PROGR LIB, P57
   Lewandowsky S., 2020, INFORM SOC
   Lynskey D., 2019, GUARDIAN
   Mandalios J, 2013, J INF SCI, V39, P470, DOI 10.1177/0165551513478889
   Meola M, 2004, PORTAL-LIBR ACAD, V4, P331, DOI 10.1353/pla.2004.0055
   Midgley N., 2018, WORD YEAR 2016 IS OX
   Orwell G., 1940, POLITICAL DIARY 1940
   Orwell G., 2018, FREEDOM PRESS
   Orwell G., 1942, POLITICAL DIARY 1942
   Orwell G., 2014, ESSAYS
   Orwell G., 2010, DIARIES
   Polizzi G., 2020, INFORM SOC
   Potter S., 2018, J RES I HIST GLOBAL, P49
   Saunders L., 2018, KNOW NEWS ENGAGING A
   Tanczer L., QUEENS U BELF
   UNESCO, 2017, 5 LAWS MIL UN ED SCI
   Vosoughi S, 2018, SCIENCE, V359, P1146, DOI 10.1126/science.aap9559
   Wineburg Sam, 2017, LATERAL READING READ
NR 34
TC 2
Z9 2
U1 7
U2 42
PU EMERALD GROUP PUBLISHING LTD
PI BINGLEY
PA HOWARD HOUSE, WAGON LANE, BINGLEY BD16 1WA, W YORKSHIRE, ENGLAND
SN 0022-0418
EI 1758-7379
J9 J DOC
JI J. Doc.
PD SEP 14
PY 2020
VL 76
IS 5
BP 961
EP 979
DI 10.1108/JD-11-2019-0223
EA APR 2020
PG 19
WC Computer Science, Information Systems; Information Science & Library
   Science
WE Social Science Citation Index (SSCI)
SC Computer Science; Information Science & Library Science
GA NC8BT
UT WOS:000526575200001
DA 2022-02-06
ER

PT J
AU Budhi, GS
   Chiong, R
   Wang, ZL
   Dhakal, S
AF Budhi, Gregorius Satia
   Chiong, Raymond
   Wang, Zuli
   Dhakal, Sandeep
TI Using a hybrid content-based and behaviour-based featuring approach in a
   parallel environment to detect fake reviews
SO ELECTRONIC COMMERCE RESEARCH AND APPLICATIONS
LA English
DT Article
DE Fake review detection; Featuring approach; Machine learning; Deep
   learning; Imbalanced data; Parallel processing
ID OPINION SPAM DETECTION; FRAMEWORK
AB The financial impact of positive reviews has prompted some fraudulent sellers to generate fake product reviews for either promoting their products or discrediting competing products. Many e-commerce portals have implemented measures to detect such fake reviews, and these measures require excellent detectors to be effective. In this work, we propose 133 unique features from the combination of content and behaviour-based features to detect fake reviews using machine learning classifiers. Preliminary results show that these features can provide good results for all datasets tested. Detailed analysis of the results, however, reveals the existence of class imbalance issues for two of the bigger datasets - there is a high imbalance between the accuracies of different classes (e.g., 7.73% for the fake class and 99.3% for the genuine class using a Multilayer Perceptron classifier). We therefore introduce two sampling methods that can improve the accuracy of the fake review class on balanced datasets. The accuracies can be improved to a maximum of 89% for both random under and oversampling on Convolutional Neural Networks. Additionally, we propose a parallel cross-validation method that can speed up the validation process in a parallel environment.
C1 [Budhi, Gregorius Satia; Chiong, Raymond; Dhakal, Sandeep] Univ Newcastle, Sch Elect Engn & Comp, Callaghan, NSW 2308, Australia.
   [Budhi, Gregorius Satia] Petra Christian Univ, Informat Dept, Surabaya 60236, Indonesia.
   [Chiong, Raymond] Fuzhou Univ, Sch Econ & Management, Fuzhou 350116, Peoples R China.
   [Wang, Zuli] Chengdu Univ Informat Technol, Sch Cybersecur, Chengdu 610225, Peoples R China.
C3 University of Newcastle; Universitas Kristen Petra; Fuzhou University;
   Chengdu University of Information Technology
RP Chiong, R (corresponding author), Univ Newcastle, Sch Elect Engn & Comp, Callaghan, NSW 2308, Australia.
EM Raymond.Chiong@newcastle.edu.au
RI Dhakal, Sandeep/AAE-6690-2020
OI Dhakal, Sandeep/0000-0001-7413-2530
FU Indonesian Endowment Fund for Education (LPDP), Ministry of Finance;
   Directorate General of Higher Education (DIKTI), Ministry of Education
   and Culture, Republic of Indonesia
FX The first author would like to acknowledge financial support from the
   Indonesian Endowment Fund for Education (LPDP) , Ministry of Finance,
   and the Directorate General of Higher Education (DIKTI) , Ministry of
   Education and Culture, Republic of Indonesia.
CR Akram AU, 2018, KSII T INTERNET INF, V12, P5120, DOI 10.3837/tiis.2018.10.026
   [Anonymous], 2018, PEDDLER FAKE REV TRI
   Baccianella S, 2010, LREC 2010 - SEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION
   Bagheri A, 2013, KNOWL-BASED SYST, V52, P201, DOI 10.1016/j.knosys.2013.08.011
   Bajaj S, 2017, PROCEDIA COMPUT SCI, V122, P1009, DOI 10.1016/j.procs.2017.11.467
   Bansal S., 2019, TEXTST 0 5 6
   Barbado R, 2019, INFORM PROCESS MANAG, V56, P1234, DOI 10.1016/j.ipm.2019.03.002
   Birchall G., 2018, TRIPADVISOR DENIES C
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655
   Buchholz S., 2002, MEMORY BASED GRAMMAT
   Budhi GS, 2021, MULTIMED TOOLS APPL, V80, P13079, DOI 10.1007/s11042-020-10299-5
   Budhi GS, 2021, ARCH COMPUT METHOD E, V28, P2543, DOI 10.1007/s11831-020-09464-8
   Budhi GS, 2017, 2017 IEEE CONFERENCE ON BIG DATA AND ANALYTICS (ICBDA), P19, DOI 10.1109/ICBDAA.2017.8284101
   Campbell C., 2011, SYNTHESIS LECT ARTIF, V5, P1, DOI [DOI 10.2200/S00324ED1V01Y201102AIM010, 10.2200/S00324ED1V01Y201102AIM010]
   Cardoso EF, 2018, NEUROCOMPUTING, V309, P106, DOI 10.1016/j.neucom.2018.04.074
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Cheng Yuan, 2019, P SCI DIS2019, P1
   Dong M, 2019, PSYCHOL MED, V49, P1691, DOI [10.1017/S0033291718002301, 10.1016/j.patrec.2018.07.013]
   Etaiwi W, 2017, PROCEDIA COMPUT SCI, V113, P273, DOI 10.1016/j.procs.2017.08.368
   Fang JM, 2019, INT J ELECTRON COMM, V23, P557, DOI 10.1080/10864415.2019.1655206
   Felbermayr A, 2016, J INTERACT MARK, V36, P60, DOI 10.1016/j.intmar.2016.05.004
   Feng VW., 2013, P 6 INT JOINT C NAT, P338
   Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
   Glorot X., 2010, P 13 INT C ART INT S, P249
   Hancock, 2011, P 49 ANN M ASS COMP, P309, DOI DOI 10.1145/2567948.2577293
   Hazim M, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0198884
   Fusilier DH, 2015, INFORM PROCESS MANAG, V51, P433, DOI 10.1016/j.ipm.2014.11.001
   Heydari A, 2016, EXPERT SYST APPL, V58, P83, DOI 10.1016/j.eswa.2016.03.020
   Heydari A, 2015, EXPERT SYST APPL, V42, P3634, DOI 10.1016/j.eswa.2014.12.029
   Hu ZY, 2019, IND MANAGE DATA SYST, V119, P676, DOI 10.1108/IMDS-02-2018-0072
   Hu ZY, 2016, IEEE C EVOL COMPUTAT, P5186, DOI 10.1109/CEC.2016.7748347
   Jindal N., 2008, P 2008 INT C WEB SEA, P219
   Keras Keras, 2019, KERAS PYTHON DEEP LE
   King DB, 2015, ACS SYM SER, V1214, P1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar N, 2018, J MANAGE INFORM SYST, V35, P350, DOI 10.1080/07421222.2018.1440758
   Lee S, 2018, ARCH COMPUT METHOD E, V25, P121, DOI 10.1007/s11831-017-9237-0
   Li H., 2015, ANAL DETECTING OPINI, V26-29, P634
   Li JW, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1566
   Li LY, 2017, NEUROCOMPUTING, V254, P33, DOI 10.1016/j.neucom.2016.10.080
   Lo SL, 2017, ARTIF INTELL REV, V48, P499, DOI 10.1007/s10462-016-9508-4
   Lo SL, 2016, DECIS SUPPORT SYST, V85, P34, DOI 10.1016/j.dss.2016.02.010
   Lo SL, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0122855
   Luca M, 2016, MANAGE SCI, V62, P3412, DOI 10.1287/mnsc.2015.2304
   Malbon J, 2013, J CONSUM POLICY, V36, P139, DOI 10.1007/s10603-012-9216-7
   Martens D, 2019, EMPIR SOFTW ENG, V24, P3316, DOI 10.1007/s10664-019-09706-9
   Menard S. W., 2010, LOGISTIC REGRESSION
   Mukherjee A, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P632
   NLTK, 2019, NLTK PACK
   Ott M, 2013, P NAACL HLT 2013, P497
   Pels H, 2019, 200 SPAM TRIGGER KEY
   Perelsztejn F, 2017, 455 SPAM TRIGGER WOR
   Picchi Aimee, 2019, CBS NEWS
   Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1007/BF00116251
   Rastogi A, 2020, J DATA INFO SCI, V5, P76, DOI 10.2478/jdis-2020-0013
   Rathore S, 2018, APPL SOFT COMPUT, V67, P920, DOI 10.1016/j.asoc.2017.09.032
   Rayana S, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P985, DOI 10.1145/2783258.2783370
   Ren YF, 2017, INFORM SCIENCES, V385, P213, DOI 10.1016/j.ins.2017.01.015
   Rout JK, 2017, MULTIMED TOOLS APPL, V76, P3187, DOI 10.1007/s11042-016-3819-y
   Rumelhart D.E., 1986, Language., V22, P98, DOI DOI 10.1016/B978-1-4832-1446-7.50035-2
   Salehan M, 2016, DECIS SUPPORT SYST, V81, P30, DOI 10.1016/j.dss.2015.10.006
   Savage D, 2015, EXPERT SYST APPL, V42, P8650, DOI 10.1016/j.eswa.2015.07.019
   Scikit-learn, 2019, API REF
   Shu C, 2019, FTC BRINGS ITS 1 CAS
   Shuteyev P., 2018, 550 SPAM TRIGGER WOR
   Song W, 2020, ELECTRON COMMER R A, V39, DOI 10.1016/j.elerap.2019.100900
   Sun CG, 2016, MATH PROBL ENG, V2016, DOI 10.1155/2016/4935792
   Tang XY, 2020, INFORM SCIENCES, V526, P274, DOI 10.1016/j.ins.2020.03.063
   Utz S, 2012, ELECTRON COMMER R A, V11, P49, DOI 10.1016/j.elerap.2011.07.010
   Venkataraman V., 2013, P INT AAAI C WEBL SO, V7, P409
   Wahyuni ED, 2016, MATEC WEB CONF, V58, DOI 10.1051/matecconf/20165803003
   Wang X., 2016, P 2016 C EMP METH NA, P866
   Wang XP, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P366, DOI 10.18653/v1/P17-1034
   Yelp, 2019, YELP DAT CHALL ROUND
   You Z., 2018, P 27 INT C COMP LING, p1884 1895
   Yu YH, 2016, ALGORITHMS, V9, DOI 10.3390/a9020041
   Yuan L, 2018, COMPLEXITY, DOI 10.1155/2018/5321280
   Zhang DS, 2016, J MANAGE INFORM SYST, V33, P456, DOI 10.1080/07421222.2016.1205907
   Zhang W, 2018, INFORM PROCESS MANAG, V54, P576, DOI 10.1016/j.ipm.2018.03.007
   Zhu J, 2009, STAT INTERFACE, V2, P349
NR 81
TC 2
Z9 2
U1 7
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1567-4223
EI 1873-7846
J9 ELECTRON COMMER R A
JI Electron. Commer. Res. Appl.
PD MAY-JUN
PY 2021
VL 47
AR 101048
DI 10.1016/j.elerap.2021.101048
PG 19
WC Business; Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Business & Economics; Computer Science
GA SM1TQ
UT WOS:000657394600015
DA 2022-02-06
ER

PT J
AU Teo, KX
AF Teo, Kai Xiang
TI Civil Society Responses to Singapore's Online "Fake News" Law
SO INTERNATIONAL JOURNAL OF COMMUNICATION
LA English
DT Article
DE fake news; POFMA; Singapore; censorship; civil society; repression;
   online discourse
ID AUTHORITARIAN RULE; MEDIA
AB Singapore's Protection Against Online Falsehoods and Misinformation Act (POFMA) is part of a growing trend of new laws against "fake news" online. This study examines POFMA's impact on online political discourse through semi-structured interviews with 17 Singapore-based journalists, academics, and activists. This study indicates that POFMA is a distinctive form of online censorship, because of its emphasis on truth and credibility. First, POFMA allows the government to prominently refute civil society actions online, which in turn creates new openings for highly visible resistance against online censorship. Second, POFMA also subtly imposes costs on participating in online political discourse, by exacerbating issues of trust in digital spaces and constrained data availability. Crucially, this form of censorship targets processes of discourse production (specifically processes that are less deferential to the state), instead of merely categories of discourse (critical speech), and legitimizes the state as the ultimate fact-checker. This new form of censorship is likely to have more wide-ranging impacts than censorship as it is traditionally understood, and merits further study.
C1 [Teo, Kai Xiang] Univ Cambridge, Cambridge, England.
C3 University of Cambridge
RP Teo, KX (corresponding author), Univ Cambridge, Cambridge, England.
EM teokaixiang@protonmail.com
CR Anis M. N., 2019, STAR 0409
   Bennett WL, 2018, EUR J COMMUN, V33, P122, DOI 10.1177/0267323118760317
   Carlson M., 2017, JOURNALISTIC AUTHORI
   Carson A., 2021, FIGHTING FAKE NEWS S
   Chen JD, 2017, J POLIT, V79, P792, DOI 10.1086/690303
   Corbin J., 1998, BASICS QUALITATIVE R, V2nd
   Deibert R, 2010, J DEMOCR, V21, P43
   Edmond C, 2013, REV ECON STUD, V80, P1422, DOI 10.1093/restud/rdt020
   Egelhofer JanaL., 2019, ANN INT COMMUNICATIO, V43, P97, DOI [10.1080/23808985.2019.1602782, DOI 10.1080/23808985.2019.1602782]
   Farkas J., 2019, POSTTRUTH FAKE NEWS
   George C., 2020, AIR CONDITIONED NATI
   George C., 2012, FREEDOM PRESS JOURNA, DOI [10.2307/j.ctv1ntht1, DOI 10.2307/J.CTV1NTHT1]
   George C, 2007, PAC REV, V20, P127, DOI 10.1080/09512740701306782
   Gomez J., 2006, COPENHAGEN J ASIAN S, V23, P105, DOI [10.22439/cjas. v23i1.694, DOI 10.22439/CJAS.V23I1.694]
   Habgood-Coote J, 2019, INQUIRY, V62, P1033, DOI 10.1080/0020174X.2018.1508363
   Han K., 2020, NEW NARATIF 0620
   Holtermann A, 2005, J ELECTROMYOGR KINES, V15, P131, DOI 10.1016/j.jelekin.2004.09.003
   Honari A, 2018, SOC MEDIA SOC, V4, DOI 10.1177/2056305118803886
   Honari A, 2018, CURR SOCIOL, V66, DOI 10.1177/0011392118787585
   International Commission of Jurists, 2019, SING PARL MUST REJ I
   Jansen SC, 2015, INT J COMMUN-US, V9, P656
   Kurohi R., 2019, STRAITS TIMES 1130
   Lam L., 2020, CHANNEL NEWS ASIA
   Lee H., 2020, PLAY MEANINGFUL ROLE
   Lee H, 2019, MEDIA INT AUST, V173, P81, DOI 10.1177/1329878X19853074
   Lee T., 2002, ASIAN STUD REV, V26, P97
   Lee T, 2009, CONTINUUM-J MEDIA CU, V23, P871, DOI 10.1080/10304310903294804
   Lorentzen P, 2014, AM J POLIT SCI, V58, P402, DOI 10.1111/ajps.12065
   MacKinnon R, 2011, J DEMOCR, V22, P32, DOI 10.1353/jod.2011.0033
   Mahmud A. H., 2020, CHANNEL NEWS ASIA
   McGonagle T, 2017, NETH Q HUM RIGHTS, V35, P203, DOI 10.1177/0924051917738685
   McPherson E., 2018, NEW TECHNOLOGIES HUM, P188, DOI [10.1017/ 9781316838952.009, DOI 10.1017/9781316838952.009]
   Meyer P., 2020, DIPLOMAT 0707
   Moore WH, 1998, AM J POLIT SCI, V42, P851, DOI 10.2307/2991732
   Neo R, 2020, INT POLITICS, V57, P724, DOI 10.1057/s41311-019-00198-4
   O'Brien KJ, 2015, J CONTEMP CHINA, V24, P457, DOI 10.1080/10670564.2014.953849
   Ong Y. K., 2019, STRAITS TIMES 0509
   Pearce KE, 2012, J COMMUN, V62, P283, DOI 10.1111/j.1460-2466.2012.01633.x
   Pereira A. W, 2005, POLITICAL IN JUSTICE, DOI [10.2307/j.ctt7zwb63, DOI 10.2307/J.CTT7ZWB63]
   Poynter Institute for Media Studies, 2020, GUID ANT ACT WORLD
   Protection from Online Falsehoods and Manipulation Act Office, 2021, MED CTR POFMA OFF PR
   Ranasinghe I., 2020, ECONOMYNEXT 1124
   Roberts M. E., 2018, CENSORED DISTRACTION, DOI [10.23943/ 9781400890057, DOI 10.23943/9781400890057]
   Roberts ME, 2020, ANNU REV POLIT SCI, V23, P401, DOI 10.1146/annurev-polisci-050718-032837
   Ruan L, 2021, CHINA INFORM, V35, P133, DOI 10.1177/0920203X20963010
   Saunders B, 2018, QUAL QUANT, V52, P1893, DOI 10.1007/s11135-017-0574-8
   Scheppele KL, 2018, U CHICAGO LAW REV, V85, P545
   Sreekumar TT, 2013, SCI TECHNOL SOC, V18, P231, DOI 10.1177/0971721813489458
   Stern RE, 2012, COMP POLIT STUD, V45, P1230, DOI 10.1177/0010414011434295
   Stockmann D, 2011, COMP POLIT STUD, V44, P436, DOI 10.1177/0010414010394773
   Tandoc E. C., 2021, CHANNEL NEWS ASIA
   Teo K. X., 2021, POFMAED DATASET V202
   Whiting SH, 2017, COMP POLIT STUD, V50, P1907, DOI 10.1177/0010414016688008
NR 53
TC 0
Z9 0
U1 0
U2 0
PU USC ANNENBERG PRESS
PI LOS ANGELES
PA UNIV SOUTHERN CALIFORNIA, KERCKHOFF HALL, 734 W ADAMS BLVD, MC7725, LOS
   ANGELES, CA 90089 USA
SN 1932-8036
J9 INT J COMMUN-US
JI Int. J. Commun.
PY 2021
VL 15
BP 4795
EP 4815
PG 21
WC Communication
WE Social Science Citation Index (SSCI)
SC Communication
GA XO1HN
UT WOS:000729944300148
DA 2022-02-06
ER

PT J
AU Khan, S
   Kamal, A
   Fazil, M
   Alshara, MA
   Sejwal, VK
   Alotaibi, RM
   Baig, AR
   Alqahtani, S
AF Khan, Shakir
   Kamal, Ashraf
   Fazil, Mohd
   Alshara, Mohammed Ali
   Sejwal, Vineet Kumar
   Alotaibi, Reemiah Muneer
   Baig, Abdul Rauf
   Alqahtani, Salihah
TI HCovBi-Caps: Hate Speech Detection Using Convolutional and
   Bi-Directional Gated Recurrent Unit With Capsule Network
SO IEEE ACCESS
LA English
DT Article
DE Hate speech; Social networking (online); Deep learning; Blogs; Context
   modeling; Logic gates; Logistics; Hate speech detection; Twitter data
   analysis; convolutional layer; capsule network; BiGRU; deep learning
AB Adversaries and anti-social elements have exploited the rapid proliferation of computing technology and online social media in the form of novel security threats, such as fake profiles, hate speech, social bots, and rumors. The hate speech problem on online social networks (OSNs) is also widespread. The existing literature has machine learning approaches for hate speech detection on OSNs. However, the effectiveness of contextual information at different orientations is understudied. This study presents a novel Convolutional, BiGRU, and Capsule network-based deep learning model, HCovBi-Caps, to classify the hate speech. The proposed model is evaluated over two Twitter-based benchmark datasets - DS1(balanced) and DS2(unbalanced) with the best performance of 0.90, 0.80, and 0.84 respectively considering precision, recall, and f-score over unbalanced dataset. In terms of training and validation accuracy, the proposed model shows the best performance of 0.93 and 0.90, respectively, over the unbalanced dataset. In comparative evaluation, HCovBi-Caps demonstrates a significantly better performance than state-of-the-art approaches. In addition, HCovBi-Caps shows comparatively better performance over the unbalanced dataset. We also investigate the impact of different hyperparameters on the efficacy of HCovBi-Caps to ascertain the selection of their values. We observed that a higher value of routing iterations adversely affects the model performance, whereas a higher value of capsule dimension improves the performance.
C1 [Khan, Shakir; Alshara, Mohammed Ali; Alotaibi, Reemiah Muneer; Baig, Abdul Rauf; Alqahtani, Salihah] Imam Mohammad Ibn Saud Islamic Univ, Coll Comp & Informat Sci, Riyadh 11564, Saudi Arabia.
   [Kamal, Ashraf] ACL Digital, Bengaluru 560029, India.
   [Fazil, Mohd] Qatar Univ, Dept Comp Engn, Doha, Qatar.
   [Sejwal, Vineet Kumar] Jamia Millia Islamia, Dept Comp Sci, New Delhi 110025, India.
C3 Qatar University; Jamia Millia Islamia
RP Khan, S (corresponding author), Imam Mohammad Ibn Saud Islamic Univ, Coll Comp & Informat Sci, Riyadh 11564, Saudi Arabia.
EM sgkhan@imamu.edu.sa
FU Deanship of Scientific Research at Imam Mohammad Ibn Saud Islamic
   University through Research Group [RG-21-07-08]
FX This work was supported by the Deanship of Scientific Research at Imam
   Mohammad Ibn Saud Islamic University through Research Group under Grant
   RG-21-07-08.
CR Abulaish M, 2020, IEEE TECHNOL SOC MAG, V39, P52, DOI 10.1109/MTS.2020.3012327
   Abulaish M, 2020, ACM T WEB, V14, DOI 10.1145/3375547
   Abulaish M, 2019, 2019 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE (WI 2019), P466, DOI [10.1145/3350346.3352569, 10.1145/3350546.3352569]
   Abulaish M, 2018, 2018 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE (WI 2018), P574, DOI 10.1109/WI.2018.00-35
   Badjatiya P, 2017, WWW'17 COMPANION: PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P759, DOI 10.1145/3041021.3054223
   Bhattacharjee Uddipta, 2019, 2019 11th International Conference on Communication Systems & Networks (COMSNETS), P473, DOI 10.1109/COMSNETS.2019.8711379
   Burnap P, 2015, POLICY INTERNET, V7, P223, DOI 10.1002/poi3.85
   Davidson T., 2017, P 11 INT AAAI C WEB, P512
   Ding Y., 2019, P 13 INTWORKSH SEM E, P535
   Djuric N, 2015, WWW'15 COMPANION: PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P29, DOI 10.1145/2740908.2742760
   Du YP, 2019, IEEE ACCESS, V7, P39321, DOI 10.1109/ACCESS.2019.2906398
   Fazil M, 2018, IEEE T INF FOREN SEC, V13, P2707, DOI 10.1109/TIFS.2018.2825958
   Fortuna P, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2021.102524
   Founta A. M., 2018, P 12 INT AAAI C WEB, P491
   Founta A.-M., 2019, P 11 INT C WEB SCI B, P105
   Gamback B., 2017, P 1 WORKSH AB LANG V, P85, DOI [10.18653/v1/W17-3013, DOI 10.18653/V1/W17-3013]
   Gover AR, 2020, AM J CRIM JUSTICE, V45, P647, DOI 10.1007/s12103-020-09545-1
   Hinton G.E, 2018, INT C LEARN REPR, DOI DOI 10.2514/6.2003
   Hinton GE, 2011, LECT NOTES COMPUT SC, V6791, P44, DOI 10.1007/978-3-642-21735-7_6
   Jain DK, 2020, NEURAL COMPUT APPL, V32, P1839, DOI 10.1007/s00521-019-04620-z
   Jain PK, 2021, COMPUT ELECTR ENG, V95, DOI 10.1016/j.compeleceng.2021.107397
   Jain PK, 2021, J SUPERCOMPUT, DOI 10.1007/s11227-021-04087-7
   Jain PK, 2021, COMPUT SCI REV, V41, DOI 10.1016/j.cosrev.2021.100413
   Jain PK, 2021, ACM T ASIAN LOW-RESO, V20, DOI 10.1145/3457206
   Jain PK, 2021, WIRELESS PERS COMMUN, V118, P2469, DOI 10.1007/s11277-021-08136-5
   Kamal A., 2019, P 16 INT C NAT LANG, P201
   Kamal A., 2019, P 16 INT C PAC ASS C, P483
   Kamal A, 2022, COGN COMPUT, V14, P91, DOI 10.1007/s12559-021-09821-0
   Kamble S., 2018, P 15 INT C NAT LANG, P155
   Kwok I., 2013, P 27 AAAI C ART INT, P1621
   Malmasi S., 2017, P RECENT ADV NATURAL, P467
   Miok K, 2022, COGN COMPUT, V14, P353, DOI 10.1007/s12559-021-09826-9
   Mossie Z, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102087
   Mozafari M., 2019, P INT C COMPL NETW A, P928
   Pamungkas EW, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2021.102544
   Park J. H., 2017, P 1 WORKSH AB LANG V, P41
   Le Q, 2014, PR MACH LEARN RES, V32, P1188
   Roy PK, 2020, IEEE ACCESS, V8, P204951, DOI 10.1109/ACCESS.2020.3037073
   Rui Cao, 2020, WebSci '20: 12th ACM Conference on Web Science, P11, DOI 10.1145/3394231.3397890
   Sabour S., 2017, NIPS, P3856
   Vlad G.-A., 2019, P 2 WORKSH NAT LANG, P148
   Wang B., 2019, P 13 INT WORKSH SEM, P529
   Warner W., 2012, P WORKSH LANG SOC ME, P19
   Waseem Z., 2016, P NAACL HLT SACR CA, P88, DOI [DOI 10.18653/V1/N16-2013, 10.18653/v1/N16]
   Wulczyn E, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P1391, DOI 10.1145/3038912.3052591
   Ziqi Zhang, 2018, The Semantic Web. 15th International Conference, ESWC 2018. Proceedings: LNCS 10843, P745, DOI 10.1007/978-3-319-93417-4_48
NR 46
TC 0
Z9 0
U1 0
U2 0
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2022
VL 10
BP 7881
EP 7894
DI 10.1109/ACCESS.2022.3143799
PG 14
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering; Telecommunications
GA YN3XT
UT WOS:000747194900001
OA gold
DA 2022-02-06
ER

PT J
AU Bonet-Jover, A
   Piad-Morffis, A
   Saquete, E
   Martinez-Barco, P
   Garcia-Cumbreras, MA
AF Bonet-Jover, Alba
   Piad-Morffis, Alejandro
   Saquete, Estela
   Martinez-Barco, Patricio
   Garcia-Cumbreras, Miguel Angel
TI Exploiting discourse structure of traditional digital media to enhance
   automatic fake news detection
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Natural language processing; Fake news; Automated fact-checking; Deep
   Learning; Machine Learning; Human Language Technologies
ID DECEPTION
AB This paper presents a novel architecture for dealing with Automatic Fake News detection. The architecture factors in the discourse structure of news in traditional digital media and is based on two premises. First, fake news tends to mix true and false information with the purpose of confusing readers. Second, this research is focused on fake news delivered in traditional digital media, so our approach considers the influence of the journalistic structure of news, and the way journalists tend to introduce the essential content in a news story using 5W1H answer. Considering both premises, this proposal deals with the news components separately because some may be true or false, instead of considering the veracity value of the news article as a unit. A two-layer architecture is proposed, Structure and Veracity layers. To demonstrate the validity of the proposal, a new dataset was created and annotated with a new fine-grained annotation scheme (FNDeepML) that considers the different elements of the news document and their veracity. Due to the severity of the COVID-19 pandemic crisis, health is the chosen domain, and Spanish is the language used to validate the architecture, given the lack of research in this language. However, the proposal can be applied to any other language or domain. The performance of the Veracity layer of our proposal, which factors in the traditional news article structure and the 5W1H annotation, is capable of delivering a result of F-1=0.807. This represents a strong improvement when compared to the baseline, which uses the whole document with a single veracity value, obtaining F-1=0.605. These findings validate the suitability and effectiveness of our approach.
C1 [Bonet-Jover, Alba; Saquete, Estela; Martinez-Barco, Patricio] Univ Alicante, Dept Software & Comp Syst, Alicante, Spain.
   [Piad-Morffis, Alejandro] Univ Havana, Sch Math & Comp Sci, Havana, Cuba.
   [Garcia-Cumbreras, Miguel Angel] Univ Jaen, CEATIC, Jaen, Spain.
C3 Universitat d'Alacant; Universidad de la Habana; Universidad de Jaen
RP Saquete, E (corresponding author), Univ Alicante, Dept Software & Comp Syst, Alicante, Spain.
EM alba.bonet@dlsi.ua.es; apiad@matcom.uh.cu; stela@dlsi.ua.es;
   patricio@dlsi.ua.es; magc@ujaen.es
RI Boro, Estela Saquete/H-1922-2015
OI Boro, Estela Saquete/0000-0002-6001-5461; Bonet,
   Alba/0000-0002-7172-0094
FU Generalitat Valenciana, Spain through project "SIIA: Tecnologias del
   lenguaje humano para una sociedad inclusiva, igualitaria, y
   accesible''Generalitat Valenciana [PROMETEU/2018/089]; Spanish
   GovernmentSpanish GovernmentEuropean Commission [RTI2018-094653-B-C22,
   RTI2018-094653-B-C21]; Fondo Europeo de Desarrollo Regional
   (FEDER)European Commission
FX This research work has been partially funded by Generalitat Valenciana,
   Spain through project "SIIA: Tecnologias del lenguaje humano para una
   sociedad inclusiva, igualitaria, y accesible'' with grant reference
   PROMETEU/2018/089, by the Spanish Government through the projects
   RTI2018-094653-B-C22: "Modelang: Modeling the behavior of digital
   entities by Human Language Technologies'' and RTI2018-094653-B-C21:
   "LIVING-LANG: Living Digital Entities by Human Language Technologies'',
   as well as being partially supported by a grant from the Fondo Europeo
   de Desarrollo Regional (FEDER). Furthermore, we would like to thank
   Difusion Comunicacion, especially Tono Jorda and Lara Sanchez Belda, and
   Newtral for their collaboration in collection and annotation of
   datasets.
CR Afroz S, 2012, P IEEE S SECUR PRIV, P461, DOI 10.1109/SP.2012.34
   Agarwal A, 2020, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS 2020), P1178, DOI 10.1109/ICICCS48265.2020.9121030
   Almela A., 2012, P WORKSH COMP APPR D, V1, P15, DOI 10.5195/LESLI.2013.5
   Faustini PHA, 2020, EXPERT SYST APPL, V158, DOI 10.1016/j.eswa.2020.113503
   Bednarek M., 2012, NEWS DISCOURSE, V46
   Bonet-Jover A., 2020, FNDEEPML ANNOTATION, DOI [10.5281/zenodo.4091549, DOI 10.5281/ZENODO.4091549]
   Bonet-Jover A., 2020, FNDEEP DATASET, DOI [10.5281/zenodo, DOI 10.5281/ZENODO]
   Brennan M. R., 2009, IAAI
   Chagas LJV, 2019, J RADIO AUDIO MEDIA, V26, P231, DOI 10.1080/19376529.2018.1481846
   Chakma K, 2018, COMPUT SIST, V22, P747, DOI [10.13053/cys-22-3-3016, 10.13053/CyS-22-3-3016]
   Chen YR, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P173, DOI 10.1145/2736277.2741085
   Ciampaglia GL, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0128193
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
   Conroy N. J., 2015, ASIST 15
   Dale R, 2017, NAT LANG ENG, V23, P319, DOI 10.1017/S1351324917000018
   Das Bhattacharjee S, 2017, IEEE INT CONF BIG DA, P556, DOI 10.1109/BigData.2017.8257971
   Devlin J, 2019, PROC C N AM CHAPTER, P4171, DOI DOI 10.18653/V1/N19-1423
   Estevez-Velarde S., 2020, P 7 ICML WORKSH AUT
   Ferreira W., 2016, P 2016 C N AM CHAPTE, P1163
   Gilda S, 2017, IEEE ST CONF RES DEV, P110, DOI 10.1109/SCORED.2017.8305411
   Gravanis G, 2019, EXPERT SYST APPL, V128, P201, DOI 10.1016/j.eswa.2019.03.036
   Hamborg F, 2018, ACM-IEEE J CONF DIG, P339, DOI 10.1145/3197026.3203899
   Han Sangdo, 2013, P SIGDIAL 2013 C, P349
   Hanselowski A., 2018, ARXIV180605180
   Huang YF, 2020, EXPERT SYST APPL, V159, DOI 10.1016/j.eswa.2020.113584
   Khan SUR, 2018, IEEE ACCESS, V6, P75452, DOI 10.1109/ACCESS.2018.2882988
   Kim JD, 2012, INT J DISTRIB SENS N, DOI 10.1155/2012/247346
   Kingma DP, 2015, 3 INT C LEARN REPR I, DOI DOI 10.1145/1830483.1830503
   Lewandowsky S, 2012, PSYCHOL SCI PUBL INT, V13, P106, DOI 10.1177/1529100612451018
   Monti F., 2019, ABS190206673 CORR ABS190206673 CORR
   Moreda P, 2011, INFORM PROCESS MANAG, V47, P870, DOI 10.1016/j.ipm.2010.03.008
   MOSTELLER F, 1963, J AM STAT ASSOC, V58, P275, DOI 10.2307/2283270
   National Institute of Standards and Technology NIST, 2011, TAC 2011 GUID SUMM T
   Newman ML, 2003, PERS SOC PSYCHOL B, V29, P665, DOI 10.1177/0146167203029005010
   Norambuena B., 2020, COMP JOURN S
   Nyhan B., 2012, MED CARE, V51, DOI [10.1097/MLR.0b013-318279486b, DOI 10.1097/MLR.0B013-318279486B]
   Padro L, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2473
   Perez-Rosas V, 2018, P 27 INT C COMPUTATI, P3391
   Posadas-Duran JP, 2019, J INTELL FUZZY SYST, V36, P4869, DOI 10.3233/JIFS-179034
   Potthast M, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P231
   Prechelt L, 1998, LECT NOTES COMPUT SC, V1524, P55
   Rashkin Hannah, 2017, P 2017 C EMPIRICAL M, P2931
   Ren YF, 2017, INFORM SCIENCES, V385, P213, DOI 10.1016/j.ins.2017.01.015
   Rubin V., 2016, P 2 WORKSH COMP APPR, P7, DOI DOI 10.18653/V1/W16-0802
   Saquete E, 2020, EXPERT SYST APPL, V141, DOI 10.1016/j.eswa.2019.112943
   Shu K, 2019, PROCEEDINGS OF THE TWELFTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'19), P312, DOI 10.1145/3289600.3290994
   Silva RM, 2020, EXPERT SYST APPL, V146, DOI 10.1016/j.eswa.2020.113199
   Socher R, 2014, P 19 C EMPIRICAL MET, V2014, P1532, DOI DOI 10.3115/V1/D14-1162
   Strapparava, 2009, P ACL IJCNLP 2009 C, P309, DOI DOI 10.3115/1667583.1667679
   Sutton C, 2012, FOUND TRENDS MACH LE, V4, P267, DOI 10.1561/2200000013
   Thomson EA, 2008, JOURNALISM STUD, V9, P212, DOI 10.1080/14616700701848261
   Verma A.K, 2019, P 4 IEEE INT C INT T, P1, DOI 10.1109/NPEC47332.2019.9034706
   Vlachos A, 2014, ACL, P18, DOI DOI 10.3115/V1/W14-2508
   Volkova S, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P647, DOI 10.18653/v1/P17-2102
   Voorhees E. M., 1999, TREC NIST SPECIAL PU, V8, P77
   Vosoughi S, 2018, SCIENCE, V359, P1146, DOI 10.1126/science.aap9559
   Wang W., 2012, WWW, P197, DOI 10.1145/ 2187980.2188008
   Wang W, 2010, LECT NOTES COMPUT SC, V6184, P644, DOI 10.1007/978-3-642-14246-8_62
   Wang WY, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P422, DOI 10.18653/v1/P17-2067
   Zhang HX, 2016, TEXT TALK, V36, P89, DOI 10.1515/text-2016-0005
   Zhou L, 2008, COMMUN ACM, V51, P119, DOI 10.1145/1378727.1389972
NR 61
TC 4
Z9 4
U1 7
U2 9
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD MAY 1
PY 2021
VL 169
AR 114340
DI 10.1016/j.eswa.2020.114340
PG 19
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic; Operations Research & Management Science
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Operations Research & Management Science
GA SV3FJ
UT WOS:000663708000021
DA 2022-02-06
ER

PT J
AU de Rezende, ERS
   Ruppert, GCS
   Theophilo, A
   Tokuda, EK
   Carvalho, T
AF de Rezende, Edmar R. S.
   Ruppert, Guilherme C. S.
   Theophilo, Antonio
   Tokuda, Eric K.
   Carvalho, Tiago
TI Exposing computer generated images by using deep convolutional neural
   networks
SO SIGNAL PROCESSING-IMAGE COMMUNICATION
LA English
DT Article
DE Digital forensics; CG detection; Deep learning; Transfer learning; Fake
   news
ID FORGERIES
AB The recent computer graphics developments have upraised the quality of the generated digital content, astonishing the most skeptical viewer. Games and movies have taken advantage of this fact but, at the same time, these advances have brought serious negative impacts like the ones yielded by fake images produced with malicious intents. Digital artists can compose artificial images capable of deceiving the great majority of people, turning this into a very dangerous weapon in a timespan currently know as "Fake News/Post-Truth" Era. In this work, we propose a new approach for dealing with the problem of detecting computer generated images, through the application of deep convolutional networks and transfer learning techniques. We start from Residual Networks and develop different models adapted to the binary problem of identifying if an image was, or not, computer generated. Differently from the current state-of-the-art approaches, we do not rely on hand-crafted features, but provide to the model the raw pixel information, achieving the same 0.97 performance of state-of-the-art methods with three main advantages: (i) executes considerably faster than state-of-the-art methods with equivalent accuracy; (ii) eliminates the laborious and manual step of specialized features extraction and selection, and (iii) is very robust against image processing operations as noise addition, blur and JPEG compression.
C1 [de Rezende, Edmar R. S.; Ruppert, Guilherme C. S.; Theophilo, Antonio] CTI Renato Archer, BR-13069901 Campinas, SP, Brazil.
   [Carvalho, Tiago] Fed Inst Sao Paulo, BR-13069901 Campinas, SP, Brazil.
   [Tokuda, Eric K.] Univ Sao Paulo, BR-05008090 Sao Paulo, SP, Brazil.
C3 Instituto Federal de Sao Paulo (IFSP); Universidade de Sao Paulo
RP Carvalho, T (corresponding author), Fed Inst Sao Paulo, BR-13069901 Campinas, SP, Brazil.
EM tiagojc@gmail.com
RI Carvalho, Tiago J/F-8589-2015
OI Rezende, Edmar/0000-0002-7601-878X; Carvalho, Tiago/0000-0002-7779-1950
FU IFSP-Campinas; FAPESPFundacao de Amparo a Pesquisa do Estado de Sao
   Paulo (FAPESP) [2017/12631-6]; Fapesp DejaVu grantFundacao de Amparo a
   Pesquisa do Estado de Sao Paulo (FAPESP) [2017/12646-3]; CNPqConselho
   Nacional de Desenvolvimento Cientifico e Tecnologico (CNPQ)
   [302923/2014-4, 313152/2015-2, 423797/2016-6]
FX The authors would like to thank the financial support of IFSP-Campinas,
   FAPESP (grant 2017/12631-6), Fapesp DejaVu (grant 2017/12646-3) and CNPq
   (grants 302923/2014-4, 313152/2015-2 and 423797/2016-6). We also would
   like to thank the authors Tokuda et al. [7] who helped us with dataset
   acquirement and we gratefully acknowledge the support of NVIDIA
   Corporation with the donation of the GPUs used for this research.
CR [Anonymous], 2017, 2017 NAT IM LIBR
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Bishop CM., 2006, PATTERN RECOGN
   Candes E.J., 1999, CURVELETS SURPRISING
   Carvalho T, 2017, IEEE ICC
   Chen T., 2016, KDD 16 P 22 ACM SIGK, DOI [10.1145/2939672.2939785, DOI 10.1145/2939672.2939785]
   Conotter V, 2014, IEEE IMAGE PROC, P248, DOI 10.1109/ICIP.2014.7025049
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Davey-Attlee F., CNN
   de Carvalho TJ, 2013, IEEE T INF FOREN SEC, V8, P1182, DOI 10.1109/TIFS.2013.2265677
   Do MN, 2002, IEEE IMAGE PROC, P357
   Donahue J, 2014, PR MACH LEARN RES, V32
   Dang-Nguyen TT, 2015, IEEE T INF FOREN SEC, V10, P1752, DOI 10.1109/TIFS.2015.2427778
   Dang-Nguyen DT, 2012, IEEE INT WORKS INFOR, P252, DOI 10.1109/WIFS.2012.6412658
   Dang-Nguyen DT, 2012, EUR SIGNAL PR CONF, P1234
   Farid H, 2012, DIGIT INVEST, V8, P226, DOI 10.1016/j.diin.2011.06.003
   Glorot X., 2010, P 13 INT C ART INT S, P249
   Gonzalez R. C., 2007, DIGITAL IMAGE PROCES
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Holmes O, 2016, ACM T APPL PERCEPT, V13, DOI 10.1145/2871714
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Keyes R, 2004, POSTTRUTH ERA DISHON
   Krizhevsky A., 2012, ADV NEURAL INF PROCE, P1097, DOI DOI 10.1145/3065386
   Kutyniok G, 2011, J APPROX THEORY, V163, P1564, DOI 10.1016/j.jat.2011.06.005
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   LIEBOVITCH LS, 1989, PHYS LETT A, V141, P386, DOI 10.1016/0375-9601(89)90854-2
   Lyu S, 2005, IEEE T SIGNAL PROCES, V53, P845, DOI 10.1109/TSP.2004.839896
   M_aenp_a_a T, 2001, LECT NOTES COMPUTER, P399, DOI DOI 10.1007/3-540-44732-6_41
   Ng TT, 2009, IEEE SIGNAL PROC MAG, V26, P49, DOI 10.1109/MSP.2008.931077
   Popescu AC, 2005, IEEE T SIGNAL PROCES, V53, P3948, DOI 10.1109/TSP.2005.855406
   Rocha A, 2012, IEEE T BIO-MED ENG, V59, P2244, DOI 10.1109/TBME.2012.2201717
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Schetinger V, 2017, COMPUT GRAPH-UK, V68, P142, DOI 10.1016/j.cag.2017.08.010
   Schulten K., 2017, NY TIMES
   Schwartz WR, 2011, IEEE IMAGE PROC, P1033, DOI 10.1109/ICIP.2011.6115600
   Sermanet P., 2013, COMPUT VIS PATTERN R, V1312, P6229, DOI DOI 10.1109/CVPR.2015.7299176
   Shane S., NY TIMES
   Simonyan K, 2015, ICLR 2015, DOI DOI 10.1109/CVPR.2015.7298594
   Tan D. Q., 2016, Pattern Recognition and Image Analysis, V26, P720, DOI 10.1134/S1054661816040167
   Tokuda E, 2013, J VIS COMMUN IMAGE R, V24, P1276, DOI 10.1016/j.jvcir.2013.08.009
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wenxiang Li, 2010, Proceedings of the 2010 Seventh International Conference on Fuzzy Systems and Knowledge Discovery (FSKD 2010), P2316, DOI 10.1109/FSKD.2010.5569821
   Yosinski J, 2014, ADV NEUR IN, V27
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
NR 47
TC 10
Z9 10
U1 1
U2 24
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0923-5965
EI 1879-2677
J9 SIGNAL PROCESS-IMAGE
JI Signal Process.-Image Commun.
PD AUG
PY 2018
VL 66
BP 113
EP 126
DI 10.1016/j.image.2018.04.006
PG 14
WC Engineering, Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA GL3MG
UT WOS:000437039100011
OA Green Submitted
DA 2022-02-06
ER

PT J
AU Sansonetti, G
   Gasparetti, F
   D'aniello, G
   Micarelli, A
AF Sansonetti, Giuseppe
   Gasparetti, Fabio
   D'aniello, Giuseppe
   Micarelli, Alessandro
TI Unreliable Users Detection in Social Media: Deep Learning Techniques for
   Automatic Detection
SO IEEE ACCESS
LA English
DT Article
DE Social networking (online); Feature extraction; Reliability engineering;
   Deep learning; Analytical models; Media; Blogs; Deep neural networks;
   fake news; machine learning; social media
AB Since the harmful consequences of the online publication of fake news have emerged clearly, many research groups worldwide have started to work on the design and creation of systems able to detect fake news and entities that share it consciously. Therefore, manifold automatic, manual, and hybrid solutions have been proposed by industry and academia. In this article, we describe a deep investigation of the features that both from an automatic and a human point of view, are more predictive for the identification of social network profiles accountable for spreading fake news in the online environment. To achieve this goal, the features of the monitored users were extracted from Twitter, such as social and personal information as well as interaction with content and other users. Subsequently, we performed (i) an offline analysis realized through the use of deep learning techniques and (ii) an online analysis that involved real users in the classification of reliable/unreliable user profiles. The experimental results, validated from a statistical point of view, show which information best enables machines and humans to detect malicious users. We hope that our research work will provide useful insights for realizing ever more effective tools to counter misinformation and those who spread it intentionally.
C1 [Sansonetti, Giuseppe; Gasparetti, Fabio; Micarelli, Alessandro] Roma Tre Univ, Dept Engn, I-00146 Rome, Italy.
   [D'aniello, Giuseppe] Univ Salerno, Dept Informat & Elect Engn & Appl Math, I-84084 Fisciano, Italy.
C3 Roma Tre University; University of Salerno
RP Sansonetti, G (corresponding author), Roma Tre Univ, Dept Engn, I-00146 Rome, Italy.
EM gsansone@dia.uniroma3.it
RI D'Aniello, Giuseppe/K-8637-2018
OI D'Aniello, Giuseppe/0000-0002-8687-9348; Sansonetti,
   Giuseppe/0000-0003-4953-1390; Gasparetti, Fabio/0000-0003-0263-531X
CR Allcott H, 2017, J ECON PERSPECT, V31, P211, DOI 10.1257/jep.31.2.211
   Benamira A, 2019, PROCEEDINGS OF THE 2019 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2019), P568, DOI 10.1145/3341161.3342958
   Bessi A, 2016, 1 MONDAY, V21, P11, DOI [DOI 10.5210/FM.V21I11.7090, 10.5210/fm.v21i11.7090]
   Bian Tian, 2020, ARXIV200106362
   Bronstein MM, 2017, IEEE SIGNAL PROC MAG, V34, P18, DOI 10.1109/MSP.2017.2693418
   Bruna J., 2014, CORR, P1, DOI DOI 10.1109/TNN.2008.2005141
   Chen Y., 2015, P 2015 ACM WORKSH MU, P15, DOI DOI 10.1145/2823465.2823467
   Demuth H.B., 2014, NEURAL NETWORK DESIG
   Feng S., 2012, P 50 ANN M ASS COMP, V50, P171
   Ferrara E, 2016, COMMUN ACM, V59, P96, DOI 10.1145/2818717
   Goodfellow I. J., 2015, ARXIV14126572
   Guacho GB, 2018, 2018 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM), P322, DOI 10.1109/ASONAM.2018.8508241
   Gupta MP, 2012, PROCEEDINGS OF THE ASME PACIFIC RIM TECHNICAL CONFERENCE AND EXHIBITION ON PACKAGING AND INTEGRATION OF ELECTRONIC AND PHOTONIC SYSTEMS, MEMS AND NEMS 2011, VOL 2, P153
   Han Y., 2020, ARXIV PREPRINT ARXIV
   Hu GY, 2019, LECT NOTES ARTIF INT, V11838, P698, DOI 10.1007/978-3-030-32233-5_54
   Jin ZW, 2016, THIRTIETH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2972
   Jin ZW, 2014, IEEE DATA MINING, P230, DOI 10.1109/ICDM.2014.91
   Kai Shu, 2017, ACM SIGKDD Explorations Newsletter, V19, P22, DOI 10.1145/3137597.3137600
   Kingma DP, 2015, 3 INT C LEARN REPR I, DOI DOI 10.1145/1830483.1830503
   Kipf T. N., 2017, ICLR, P1, DOI DOI 10.1051/0004-6361/201527329
   Kirkpatricka J, 2017, P NATL ACAD SCI USA, V114, P3521, DOI 10.1073/pnas.1611835114
   Kumar S., 2018, ARXIV180408559
   Li C., 2015, P 24 ACM INT C INF K, P1835, DOI [10.1145/2806416.2806652, DOI 10.1145/2806416.2806652]
   Liu Y, 2018, THIRTY-SECOND AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTIETH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / EIGHTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P354
   Lopez-Paz D., 2017, ABS170608840 NIPS
   Lu YJ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P505
   Mikolov T, 2013, P ICLR WORKSH, V1, P1
   Mohammad SM, 2017, ACM T INTERNET TECHN, V17, DOI 10.1145/3003433
   Monti F., 2019, ICLR 2019 WORKSH REP
   Potthast M, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P231
   Ruchansky N, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P797, DOI 10.1145/3132847.3132877
   Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605
   Shi BX, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16 COMPANION), P101, DOI 10.1145/2872518.2889354
   Shu K., 2020, P INT AAAI C WEB SOC, V14, P626
   Shu K., 2020, MINING DISINFORMATIO, P1, DOI [10.1007/978-3-030-42699-6_1, DOI 10.1007/978-3-030-42699-6_1]
   Shu K, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P395, DOI 10.1145/3292500.3330935
   Szegedy C., 2014, ARXIV13126199
   Tacchini E., 2017, ABS170407506 CORR
   Thekumparampil K.K., 2018, ATTENTION BASED GRAP
   Varol Onur, 2017, P 11 INT AAAI C WEB, P280
   Vosoughi S, 2018, SCIENCE, V359, P1146, DOI 10.1126/science.aap9559
   Wang WY, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P422, DOI 10.18653/v1/P17-2067
   Wu L, 2018, WSDM'18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P637, DOI 10.1145/3159652.3159677
   Wu ZH, 2021, IEEE T NEUR NET LEAR, V32, P4, DOI 10.1109/TNNLS.2020.2978386
   Xinyi Zhou, 2019, ACM SIGKDD Explorations Newsletter, V21, P48, DOI 10.1145/3373464.3373473
   Ya Gao, 2010, Proceedings of the 2010 Seventh International Conference on Fuzzy Systems and Knowledge Discovery (FSKD 2010), P1502, DOI 10.1109/FSKD.2010.5569327
   Yang S, 2019, THIRTY-THIRD AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTY-FIRST INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / NINTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P5644
   Ying Z., 2018, ADV NEURAL INFORM PR, P4800, DOI 10.5555/3327345.3327389
   Zhang XC, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.03.004
   Zhou J, 2018, ARXIV181208434
   Zhou XY, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3395046
   杨云峰, 1999, [西安公路交通大学学报, Journal of Xian Highway University], P67
NR 52
TC 3
Z9 3
U1 0
U2 3
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2020
VL 8
BP 213154
EP 213167
DI 10.1109/ACCESS.2020.3040604
PG 14
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA PC7MK
UT WOS:000597180600001
OA Green Submitted, gold
DA 2022-02-06
ER

PT J
AU Wang, YH
   Wang, L
   Yang, YJ
   Lian, T
AF Wang, Yuhang
   Wang, Li
   Yang, Yanjie
   Lian, Tao
TI SemSeq4FD: Integrating global semantic relationship and local sequential
   order to enhance text representation for fake news detection
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Fake news detection; Enhanced text representation; Global semantic
   relationship; Local sequential order; Graph neural network
AB The wide spread of fake news has caused huge losses to both governments and the public. Many existing works on fake news detection utilized spreading information like propagators profiles and the propagation structure. However, such methods face the difficulty of data collection and cannot detect fake news at the early stage. An alternative approach is to detect fake news solely based on its content. Early content-based methods rely on manually designed linguistic features. Such shallow features are domain-dependent, and cannot easily be generalized to cross-domain data. Recently, many natural language processing tasks resort to deep learning methods to learn word, sentence, and document representations. In this paper, we propose a novel graph-based neural network model named SemSeq4FD for early fake news detection based on enhanced text representations. In SemSeq4FD, we model the global pair-wise semantic relations between sentences as a complete graph, and learn the global sentence representations via a graph convolutional network with self-attention mechanism. Considering the importance of local context in conveying the sentence meaning, we employ a 1D convolutional network to learn the local sentence representations. The two representations are combined to form the enhanced sentence representations. Then a LSTM-based network is used to model the sequence of enhanced sentence representations, yielding the final document representation for fake news detection. Experiments conducted on four real-world datasets in English and Chinese, including cross-source and cross-domain datasets, demonstrate that our model can outperform the state-of-the-art methods.
C1 [Wang, Yuhang; Wang, Li; Yang, Yanjie; Lian, Tao] Taiyuan Univ Technol, Data Sci Coll, Jinzhong 030600, Shanxi, Peoples R China.
C3 Taiyuan University of Technology
RP Wang, L (corresponding author), Taiyuan Univ Technol, Data Sci Coll, Jinzhong 030600, Shanxi, Peoples R China.
EM wangyuhang0983@link.tyut.edu.cn; wangyuhang0983@link.tyut.edu.cn;
   yangyanjie1073@link.tyut.edu.cn; liantao@tyut.edu.cn
RI Wang, Yuhang/AAN-5701-2021
OI Wang, Yuhang/0000-0001-5181-0271; /0000-0002-8941-5143; Wang,
   Li/0000-0002-7385-1426
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61872260]; GF Innovative Research Program,
   China
FX This work was supported by the National Natural Science Foundation of
   China (No: 61872260) and GF Innovative Research Program, China.
CR Ahn YC, 2019, INT JOINT CONF COMP, P289, DOI 10.1109/JCSSE.2019.8864171
   Devlin J, 2019, PROC C N AM CHAPTER, P4171, DOI DOI 10.18653/V1/N19-1423
   Horne B. D., 2017, ICWSM 17
   Hu GY, 2019, LECT NOTES ARTIF INT, V11838, P698, DOI 10.1007/978-3-030-32233-5_54
   Kim Y., 2014, P EMNLP 2014, P1746, DOI 10.3115/v1/D14-1181
   Kipf TN, 2017, ICLR 2017
   Kleinbaum D.G., 2002, LOGISTIC REGRESSION
   Kouzy R, 2020, CUREUS, V12, DOI 10.7759/cureus.7255
   Leening MJG, 2014, ANN INTERN MED, V160, P122, DOI 10.7326/M13-1522
   Liu Q, 2018, ACM T INTEL SYST TEC, V9, DOI 10.1145/3168361
   Liu Y, 2018, THIRTY-SECOND AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTIETH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / EIGHTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P354
   Ma J., 2015, P 24 ACM INT C INF K, V19-23, P1751, DOI DOI 10.1145/2806416.2806607
   Ma J., 2016, P 25 INT JOINT C ART, P3818
   Ozbay FA, 2020, PHYSICA A, V540, DOI 10.1016/j.physa.2019.123174
   Ozbay FA, 2019, ELEKTRON ELEKTROTECH, V25, P62, DOI 10.5755/j01.eie.25.4.23972
   Perez-Rosas V, 2018, P 27 INT C COMPUTATI, P3391
   Rapoza K., 2017, CAN FAKE NEWSIMPACT
   Rashkin Hannah, 2017, P 2017 C EMPIRICAL M, P2931
   Rath B., 2017, RETWEET BELIEVABILIT, P179, DOI [10.1145/3110025.3110121, DOI 10.1145/3110025.3110121]
   Rubin V., 2016, P 2 WORKSH COMP APPR, P7, DOI DOI 10.18653/V1/W16-0802
   Ruchansky N, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P797, DOI 10.1145/3132847.3132877
   Scholkopf B., 2001, LEARNING KERNELS SUP
   Shin J, 2018, COMPUT HUM BEHAV, V83, P278, DOI 10.1016/j.chb.2018.02.008
   Shu K, 2018, IEEE 1ST CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2018), P430, DOI 10.1109/MIPR.2018.00092
   Song C., 2019, IEEE Transactions on Knowledge and Data Engineering, V1
   Uppal A, 2020, PROCEEDINGS OF THE CONFLUENCE 2020: 10TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE & ENGINEERING, P751, DOI 10.1109/Confluence47617.2020.9058106
   Vaibhav V., 2019, ARXIV PREPRINT ARXIV
   Vaswani A., 2017, ADV NEUR IN, pPP 5998
   Velickovic P., 2018, INT C LEARN REPR
   Volkova S, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P647, DOI 10.18653/v1/P17-2102
   Vosoughi S, 2017, ACM T KNOWL DISCOV D, V11, DOI 10.1145/3070644
   Wang WY, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P422, DOI 10.18653/v1/P17-2067
   Wei P., 2019, P 2019 C EMP METH NA, P4787
   Wu K, 2015, PROC INT CONF DATA, P651, DOI 10.1109/ICDE.2015.7113322
   Yang S, 2019, THIRTY-THIRD AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTY-FIRST INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / NINTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P5644
   Yu F., 2017, IJCAI 2017, P3901, DOI 10.24963/ijcai.2017/545
   Zhang X., 2015, ADV NEURAL INFORM PR, V28, P649, DOI DOI 10.1063/1.4906785
   Zhou Xinyi, 2019, INFECT DIS POVERTY
NR 38
TC 4
Z9 5
U1 11
U2 144
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD MAR 15
PY 2021
VL 166
AR 114090
DI 10.1016/j.eswa.2020.114090
PG 12
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic; Operations Research & Management Science
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Operations Research & Management Science
GA PE7CG
UT WOS:000598519700022
PM 33041529
OA Bronze, Green Published
DA 2022-02-06
ER

PT J
AU Ananthi, M
   Rajkumar, P
   Sabitha, R
   Karthik, S
AF Ananthi, M.
   Rajkumar, P.
   Sabitha, R.
   Karthik, S.
TI A secure model on Advanced Fake Image-Feature Network (AFIFN) based on
   deep learning for image forgery detection
SO PATTERN RECOGNITION LETTERS
LA English
DT Article
DE Image Forgery Detection; Real Image; Pair-wise Learning; Image
   Classification; AFIFN; Security
AB Recent advancements in image editing tools made much impact on analysis of security issues with respect to digital media domain. In specific, the forged images been uploaded to create a panic situation for the users. Those synthesized images with fake content can be used in social media, which may cause several problems. Hence, it is important for the image forensics to detect the forged or manipulated images. With the motive to effectively detect the fake images and to provide security, the proposed work focused on developing an Advanced Fake Image-Feature Network (AFIFN) based on deep learning methods. In this model, Discrete Cosine Transformation (DCT) and Y Cr Cb based image pre-processing is employed. Further, the AFIFN is framed with two-layered network structure, obtaining the pair-wise data as input. The network is trained for differentiating the features between the forged and real images. Additionally, a classification layer is added with the framed AFIFN to detect the input image is forged or not. The results show that the proposed model significantly outperforms the results of other existing models in image forgery detection. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Ananthi, M.] KGiSL Inst Technol, Dept Informat Technol, Coimbatore, Tamil Nadu, India.
   [Rajkumar, P.] KGiSL Inst Technol, Dept Comp Sci & Engn, Coimbatore, Tamil Nadu, India.
   [Sabitha, R.] Karunya Inst Technol & Sci, Dept Comp Sci & Engn, Coimbatore, Tamil Nadu, India.
   [Karthik, S.] SNS Coll Technol, Dept Comp Sci & Engn, Coimbatore, Tamil Nadu, India.
C3 Karunya Institute of Technology & Sciences; SNS College of Technology
RP Ananthi, M (corresponding author), KGiSL Inst Technol, Dept Informat Technol, Coimbatore, Tamil Nadu, India.
EM mail2ananthiinfo@gmail.com
CR Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   Bahrami K, 2015, IEEE T INF FOREN SEC, V10, P999, DOI 10.1109/TIFS.2015.2394231
   Cao G, 2014, IEEE T INF FOREN SEC, V9, P515, DOI 10.1109/TIFS.2014.2300937
   Dang LM, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8122610
   Farid H, 2009, IEEE T INF FOREN SEC, V4, P154, DOI 10.1109/TIFS.2008.2012215
   Fridrich J., 2003, P DIG FOR RES WORKSH, DOI 10.1109/PACIIA.2008.240
   Gautam KS, 2019, SOFT COMPUT, V23, P2813, DOI 10.1007/s00500-019-03870-2
   Gautam K.S., 2019, INT J COMPUT APPL, V43, P1
   GMI_BLOGGER, SAUD AR SOC MED STAT
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Huang FJ, 2016, IEEE T CIRC SYST VID, V26, P1610, DOI 10.1109/TCSVT.2015.2473235
   Kim D.-H., 2017, INT J APPL ENG RES, V12, P11640
   Kit S., 49 INCREDIBLE INSTAG
   Korus P, 2017, IEEE T INF FOREN SEC, V12, P809, DOI 10.1109/TIFS.2016.2636089
   Korus P, 2016, IEEE T IMAGE PROCESS, V25, P1312, DOI 10.1109/TIP.2016.2518870
   Larsson G, 2016, LECT NOTES COMPUT SC, V9908, P577, DOI 10.1007/978-3-319-46493-0_35
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Li WH, 2010, IEEE IMAGE PROC, P2113, DOI 10.1109/ICIP.2010.5652519
   Li Y., 2016, P AS PAC SIGN INF PR, P1
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Marra F, 2018, IEEE 1ST CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2018), P384, DOI 10.1109/MIPR.2018.00084
   Mo HX, 2018, PROCEEDINGS OF THE 6TH ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY (IH&MMSEC'18), P43, DOI 10.1145/3206004.3206009
   Qureshi MA, 2015, SIGNAL PROCESS-IMAGE, V39, P46, DOI 10.1016/j.image.2015.08.008
   Raturi R., 2018, INT J PURE APPL MATH, V118, P4785
   Ryu SJ, 2013, IEEE T INF FOREN SEC, V8, P1355, DOI 10.1109/TIFS.2013.2272377
   Sikandar G. Mohamed, 100 SOCIAL MEDIA STA
   Strigl D, 2010, EUROMICRO WORKSHOP P, P317, DOI 10.1109/PDP.2010.43
   Wang JW, 2017, MULTIDIM SYST SIGN P, V28, P617, DOI 10.1007/s11045-015-0363-2
   Yin J., 2016, P INT WORKSH DIG FOR, P456
   Zhang W, 2009, IEEE INT CON MULTI, P1078, DOI 10.1109/ICME.2009.5202685
NR 30
TC 0
Z9 0
U1 3
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0167-8655
EI 1872-7344
J9 PATTERN RECOGN LETT
JI Pattern Recognit. Lett.
PD DEC
PY 2021
VL 152
BP 260
EP 265
DI 10.1016/j.patrec.2021.10.011
PG 6
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WW5LM
UT WOS:000717957900003
DA 2022-02-06
ER

PT J
AU Jin, XL
   Ye, DP
   Chen, CAX
AF Jin, Xinlei
   Ye, Dengpan
   Chen, Chuanxi
TI Countering Spoof: Towards Detecting Deepfake with Multidimensional
   Biological Signals
SO SECURITY AND COMMUNICATION NETWORKS
LA English
DT Article
AB The deepfake technology is conveniently abused with the low technology threshold, which may bring the huge social security risks. As GAN-based synthesis technology is becoming stronger, various methods are difficult to classify the fake content effectively. However, although the fake content generated by GANs can deceive the human eyes, it ignores the biological signals hidden in the face video. In this paper, we proposed a novel video forensics method with multidimensional biological signals, which extracting the difference of the biological signal between real and fake videos from three dimensions. The experimental results show that our method achieves 98% accuracy on the main public dataset. Compared with other technologies, the proposed method only extracts fake video information and is not limited to a specific generation method, so it is not affected by synthetic methods and has good adaptability.
C1 [Jin, Xinlei; Ye, Dengpan; Chen, Chuanxi] Wuhan Univ, Sch Cyber Sci & Engn, Wuhan 430072, Peoples R China.
C3 Wuhan University
RP Ye, DP (corresponding author), Wuhan Univ, Sch Cyber Sci & Engn, Wuhan 430072, Peoples R China.
EM yedp@whu.edu.cn
OI Jin, Xinlei/0000-0002-3991-1405; Chen, Chuanxi/0000-0002-3863-0417; Ye,
   Dengpan/0000-0003-2510-9523
FU National Natural Science Foundation of China NSFCNational Natural
   Science Foundation of China (NSFC) [62072343, U1736211]; National Key
   Research Development Program of China [2019QY(Y)0206]
FX This work was partially supported by the National Natural Science
   Foundation of China NSFC (grant numbers 62072343, U1736211), the
   National Key Research Development Program of China (grant numbers
   2019QY(Y)0206). The views and conclusions contained herein are those of
   the authors and should not be interpreted as necessarily representing
   the official policies or endorsements.
CR Afchar D., 2018, 2018 IEEE INT WORKSH, P1, DOI DOI 10.1109/WIFS.2018.8630761
   Agarwal S., 2019, P CVPR WORKSH LONG B, P38
   Baek JY, 2020, IEEE ACCESS, V8, P45421, DOI 10.1109/ACCESS.2020.2968612
   Balakrishnan G, 2013, PROC CVPR IEEE, P3430, DOI 10.1109/CVPR.2013.440
   Bayar B., 2016, P 4 ACM WORKSH INF H, P5, DOI DOI 10.1145/2909827.2930786
   Bonettini N., 2020, VIDEO FACE MANIPULAT
   Chen BJ, 2020, J VIS COMMUN IMAGE R, V73, DOI 10.1016/j.jvcir.2020.102967
   Chen BJ, 2021, IEEE T MULTIMEDIA, V23, P3506, DOI 10.1109/TMM.2020.3026868
   Ciftci U.A., 2020, FAKECATCHER DETECTIO
   Conotter V, 2014, IEEE IMAGE PROC, P248, DOI 10.1109/ICIP.2014.7025049
   Do Nhu-Tai, 2018, FORENSICS FACE DETEC
   Dogonadze N., 2020, DEEP FACE FORGERY DE
   Guera D, 2018, 2018 15TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P127
   Korshunov P., 2018, DEEPFAKES NEW THREAT
   Li L., 2020, P IEEE CVF C COMP VI, P5001
   Li Y, 2018, EXPOSING DEEPFAKE VI
   Li Y., 2018, P 2018 IEEE INT WORK, P1
   Liu H., 2021, SPATIAL PHASE SHALLO
   Nguyen HH, 2019, INT CONF ACOUST SPEE, P2307, DOI 10.1109/ICASSP.2019.8682602
   Niu XS, 2020, IEEE T IMAGE PROCESS, V29, P2409, DOI 10.1109/TIP.2019.2947204
   Prakash SKA, 2018, BIOMED OPT EXPRESS, V9, P873, DOI 10.1364/BOE.9.000873
   Rahmouni N, 2017, IEEE INT WORKS INFOR
   Rossler A., 2019, P IEEE CVF INT C COM
   Rossler Andreas, 2018, FACEFORENSICS LARGE
   Rouast PV, 2018, FRONT COMPUT SCI-CHI, V12, P858, DOI 10.1007/s11704-016-6243-6
   Sabir E., 2019, INTERFACES GUI, V3
   Tulyakov S, 2016, PROC CVPR IEEE, P2396, DOI 10.1109/CVPR.2016.263
   Viola P., 2001, P 2001 IEEE COMP VIS
   Wang R., 2019, FAKESPOTTER SIMPLE Y
   Yang X, 2019, INT CONF ACOUST SPEE, P8261, DOI 10.1109/ICASSP.2019.8683164
   Zhao H., 2021, ARXIV PREPRINT ARXIV
NR 31
TC 0
Z9 0
U1 1
U2 3
PU WILEY-HINDAWI
PI LONDON
PA ADAM HOUSE, 3RD FL, 1 FITZROY SQ, LONDON, WIT 5HE, ENGLAND
SN 1939-0114
EI 1939-0122
J9 SECUR COMMUN NETW
JI Secur. Commun. Netw.
PD APR 22
PY 2021
VL 2021
DI 10.1155/2021/6626974
PG 8
WC Computer Science, Information Systems; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA SU7YQ
UT WOS:000663348300001
OA gold
DA 2022-02-06
ER

PT J
AU Lee, J
   Shin, SY
AF Lee, Jiyoung
   Shin, Soo Yun
TI Something that They Never Said: Multimodal Disinformation and Source
   Vividness in Understanding the Power of AI-Enabled Deepfake News
SO MEDIA PSYCHOLOGY
LA English
DT Article; Early Access
ID PICTURE-SUPERIORITY; SOCIAL MEDIA; COMMUNICATION; WARNINGS; MODEL
AB While deepfake has emerged as a severe issue in the multimedia environment, most studies examined text-based false claims, leaving the question of what unique features of video-based deepfake news deceives recipients and how it can be corrected. By conducting two online experiments, we study perceived source vividness as a psychological mechanism of the effect of AI-enabled deepfake news on news credibility and engagement intentions. Furthermore, we test how an inserted false-tag onto the fake news can reduce the impact of source vividness experienced by seeing multimodal disinformation on news credibility and engagement intentions. The results suggest that participants who saw deepfake news had higher source vividness than those who saw fake news with other modalities (i.e., text-only and text-photo), and such source vividness increased credibility and engagement intentions of fake news. The false-tag successfully reduced engagement intentions of deepfake news for those who perceived a high vividness of the superimposed interviewee.
C1 [Lee, Jiyoung] Univ Alabama, Coll Commun & Informat Sci, Dept Journalism & Creat Media, 486C Reese Phifer Hall, Tuscaloosa, AL 35404 USA.
   [Shin, Soo Yun] Univ Hawaii Manoa, Dept Communicol, Honolulu, HI USA.
C3 University of Alabama System; University of Alabama Tuscaloosa;
   University of Hawaii System; University of Hawaii Manoa
RP Lee, J (corresponding author), Univ Alabama, Coll Commun & Informat Sci, Dept Journalism & Creat Media, 486C Reese Phifer Hall, Tuscaloosa, AL 35404 USA.
EM jlee284@ua.edu
FU University of Alabama; University of Hawaii at Manoa
FX This work was supported by The University of Alabama and University of
   Hawaii at Manoa.
CR AJZEN I, 1991, ORGAN BEHAV HUM DEC, V50, P179, DOI 10.1016/0749-5978(91)90020-T
   Alhabash S, 2013, CYBERPSYCH BEH SOC N, V16, P175, DOI 10.1089/cyber.2012.0265
   [Anonymous], 2019, ABC NEWS
   Appiah O, 2006, J CURRENT ISSUES RES, V28, P73, DOI DOI 10.1080/10641734.2006.10505192
   Baden C, 2012, COMMUN THEOR, V22, P359, DOI 10.1111/j.1468-2885.2012.01413.x
   Big Think, 2011, LEGALIZE ALL DRUGS
   Bundesen C., 2008, PRINCIPLES VISUAL AT
   CHILDERS TL, 1984, J CONSUM RES, V11, P643, DOI 10.1086/209001
   Chiu HC, 2007, J ADVERTISING RES, V47, P524, DOI 10.2501/S0021849907070547
   Clayton K, 2020, POLIT BEHAV, V42, P1073, DOI 10.1007/s11109-019-09533-0
   Dobber T, 2021, INT J PRESS/POLIT, V26, P69, DOI 10.1177/1940161220944364
   Eagly A.H., 1993, PSYCHOL ATTITUDES
   Ecker UKH, 2020, BRIT J PSYCHOL, V111, P36, DOI 10.1111/bjop.12383
   Fazio L., 2020, HARVARD KENNEDY SCH, DOI [10.37016/mr-2020-009, DOI 10.37016/MR-2020-009]
   Garrett RK, 2019, J COMPUT-MEDIAT COMM, V24, P240, DOI 10.1093/jcmc/zmz012
   Geise S, 2015, COMMUN THEOR, V25, P46, DOI 10.1111/comt.12048
   Gibson R, 2000, JOURNALISM MASS COMM, V77, P355, DOI 10.1177/107769900007700209
   Hancock JT, 2020, J COMPUT-MEDIAT COMM, V25, P89, DOI 10.1093/jcmc/zmz022
   Horton JJ, 2011, EXP ECON, V14, P399, DOI 10.1007/s10683-011-9273-9
   Hsu CL, 2008, INFORM MANAGE-AMSTER, V45, P65, DOI 10.1016/j.im.2007.11.001
   Hwang Y, 2021, CYBERPSYCH BEH SOC N, V24, P188, DOI 10.1089/cyber.2020.0174
   Jenkins M., 2001, VISION AND ATTENTION
   Kasra M., 2017, AOIR SELECTED PAPERS, V6
   Lang A, 2000, J COMMUN, V50, P46, DOI 10.1093/joc/50.1.46
   Lee J, 2022, J APPL COMMUN RES, V50, P70, DOI 10.1080/00909882.2021.1964574
   Lee J, 2020, BEHAV INFORM TECHNOL, DOI 10.1080/0144929X.2020.1829708
   Lee KM, 2005, MEDIA PSYCHOL, V7, P31, DOI 10.1207/S1532785XMEP0701_2
   Ma L, 2014, ONLINE INFORM REV, V38, P598, DOI 10.1108/OIR-10-2013-0239
   Mason W, 2012, BEHAV RES METHODS, V44, P1, DOI 10.3758/s13428-011-0124-6
   Mena P, 2020, POLICY INTERNET, V12, P165, DOI 10.1002/poi3.214
   Mervosh S., 2019, NEW YORK TIMES
   Mingkun Gao, 2018, Proceedings of the ACM on Human-Computer Interaction, V2, DOI 10.1145/3274324
   NELSON DL, 1976, J EXP PSYCHOL-HUM L, V2, P523, DOI 10.1037/0278-7393.2.5.523
   OHalloran Kay, 2012, MULTIMODAL STUDIES E
   PAIVIO A, 1973, COGNITIVE PSYCHOL, V5, P176, DOI 10.1016/0010-0285(73)90032-7
   Pennycook G, 2020, PSYCHOL SCI, V31, P770, DOI 10.1177/0956797620939054
   Pennycook G, 2018, J EXP PSYCHOL GEN, V147, P1865, DOI 10.1037/xge0000465
   Pennycook G, 2019, COGNITION, V188, P39, DOI 10.1016/j.cognition.2018.06.011
   Powell TE, 2015, J COMMUN, V65, P997, DOI 10.1111/jcom.12184
   Silverman Craig, 2018, BUZZFEED
   Stefanone M.A., 2019, P 10 INT C SOC MED S, P136
   Stenberg G, 2006, EUR J COGN PSYCHOL, V18, P813, DOI 10.1080/09541440500412361
   Sundar SS, 2021, J COMPUT-MEDIAT COMM, V26, P301, DOI 10.1093/jcmc/zmab010
   Sundar SS., 2008, DIGITAL MEDIA YOUTH, P73, DOI DOI 10.1162/DMAL.9780262562324.073
   Talwar S, 2019, J RETAIL CONSUM SERV, V51, P72, DOI 10.1016/j.jretconser.2019.05.026
   Tran H.L., 2015, ELECTRON NEWS, V9, P51, DOI [10.1177/1931243115572821, DOI 10.1177/1931243115572821]
   Vaccari C, 2020, SOC MEDIA SOC, V6, DOI 10.1177/2056305120903408
   Vosoughi S, 2018, SCIENCE, V359, P1146, DOI 10.1126/science.aap9559
   Walter N, 2020, POLIT COMMUN, V37, P350, DOI 10.1080/10584609.2019.1668894
   Weeks BE, 2013, J MASS COMMUN Q, V90, P212, DOI 10.1177/1077699013482906
   Wood T, 2019, POLIT BEHAV, V41, P135, DOI 10.1007/s11109-018-9443-y
   Zhang Z., 2018, WebPower: Basic and advanced statistical power analysis
NR 52
TC 0
Z9 0
U1 4
U2 4
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 1521-3269
EI 1532-785X
J9 MEDIA PSYCHOL
JI Media Psychol.
DI 10.1080/15213269.2021.2007489
EA DEC 2021
PG 16
WC Communication; Film, Radio, Television; Psychology, Applied
WE Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Communication; Film, Radio & Television; Psychology
GA XM7UP
UT WOS:000729027400001
DA 2022-02-06
ER

PT J
AU Lunga, CM
   Mthembu, MV
AF Lunga, Carolyne Mande
   Mthembu, Maxwell Vusumuzi
TI Investigating the Source and Strategies Adopted by Mainstream Media in
   Combating Fake News in the Kingdom of Eswatini
SO AFRICAN JOURNALISM STUDIES
LA English
DT Article
DE Fake news; Times of Swaziland; Swazi Observer; mainstream media; social
   media; strategies
AB The spread of "fake news" is a threat to the credibility of the media in the Southern African Development Community (SADC), including Eswatini (formerly Swaziland). These intentionally false stories or disinformation purporting to be news threaten the democratic role of mainstream media in creating a well-informed citizenry. There is hate speech, and disinformation directed at the royal family, the cabinet, prominent figures and the larger Swazi society. This study focuses on disinformation in the mainstream media, theSwazi Observerand theTimes of Swaziland, and the strategies being adopted to combat it. The article adopts a qualitative methodological approach using in-depth interviews with journalists and qualitative content analysis of the newspapers as data-gathering methods. The study reveals that the dissemination of false information is partially a consequence of the secretive nature of Swazi society even on matters of public interest. This has resulted in people spreading false news through social media aimed at ridiculing those in authority. On the other hand, "fake news" has found its way into mainstream media as journalists use the internet and social media such as Facebook and Twitter as sources of news without verifying their authenticity due to the pressure to be the first to publish.
C1 [Lunga, Carolyne Mande; Mthembu, Maxwell Vusumuzi] Univ Eswatini UNESWA, Fac Humanities, Journalism & Mass Commun, Kwaluseni, Eswatini.
RP Lunga, CM (corresponding author), Univ Eswatini UNESWA, Fac Humanities, Journalism & Mass Commun, Kwaluseni, Eswatini.
EM clunga@uniswa.sz
OI Mthembu, Maxwell/0000-0002-9872-5776; Lunga, Carolyne
   M./0000-0001-7242-5858
CR Brondani MA, 2011, INT J QUAL METH, V10, P221, DOI 10.1177/160940691101000303
   Burns E, 2010, SOCIOL RES ONLINE, V15, DOI 10.5153/sro.2232
   Cooke Nicole, 2018, FAKE NEWS ALTERNATIV
   DICE Mark, 2017, TRUE STORY FAKE NEWS
   Dube P., 2015, THESIS
   Duffy E., 2018, FAKE NEWS ROADMAP, P14
   Government of Swaziland, 2011, SWAZ POP HOUS CENS R
   Hlatshwayo V.S., 2011, THESIS
   Internet World Stats, 2019, US POP STAT
   Ireton C., 2018, HDB JOURNALISM ED TR HDB JOURNALISM ED TR
   Kvale S, 2006, QUAL INQ, V12, P480, DOI 10.1177/1077800406286235
   Lemke J, 2018, AFR JOURNAL STUD, V39, P61, DOI 10.1080/23743670.2018.1473268
   Mare A., 2018, NEWS DAY        0531
   Mare A., 2019, CONVERSATION
   McCombs M, 2002, MASS MED EC 2002 C MASS MED EC 2002 C
   McManus C., 2018, FAKE NEWS ROADMAP, P14
   Mihailidis P, 2017, AM BEHAV SCI, V61, P441, DOI 10.1177/0002764217701217
   Moyo L, 2011, JOURNALISM, V12, P745, DOI 10.1177/1464884911405469
   Mthembu M., 2012, SO THIS IS DEMOCRACY
   Mthembu M. Z., 2009, THESIS
   Mthembu MV, 2018, COMMUNICARE, V37, P74
   Nelson JL, 2018, NEW MEDIA SOC, V20, P3720, DOI 10.1177/1461444818758715
   Rice D.H., 2018, DECEPTION REAL FAKE
   Sanef, 2017, SAN COND FAK NEWS SI
   Social Media Stats, 2019, SOCIAL MEDIA STATS
   Stassen Wilma, 2010, GLOBAL MEDIA J AFRIC, V4, P1
   Tandoc EC, 2018, DIGIT JOURNAL, V6, P137, DOI 10.1080/21670811.2017.1360143
   Tonkiss F., 2003, RES SOC CULTURE, P368
   Wasserman H, 2020, JOURNALISM, V21, P3, DOI 10.1177/1464884917746861
NR 29
TC 2
Z9 2
U1 2
U2 6
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 2374-3670
EI 2374-3689
J9 AFR JOURNAL STUD
JI Afr. Journal. Stud.
PD OCT 2
PY 2019
VL 40
IS 4
SI SI
BP 96
EP 111
DI 10.1080/23743670.2019.1664606
PG 16
WC Communication
WE Social Science Citation Index (SSCI)
SC Communication
GA MT6SD
UT WOS:000555101700007
DA 2022-02-06
ER

PT J
AU Caldelli, R
   Galteri, L
   Amerini, I
   Del Bimbo, A
AF Caldelli, Roberto
   Galteri, Leonardo
   Amerini, Irene
   Del Bimbo, Alberto
TI Optical Flow based CNN for detection of unlearnt deepfake manipulations
SO PATTERN RECOGNITION LETTERS
LA English
DT Article
DE Deepfake manipulations; Optical Flow; Video forensics; CNN
AB A new phenomenon named Deepfakes constitutes a serious threat in video manipulation. AI-based tech-nologies have provided easy-to-use methods to create extremely realistic videos. On the side of multi-media forensics, being able to individuate this kind of fake contents becomes ever more crucial. In this work, a new forensic technique able to detect fake and original video sequences is proposed; it is based on the use of CNNs trained to distinguish possible motion dissimilarities in the temporal structure of a video sequence by exploiting optical flow fields. The results obtained highlight comparable performances with the state-of-the-art methods which, in general, only resort to single video frames. Furthermore, the proposed optical flow based detection scheme also provides a superior robustness in the more realistic cross-forgery operative scenario and can even be combined with frame-based approaches to improve their global effectiveness.
   (c) 2021 Elsevier B.V. All rights reserved.
C1 [Caldelli, Roberto] Univ Mercatorum, Rome, Italy.
   [Galteri, Leonardo; Del Bimbo, Alberto] Univ Florence, Media Integrat & Commun Ctr, Florence, Italy.
   [Amerini, Irene] Sapienza Univ Rome, Rome, Italy.
   [Caldelli, Roberto] Natl Interuniv Consortium Telecommun CNIT, Parma, Italy.
C3 Universita Telematica Mercatorum; University of Florence; Sapienza
   University Rome
RP Caldelli, R (corresponding author), Natl Interuniv Consortium Telecommun CNIT, Parma, Italy.
EM roberto.caldelli@unifi.it
OI GALTERI, LEONARDO/0000-0002-7247-9407
FU EC under European H2020 Programme [951911AI4Media]; NVIDIA Corporation
FX The work has been partially supported by the EC under European H2020
   Programme, grant number no. 951911AI4Media. The authors gratefully
   acknowledge the support of NVIDIA Corporation with the donation of the
   Titan Xp GPU used for this research.
CR Afchar D, 2018, IEEE INT WORKS INFOR
   Agarwal S., 2019, P CVPR WORKSH LONG B, P38
   Alparone L, 1999, IEEE T IMAGE PROCESS, V8, P1462, DOI 10.1109/83.791974
   Amerini I, 2019, IEEE INT CONF COMP V, P1205, DOI 10.1109/ICCVW.2019.00152
   Beauchemin SS, 1995, ACM COMPUT SURV, V27, P433, DOI 10.1145/212094.212141
   Choi Y., 2017, ARXIV171109020
   Cozzolino Davide, 2018, ARXIV181202510
   Dang H, 2020, PROC CVPR IEEE, P5780, DOI 10.1109/CVPR42600.2020.00582
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Feng D., 2020, NEURAL INFORM PROCES, P316
   Guera D, 2018, 2018 15TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P127
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Karras T., 2017, ARXIV171010196
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Li YZ, 2020, PROC CVPR IEEE, P3204, DOI 10.1109/CVPR42600.2020.00327
   Li Yuezun, 2018, CVPR
   Marra Francesco, 2019, 2019 IEEE INT WORKSH
   Matern F, 2019, IEEE WINT CONF APPL, P83, DOI 10.1109/WACVW.2019.00020
   Nguyen HH, 2019, INT CONF ACOUST SPEE, P2307, DOI 10.1109/ICASSP.2019.8682602
   Niessner M., 2016, ACM SIGGRAPH 2016 EM
   Rossler A, 2019, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2019.00009
   Sabir E., 2019, RECURRENT CONVOLUTIO
   Simonyan K, 2015, ICLR 2015, DOI DOI 10.1109/CVPR.2015.7298594
   Thies J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323035
   Verdoliva L, 2020, IEEE J-STSP, V14, P910, DOI 10.1109/JSTSP.2020.3002101
   Wang S.-Y., 2019, ARXIV191211035
   Yang X, 2019, INT CONF ACOUST SPEE, P8261, DOI 10.1109/ICASSP.2019.8683164
   Zach C, 2007, LECT NOTES COMPUT SC, V4713, P214, DOI 10.1007/978-3-540-74936-3_22
NR 29
TC 2
Z9 2
U1 4
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0167-8655
EI 1872-7344
J9 PATTERN RECOGN LETT
JI Pattern Recognit. Lett.
PD JUN
PY 2021
VL 146
BP 31
EP 37
DI 10.1016/j.patrec.2021.03.005
PG 7
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA RV7OX
UT WOS:000646018400005
DA 2022-02-06
ER

PT J
AU Pan, ZG
   Ren, YL
   Zhang, XP
AF Pan, Zhaoguang
   Ren, Yanli
   Zhang, Xinpeng
TI Low-complexity fake face detection based on forensic similarity
SO MULTIMEDIA SYSTEMS
LA English
DT Article
DE Face forgery; Face forensics; Deep learning; Similarity difference;
   Complexity
AB In recent years, face synthesis and manipulation technology have been developed rapidly, and now it is feasible to synthesize extremely realistic fake face videos, which can easily deceive existing face recognition systems. Due to the high quality of fake videos, allowing fake face videos to propagate on Internet may cause serious ethical, moral and legal problems. Therefore, the effective and reliable detection method is urgently needed to distinguish fake face videos. We notice that existing face forgery methods commonly extract face area of each frame first and perform manipulations only on face areas while background areas remain unchanged. Therefore, the difference between the face area and the background area in a forged face frame is significantly larger than the difference between the face area and the background area in the corresponding unforged frame. In this paper, based on such observation, we propose a new detection method-forensic similarity method-which judges the authenticity of face video frames by detecting the difference in similarity between the face area and the background area. For evaluation, we conduct training and testing on FaceForensics++ dataset, and evaluate the generalization capability on Celeb-DF dataset. From the experimental results, we can find that the proposed method has a better or comparable performance, especially in the term of generalization capability. Compared with Xception, our model can attain 8-12% accuracy gains under Celeb-DF dataset. In addition, our model has lower complexity than Xception.
C1 [Pan, Zhaoguang; Ren, Yanli; Zhang, Xinpeng] Shanghai Univ, Sch Commun & Informat Engn, Shanghai, Peoples R China.
C3 Shanghai University
RP Ren, YL (corresponding author), Shanghai Univ, Sch Commun & Informat Engn, Shanghai, Peoples R China.
EM renyanli@shu.edu.cn
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [U1736120, U1636206, 61525203]; Natural
   Science Foundation of ShanghaiNatural Science Foundation of Shanghai
   [20ZR1419700]
FX The work described in this paper was supported by the National Natural
   Science Foundation of China (Grant No. U1736120, U1636206, 61525203),
   and Natural Science Foundation of Shanghai (20ZR1419700).
CR Afchar D, 2018, IEEE INT WORKS INFOR
   Agarwal S., 2019, P CVPR WORKSH LONG B, P38
   [Anonymous], 2018, FACESWAP
   [Anonymous], DEEPFAKES GITHUB
   Averbuch-Elor H, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130818
   Blanz V, 2004, COMPUT GRAPH FORUM, V23, P669, DOI 10.1111/j.1467-8659.2004.00799.x
   Bruna J, ARXIV PREPRINT ARXIV
   Chen P, 2020, IEEE INT CON MULTI
   Chollet F, 2016, P IEEE C COMP VIS PA, P1251
   Dale K, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024164
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Durall Ricard, 2019, ARXIV191100686
   Guera D, 2018, 2018 15TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P127
   Hung-Shin Lee, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P1660, DOI 10.1109/ICASSP.2014.6853880
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Li, 2019, IEEE T CIRC SYST VID, P1
   Li LZ, 2020, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR42600.2020.00505
   Li YJ, 2019, IEEE INT C BIOINFORM, P303, DOI 10.1109/BIBM47256.2019.8982964
   Li Yuezun, 2018, CVPR
   Loffe S., 2015, ABS150203167 ARXIV, P448, DOI DOI 10.1109/CVPR.2016.90
   Matern F, 2019, IEEE WINT CONF APPL, P83, DOI 10.1109/WACVW.2019.00020
   Mayer O, 2020, IEEE T INF FOREN SEC, V15, P1331, DOI 10.1109/TIFS.2019.2924552
   Nguyen Huy H, 2019, ARXIV191012467
   Nirkin Y, 2019, IEEE I CONF COMP VIS, P7183, DOI 10.1109/ICCV.2019.00728
   Rossler A, 2019, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2019.00009
   Simonyan K, 2015, ICLR 2015, DOI DOI 10.1109/CVPR.2015.7298594
   Suwajanakorn S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073640
   Szegedy C, 2017, THIRTY-FIRST AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4278
   Thies J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323035
   Thies J, 2016, PROC CVPR IEEE, P2387, DOI 10.1109/CVPR.2016.262
   Tolosana R, 2020, INFORM FUSION, V64, P131, DOI 10.1016/j.inffus.2020.06.014
   Woo S.S., 2020, ARXIV PREPRINT ARXIV, P416
   Xu L., 2016, P IEEE INT WORKSH AC, P1
   Yang X, 2019, INT CONF ACOUST SPEE, P8261, DOI 10.1109/ICASSP.2019.8683164
   Zhou P, 2017, IEEE COMPUT SOC CONF, P1831, DOI 10.1109/CVPRW.2017.229
NR 35
TC 0
Z9 0
U1 5
U2 14
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0942-4962
EI 1432-1882
J9 MULTIMEDIA SYST
JI Multimedia Syst.
PD JUN
PY 2021
VL 27
IS 3
SI SI
BP 353
EP 361
DI 10.1007/s00530-021-00756-y
EA FEB 2021
PG 9
WC Computer Science, Information Systems; Computer Science, Theory &
   Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ST2XW
UT WOS:000621326800001
DA 2022-02-06
ER

PT J
AU Gosztolya, G
   Grosz, T
   Toth, L
AF Gosztolya, Gabor
   Grosz, Tamas
   Toth, Laszlo
TI Using Temporal Features of Observers' Physiological Measures to
   Distinguish Between Genuine and Fake Smiles
SO IEEE TRANSACTIONS ON AFFECTIVE COMPUTING
LA English
DT Article
DE Observers; Videos; Physiology; Databases; Electrocardiography; Feature
   extraction; Face; Affective computing; genuine smile; fake smile;
   physiological signals; temporal features
AB Future affective computing research could be enhanced by enabling the computer to recognise a displayer's mental state from an observer's reaction (measured by physiological signals), using this information to improve recognition algorithms, and eventually to computer systems which are more responsive to human emotions. In this paper, an observer's physiological signals are analysed to distinguish displayers' genuine from fake smiles. Overall, thirty smile videos were collected from four benchmark database and classified as showing genuine or fake smiles. Overall, forty observers viewed videos. We generally recorded four physiological signals: pupillary response (PR), electrocardiogram (ECG), galvanic skin response (GSR), and blood volume pulse (BVP). A number of temporal features were extracted after a few processing steps, and minimally correlated features between genuine and fake smiles were selected using the NCCA (canonical correlation analysis with neural network) system. Finally, classification accuracy was found to be as high as 98.8 percent from PR features using a leave-one-observer-out process. In comparison, the best current image processing technique [1] on the same video data was 95 percent correct. Observers were 59 percent (on average) to 90 percent (by voting) correct by their conscious choices. Our results demonstrate that humans can non-consciously (or emotionally) recognise the quality of smiles 4 percent better than current image processing techniques and 9 percent better than the conscious choices of groups.
C1 [Gosztolya, Gabor; Toth, Laszlo] Hungarian Acad Sci, MTA SZTE Res Grp Artificial Intelligence, H-6720 Szeged, Hungary.
   [Gosztolya, Gabor; Grosz, Tamas; Toth, Laszlo] Univ Szeged, H-6720 Szeged, Hungary.
C3 Hungarian Academy of Sciences; Szeged University
RP Gosztolya, G (corresponding author), Hungarian Acad Sci, MTA SZTE Res Grp Artificial Intelligence, H-6720 Szeged, Hungary.
EM ggabor@inf.u-szeged.hu; groszt@inf.u-szeged.hu; tothl@inf.u-szeged.hu
RI Hossain, Zakir/Y-1537-2019
OI Hossain, Zakir/0000-0003-1892-831X
FU National Research, Development and Innovation Office of Hungary
   [ID-124413]; Janos Bolyai Research Scholarship of the Hungarian Academy
   of SciencesHungarian Academy of Sciences
FX Gabor Gosztolya was funded by the National Research, Development and
   Innovation Office of Hungary via contract ID-124413 'Enhancement of deep
   learning based semantic representations with acoustic-prosodic features
   for automatic spoken document summarization and retrieval'. Laszlo Toth
   was supported by the Janos Bolyai Research Scholarship of the Hungarian
   Academy of Sciences.
NR 0
TC 3
Z9 3
U1 2
U2 8
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1949-3045
J9 IEEE T AFFECT COMPUT
JI IEEE Trans. Affect. Comput.
PD JAN-MAR
PY 2020
VL 11
IS 1
BP 164
EP 177
DI 10.1109/TAFFC.2018.2878029
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Cybernetics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KX6LC
UT WOS:000521989700012
DA 2022-02-06
ER

PT J
AU Brasoveanu, AMP
   Andonie, R
AF Brasoveanu, Adrian M. P.
   Andonie, Razvan
TI Integrating Machine Learning Techniques in Semantic Fake News Detection
SO NEURAL PROCESSING LETTERS
LA English
DT Article
DE NLP; Semantics; Relation extraction; Deep learning
AB The nuances of languages, as well as the varying degrees of truth observed in news items, make fake news detection a difficult problem to solve. A news item is never launched without a purpose, therefore in order to understand its motivation it is best to analyze the relations between the speaker and its subject, as well as different credibility metrics. Inferring details about the various actors involved in a news item is a problem that requires a hybrid approach that mixes machine learning, semantics and natural language processing. This article discusses a semantic fake news detection method built around relational features like sentiment, entities or facts extracted directly from text. Our experiments are focused on short texts with different degrees of truth and show that adding semantic features improves accuracy significantly.
C1 [Brasoveanu, Adrian M. P.] MODUL Technol GmbH, Vienna, Austria.
   [Andonie, Razvan] Cent Washington Univ, Comp Sci Dept, Ellensburg, WA USA.
   [Brasoveanu, Adrian M. P.; Andonie, Razvan] Transilvania Univ Brasov, Elect & Comp Dept, Brasov, Romania.
C3 Central Washington University; Transylvania University of Brasov
RP Brasoveanu, AMP (corresponding author), MODUL Technol GmbH, Vienna, Austria.; Brasoveanu, AMP (corresponding author), Transilvania Univ Brasov, Elect & Comp Dept, Brasov, Romania.
EM adrian.brasoveanu@modul.ac.at; andonie@cwu.edu
OI Andonie, Razvan/0000-0002-6015-3151
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Aghakhani Hojjat, 2018, ARXIV180510364
   Al-Moslmi T, 2020, IEEE ACCESS, V8, P32862, DOI 10.1109/ACCESS.2020.2973928
   Allcott H, 2017, J ECON PERSPECT, V31, P211, DOI 10.1257/jep.31.2.211
   Atanasova P, 2019, ACM J DATA INF QUAL, V11, DOI 10.1145/3297722
   Barron-Cedeno A, 2019, THIRTY-THIRD AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTY-FIRST INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / NINTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P9847
   Bender EM, 2018, P 27 INT C COMP LING
   Berghel H, 2017, COMPUTER, V50, P80, DOI 10.1109/MC.2017.56
   Brasoveanu AMP, 2019, LECT NOTES COMPUT SC, V11506, P656, DOI 10.1007/978-3-030-20521-8_54
   Cambria E, 2017, IEEE INTELL SYST, V32, P74, DOI 10.1109/MIS.2017.4531228
   Chiu JPC., 2016, T ASSOC COMPUT LING, V4, P357, DOI [10.1162/tacl_a_00104, DOI 10.1162/TACL_A_00104, 10.3115/1119176.1119204]
   Chollet F., 2017, DEEP LEARNING PYTHON
   Clark K, 2019, BLACKBOXNLP WORKSHOP ON ANALYZING AND INTERPRETING NEURAL NETWORKS FOR NLP AT ACL 2019, P276, DOI 10.18653/v1/w19-4828
   Daiber Joachim, 2013, P 9 INT C SEMANTIC S, P121
   Devlin J, 2019, PROC C N AM CHAPTER, P4171, DOI DOI 10.18653/V1/N19-1423
   Fentaw HW, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9112200
   Fourney A, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P2071, DOI 10.1145/3132847.3133147
   Friedman J., 2009, MATH INTELL, DOI DOI 10.1007/BF02985802
   Gandon F., 2018, INGENIERIE SYSTEMES, V23, P11, DOI [10.3166/isi.23.3-4.11-38, DOI 10.3166/ISI.23.3-4.11-38]
   Gangemi A, 2017, SEMANT WEB, V8, P873, DOI 10.3233/SW-160240
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Gururangan S, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5880
   Guyon I, 2017, ADV NEURAL INFORM PR
   Habib A, 2019, SOC NETW ANAL MIN, V9, DOI 10.1007/s13278-019-0595-5
   Huang CR, 2017, P 8 INT JOINT C NAT, V2, P252
   Irie K, 2016, INTERSPEECH, P3519, DOI 10.21437/Interspeech.2016-491
   Ji H., 2016, 8 TEXT AN C TAC
   Jin ZW, 2016, THIRTIETH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2972
   Kai Shu, 2017, ACM SIGKDD Explorations Newsletter, V19, P22, DOI 10.1145/3137597.3137600
   Karimi H., 2018, P 27 INT C COMP LING, P1546
   Kiesel J., 2019, P 13 INT WORKSH SEM
   Kim, 2014, ARXIV14085882, P1746, DOI [10.3115/v1/d14, 10.3115/v1/D14-1181]
   Kim J, 2020, NEUROCOMPUTING, V376, P214, DOI 10.1016/j.neucom.2019.10.033
   Kingma DP, 2015, 3 INT C LEARN REPR I, DOI DOI 10.1145/1830483.1830503
   Kiperwasser E., 2016, T ASS COMPUTATIONAL, V4, P313, DOI [10.1162/tacl_a_00101, DOI 10.1162/TACL_A_00101]
   Korhonen A., 2019, P 57 C ASS COMP LING, V1
   Lehmann J, 2015, SEMANT WEB, V6, P167, DOI 10.3233/SW-140134
   Lim E, 2017, P 2017 ACM C INF KNO
   Liu C, 2019, SPRINGER SER ADV MAN, P117, DOI 10.1007/978-3-319-72986-2_6
   Liu Y., 2019, CORR
   Liu Y, 2018, THIRTY-SECOND AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTIETH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / EIGHTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P354
   Lundberg SM., 2017, ADV NEURALINFOR MATI, DOI DOI 10.5555/3295222.3295230
   Mikolov T, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P52
   Vo N, 2018, ACM/SIGIR PROCEEDINGS 2018, P275, DOI 10.1145/3209978.3210037
   Nickel M, 2016, P IEEE, V104, P11, DOI 10.1109/JPROC.2015.2483592
   Parikh SB, 2018, IEEE 1ST CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2018), P436, DOI 10.1109/MIPR.2018.00093
   Qi Y., 2018, ARXIV PREPRINT ARXIV
   Rashkin Hannah, 2017, P 2017 C EMPIRICAL M, P2931
   Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778
   Rubin V., 2016, P 2 WORKSH COMP APPR, P7, DOI DOI 10.18653/V1/W16-0802
   Rubin V.L., 2015, P ASS INFORM SCI TEC, V52, P1, DOI [https://doi.org/10.1002/pra2.2015.145052010083, DOI 10.1002/PRA2.2015.145052010083]
   Ruchansky N, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P797, DOI 10.1145/3132847.3132877
   Sabour S., 2017, NIPS, P3856
   Schlichtkrull M., 2018, 15 INT C SEM WEB C, DOI DOI 10.1007/978-3-319-93417-4_38
   Shu K, 2017, ARXIV171207709
   Singhania S, 2017, LECT NOTES COMPUT SC, V10635, P572, DOI 10.1007/978-3-319-70096-0_59
   Solaiman I, 2019, ARXIV190809202
   Strubell E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3645
   Thorne J., 2018, P 27 INT C COMP LINB, P3346
   Vaswani A., 2017, ADV NEURAL INFORM PR, P5998, DOI DOI 10.5555/3295222.3295349
   Vosoughi S, 2018, SCIENCE, V359, P1146, DOI 10.1126/science.aap9559
   Wang WY, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P422, DOI 10.18653/v1/P17-2067
   Wu L, 2018, WSDM'18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P637, DOI 10.1145/3159652.3159677
   Yang K, 2019, ARXIV190707347
   Young T, 2018, IEEE COMPUT INTELL M, V13, P55, DOI 10.1109/MCI.2018.2840738
   Zannettou S, 2018, ARXIV180403461
   Zellers R., 2019, ADV NEURAL INFORM PR
NR 67
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1370-4621
EI 1573-773X
J9 NEURAL PROCESS LETT
JI Neural Process. Lett.
PD OCT
PY 2021
VL 53
IS 5
SI SI
BP 3055
EP 3072
DI 10.1007/s11063-020-10365-x
EA OCT 2020
PG 18
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WH4LR
UT WOS:000584974700001
DA 2022-02-06
ER

PT J
AU Ying, L
   Yu, H
   Wang, JG
   Ji, YZ
   Qian, SS
AF Ying, Long
   Yu, Hui
   Wang, Jinguang
   Ji, Yongze
   Qian, Shengsheng
TI Multi-Level Multi-Modal Cross-Attention Network for Fake News Detection
SO IEEE ACCESS
LA English
DT Article
DE Feature extraction; Semantics; Visualization; Task analysis; Bit error
   rate; Convolutional neural networks; Social networking (online);
   Multi-level neural networks; fake news detection; multi-modal fusion
AB With the development of the Mobile Internet, more and more users publish multi-modal posts on social media platforms. Fake news detection has become an increasingly challenging task. Although there are many works using deep schemes to extract and combine textual and visual representation in the post, most existing methods do not sufficiently utilize the complementary multi-modal information containing semantic concepts and entities to complement and enhance each modality. Moreover, these methods do not model and incorporate the rich multi-level semantics of text information to improve fake news detection tasks. In this paper, we propose a novel end-to-end Multi-level Multi-modal Cross-attention Network (MMCN) which exploits the multi-level semantics of textual content and jointly integrates the relationships of duplicate and different modalities (textual and visual modality) of social multimedia posts in a unified framework. Pre-trained BERT and ResNet models are employed to generate high-quality representations for text words and image regions respectively. A multi-modal cross-attention network is then designed to fuse the feature embeddings of the text words and image regions by simultaneously considering data relationships in duplicate and different modalities. Specially, due to different layers of the transformer architecture have different feature representations, we employ a multi-level encoding network to capture the rich multi-level semantics to enhance the presentations of posts. Extensive experiments on the two public datasets (WEIBO and PHEME) demonstrate that compared with the state-of-the-art models, the proposed MMCN has an advantageous performance.
C1 [Ying, Long; Yu, Hui] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Peoples R China.
   [Wang, Jinguang] Hefei Univ Technol, Sch Comp Sci & Informat Engn, Hefei 230601, Peoples R China.
   [Ji, Yongze] China Univ Petr, Sch Informat Sci & Engn, Beijing 102249, Peoples R China.
   [Qian, Shengsheng] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China.
C3 Nanjing University of Information Science & Technology; Hefei University
   of Technology; China University of Petroleum; Chinese Academy of
   Sciences; Institute of Automation, CAS
RP Ying, L; Yu, H (corresponding author), Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Peoples R China.
EM lorin_ying@hotmail.com; 20191221027@nuist.edu.cn
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61902193]; Priority Academic Program
   Development of Jiangsu Higher Education Institutions (PAPD)
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61902193, and in part by the Priority
   Academic Program Development of Jiangsu Higher Education Institutions
   (PAPD).
CR Castillo C., 2011, WWW, P675
   Devlin J, 2019, PROC C N AM CHAPTER, P4171, DOI DOI 10.18653/V1/N19-1423
   Dun YQ, 2021, AAAI CONF ARTIF INTE, V35, P81
   Gupta A, 2014, LECT NOTES COMPUT SC, V8851, P228, DOI 10.1007/978-3-319-13734-6_16
   Han, 2012, SDM, P153
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hsu CC, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2687, DOI 10.1145/3343031.3356064
   Ji RR, 2019, IEEE T MULTIMEDIA, V21, P1062, DOI 10.1109/TMM.2018.2867718
   Jiang T, 2021, IEEE ACCESS, V9, P22626, DOI 10.1109/ACCESS.2021.3056079
   Jin ZW, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P795, DOI 10.1145/3123266.3123454
   Jin ZW, 2017, IEEE T MULTIMEDIA, V19, P598, DOI 10.1109/TMM.2016.2617078
   Kai Shu, 2017, ACM SIGKDD Explorations Newsletter, V19, P22, DOI 10.1145/3137597.3137600
   Kalamaras I, 2014, IEEE T MULTIMEDIA, V16, P1460, DOI 10.1109/TMM.2014.2316473
   Khattar D, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P2915, DOI 10.1145/3308558.3313552
   King DB, 2015, ACS SYM SER, V1214, P1
   Kovaleva O., 2019, P 2019 C EMP METH NA, P4365, DOI [10.18653/v1/D19-1445, DOI 10.18653/V1/D19-1445]
   Kwon S, 2013, IEEE DATA MINING, P1103, DOI 10.1109/ICDM.2013.61
   Ma J., 2015, P 24 ACM INT C INF K, V19-23, P1751, DOI DOI 10.1145/2806416.2806607
   Ma J., 2016, P 25 INT JOINT C ART, P3818
   Mishra R., 2020, P IEEE CVF C COMP VI, P652
   Qi P, 2019, IEEE DATA MINING, P518, DOI 10.1109/ICDM.2019.00062
   Sanh Victor, 2019, EMC2
   Song Y., 2020, ABS200204815 CORR
   Sun C, 2019, LECT NOTES ARTIF INT, V11856, P194, DOI 10.1007/978-3-030-32381-3_16
   Tian D.P., 2013, INT J MULTIMEDIA UBI, V8, P385
   Umer M, 2020, IEEE ACCESS, V8, P156695, DOI 10.1109/ACCESS.2020.3019735
   Wang YQ, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P849, DOI 10.1145/3219819.3219903
   Wu X, 2008, IEEE T MULTIMEDIA, V10, P188, DOI 10.1109/TMM.2007.911778
   Yan TK, 2016, CIKM'16: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1271, DOI 10.1145/2983323.2983743
   Yang XS, 2015, IEEE T MULTIMEDIA, V17, P64, DOI 10.1109/TMM.2014.2375793
   Yao L, 2019, THIRTY-THIRD AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTY-FIRST INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / NINTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P7370
   Yu F., 2017, P 26 INT JOINT C ART P 26 INT JOINT C ART, P3901
   Zhao L, 2015, IEEE T MULTIMEDIA, V17, P1936, DOI 10.1109/TMM.2015.2477058
   Zhao Z, 2018, IEEE T MULTIMEDIA, V20, P430, DOI 10.1109/TMM.2017.2740022
   Zhou XY, 2020, LECT NOTES ARTIF INT, V12085, P354, DOI 10.1007/978-3-030-47436-2_27
   Zubiaga A, 2017, INT C SOC INF, P109
NR 36
TC 0
Z9 0
U1 9
U2 9
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2021
VL 9
BP 132363
EP 132373
DI 10.1109/ACCESS.2021.3114093
PG 11
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA UZ9SS
UT WOS:000702539000001
OA gold
DA 2022-02-06
ER

PT J
AU Ying, L
   Yu, H
   Wang, JG
   Ji, YG
   Qian, SS
AF Ying, Long
   Yu, Hui
   Wang, Jinguang
   Ji, Yongze
   Qian, Shengsheng
TI Fake News Detection via Multi-Modal Topic Memory Network
SO IEEE ACCESS
LA English
DT Article
DE Feature extraction; Semantics; Social networking (online);
   Visualization; Data mining; Task analysis; Training data; Fake news
   detection; multi-modal fusion; topic memory network; blended attention
   module
AB With the development of the Mobile Internet, more and more people create and release multi-modal posts on social media platforms. Fake news detection has become an increasingly challenging task. Although many current works focus on constructing models extracting abstract features from the content of each post, they neglect the intrinsic semantic architecture such as latent topics, etc. These models only learn patterns in content coupled with certain specific latent topics on the training set to distinguish real and fake posts, which will suffer generalization and discriminating ability decline, especially when posts are associated with rare or new topics. Moreover, most existing works using deep schemes to extract and integrate textual and visual representation in post have not effectively modeled and sufficiently utilized the complementary and noisy multi-modal information containing semantic concepts and entities to complement and enhance each modal. In this paper, to deal with the above problems, we propose a novel end-to-end Multi-modal Topic Memory Network (MTMN), which obtains and combines post representations shared across latent topics together with global features of latent topics while modeling intra-modality and inter-modality information in a unified framework. (1) To tackle real scenarios where newly arriving posts with different topic distribution from the training data, our method incorporates a topic memory module to explicitly characterize final representation as post feature shared across topics and global features of latent topics. These two kinds of features are jointly learned and then combined to generate robust representation. (2) To effectively integrate multi-modality information in posts, we propose a novel blended attention module for multi-modal fusion, which can simultaneously exploit the intra-modality relation within each modal and the inter-modality relation between text words and image regions to complement and enhance each other for high-quality representation. Extensive experiments on two public real-world datasets demonstrate the superior performance of MTMN compared with other state-of-the-art algorithms.
C1 [Ying, Long; Yu, Hui] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Peoples R China.
   [Wang, Jinguang] Hefei Univ Technol, Sch Comp Sci & Informat Engn, Hefei 230601, Peoples R China.
   [Ji, Yongze] China Univ Petr, Sch Informat Sci & Engn, Beijing 102249, Peoples R China.
   [Qian, Shengsheng] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China.
C3 Nanjing University of Information Science & Technology; Hefei University
   of Technology; China University of Petroleum; Chinese Academy of
   Sciences; Institute of Automation, CAS
RP Wang, JG (corresponding author), Hefei Univ Technol, Sch Comp Sci & Informat Engn, Hefei 230601, Peoples R China.; Qian, SS (corresponding author), Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China.
EM wangjinguang502@gmail.com; shengsheng.qian@nlpr.ia.ac.cn
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61902193]; Priority Academic Program
   Development of Jiangsu Higher Education Institutions (PAPD)
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61902193, and in part by the Priority
   Academic Program Development of Jiangsu Higher Education Institutions
   (PAPD).
CR Chen X, 2018, WSDM'18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P108, DOI 10.1145/3159652.3159668
   Chen Y., ARXIV190302188
   Collier M, 2018, LECT NOTES COMPUT SC, V11141, P94, DOI 10.1007/978-3-030-01424-7_10
   Das R, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P358, DOI 10.18653/v1/P17-2057
   Devlin J, 2019, PROC C N AM CHAPTER, P4171, DOI DOI 10.18653/V1/N19-1423
   Fan CY, 2019, PROC CVPR IEEE, P1999, DOI 10.1109/CVPR.2019.00210
   Graves A., 2014, ARXIV PREPRINT ARXIV
   Graves A, 2016, NATURE, V538, P471, DOI 10.1038/nature20101
   Gulcehre C, 2018, NEURAL COMPUT, V30, P857, DOI [10.1162/neco_a_01060, 10.1162/NECO_a_01060]
   Guo WZ, 2019, IEEE ACCESS, V7, P63373, DOI 10.1109/ACCESS.2019.2916887
   Gupta A, 2014, LECT NOTES COMPUT SC, V8851, P228, DOI 10.1007/978-3-319-13734-6_16
   Han, 2012, SDM, P153
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Ji RR, 2019, IEEE T MULTIMEDIA, V21, P1062, DOI 10.1109/TMM.2018.2867718
   Jin ZW, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P795, DOI 10.1145/3123266.3123454
   Jin ZW, 2017, IEEE T MULTIMEDIA, V19, P598, DOI 10.1109/TMM.2016.2617078
   Kai Shu, 2017, ACM SIGKDD Explorations Newsletter, V19, P22, DOI 10.1145/3137597.3137600
   Kalamaras I, 2014, IEEE T MULTIMEDIA, V16, P1460, DOI 10.1109/TMM.2014.2316473
   Khattar D, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P2915, DOI 10.1145/3308558.3313552
   Kim B., 2018, ARXIV181100783
   King DB, 2015, ACS SYM SER, V1214, P1
   Kumar V, 2016, INT CONF ADVAN COMPU
   Kwon S, 2013, IEEE DATA MINING, P1103, DOI 10.1109/ICDM.2013.61
   Liu H, 2017, IEEE T IMAGE PROCESS, V26, P3492, DOI 10.1109/TIP.2017.2700762
   Lu Xiankai, 2020, EUR C COMP VIS, DOI DOI 10.1007/978-3-030-58580-8_39
   Ma J., 2015, P 24 ACM INT C INF K, V19-23, P1751, DOI DOI 10.1145/2806416.2806607
   Ma J., 2016, P 25 INT JOINT C ART, P3818
   Majumder N., 2018, EMPIR METHODS NAT LA, P3402
   Meel P, 2020, EXPERT SYST APPL, V153, DOI 10.1016/j.eswa.2019.112986
   Oh SW, 2019, IEEE I CONF COMP VIS, P9225, DOI 10.1109/ICCV.2019.00932
   Qi P, 2019, IEEE DATA MINING, P518, DOI 10.1109/ICDM.2019.00062
   Sharma K, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3305260
   Sukhbaatar S., 2015, ADV NEURAL INF PROCE, V28, P2440, DOI DOI 10.5555/2969442.2969512
   Tong S, 2002, J MACH LEARN RES, V2, P45, DOI 10.1162/153244302760185243
   Wang YQ, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P849, DOI 10.1145/3219819.3219903
   Wu C.-S., ARXIV190104713
   Xu K, 2019, P 2019 C N AM CHAPT, V1, P2937, DOI [10.18653/v1/N19-1301, DOI 10.18653/V1/N19-1301]
   Yan TK, 2016, CIKM'16: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1271, DOI 10.1145/2983323.2983743
   Yang XS, 2015, IEEE T MULTIMEDIA, V17, P64, DOI 10.1109/TMM.2014.2375793
   Yao L, 2019, THIRTY-THIRD AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTY-FIRST INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / NINTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P7370
   Yu F., 2017, P 26 INT JOINT C ART P 26 INT JOINT C ART, P3901
   Zhang Q, 2018, THIRTY-SECOND AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTIETH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / EIGHTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P5674
   Zhao L, 2015, IEEE T MULTIMEDIA, V17, P1936, DOI 10.1109/TMM.2015.2477058
   Zhao Z, 2018, IEEE T MULTIMEDIA, V20, P430, DOI 10.1109/TMM.2017.2740022
   Zhou H, 2020, KNOWL-BASED SYST, V195, DOI 10.1016/j.knosys.2020.105695
   Zhou XY, 2020, LECT NOTES ARTIF INT, V12085, P354, DOI 10.1007/978-3-030-47436-2_27
   Zubiaga A, 2017, INT C SOC INF, P109
NR 47
TC 0
Z9 0
U1 6
U2 6
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2021
VL 9
BP 132818
EP 132829
DI 10.1109/ACCESS.2021.3113981
PG 12
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA UZ9TO
UT WOS:000702541200001
OA gold
DA 2022-02-06
ER

PT J
AU Martin-Gutierrez, D
   Hernandez-Penaloza, G
   Hernandez, AB
   Lozano-Diez, A
   Alvarez, F
AF Martin-Gutierrez, David
   Hernandez-Penaloza, Gustavo
   Belmonte Hernandez, Alberto
   Lozano-Diez, Alicia
   Alvarez, Federico
TI A Deep Learning Approach for Robust Detection of Bots in Twitter Using
   Transformers
SO IEEE ACCESS
LA English
DT Article
DE Social networking (online); Blogs; Encoding; Metadata; Feature
   extraction; Deep learning; Task analysis; Artificial intelligence; bot
   detector; deep learning; feature representation; language models;
   misinformation detection; social media mining; transfer learning;
   transformers
ID NEURAL-NETWORK
AB During the last decades, the volume of multimedia content posted in social networks has grown exponentially and such information is immediately propagated and consumed by a significant number of users. In this scenario, the disruption of fake news providers and bot accounts for spreading propaganda information as well as sensitive content throughout the network has fostered applied research to automatically measure the reliability of social networks accounts via Artificial Intelligence (AI). In this paper, we present a multilingual approach for addressing the bot identification task in Twitter via Deep learning (DL) approaches to support end-users when checking the credibility of a certain Twitter account. To do so, several experiments were conducted using state-of-the-art Multilingual Language Models to generate an encoding of the text-based features of the user account that are later on concatenated with the rest of the metadata to build a potential input vector on top of a Dense Network denoted as Bot-DenseNet. Consequently, this paper assesses the language constraint from previous studies where the encoding of the user account only considered either the metadata information or the metadata information together with some basic semantic text features. Moreover, the Bot-DenseNet produces a low-dimensional representation of the user account which can be used for any application within the Information Retrieval (IR) framework.
C1 [Martin-Gutierrez, David; Hernandez-Penaloza, Gustavo; Belmonte Hernandez, Alberto; Alvarez, Federico] Univ Politecn Madrid, Signals Syst & Radio Commun SSR Dept, Visual Telecommun Applicat Grp, Madrid 28040, Spain.
   [Lozano-Diez, Alicia] Univ Autonoma Madrid, AUDIAS Audio Data Intelligence & Speech, Madrid 28049, Spain.
C3 Universidad Politecnica de Madrid; Autonomous University of Madrid
RP Martin-Gutierrez, D (corresponding author), Univ Politecn Madrid, Signals Syst & Radio Commun SSR Dept, Visual Telecommun Applicat Grp, Madrid 28040, Spain.
EM dmz@gatv.ssr.upm.es
OI Lozano Diez, Alicia/0000-0002-5918-8568; Martin Gutierrez,
   David/0000-0002-8824-8304
FU H2020 European Project: FAke News discovery and propagation from big
   Data ANalysis and artificial intelliGence Operations (FANDANGO) [780355]
FX This work was supported by the H2020 European Project: FAke News
   discovery and propagation from big Data ANalysis and artificial
   intelliGence Operations (FANDANGO) under Grant 780355.
CR Agic E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3204
   Akbik A, 2019, PROC 2019 C N AM CHA, P54, DOI 10.18653/v1/N19-4010
   Akbik A, 2018, PROC 27 INT C COMPUT
   Alharbi ASM, 2019, COGN SYST RES, V54, P50, DOI 10.1016/j.cogsys.2018.10.001
   Aljohani NR, 2020, SOFT COMPUT, V24, P11109, DOI 10.1007/s00500-020-04689-y
   Arora M, 2019, SOC NETW ANAL MIN, V9, DOI 10.1007/s13278-019-0557-y
   Balestrucci A, 2019, SAC '19: PROCEEDINGS OF THE 34TH ACM/SIGAPP SYMPOSIUM ON APPLIED COMPUTING, P2096, DOI 10.1145/3297280.3297486
   Bhoi A., 2018, ARXIVABS180501984
   Chu Z, 2012, IEEE T DEPEND SECURE, V9, P811, DOI 10.1109/TDSC.2012.75
   Cooijmans T., 2016, ARXIV160309025
   Cresci S, 2017, WWW'17 COMPANION: PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P963, DOI 10.1145/3041021.3055135
   Davis CA, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16 COMPANION), P273, DOI 10.1145/2872518.2889302
   Davoudi Anahita, 2020, AMIA Jt Summits Transl Sci Proc, V2020, P136
   Devlin J, 2019, PROC C N AM CHAPTER, P4171, DOI DOI 10.18653/V1/N19-1423
   Diesner J., 2017, P IEEE ACM INT C ADV, DOI [10.1145/3110025, DOI 10.1145/3110025]
   Dos Santos C. N., 2014, P COLING 2014 25 INT, V2014, P69
   Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1
   Gao R., 2020, ARXIV201011415
   He X., 2018, ARXIV180803912
   Im J, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI [10.1145/3394231.3397889, 10.1145/3313831.3376383]
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Knauth J., 2019, P INT C REC ADV NAT, P550
   Lin ZQ, 2019, IEEE ACCESS, V7, P11570, DOI 10.1109/ACCESS.2019.2891739
   Liu F., 2020, ARXIV200209116
   Liu Y., 2019, ARXIV190501971
   Lynn P, 2019, METHODS DATA ANAL, V13, P253, DOI 10.12758/mda.2018.02
   Mazza M., 2019, P 10 ACM C WEB SCI, P183, DOI DOI 10.1145/3292522.3326015
   Minnich Amanda, 2017, 2017 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM), P467, DOI 10.1145/3110025.3110163
   Naseem U, 2020, FUTURE GENER COMP SY, V113, P58, DOI 10.1016/j.future.2020.06.050
   Orlinski M, 2020, KNOWL-BASED SYST, V206, DOI 10.1016/j.knosys.2020.106318
   Pizarro J., 2019, CEUR WS C 20 WORK NO, P1
   Polignano M., 2019, P CLEF, P1
   Raffel C, 2020, J MACH LEARN RES, V21
   Rodriguez-Ruiz J, 2020, COMPUT SECUR, V91, DOI 10.1016/j.cose.2020.101715
   Shuang K, 2019, J EXP THEOR ARTIF IN, V31, P455, DOI 10.1080/0952813X.2019.1572654
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Stojanovski D, 2015, LECT NOTES ARTIF INT, V9121, P726, DOI 10.1007/978-3-319-19644-2_60
   Varol O., 2017, ARXIV170303107
   Vaswani A, 2017, ADV NEUR IN, V30
   Vogel I., 2019, P CLEF, P1
   Wang B., 2020, ARXIV200206652
   Wang L, 2020, IEEE T KNOWL DATA EN, V32, P2026, DOI 10.1109/TKDE.2019.2913641
   Wolf T., 2019, HUGGINGFACES TRANSFO
   Yang KC, 2020, AAAI CONF ARTIF INTE, V34, P1096
   Yang KC, 2019, HUM BEHAV EMERG TECH, V1, P48, DOI 10.1002/hbe2.115
   Zhang Chiyuan, 2016, ARXIV161103530
   Zhang SQ, 2020, NEURAL PROCESS LETT, V51, P2089, DOI 10.1007/s11063-019-10017-9
   Zhu J, 2019, INFORM SCIENCES, V473, P190, DOI 10.1016/j.ins.2018.09.029
NR 48
TC 1
Z9 1
U1 4
U2 4
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2021
VL 9
BP 54591
EP 54601
DI 10.1109/ACCESS.2021.3068659
PG 11
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA RO4CH
UT WOS:000640992100001
OA gold
DA 2022-02-06
ER

PT J
AU Qureshi, KA
   Malick, RAS
   Sabih, M
   Cherifi, H
AF Qureshi, Khubaib Ahmed
   Malick, Rauf Ahmed Shams
   Sabih, Muhammad
   Cherifi, Hocine
TI Complex Network and Source Inspired COVID-19 Fake News Classification on
   Twitter
SO IEEE ACCESS
LA English
DT Article
DE Social networking (online); Feature extraction; COVID-19; Complex
   networks; Biological system modeling; Knowledge based systems; Blogs;
   Context based model; COVID-19; complex network measures; dis;
   misinformation; hybrid model; machine learning; pandemics; source based;
   social media; social network analysis
ID FALSE NEWS; INFORMATION
AB In COVID-19 related infodemic, social media becomes a medium for wrongdoers to spread rumors, fake news, hoaxes, conspiracies, astroturf memes, clickbait, satire, smear campaigns, and other forms of deception. It puts a tremendous strain on society by damaging reputation, public trust, freedom of expression, journalism, justice, truth, and democracy. Therefore, it is of paramount importance to detect and contain unreliable information. Multiple techniques have been proposed to detect fake news propagation in tweets based on tweets content, propagation on the network of users, and the profile of the news generators. Generating human-like content allows deceiving content-based methods. Network-based methods rely on the complete graph to detect fake news, resulting in late detection. User profile-based techniques are effective for bots or fake accounts detection. However, they are not suited to detect fake news from original accounts. To deal with the shortcomings in existing methods, we introduce a source-based method focusing on the news propagators' community, including posters and re-tweeters to detect such contents. Propagators are connected using follower-following relations. A feature set combining the connectivity patterns of news propagators with their profile features is used in a machine learning framework to perform binary classification of tweets. Complex network measures and user profile features are also examined separately. We perform an extensive comparative analysis of the proposed methodology on a real-world COVID-19 dataset, exploiting various machine learning and deep learning models at the community and node levels. Results show that hybrid features perform better than network features and user features alone. Further optimization demonstrates that Ensemble's boosting model CATBoost and deep learning model RNN are the most effective, with an AUC score of 98%. Furthermore, preliminary results show that the proposed solution can also handle fake news in the political and entertainment domain using a small training set.
C1 [Qureshi, Khubaib Ahmed] DHA Suffa Univ, Dept Comp Sci, Karachi 75500, Pakistan.
   [Malick, Rauf Ahmed Shams] Natl Univ Comp & Emerging Sci, Dept Comp Sci, Karachi 75300, Pakistan.
   [Sabih, Muhammad] DHA Suffa Univ, Dept Elect Engn, Karachi 75500, Pakistan.
   [Cherifi, Hocine] Univ Burgundy, Lab Informat Bourgogne, LIB, F-21078 Dijon, France.
C3 Universite de Bourgogne
RP Qureshi, KA (corresponding author), DHA Suffa Univ, Dept Comp Sci, Karachi 75500, Pakistan.
EM k.ahmed@dsu.edu.pk
RI cherifi, hocine/X-9376-2019
OI cherifi, hocine/0000-0001-9124-4921
CR Abdullah S, 2011, PROC INT C TOOLS ART, P163, DOI 10.1109/ICTAI.2011.33
   Abdullah-All-Tanvir E. M., 2019, P 7 INT C SMART COMP, P1, DOI 10.1109/ICSCC. 2019.8843612
   Ahmed S., 2019, P SPRING S, V12, P8
   Ajao Oluwaseun, 2018, P 9 INT C SOC MED SO, DOI 10.1145/3217804.3217917
   Al-Rakhami MS, 2020, IEEE ACCESS, V8, P155961, DOI 10.1109/ACCESS.2020.3019600
   Al-Zaman M., 2021, J MEDIA, V2, P100
   Albahli AS, 2021, CMC-COMPUT MATER CON, V67, P1613, DOI 10.32604/cmc.2021.014265
   Allcott H, 2017, J ECON PERSPECT, V31, P211, DOI 10.1257/jep.31.2.211
   Amador J, 2017, ARXIV171205999
   [Anonymous], 2012, P 18 ACM SIGKDD INT, DOI DOI 10.1145/2339530.2339662
   Blatchford T, AM BELIEVE 2 3 NEWS
   Bollen J, 2011, J COMPUT SCI-NETH, V2, P1, DOI 10.1016/j.jocs.2010.12.007
   Brauer F, 2008, LECT NOTES MATH, V1945, P19
   Cai J, 2018, NEUROCOMPUTING, V300, P70, DOI 10.1016/j.neucom.2017.11.077
   Celliers Marlie, 2020, Responsible Design, Implementation and Use of Information and Communication Technology. 19th IFIP WG 6.11 Conference on e-Business, e-Services, and e-Society, I3E 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12067), P223, DOI 10.1007/978-3-030-45002-1_19
   Chandra S, ARXIV200806274
   Chu Z, 2012, IEEE T DEPEND SECURE, V9, P811, DOI 10.1109/TDSC.2012.75
   Cialdini R. B, 2009, SCI AND PRACTICE, V4
   Classen S, 2012, CINEMA J, V51, P212, DOI 10.1353/cj.2012.0075
   De Keersmaecker J, 2017, INTELLIGENCE, V65, P107, DOI 10.1016/j.intell.2017.10.005
   Demirkesen C, 2008, LECT NOTES COMPUT SC, V5259, P752, DOI 10.1007/978-3-540-88458-3_68
   Erku DA, 2021, RES SOC ADMIN PHARM, V17, P1954, DOI 10.1016/j.sapharm.2020.04.032
   Fisher M, 2016, DC WASHINGTON POST
   Ginsca AL, 2015, FOUND TRENDS INF RET, V9, P355, DOI 10.1561/1500000046
   Guo B, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3393880
   Hall A. M, 1999, THESIS U WAIKATO HAM
   Hermida A, 2010, JOURNAL PRACT, V4, P297, DOI 10.1080/17512781003640703
   Horne DB, 2019, P INT AAAI C WEB SOC, P257
   Howell Lee, 2013, WORLD EC FORUM REP
   Hu M, 2012, P SIGCHI C HUM FACT, P2751, DOI [10.1145/2207676.2208672, DOI 10.1145/2207676.2208672]
   Ji YF, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P13
   Jin Fang, 2013, P 7 WORKSH SOC NETW, V8, p[1, 3], DOI DOI 10.1145/2501025.2501027
   Jin ZW, 2017, LECT NOTES COMPUT SC, V10354, P14, DOI 10.1007/978-3-319-60240-0_2
   Kai Shu, 2017, ACM SIGKDD Explorations Newsletter, V19, P22, DOI 10.1145/3137597.3137600
   Kumar S., 2018, ARXIV180408559
   Labatut Vincent, 2012, ARXIV12073790
   Le Q., 2014, P 31 INT C INT C MAC
   Lillie A. Edelbo, ARXIV190700181
   LING CX, 2003, IJCAI 2003, V3, P519, DOI DOI 10.5555/1630659.1630736
   Luca M, 2016, MANAGE SCI, V62, P3412, DOI 10.1287/mnsc.2015.2304
   Matsa Katerina Eva, SOCIAL MEDIA USAGE 2
   McPherson M, 2001, ANNU REV SOCIOL, V27, P415, DOI 10.1146/annurev.soc.27.1.415
   Memon S. Ali, ARXIV200800791
   Mendoza Marcelo, 2010, P 1 WORKSH SOC MED A, DOI DOI 10.1145/1964858.1964869
   Mikolov T., 2013, ARXIV13013781, P1
   Mitra T., 2015, ICWSM, P258
   Monti F., ARXIV190206673
   Mukherjee A, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P632
   Norregaard Jeppe, 2019, P 13 INT C WEB SOC M, V13, P630
   Paul Christopher, 2016, PE198OSD RAND
   Perc A, 2017, PLOS ONE, V12
   Perez-Rosas V, 2017, ARXIV PREPRINT ARXIV
   Perrin A, SOCIAL MEDIA USAGE 2
   Pierri F, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-58166-5
   Pierri F, 2019, SIGMOD REC, V48, P18, DOI 10.1145/3377330.3377334
   Potthast M., 2017, ARXIV PREPRINT ARXIV
   Priesemann V, 2021, LANCET, V397, P92, DOI 10.1016/S0140-6736(20)32625-8
   Rodriguez CP, 2020, INT MULTIDISCIP J SO, V9, P107, DOI 10.17583/rimcis.2020.5386
   Qureshi KA, 2021, IEEE ACCESS, V9, P109465, DOI 10.1109/ACCESS.2021.3101977
   Rapoza K., CANFAKE NEWS IMPACT
   Reis JCS, 2019, IEEE INTELL SYST, V34, P76, DOI 10.1109/MIS.2019.2899143
   Roozenbeek J, 2019, PALGR COMMUN, V5, DOI 10.1057/s41599-019-0279-9
   Rubin Victoria L, 2015, P HAW INT C SYST HIC, P5
   Shao CC, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-06930-7
   Shi BX, 2016, KNOWL-BASED SYST, V104, P123, DOI 10.1016/j.knosys.2016.04.015
   Shu K., 2020, P INT AAAI C WEB SOC, V14, P626
   Shu K, 2020, BIG DATA-US, V8, P171, DOI 10.1089/big.2020.0062
   Shu K, 2019, PROCEEDINGS OF THE 2019 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2019), P436, DOI 10.1145/3341161.3342927
   Shu K, 2018, IEEE 1ST CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2018), P430, DOI 10.1109/MIPR.2018.00092
   Silverman C., 2016, THIS ANAL SHOWS VIRA
   Sitaula N., 2020, DISINFORMATION MISIN, P163
   Skaza J, 2017, PHYSICA A, V465, P289, DOI 10.1016/j.physa.2016.08.038
   Smith A, 2016, NBC NEWS
   Starbird K, 2014, P ICONFERENCE, P1
   Volkova S, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P647, DOI 10.18653/v1/P17-2102
   Vosoughi S, 2018, SCIENCE, V359, P1146, DOI 10.1126/science.aap9559
   Wang, 2018, ARXIV180901286
   Wang YQ, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P849, DOI 10.1145/3219819.3219903
   Wiratsudakul A, 2018, PEERJ, V6, DOI 10.7717/peerj.4526
   Zhang JW, 2020, PROC INT CONF DATA, P1826, DOI 10.1109/ICDE48307.2020.00180
   Zhou X., 2020, DIGITAL THREATS RES, DOI 10.1145/3377478
   Zhou XY, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3395046
NR 82
TC 0
Z9 0
U1 11
U2 11
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2021
VL 9
BP 139636
EP 139656
DI 10.1109/ACCESS.2021.3119404
PG 21
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA WJ5EB
UT WOS:000709066700001
OA gold
DA 2022-02-06
ER

PT J
AU Jadhav, SS
   Thepade, SD
AF Jadhav, Shrutika S.
   Thepade, Sudeep D.
TI Fake News Identification and Classification Using DSSM and Improved
   Recurrent Neural Network Classifier
SO APPLIED ARTIFICIAL INTELLIGENCE
LA English
DT Article
AB The widespread use of social media has enormous consequences for the society, culture and business with potentially positive and negative effects. As online social networks are increasingly used for dissemination of information, at the same they are also becoming a medium for the spread of fake news for various commercial and political purposes. Technologies such as Artificial Intelligence (AI) and Natural Language Processing (NLP) tools offer great promise for researchers to build systems, which could automatically detect fake news. However, detecting fake news is a challenging task to accomplish as it requires models to summarize the news and compare it to the actual news in order to classify it as fake. This project proposes a framework that detects and classifies fake news messages using improved Recurrent Neural Networks and Deep Structured Semantic Model. The proposed approach intuitively identifies important features associated with fake news without previous domain knowledge while achieving accuracy 99%. The performance analysis method used for the proposed system is based on accuracy, specificity and sensitivity.
C1 [Jadhav, Shrutika S.; Thepade, Sudeep D.] Pimpri Chinchwad Coll Engn, Dept Comp Engn, Pune, Maharashtra, India.
RP Jadhav, SS (corresponding author), Pimpri Chinchwad Coll Engn, Dept Comp Engn, Pune, Maharashtra, India.
EM shrutikajadhav0595@gmail.com
RI THEPADE, SUDEEP D/P-9054-2015
OI THEPADE, SUDEEP D/0000-0001-7809-4148
CR [Anonymous], 2019, GLOB SOC MED RES SUM
   Buntain C., 2017, 2017 IEEE INT C SMAR
   Campan A., 2017, 2017 IEEE INT C BIG
   Dimpas P. K., 2017, 2017 INT C AS LANG P
   Granik Mykhailo, 2017, 2017 IEEE 1 UKR C EL
   GUPTA A, 2015, 2015 INT C COGN
   Kai Shu, 2017, ACM SIGKDD Explorations Newsletter, V19, P22, DOI 10.1145/3137597.3137600
   Liu Y, 2018, 32 AAAI C ART INT HI, P1
   Parikh S. B., 2018, 2018 IEEE C MULT INF
   Poblete B., 2011, P 20 INT C WORLD WID
   RUCHANSKY N, 2017, P 2017 ACM C INF KNO
   Tschiatschek S., 2018, INT WORLD WID WEB C
   Wang WY, 2017, ARXIV170500648
   Wu L., 2018, P 11 ACM INT C WEB S
   Zhou X., 2018, ARXIV181200315
NR 15
TC 8
Z9 8
U1 0
U2 24
PU TAYLOR & FRANCIS INC
PI PHILADELPHIA
PA 530 WALNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA
SN 0883-9514
EI 1087-6545
J9 APPL ARTIF INTELL
JI Appl. Artif. Intell.
PD OCT 15
PY 2019
VL 33
IS 12
BP 1058
EP 1068
DI 10.1080/08839514.2019.1661579
EA SEP 2019
PG 11
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JB8SI
UT WOS:000484962800001
DA 2022-02-06
ER

PT J
AU Yadlin-Segal, A
   Oppenheim, Y
AF Yadlin-Segal, Aya
   Oppenheim, Yael
TI Whose dystopia is it anyway? Deepfakes and social media regulation
SO CONVERGENCE-THE INTERNATIONAL JOURNAL OF RESEARCH INTO NEW MEDIA
   TECHNOLOGIES
LA English
DT Article
DE Artificial intelligence; deep learning; deepfake; dystopia; gender;
   internet policy; journalism; narrative analysis; news; social media
   regulation; thick data
ID DISABILITY; NEWS
AB This study explores global journalistic discussions of deepfake applications (audiovisual manipulating applications based on artificial intelligence (AI)) to understand the narratives constructed through global coverage, the regulatory actions associated with these offered narratives, and the functions such narratives might serve in global sociopolitical contexts. Through a qualitative-interpretive narrative analysis, this article shows how journalists frame deepfakes as a destabilizing platform that undermines a shared sense of social and political reality, enables the abuse and harassment of women online, and blurs the acceptable dichotomy between real and fake. This phenomenon is tied to discussions of dis/misinformation, manipulation, exploitation, and polarization in the media ecosystem these days. Based on these findings, the article then provides broader practical and theoretical insights about AI content regulation and ethics, accountability, and responsibility in digital culture.
C1 [Yadlin-Segal, Aya] Hadassah Acad Coll, Dept Polit & Commun, 37 HaNeviim St, IL-9101001 Jerusalem, Israel.
   [Oppenheim, Yael] Univ Haifa, Fac Management, Haifa, Israel.
C3 University of Haifa
RP Yadlin-Segal, A (corresponding author), Hadassah Acad Coll, Dept Polit & Commun, 37 HaNeviim St, IL-9101001 Jerusalem, Israel.
EM ayayad@hac.ac.il
OI Yadlin, Aya/0000-0002-7199-6664
CR Baumgartner F. R., 2009, WINNING WORDS ORIGIN, P159
   Benjamin Walter, 2001, NORTON ANTHOLOGY THE, P1166
   Blitz Marc Jonathan, 2018, OKLA L REV, V71, P59
   Bruns A, 2005, A BRUNS IDC
   Cision, 2018, STAT MED REP
   Cobb R.W., 1981, HDB POLITICAL COMMUN, P391
   COOPERSMITH J, 1998, ICON, V4, P94
   Crowa D. A., 2012, Journal of Natural Resources Policy Research, V4, P27, DOI 10.1080/19390459.2012.642635
   Dibbell Julian., 1993, RAPE CYBERSPACE EVIL
   DOWNS A, 1972, PUBLIC INTEREST, P38
   Edelman Research, 2019, 2019 ED TRUST BAR GL
   ENTMAN RM, 1993, J COMMUN, V43, P51, DOI 10.1111/j.1460-2466.1993.tb01304.x
   Fischer CS., 1992, AM CALLING SOCIAL HI
   Fisher DanaR., 2001, J COMPUT-MEDIAT COMM, V6, pJCMC624
   Floridi L., 2018, PHILOS TECHNOLOGY, V31, P317, DOI [10.1007/s13347-018-0325-3, DOI 10.1007/S13347-018-0325-3]
   Fox J, 2015, PERS INDIV DIFFER, V76, P161, DOI 10.1016/j.paid.2014.12.017
   Gamson W.A., 2004, BLACKWELL COMPANION, P242, DOI DOI 10.1002/9780470999103.CH12
   Gillmor Dan., 2006, WE MEDIA GRASSROOTS
   Gingras R, 2018, GROWING LINES
   Greenberg J, 2009, CAN J COMMUN, V34, P461
   Iyengar Shanto, 2010, NEWS MATTERS TELEVIS
   Jenkins H., 2008, CONVERGENCE CULTURE
   KOSICKI GM, 1993, J COMMUN, V43, P100, DOI 10.1111/j.1460-2466.1993.tb01265.x
   Latzko-Toth G., 2017, SAGE HDB SOCIAL MEDI, P199
   Lazer DMJ, 2018, SCIENCE, V359, P1094, DOI 10.1126/science.aao2998
   Lieblich A, 1998, NARRATIVE RES READIN, V47, P199
   Lotan G., 2014, HUFFINGTON POST
   Marciano A, 2019, JOURNALISM STUD, V20, P972, DOI 10.1080/1461670X.2018.1468723
   MCCOMBS ME, 1972, PUBLIC OPIN QUART, V36, P176, DOI 10.1086/267990
   MEYROWITZ J, 1985, NO SENSE PLACE
   Napoli PM, 2019, POLICY INTERNET, V11, P439, DOI 10.1002/poi3.216
   Ong W, 1982, ORALITY LITERACY
   Ophir Y, 2019, J HEALTH COMMUN, V24, P547, DOI 10.1080/10810730.2019.1632990
   Pan Z., 1993, POLIT COMMUN, V10, P55
   Pearson C, 2015, DISABIL SOC, V30, P924, DOI 10.1080/09687599.2015.1051516
   Sarbin T.R., 1986, NARRATIVE PSYCHOL ST, P233
   Shih TJ, 2008, MASS COMMUN SOC, V11, P141, DOI 10.1080/15205430701668121
   Sparkes A. C., 2006, QUAL RES PSYCHOL, V3, P169, DOI [DOI 10.1191/1478088706QRP068OA, DOI 10.1191/1478088706QRP0680A]
   Spigel Lynn, 1992, MAKE ROOM TV TELEVIS
   Spilioti T., 2016, OUTLEDGE HDB LANGUAG, P133
   Sturken M, 2004, TECHNOLOGICAL VISION, P3
   Tandoc EC, 2018, DIGIT JOURNAL, V6, P137, DOI 10.1080/21670811.2017.1360143
   Turkle S., 2012, ALONE TOGETHER WHY W
   Van Gorp B, 2007, J COMMUN, V57, P60, DOI 10.1111/j.1460-2466.2006.00329.x
   Verschueren P, 2006, SUSTAINABLE INFORM S, P169
   Wang T, 2016, WEB LOG POST    0120
   Yadlin-Segal A, 2019, J COMPUT-MEDIAT COMM, V24, P36, DOI 10.1093/jcmc/zmy023
   Zelenkauskaite A, 2017, 1 MONDAY, V22
   Zimmer M., 2008, 1 MONDAY, V13, P3, DOI DOI 10.5210/fm.v13i3.2136
NR 49
TC 8
Z9 8
U1 8
U2 59
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 1354-8565
EI 1748-7382
J9 CONVERGENCE-US
JI Convergence
PD FEB
PY 2021
VL 27
IS 1
BP 36
EP 51
AR 1354856520923963
DI 10.1177/1354856520923963
EA MAY 2020
PG 16
WC Communication
WE Social Science Citation Index (SSCI)
SC Communication
GA PZ0HJ
UT WOS:000532309400001
DA 2022-02-06
ER

PT J
AU Fei, JW
   Xia, ZH
   Yu, PP
   Xiao, FJ
AF Fei, Jianwei
   Xia, Zhihua
   Yu, Peipeng
   Xiao, Fengjun
TI Exposing AI-generated videos with motion magnification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Fake videos; DeepFakes detection; Motion magnification
AB Recent progress of artificial intelligence makes it easier to edit facial movements in videos or create face substitutions, bringing new challenges to anti-fake-faces techniques. Although multimedia forensics provides many detection algorithms from a traditional point of view, it is increasingly hard to discriminate the fake videos from real ones while they become more sophisticated and plausible with updated forgery technologies. In this paper, we introduce a motion discrepancy based method that can effectively differentiate AI-generated fake videos from real ones. The amplitude of face motions in videos is first magnified, and fake videos will show more serious distortion or flicker than the pristine videos. We pre-trained a deep CNN on frames extracted from the training videos and the output vectors of the frame sequences are used as input of an LSTM at secondary training stage. Our approach is evaluated over a large fake video dataset Faceforensics++ produced by various advanced generation technologies, it shows superior performance contrasted to existing pixel-based fake video forensics approaches.
C1 [Fei, Jianwei; Xia, Zhihua; Yu, Peipeng] Nanjing Univ Informat Sci & Technol, Jiangsu Collaborat Innovat Ctr Atmospher Environm, Jiangsu Engn Ctr Network Monitoring, Sch Comp & Software, Nanjing 210044, Peoples R China.
   [Xiao, Fengjun] Hangzhou Dianzi Univ, Sch Management, Hangzhou 310018, Peoples R China.
C3 Nanjing University of Information Science & Technology; Hangzhou Dianzi
   University
RP Xia, ZH (corresponding author), Nanjing Univ Informat Sci & Technol, Jiangsu Collaborat Innovat Ctr Atmospher Environm, Jiangsu Engn Ctr Network Monitoring, Sch Comp & Software, Nanjing 210044, Peoples R China.
EM feijianwei@nuist.edu.cn; xia_zhihua@163.com; ypp865@163.com;
   bhxfj@126.com
OI Xia, Zhihua/0000-0001-6860-647X
FU Jiangsu Basic Research Programs-Natural Science Foundation [BK20181407,
   BK20150925, BK20151530]; National Natural Science Foundation of
   ChinaNational Natural Science Foundation of China (NSFC) [61672294,
   U1836208, 61502242, 61702276, U1536206, 61772283, 61602253, 61601236,
   61572258]; Six peak talent project of Jiangsu Province [R2016L13]; Qing
   Lan Project of Jiangsu Province; "333" project of Jiangsu
   ProvinceNatural Science Foundation of Jiangsu Province; National Key R&D
   Program of China [2018YFB1003205]; Humanity and Social Science Youth
   foundation of Ministry of Education of China [15YJC870021]; Priority
   Academic Program Development of Jiangsu Higher Education Institutions
   (PAPD) fund; Collaborative Innovation Center of Atmospheric Environment
   and Equipment Technology (CICAEET) fund, China; BK21+ program from the
   Ministry of Education of Kore;  [NRF-2016R1D1A1B03933294]
FX This work is supported in part by the Jiangsu Basic Research
   Programs-Natural Science Foundation under grant numbers BK20181407, in
   part by the National Natural Science Foundation of China under grant
   numbers 61672294, in part by Six peak talent project of Jiangsu Province
   (R2016L13), Qing Lan Project of Jiangsu Province and "333" project of
   Jiangsu Province, in part by the National Natural Science Foundation of
   China under grant numbers U1836208, 61502242, 61702276, U1536206,
   61772283, 61602253, 61601236, and 61572258, in part by National Key R&D
   Program of China under grant 2018YFB1003205, in part by
   NRF-2016R1D1A1B03933294, in part by the Jiangsu Basic Research
   Programs-Natural Science Foundation under grant numbers BK20150925 and
   BK20151530, in part by Humanity and Social Science Youth foundation of
   Ministry of Education of China (15YJC870021), in part by the Priority
   Academic Program Development of Jiangsu Higher Education Institutions
   (PAPD) fund, in part by the Collaborative Innovation Center of
   Atmospheric Environment and Equipment Technology (CICAEET) fund, China.
   Zhihua Xia is supported by BK21+ program from the Ministry of Education
   of Kore.
CR AFCHAR D, 2018, IEEE INT WORKS INFOR, pNIL_0035
   Alexander O, 2009, 2009 CONFERENCE FOR VISUAL MEDIA PRODUCTION: CVMP 2009, P176, DOI 10.1109/CVMP.2009.29
   Bayar B, 2018, IEEE T INF FOREN SEC, V13, P2691, DOI 10.1109/TIFS.2018.2825953
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Booth J, 2018, INT J COMPUT VISION, V126, P233, DOI 10.1007/s11263-017-1009-7
   Cao C., 2013, IEEE T VISUALIZATION, V20, P413
   Cozzolino D., 2019, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPRW47913.2019
   Cozzolino D., 2019, IEEE T INFORM FORENS
   Fei JW, 2020, EURASIP J IMAGE VIDE, V2020, DOI 10.1186/s13640-020-0490-z
   Garrido P, 2014, PROC CVPR IEEE, P4217, DOI 10.1109/CVPR.2014.537
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   GUERA D, 2019, ARXIV190608743
   GUERA D, 2018, 15 IEEE INT C ADV VI, P00001
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Kim H, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201283
   Koopman Marissa, 2018, C IMVIP
   Korshunova I, 2017, IEEE I CONF COMP VIS, P3697, DOI 10.1109/ICCV.2017.397
   Korus P, 2017, IEEE T INF FOREN SEC, V12, P809, DOI 10.1109/TIFS.2016.2636089
   Lassner C, 2017, IEEE I CONF COMP VIS, P853, DOI 10.1109/ICCV.2017.98
   LI Y, 2018, ARXIV180602877 CS, P2
   LI Y, 2018, P IEEE INT WORKSH IN, P00001
   Liu C, 2005, ACM T GRAPHIC, V24, P519, DOI 10.1145/1073204.1073223
   Liu DL, 2017, 2017 INTERNATIONAL CONFERENCE ON SMART GRID AND ELECTRICAL AUTOMATION (ICSGEA), P406, DOI 10.1109/ICSGEA.2017.74
   Matern F, 2019, IEEE WINT CONF APPL, P83, DOI 10.1109/WACVW.2019.00020
   Nguyen T., 2019, DEEP LEARNING DEEPFA
   OH TH, 2018, P IEEE CVF EUR C COM, P00633
   Olszewski K, 2017, IEEE I CONF COMP VIS, P5439, DOI 10.1109/ICCV.2017.580
   Peng B, 2016, IEEE IMAGE PROC, P3932, DOI 10.1109/ICIP.2016.7533097
   RICHARDSON E, 2017, P IEEE C COMP VIS PA, P01259
   Richardson E, 2016, INT CONF 3D VISION, P460, DOI 10.1109/3DV.2016.56
   ROSSLER A, 2019, ARXIV190108971
   Sabir Ekraam, 2019, INTERFACES GUI, P80
   Scherhag Ulrich, 2019, IEEE Transactions on Biometrics, Behavior, and Identity Science, V1, P302, DOI 10.1109/TBIOM.2019.2942395
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   THIES J, 2016, PROC CVPR IEEE, P2387, DOI DOI 10.1109/CVPR.2016.262
   Tu X., 2019, ARXIV190105635
   Wadhwa N, 2014, IEEE INT CONF COMPUT
   Wu H.-Y., 2012, EULERIAN VIDEO MAGNI
   Yang X, 2019, INT CONF ACOUST SPEE, P8261, DOI 10.1109/ICASSP.2019.8683164
   ZAKHAROV E, 2019, ARXIV190508233
   Zhou P, 2018, PROC CVPR IEEE, P1053, DOI 10.1109/CVPR.2018.00116
   Zhou P, 2017, IEEE COMPUT SOC CONF, P1831, DOI 10.1109/CVPRW.2017.229
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zollhofer M, 2018, COMPUT GRAPH FORUM, V37, P523, DOI 10.1111/cgf.13382
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
NR 49
TC 2
Z9 2
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 30789
EP 30802
DI 10.1007/s11042-020-09147-3
EA JUN 2020
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000539519000006
DA 2022-02-06
ER

PT J
AU Ali-Gombe, A
   Elyan, E
AF Ali-Gombe, Adamu
   Elyan, Eyad
TI MFC-GAN: Class-imbalanced dataset classification using Multiple Fake
   Class Generative Adversarial Network
SO NEUROCOMPUTING
LA English
DT Article
DE Image classification; Imbalanced data; Deep learning
AB Class-imbalanced datasets are common across different domains such as health, banking, security and others. With such datasets, the learning algorithms are often biased toward the majority class-instances. Data augmentation is a common approach that aims at rebalancing a dataset by injecting more data samples of the minority class instances. In this paper, a new data augmentation approach is proposed using a Generative Adversarial Networks (GAN) to handle the class imbalance problem. Unlike common GAN models, which use a single fake class, the proposed method uses multiple fake classes to ensure a fine-grained generation and classification of the minority class instances. Moreover, the proposed GAN model is conditioned to generate minority class instances aiming at rebalancing the dataset. Extensive experiments were carried out using public datasets, where synthetic samples generated using our model were added to the imbalanced dataset, followed by performing classification using Convolutional Neural Network. Experiment results show that our model can generate diverse minority class instances, even in extreme cases where the number of minority class instances is relatively low. Additionally, superior performance of our model over other common augmentation and oversampling methods was achieved in terms of classification accuracy and quality of the generated samples. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Ali-Gombe, Adamu; Elyan, Eyad] Robert Gordon Univ, Sch Comp Sci & Digital Media, Aberdeen, Scotland.
   [Elyan, Eyad] Robert Gordon Univ, Higher Educ Acad, Aberdeen, Scotland.
C3 Robert Gordon University; Robert Gordon University
RP Ali-Gombe, A (corresponding author), Robert Gordon Univ, Sch Comp Sci & Digital Media, Aberdeen, Scotland.
EM a.ali-gombe@rgu.ac.uk
RI Ali-Gombe, Adamu/AAC-8805-2020
OI Ali-Gombe, Adamu/0000-0001-7152-5697; Elyan, Eyad/0000-0002-8342-9026
CR Adamu A.-G., 2018, P 2018 INT JOINT C N
   Ali-Gombe A., 2017, P INT C ENG APPL NEU
   Antoniou A., ARXIV171104340
   Baur C., ARXIV180404338
   Buda M., ARXIV171005381
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Cohen G, 2017, IEEE IJCNN, P2921, DOI 10.1109/IJCNN.2017.7966217
   Denton E. L., 2015, ADV NEURAL INFORM PR, P1486, DOI DOI 10.5555/
   Dong Q., 2017, ICCV
   Dosovitskiy Alexey, 2014, ADV NEURAL INFORM PR, DOI DOI 10.1109/TPAMI.2015.2496141
   Douzas G, 2018, EXPERT SYST APPL, V91, P464, DOI 10.1016/j.eswa.2017.09.030
   Fernandez A, 2013, KNOWL-BASED SYST, V42, P97, DOI 10.1016/j.knosys.2013.01.018
   Frid-Adar M., ARXIV180102385
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Gurumurthy S., 2017, P IEEE C COMP VIS PA, P166
   He K., 2016, DEEP RESIDUAL LEARNI, DOI DOI 10.1109/CVPR.2016.90
   Huang C, 2016, PROC CVPR IEEE, P5375, DOI 10.1109/CVPR.2016.580
   Inoue H, ARXIV180102929
   Karras Tero, ICLR2018
   Krawczyk B, 2016, PROG ARTIF INTELL, V5, P221, DOI 10.1007/s13748-016-0094-0
   Krizhevsky A., 2012, ADV NEURAL INF PROCE, P1097, DOI DOI 10.1145/3065386
   LeCun Y., 1990, ADV NEURAL INF PROCE, P396, DOI 10.1016/S0925-2312(02)00614-8
   Lopez-Paz, ARXIV171009412
   Mariani G., ARXIV180309655
   Mirza M, 2014, ARXIV PREPRINT ARXIV
   Miyato T., ICLR2018
   Netzer Y., 2011, READING DIGITS NATUR
   Odena A., ARXIV160601583
   Odena A, 2017, PR MACH LEARN RES, V70
   Radford A., 2015, ARXIV151106434
   Wan LP, 2018, INT CONF BIOMETR, P98, DOI 10.1109/ICB2018.2018.00025
   Wang SJ, 2016, IEEE IJCNN, P4368, DOI 10.1109/IJCNN.2016.7727770
   Zeiler MD, 2012, ARXIV12125701
   Zhu X., 2017, ARXIV171100648
NR 34
TC 37
Z9 38
U1 11
U2 62
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0925-2312
EI 1872-8286
J9 NEUROCOMPUTING
JI Neurocomputing
PD OCT 7
PY 2019
VL 361
BP 212
EP 221
DI 10.1016/j.neucom.2019.06.043
PG 10
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IQ0AV
UT WOS:000480413200021
OA Green Accepted
DA 2022-02-06
ER

PT J
AU Dobber, T
   Metoui, N
   Trilling, D
   Helberger, N
   de Vreese, C
AF Dobber, Tom
   Metoui, Nadia
   Trilling, Damian
   Helberger, Natali
   de Vreese, Claes
TI Do (Microtargeted) Deepfakes Have Real Effects on Political Attitudes?
SO INTERNATIONAL JOURNAL OF PRESS-POLITICS
LA English
DT Article
DE deepfake; political microtargeting; disinformation; political attitudes
ID SELF; DISINFORMATION; CONSTRUCTION; FOUNDATIONS; OPINION; ORIGINS;
   VOTERS
AB Deepfakes are perceived as a powerful form of disinformation. Although many studies have focused on detecting deepfakes, few have measured their effects on political attitudes, and none have studied microtargeting techniques as an amplifier. We argue that microtargeting techniques can amplify the effects of deepfakes, by enabling malicious political actors to tailor deepfakes to susceptibilities of the receiver. In this study, we have constructed a political deepfake (video and audio), and study its effects on political attitudes in an online experiment (N= 278). We find that attitudes toward the depicted politician are significantly lower after seeing the deepfake, but the attitudes toward the politician's party remain similar to the control condition. When we zoom in on the microtargeted group, we see that both the attitudes toward the politician and the attitudes toward his party score significantly lower than the control condition, suggesting that microtargeting techniques can indeed amplify the effects of a deepfake, but for a much smaller subgroup than expected.
C1 [Dobber, Tom; Metoui, Nadia; Trilling, Damian] Univ Amsterdam, Amsterdam Sch Commun Res ASCoR, Amsterdam, Netherlands.
   [Helberger, Natali] Univ Amsterdam, Law & Digital Technol, Inst Informat Law, Amsterdam, Netherlands.
   [Helberger, Natali] Univ Amsterdam, Informat Law, Inst Informat Law, Amsterdam, Netherlands.
   [de Vreese, Claes] Univ Amsterdam, Amsterdam Sch Commun Res ASCoR, Artificial Intelligence Data & Democracy, Amsterdam, Netherlands.
   [de Vreese, Claes] Univ Amsterdam, Amsterdam Sch Commun Res ASCoR, Polit Commun, Amsterdam, Netherlands.
C3 University of Amsterdam; University of Amsterdam; University of
   Amsterdam; University of Amsterdam; University of Amsterdam
RP Dobber, T (corresponding author), Univ Amsterdam, Amsterdam Sch Commun Res, Nieuwe Achtergracht 166, NL-1018 WV Amsterdam, Netherlands.
EM t.dobber@uva.nl
OI Trilling, Damian/0000-0002-2586-0352; Metoui, Nadia/0000-0001-6690-2937;
   Dobber, Tom/0000-0002-6657-4037
CR Abramowitz AI, 2013, PRES STUD Q, V43, P709, DOI 10.1111/psq.12063
   Adams William C., 1986, POLIT COMMUN, V3, P191
   Afchar D, 2018, IEEE INT WORKS INFOR
   Agarwal Sakshi, 2019, LIMITS DEEPFAKE DETE
   Appelman A, 2016, J MASS COMMUN Q, V93, P59, DOI 10.1177/1077699015606057
   Arendt H., 1951, ORIGINS TOTALITARIAN
   Asmolov G, 2018, J INT AFF, V71, P69
   Atlantic Council, 2019, DEM DEF DIS 2 0
   Bail CA, 2020, P NATL ACAD SCI USA, V117, P243, DOI 10.1073/pnas.1906420116
   Baldwin-Philippi J, 2019, INTERNET POLICY REV, V8, DOI 10.14763/2019.4.1437
   Bennett WL, 2018, EUR J COMMUN, V33, P122, DOI 10.1177/0267323118760317
   Bennett WL, 2008, J COMMUN, V58, P707, DOI 10.1111/j.1460-2466.2008.00410.x
   Bisgaard M, 2015, J POLIT, V77, P849, DOI 10.1086/681591
   Bolsen T, 2014, POLIT BEHAV, V36, P235, DOI 10.1007/s11109-013-9238-0
   Boomgaarden HG, 2016, INT J COMMUN-US, V10, P2529
   Borgesius FJZ, 2018, UTRECHT LAW REV, V14, P82, DOI 10.18352/ulr.420
   Brandshaw S., 2018, J INT AFF, V71, P23
   Briggs Meyers Isabel, 2010, GIFTS DIFFERING UNDE
   BRODY RA, 1989, POLITICAL BEHAV, V0011
   Chadwick A, 2018, NEW MEDIA SOC, V20, P4255, DOI 10.1177/1461444818769689
   Chang CC, 2006, J BUS PSYCHOL, V20, P445, DOI 10.1007/s10869-005-9011-4
   Chanley VA, 2000, PUBLIC OPIN QUART, V64, P239, DOI 10.1086/317987
   Cohen J., 1988, STAT POWER ANAL BEHA, V2nd ed.
   De Hart Joep, 2018, CHRISTENEN NEDERLAND
   Dobber T, 2017, INTERNET POLICY REV, V6, DOI 10.14763/2017.4.777
   Dommett K, 2021, PARLIAMENT AFF, V74, P378, DOI 10.1093/pa/gsaa007
   Dommett K, 2019, INTERNET POLICY REV, V8, DOI 10.14763/2019.4.1432
   Endres K, 2020, AM POLIT RES, V48, P317, DOI 10.1177/1532673X19875694
   European Commission, 2019, 20 EUR COMM
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Flynn DJ, 2017, POLIT PSYCHOL, V38, P127, DOI 10.1111/pops.12394
   Frantzich Stephen, 2012, OOPS OBSERVING OUR P
   Gaines BJ, 2007, J POLIT, V69, P957, DOI 10.1111/j.1468-2508.2007.00601.x
   Guess A., 2018, SELECTIVE EXPOSURE M
   Haenschen K, 2019, POLIT COMMUN, V36, P357, DOI 10.1080/10584609.2018.1548530
   Jack Caroline, 2018, LEXICON LIES TERMS P
   Kahan DM, 2017, BEHAV PUBLIC POL, V1, P54, DOI DOI 10.1017/BPP.2016.2
   Kalla JL, 2018, AM POLIT SCI REV, V112, P148, DOI 10.1017/S0003055417000363
   Karpf David., 2019, DIGITAL DISINFORMATI
   Kreiss D., 2012, TAKING OUR COUNTRY B
   Kreiss D, 2016, PROTOTYPE POLITICS T
   Lauderdale BE, 2016, POLIT SCI RES METH, V4, P477, DOI 10.1017/psrm.2015.51
   Li Yuezun, 2018, ARXIV181100656V3
   Lukito J, 2020, POLIT COMMUN, V37, P238, DOI 10.1080/10584609.2019.1661889
   Maarek P., 2003, J POLITICAL MARKETIN, V2, P13
   Maier J, 2011, INT POLIT SCI REV, V32, P283, DOI 10.1177/0192512110378056
   Matsumoto Asuka, 2018, SAIREV INT AFFAIRS, V38, P27, DOI [10.1353/sais.2018.0003, DOI 10.1353/SAIS.2018.0003]
   Matthes J, 2015, COMMUN RES, V42, P134, DOI 10.1177/0093650213514600
   Metodieva Asya, 2018, DISINFORMATION CYBER
   Moura M, 2017, INTERNET POLICY REV, V6, DOI 10.14763/2017.4.775
   Nyhan B, 2020, POLIT BEHAV, V42, P939, DOI 10.1007/s11109-019-09528-x
   Park, 2015, J CURRENT ISSUES RES, V36, P157, DOI [10.1080/10641734.2015.1023873, DOI 10.1080/10641734.2015.1023873]
   Parker-Stephen E, 2013, J POLIT, V75, P1077, DOI 10.1017/S0022381613000789
   Perugini M, 2018, INT REV SOC PSYCHOL, V31, DOI 10.5334/irsp.181
   Petty R., 1986, COMMUNICATION PERSUA, DOI DOI 10.1016/S0065-2601(08)60214-2
   Redlawsk DP, 2010, POLIT PSYCHOL, V31, P563, DOI 10.1111/j.1467-9221.2010.00772.x
   Rekker R, 2019, ELECT STUD, V57, P284, DOI 10.1016/j.electstud.2018.08.006
   Richey M, 2012, PHILOS SOC SCI, V42, P511, DOI 10.1177/0048393111430761
   Seltzer T, 2010, J PUBLIC RELAT RES, V23, P24, DOI 10.1080/1062726X.2010.504791
   Sheinheit I, 2016, SOCIOL FORUM, V31, P970, DOI 10.1111/socf.12292
   Siegel A., 2018, POLITICAL POLARIZATI, DOI DOI 10.2139/SSRN.3144139
   Slothuus R, 2010, J POLIT, V72, P630, DOI 10.1017/S002238161000006X
   Suwajanakorn S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073640
   Vaccari C, 2020, SOC MEDIA SOC, V6, DOI 10.1177/2056305120903408
   Wardle Claire, 2017, INFORM DISORDER TOWA
   Webster SW, 2017, AM POLIT RES, V45, P621, DOI 10.1177/1532673X17703132
   Wheeler SC, 2008, J EXP SOC PSYCHOL, V44, P1035, DOI 10.1016/j.jesp.2008.03.007
   Wheeler SC, 2005, J CONSUM RES, V31, P787, DOI 10.1086/426613
   Xia YP, 2019, INFORM COMMUN SOC, V22, P1646, DOI 10.1080/1369118X.2019.1621921
   Yang X, 2019, INT CONF ACOUST SPEE, P8261, DOI 10.1109/ICASSP.2019.8683164
   Zimmermann F, 2020, POLIT COMMUN, V37, P215, DOI 10.1080/10584609.2019.1686095
NR 71
TC 14
Z9 14
U1 12
U2 33
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 1940-1612
EI 1940-1620
J9 INT J PRESS/POLIT
JI Int. J. Press-Polit.
PD JAN
PY 2021
VL 26
IS 1
SI SI
BP 69
EP 91
AR 1940161220944364
DI 10.1177/1940161220944364
EA JUL 2020
PG 23
WC Communication; Political Science
WE Social Science Citation Index (SSCI)
SC Communication; Government & Law
GA PJ7AE
UT WOS:000552705100001
OA Green Published
DA 2022-02-06
ER

PT J
AU Qayyum, A
   Qadir, J
   Janjua, MU
   Sher, F
AF Qayyum, Adnan
   Qadir, Junaid
   Janjua, Muhammad Umar
   Sher, Falak
TI Using Blockchain to Rein in the New Post-Truth World and Check the
   Spread of Fake News
SO IT PROFESSIONAL
LA English
DT Article
AB In recent years, "fake news" has become a global issue that raises unprecedented challenges for human society and democracy. This problem has arisen due to the emergence of various concomitant phenomena such as 1) the digitization of human life and the ease of disseminating news through social networking applications (such as Facebook and WhatsApp); 2) the availability of "big data" that allows customization of news feeds and the creation of polarized so-called "filter-bubbles"; and 3) the rapid progress made by generative machine learning (ML) and deep learning (DL) algorithms in creating realistic-looking yet fake digital content (such as text, images, and videos). There is a crucial need to combat the rampant rise of fake news and disinformation. In this article, we propose a high-level overview of a blockchain-based framework for fake news prevention and highlight the various design issues and consideration of such a blockchain-based framework for tackling fake news.
C1 [Qayyum, Adnan; Janjua, Muhammad Umar; Sher, Falak] Informat Technol Univ, Dept Comp Sci, Punjab, Pakistan.
   [Qadir, Junaid] Informat Technol Univ, Dept Elect Engn, Lahore, Punjab, Pakistan.
RP Qayyum, A (corresponding author), Informat Technol Univ, Dept Comp Sci, Punjab, Pakistan.
EM adnan.qayyum@itu.edu.pk; junaid.qadir@itu.edu.pk;
   umar.janjua@itu.edu.pk; falak.sher@itu.edu.pk
RI Qadir, Junaid/Q-6329-2019
OI Qadir, Junaid/0000-0001-9466-2475
CR Allcott H, 2017, J ECON PERSPECT, V31, P211, DOI [DOI 10.1257/jep.31.2.211, DOI 10.1257/JEP.31.2.211]
   Ball J., 2017, POST TRUTH BULLSHIT
   Chesney R., 2018, DEEP FAKES LOOMING C
   Flintham M., 2018, P CHI C HUM FACT COM
   Gowen A., 2018, WASHINGTON POST
   Huckle S, 2017, BIG DATA-US, V5, P356, DOI 10.1089/big.2017.0071
   Jin ZW, 2016, THIRTIETH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2972
   Jing TW, 2018, INT C REL INF COMM T, P955
   Kai Shu, 2017, ACM SIGKDD Explorations Newsletter, V19, P22, DOI 10.1145/3137597.3137600
   Lazer DMJ, 2018, SCIENCE, V359, P1094, DOI 10.1126/science.aao2998
   Mullainathan S, 2005, AM ECON REV, V95, P1031, DOI 10.1257/0002828054825619
   Nakamoto Satoshi, 2008, BITCOIN PEER TO PEER
   Pariser, 2011, FILTER BUBBLE WHAT I
   Shang B, 2018, I C CONT AUTOMAT ROB, P377, DOI 10.1109/ICARCV.2018.8581196
   Shao Chengcheng, 2018, NATURE COMM, V9, P1
   Shu K., 2019, EMERGING RES CHALLEN, P43
   Sunstein CR, 2018, REPUBLIC DIVIDED DEM
   Suwajanakorn S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073640
   Tacchini E., 2017, CEUR WORKSHOP P, V1960
NR 19
TC 12
Z9 12
U1 4
U2 52
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1520-9202
EI 1941-045X
J9 IT PROF
JI IT Prof.
PD JUL-AUG
PY 2019
VL 21
IS 4
BP 16
EP 24
DI 10.1109/MITP.2019.2910503
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA IK7RQ
UT WOS:000476789400004
OA Green Submitted
DA 2022-02-06
ER

PT J
AU Zhao, H
   Xiao, YF
   Zhang, ZX
AF Zhao, Huan
   Xiao, Yufeng
   Zhang, Zixing
TI Robust Semisupervised Generative Adversarial Networks for Speech Emotion
   Recognition via Distribution Smoothness
SO IEEE ACCESS
LA English
DT Article
DE Semisupervised learning; generative adversarial network; adversarial
   training; speech emotion recognition
AB Despite the recent great achievements in speech emotion recognition (SER) with the development of deep learning, the performance of SER systems depends strongly on the amount of labeled data available for training. Obtaining sufficient annotated data, however, is often extremely time consuming and costly and sometimes even prohibitive because of privacy and ethical concerns. To address this issue, this article proposes the semisupervised generative adversarial network (SSGAN) for SER to capture underlying knowledge from both labeled and unlabeled data. The SSGAN is derived from a GAN, but the discriminator of the SSGAN can not only classify its input samples as real or fake but also distinguish their emotional class if they are real. Thus, the distribution of realistic inputs can be learned to encourage label information sharing between labeled and unlabeled data. This article proposes two advanced methods, i.e., the smoothed SSGAN (SSSGAN) and the virtual smoothed SSGAN (VSSSGAN), which, respectively, smooth the data distribution of the SSGAN via adversarial training (AT) and virtual adversarial training (VAT). The SSSGAN smooths the conditional label distribution given inputs using labeled examples, while the VSSSGAN smooths the conditional label distribution without label information (& x201C;virtual& x201D; labels). To evaluate the effectiveness of the proposed methods, four publicly available and frequently used corpora are selected to conduct experiments in intradomain and interdomain situations. The results illustrate that the proposed methods are superior to the state-of-the-art methods. Specifically, in experimental settings with mismatched and semimismatched unlabeled training sets, the SSSGAN and VSSSGAN are more robust than the SSGAN because of the distributional smoothness.
C1 [Zhao, Huan; Xiao, Yufeng] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Peoples R China.
   [Zhang, Zixing] Imperial Coll London, Grp Language Audio & Music, London SW7 2AZ, England.
C3 Hunan University; Imperial College London
RP Xiao, YF (corresponding author), Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Peoples R China.
EM hnxiaoyf@hnu.edu.cn
FU National Science Foundation of ChinaNational Natural Science Foundation
   of China (NSFC) [61772188]; National Key Research and Development
   Program of China [2018YFC0831800]
FX This work was supported in part by the National Science Foundation of
   China under Grant 61772188, and in part by the National Key Research and
   Development Program of China under Grant 2018YFC0831800.
CR BURKE W, 2005, P 21 IEEE NPS S FUS, P1
   Busso C, 2017, IEEE T AFFECT COMPUT, V8, P67, DOI 10.1109/TAFFC.2016.2515617
   Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6
   Chen WH, 2018, FUTURE GENER COMP SY, V89, P78, DOI 10.1016/j.future.2018.06.021
   Cheng X., 2012, 2 INT C COMP APPL SY, P1222
   Deng J, 2018, IEEE-ACM T AUDIO SPE, V26, P31, DOI 10.1109/TASLP.2017.2759338
   Deng J, 2017, IEEE ACCESS, V5, P5235, DOI 10.1109/ACCESS.2017.2672722
   Diasse A, 2019, INTELL DATA ANAL, V23, P555, DOI 10.3233/IDA-183914
   Eskimez SE, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5099, DOI 10.1109/ICASSP.2018.8462685
   Esparza Javier, 2011, Algebra and Coalgebra in Computer Science. Proceedings 4th International Conference, CALCO 2011, P19, DOI 10.1007/978-3-642-22944-2_2
   Eyben F., 2010, P 18 ACM INT C MULT, P1459
   Gao QS, 2019, AER ADV ENG RES, V181, P1
   Goodfellow I.J., 2014, ARXIV14126572
   GOODFELLOW IJ, 2014, P NIPS, V27
   Han K, 2014, INTERSPEECH, P223
   Huang J., 2018, 2018 1 AS C AFF COMP, P1, DOI [10.1109/ACIIAsia.2018.8470363, DOI 10.1109/ACIIASIA.2018.8470363]
   Huang ZW, 2015, FRONT INFORM TECH EL, V16, P358, DOI 10.1631/FITEE.1400323
   Kingma DP, 2015, 3 INT C LEARN REPR I, DOI DOI 10.1145/1830483.1830503
   Lanjewar RB, 2015, PROCEDIA COMPUT SCI, V49, P50, DOI 10.1016/j.procs.2015.04.226
   Latif S., 2019, ARXIV190706078
   Liu J, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P999
   Luo YC, 2018, PROC CVPR IEEE, P8896, DOI 10.1109/CVPR.2018.00927
   Meng H, 2019, IEEE ACCESS, V7, P125868, DOI 10.1109/ACCESS.2019.2938007
   Mirsamadi S, 2017, INT CONF ACOUST SPEE, P2227, DOI 10.1109/ICASSP.2017.7952552
   Miyato T, 2019, IEEE T PATTERN ANAL, V41, P1979, DOI 10.1109/TPAMI.2018.2858821
   Nair V., 2010, ICML, DOI DOI 10.5555/3104322.3104425
   Njikam ANS, 2016, APPL INTELL, V45, P75, DOI 10.1007/s10489-015-0744-0
   Nogueiras A., 2001, P EUROSPEECH
   Nwe TL, 2003, SPEECH COMMUN, V41, P603, DOI 10.1016/S0167-6393(03)00099-2
   Odena A., 2016, ARXIV160601583, DOI DOI 10.23915/distill.00003
   Peipei Shen, 2011, 2011 International Conference on Electronic & Mechanical Engineering and Information Technology (EMEIT 2011), P621, DOI 10.1109/EMEIT.2011.6023178
   Salimans T., 2016, NEURIPS, P2234, DOI DOI 10.5555/3157096.3157346
   Schuller B, 2003, INT CONF ACOUST SPEE, P1
   Schuller B, 2009, INTERSPEECH 2009: 10TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2009, VOLS 1-5, P336
   Shen, 2012, INT J SMART HOME, V6, P101, DOI DOI 10.5120/431-636
   Steidl S, 2009, AUTOMATIC CLASSIFICA
   Szegedy C., 2013, P 2 INT C LEARN REPR
   Tang H, 2009, IEEE INT CON MULTI, P294, DOI 10.1109/ICME.2009.5202493
   Tao JH, 2019, INT J AUTOM COMPUT, V16, P437, DOI 10.1007/s11633-019-1175-x
   Trigeorgis G, 2016, INT CONF ACOUST SPEE, P5200, DOI 10.1109/ICASSP.2016.7472669
   Wang JL, 2019, NEUROCOMPUTING, V349, P212, DOI 10.1016/j.neucom.2019.03.083
   Xiao YF, 2020, IEEE TETCI, V4, P480, DOI 10.1109/TETCI.2020.2972926
   Zhang ZX, 2016, INT CONF ACOUST SPEE, P5185, DOI 10.1109/ICASSP.2016.7472666
   Zhang ZX, 2018, IEEE ACCESS, V6, P22196, DOI 10.1109/ACCESS.2018.2821192
   Zhang ZX, 2015, IEEE-ACM T AUDIO SPE, V23, P115, DOI 10.1109/TASLP.2014.2375558
   Zhang ZX, 2013, INT CONF ACOUST SPEE, P8505, DOI 10.1109/ICASSP.2013.6639325
   Zhao H, 2019, INT CONF ACOUST SPEE, P6690, DOI 10.1109/ICASSP.2019.8683389
   Zhao ZP, 2019, IEEE ACCESS, V7, P97515, DOI 10.1109/ACCESS.2019.2928625
NR 48
TC 6
Z9 6
U1 2
U2 4
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2020
VL 8
BP 106889
EP 106900
DI 10.1109/ACCESS.2020.3000751
PG 12
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA MD5VP
UT WOS:000544040800034
OA gold
DA 2022-02-06
ER

PT J
AU Raj, C
   Meel, P
AF Raj, Chahat
   Meel, Priyanka
TI ARCNN framework for multimodal infodemic detection
SO NEURAL NETWORKS
LA English
DT Article
DE COVID-19 fake news; Infodemic; Deep learning; Multimodal fusion; Neural
   networks
AB Fake news and misinformation have adopted various propagation media over time, nowadays spreading predominantly through online social networks. During the ongoing COVID-19 pandemic, false information is affecting human life in many spheres The world needs automated detection technology and efforts are being made to meet this requirement with the use of artificial intelligence. Neural network detection mechanisms are robust and durable and hence are used extensively in fake news detection. Deep learning algorithms demonstrate efficiency when they are provided with a large amount of training data. Given the scarcity of relevant fake news datasets, we built the Coronavirus Infodemic Dataset (CovID), which contains fake news posts and articles related to coronavirus. This paper presents a novel framework, the Allied Recurrent and Convolutional Neural Network (ARCNN), to detect fake news based on two different modalities: text and image. Our approach uses recurrent neural networks (RNNs) and convolutional neural networks (CNNs) and combines both streams to generate a final prediction. We present extensive research on various popular RNN and CNN models and their performance on six coronavirus-specific fake news datasets. To exhaustively analyze performance, we present experimentation performed and results obtained by combining both modalities using early fusion and four types of late fusion techniques. The proposed framework is validated by comparisons with state-of-the-art fake news detection mechanisms, and our models outperform each of them. (C) 2021 Elsevier Ltd. All rights reserved.
C1 [Raj, Chahat; Meel, Priyanka] Delhi Technol Univ, Dept Informat Technol, Delhi, India.
C3 Delhi Technological University
RP Meel, P (corresponding author), Delhi Technol Univ, Dept Informat Technol, Delhi, India.
EM chahatraj58@gmail.com; priyankameel86@gmail.com
RI Raj, Chahat/AAL-9102-2021
OI Raj, Chahat/0000-0003-0083-6812
CR Adiba F. I., 2020, INT J AUTOMATION ART, V1
   Ajao Oluwaseun, 2018, P 9 INT C SOC MED SO, DOI 10.1145/3217804.3217917
   Al-Ahmad B, 2021, SYMMETRY-BASEL, V13, DOI 10.3390/sym13061091
   Al-Rakhami MS, 2020, IEEE ACCESS, V8, P155961, DOI 10.1109/ACCESS.2020.3019600
   ALLAHVERDIPOUR Herbert, 2020, J ED COMMUNITY HLTH, V7, P65, DOI 10.29252/jech.7.2.65
   Allcott H, 2017, J ECON PERSPECT, V31, P211, DOI 10.1257/jep.31.2.211
   Anoop K., 2019, LEVERAGING HETEROGEN, DOI [10.1007/978-3-030-01872-6_10, DOI 10.1007/978-3-030-01872-6_10]
   Atrey PK, 2010, MULTIMEDIA SYST, V16, P345, DOI 10.1007/s00530-010-0182-0
   Bin Naeem S, 2021, HEALTH INFO LIBR J, V38, P143, DOI 10.1111/hir.12320
   Boididou C, 2018, MULTIMED TOOLS APPL, V77, P15545, DOI 10.1007/s11042-017-5132-9
   Burkhardt J. M, 2017, LIBR TECHNOL REPOR, V53
   Cui LM, 2019, PROCEEDINGS OF THE 2019 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2019), P41, DOI 10.1145/3341161.3342894
   Elhadad Mohamed K., 2021, Advances in Intelligent Networking and Collaborative Systems. 12th International Conference on Intelligent Networking and Collaborative Systems (INCoS-2020). Advances in Intelligent Systems and Computing (AISC 1263), P256, DOI 10.1007/978-3-030-57796-4_25
   Elhadad M. K., ADV INTELLIGENT SYST, V1264, DOI [10.1007/978-3-030-57811-4_16, DOI 10.1007/978-3-030-57811-4_16]
   Ferrara E, 2020, J COMPUT SOC SCI, V3, P271, DOI 10.1007/s42001-020-00094-5
   Figueira A, 2017, PROCEDIA COMPUT SCI, V121, P817, DOI 10.1016/j.procs.2017.11.106
   Jin Z., 2015, MCG ICT MED CEUR WOR, V1436
   Jin ZW, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P795, DOI 10.1145/3123266.3123454
   Kaliyar RK, 2021, ICAART: PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON AGENTS AND ARTIFICIAL INTELLIGENCE - VOL 2, P1066, DOI 10.5220/0010316010661072
   Khattar D, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P2915, DOI 10.1145/3308558.3313552
   Krishnamurthy G., 2018, DEEP LEARNING APPROA
   Lago F, 2019, SECUR COMMUN NETW, DOI 10.1155/2019/9236910
   Lee Dongwon, 2020, COAID COVID 19 HEALT
   Maigrot C., 2016, MEDIAEVAL CEUR WORKS, P1739
   Majumder S. B., 2020, DETECTING FAKE NEWS
   Meel P, 2021, INFORM SCIENCES, V567, P23, DOI 10.1016/j.ins.2021.03.037
   Meel P, 2020, EXPERT SYST APPL, V153, DOI 10.1016/j.eswa.2019.112986
   Mookdarsanit P., 2021, B ELECT ENG INFORM, V10, DOI [10.11591/eei.v10i2.2745, DOI 10.11591/EEI.V10I2.2745]
   Narwal B., 2018, P IEEE 2018 INT C AD, P977, DOI [DOI 10.1109/ICACCCN.2018.8748586, 10.1109/ICACCCN.2018.8748586]
   Orso D, 2020, EUR J EMERG MED, V27, P327, DOI 10.1097/MEJ.0000000000000713
   Pogorelov K., 2020, CEUR WORKSHOP PROC, V2882
   Saini N, 2020, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS 2020), P948, DOI 10.1109/ICICCS48265.2020.9121005
   Shahi GK, 2020, FAKECOVID MULTILINGU
   Shim JS, 2021, EXPERT SYST APPL, V184, DOI 10.1016/j.eswa.2021.115491
   Shu K., 2017, ACM SIGKDD EXPLORATI, DOI [10.1145/3137597.3137600, DOI 10.1145/3137597.3137600]
   Shu K, 2019, PROCEEDINGS OF THE 2019 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2019), P436, DOI 10.1145/3341161.3342927
   Singh M., 2020, LECT NOTES COMPUTER
   Singh VK, 2021, J ASSOC INF SCI TECH, V72, P3, DOI 10.1002/asi.24359
   Singhal S, 2019, 2019 IEEE FIFTH INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2019), P39, DOI [10.1109/BigMM.2019.00018, 10.1109/BigMM.2019.00-44]
   Vishwakarma D.K., 2020, 2020 INT C EM TECHN, P1, DOI [10.1109/INCET49848.2020.9153985, DOI 10.1109/INCET49848.2020.9153985]
   Wang YQ, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P849, DOI 10.1145/3219819.3219903
   Xiao LZ, 2018, INT SYM COMPUT INTEL, P71, DOI 10.1109/ISCID.2018.00023
   Xinyi Zhou, 2020, CIKM '20: Proceedings of the 29th International Conference on Information & Knowledge Management, P3205, DOI 10.1145/3340531.3412880
   Yang Y., 2018, TI CNN CONVOLUTIONAL
NR 44
TC 0
Z9 0
U1 14
U2 14
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0893-6080
EI 1879-2782
J9 NEURAL NETWORKS
JI Neural Netw.
PD FEB
PY 2022
VL 146
BP 36
EP 68
DI 10.1016/j.neunet.2021.11.006
PG 33
WC Computer Science, Artificial Intelligence; Neurosciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Neurosciences & Neurology
GA XJ2ET
UT WOS:000726608700004
PM 34839091
DA 2022-02-06
ER

PT J
AU Zhou, W
   Lian, C
   Zeng, ZG
   Xu, BR
   Su, YX
AF Zhou, Wei
   Lian, Cheng
   Zeng, Zhigang
   Xu, Bingrong
   Su, Yixin
TI Improve Semi-supervised Learning with Metric Learning Clusters and
   Auxiliary Fake Samples
SO NEURAL PROCESSING LETTERS
LA English
DT Article
DE Semi-supervised learning; Metric learning; Variational auto-encoders;
   Very few labeled data
AB Because it is very expensive to collect a large number of labeled samples to train deep neural networks in certain fields, semi-supervised learning (SSL) researcher has become increasingly important in recent years. There are many consistency regularization-based methods for solving SSL tasks, such as the Pi model and mean teacher. In this paper, we first show through an experiment that the traditional consistency-based methods exist the following two problems: (1) as the size of unlabeled samples increases, the accuracy of these methods increases very slowly, which means they cannot make full use of unlabeled samples. (2) When the number of labeled samples is vary small, the performance of these methods will be very low. Based on these two findings, we propose two methods, metric learning clustering (MLC) and auxiliary fake samples, to alleviate these problems. The proposed methods achieve state-of-the-art results on SSL benchmarks. The error rates are 10.20%, 38.44% and 4.24% for CIFAR-10 with 4000 labels, CIFAR-100 with 10,000 labels and SVHN with 1000 labels by using MLC. For MNIST, the auxiliary fake samples method shows great results in cases with the very few labels.
C1 [Zhou, Wei; Lian, Cheng; Su, Yixin] Wuhan Univ Technol, Sch Automat, Wuhan 430074, Peoples R China.
   [Zeng, Zhigang; Xu, Bingrong] Huazhong Univ Sci & Technol, Sch Artificial Intelligence & Automat, Wuhan 430074, Peoples R China.
C3 Wuhan University of Technology; Huazhong University of Science &
   Technology
RP Lian, C (corresponding author), Wuhan Univ Technol, Sch Automat, Wuhan 430074, Peoples R China.
EM zw602324@163.com; chenglian@whut.edu.cn; zgzeng@hust.edu.cn;
   bingrongxu@hust.edu.cn; suyixin@whut.edu.cn
FU Natural Science Foundation of ChinaNational Natural Science Foundation
   of China (NSFC) [61876219, 61503144, 61761130081, 61821003]; National
   Key R&D Program of China [2017YFC1501301]; Fundamental Research Funds
   for the Central UniversitiesFundamental Research Funds for the Central
   Universities [WUT: 2020III044]
FX This work was supported in part by the Natural Science Foundation of
   China under Grants 61876219, 61503144, 61761130081 and 61821003; in part
   by the National Key R&D Program of China under Grant 2017YFC1501301; and
   in part by the Fundamental Research Funds for the Central Universities
   (WUT: 2020III044).
CR Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P92, DOI 10.1145/279943.279962
   Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS)
   CHONGXUAN L, 2017, ADV NEURAL INFORM PR, P4091
   Cong Y, 2013, IEEE T IMAGE PROCESS, V22, P3179, DOI 10.1109/TIP.2013.2260168
   Dai Zihang, 2017, ADV NEURAL INFORM PR
   Goodfellow I.J., 2014, ARXIV14126572
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Haeusser P, 2017, PROC CVPR IEEE, P626, DOI 10.1109/CVPR.2017.74
   Hoffer E, 2016, ARXIV161101449
   Hoffer E, 2015, LECT NOTES COMPUT SC, V9370, P84, DOI 10.1007/978-3-319-24261-3_7
   JOHNSON SC, 1967, PSYCHOMETRIKA, V32, P241, DOI 10.1007/BF02289588
   Kamnitsas K, 2018, PR MACH LEARN RES, V80
   Kingma D., 2013, ARXIV13126114
   Kingma DP, 2014, 2 INT C LEARN REPR I, P1
   Kipf T.N., 2016, ARXIV160902907
   Kriegel HP, 2011, WIRES DATA MIN KNOWL, V1, P231, DOI 10.1002/widm.30
   Krizhevsky A., 2009, TECHNICAL REPORT, DOI 10.1.1.222.9220
   Kumar M. P., 2010, P NEURIPS, P1189
   Laine S., 2016, ARXIV161002242
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y., 2006, IEEE C COMP VIS PATT, V2, P1735
   Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI [10.1109/TPAMI.2018.2858826, 10.1109/ICCV.2017.324]
   Lopez-Paz D, 2019, ARXIV190303825, P3635, DOI DOI 10.24963/IJCAI.2019/504
   Luo YC, 2018, PROC CVPR IEEE, P8896, DOI 10.1109/CVPR.2018.00927
   Min SB, 2019, THIRTY-THIRD AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTY-FIRST INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / NINTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P4578, DOI 10.1609/aaai.v33i01.33014578
   Miyato T, 2019, IEEE T PATTERN ANAL, V41, P1979, DOI 10.1109/TPAMI.2018.2858821
   Miyato Takeru, 2015, ARXIV150700677, P2
   Netzer Y., 2011, NIPS WORKSH DEEP LEA
   Phil, 2008, J COMPUTER APPL, V1, P18
   Salimans T., 2016, NEURIPS, P2234, DOI DOI 10.5555/3157096.3157346
   SIETSMA J, 1991, NEURAL NETWORKS, V4, P67, DOI 10.1016/0893-6080(91)90033-2
   Sindhwani Vikas, 2005, P 22 INT C MACH LEAR, V2005, P74, DOI DOI 10.1145/1102351.1102455
   Sohn Kihyuk, 2016, ADV NEURAL INFORM PR
   Song HO, 2016, PROC CVPR IEEE, P4004, DOI 10.1109/CVPR.2016.434
   Springenberg Jost Tobias, 2015, ARXIV151106390
   Valpola, 2017, ADV NEURAL INFORM PR, P1195
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang X, 2021, IEEE T IMAGE PROCESS, V30, P1639, DOI 10.1109/TIP.2020.3044220
   Wang X, 2019, PROC CVPR IEEE, P5017, DOI 10.1109/CVPR.2019.00516
   Xie Q., 2019, SELF TRAINING NOISY
   Yarowsky D, 1995, P ACL, P189, DOI DOI 10.3115/981658.981684
   Yu J, 2014, IEEE T IMAGE PROCESS, V23, P2019, DOI 10.1109/TIP.2014.2311377
   Yu J, 2014, IEEE T MULTIMEDIA, V16, P159, DOI 10.1109/TMM.2013.2284755
   Zhang B, 2015, ARXIV150604557
   Zhang H, 2017, MIXUP EMPIRICAL RISK, DOI DOI 10.1007/978-3-030-01231-1_31
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhou W, 2020, NEURAL PROCESS LETT, V51, P1111, DOI 10.1007/s11063-019-10132-7
NR 47
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1370-4621
EI 1573-773X
J9 NEURAL PROCESS LETT
JI Neural Process. Lett.
PD OCT
PY 2021
VL 53
IS 5
SI SI
BP 3427
EP 3443
DI 10.1007/s11063-021-10556-0
EA JUN 2021
PG 17
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WH4LR
UT WOS:000660483000001
DA 2022-02-06
ER

PT J
AU Luo, SH
   Peng, AJ
   Zeng, H
   Kang, XG
   Liu, L
AF Luo, Shenghai
   Peng, Anjie
   Zeng, Hui
   Kang, Xiangui
   Liu, Li
TI Deep Residual Learning Using Data Augmentation for Median Filtering
   Forensics of Digital Images
SO IEEE ACCESS
LA English
DT Article
DE Multimedia security; median filtering forensics; deep learning;
   convolutional neural network
AB This paper addresses the median filtering forensics for a lossy compressed image with low resolution, which is essential for the identification of fake images and fake videos. A deep residual model with training data augmentation is employed in the proposed method. To solve the dilemma that the low-resolution image is the lack of enough statistical pixels for extracting reliable features, we propose a filter layer to widen the inputs for the convolutional neural network (CNN). First, we perform the high-pass filtering to an image in the filtered layer and stack the multiple filtered residuals into 16-channel feature maps as inputs of CNN. Then, a deep residual CNN model has proposed to self-learn the median filtering traces that are hidden in the JPEG lossy compressed image. To alleviate the over-fitting issue of the deeper CNN model, we employ a data augmentation scheme in the training to increase the diversity of training data and, thus, obtain a more stable median filtering detector. The experimental results demonstrate that the proposed net with training data augmentation outperforms state of the arts in both baseline test and generalization ability test, achieving at least 2% higher in terms of detection accuracy.
C1 [Luo, Shenghai; Peng, Anjie; Zeng, Hui] Southwest Univ Sci & Technol, Sch Comp Sci & Technol, Mianyang 62010, Sichuan, Peoples R China.
   [Peng, Anjie; Zeng, Hui; Kang, Xiangui] Sun Yat Sen Univ, Guangdong Prov Key Lab Informat Secur Technol, Guangzhou 510275, Guangdong, Peoples R China.
   [Liu, Li] Marvell Semicond Inc, Santa Clara, CA 95054 USA.
C3 Southwest University of Science & Technology - China; Sun Yat Sen
   University; Marvell Technology Group
RP Peng, AJ (corresponding author), Southwest Univ Sci & Technol, Sch Comp Sci & Technol, Mianyang 62010, Sichuan, Peoples R China.; Peng, AJ (corresponding author), Sun Yat Sen Univ, Guangdong Prov Key Lab Informat Secur Technol, Guangzhou 510275, Guangdong, Peoples R China.
EM penganjie200012@163.com
RI Kang, Xiangui/AAO-5527-2020; Zeng, Hui/ABE-6533-2021
FU NSFCNational Natural Science Foundation of China (NSFC) [61702429,
   61772571, 61872304]; Scientic Research of Sichuan Provincial Education
   Department [17ZB0450]; Sichuan Science and Technology Program
   [19yyjc1656]; Doctoral Research Fund of Southwest University of Science
   and Technology [16zx7104]; Program for Innovation Team of Sichuan
   Province Committee of China [18zd1102]; Opening Project of Guangdong
   Province Key Laboratory of Information Security Technology
   [2017B030314131]
FX This work was supported in part by the NSFC under Grant 61702429, Grant
   61772571, and Grant 61872304, in part by the Scientic Research of
   Sichuan Provincial Education Department under Grant 17ZB0450, in part by
   the Sichuan Science and Technology Program under Grant 19yyjc1656, in
   part by the Doctoral Research Fund of Southwest University of Science
   and Technology under Grant 16zx7104, in part by the Program for
   Innovation Team of Sichuan Province Committee of China under Grant
   18zd1102, and in part by the Opening Project of Guangdong Province Key
   Laboratory of Information Security Technology under Grant
   2017B030314131.
CR Barni M, 2010, INT CONF ACOUST SPEE, P1690, DOI 10.1109/ICASSP.2010.5495494
   Bas Patrick, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P59, DOI 10.1007/978-3-642-24178-9_5
   Bayar B, 2018, IEEE T INF FOREN SEC, V13, P2691, DOI 10.1109/TIFS.2018.2825953
   Cao G, 2010, IEEE INT CON MULTI, P89, DOI 10.1109/ICME.2010.5583869
   Chen C., 2012, P IH BERK CA US MAY, P1
   Chen JS, 2015, IEEE SIGNAL PROC LET, V22, P1849, DOI 10.1109/LSP.2015.2438008
   Chen YF, 2018, PROCEEDINGS OF THE 6TH ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY (IH&MMSEC'18), P91, DOI 10.1145/3206004.3206013
   Chen YF, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2111, DOI 10.1109/ICASSP.2018.8462057
   Dang-Nguyen D.T., 2015, P 6 ACM MULT SYST C, P219, DOI [10.1145/2713168.2713194, DOI 10.1145/2713168.2713194]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kang XG, 2013, IEEE T INF FOREN SEC, V8, P1456, DOI 10.1109/TIFS.2013.2273394
   Kirchner M, 2010, PROC SPIE, V7541, DOI 10.1117/12.839100
   Lei JJ, 2018, IEEE T CIRC SYST VID, V28, P706, DOI 10.1109/TCSVT.2016.2617332
   Li HD, 2018, IEEE T CIRC SYST VID, V28, P31, DOI 10.1109/TCSVT.2016.2599849
   Li Z., 2019, COMPUT MAT CONTINUA, V59, P607, DOI DOI 10.32604/CMC.2019.02656
   Niu YK, 2017, SIGNAL PROCESS-IMAGE, V53, P65, DOI 10.1016/j.image.2017.01.008
   Pan ZQ, 2019, INT J SENS NETW, V30, P116, DOI 10.1504/IJSNET.2019.099473
   Pan ZQ, 2019, SECUR COMMUN NETW, DOI 10.1155/2019/7682306
   Pan ZQ, 2019, IEEE ACCESS, V7, P36322, DOI 10.1109/ACCESS.2019.2905015
   [彭安杰 Peng Anjie], 2016, [计算机学报, Chinese Journal of Computers], V39, P503
   Pevny T, 2010, IEEE T INF FOREN SEC, V5, P215, DOI 10.1109/TIFS.2010.2045842
   Qu ZG, 2019, CMC-COMPUT MATER CON, V59, P607, DOI 10.32604/cmc.2019.02656
   Shan WY, 2019, IEEE ACCESS, V7, P17174, DOI 10.1109/ACCESS.2019.2894981
   Shen ZY, 2016, MULTIMED TOOLS APPL, V75, P2327, DOI 10.1007/s11042-014-2407-2
   Stamm MC, 2011, IEEE T INF FOREN SEC, V6, P1050, DOI 10.1109/TIFS.2011.2119314
   Wang BW, 2019, CMC-COMPUT MATER CON, V58, P679, DOI 10.32604/cmc.2019.06106
   Weng SW, 2019, INFORM SCIENCES, V489, P136, DOI 10.1016/j.ins.2019.03.032
   Yang JQ, 2018, MULTIMED TOOLS APPL, V77, P7931, DOI 10.1007/s11042-017-4691-0
   Yuan HD, 2011, IEEE T INF FOREN SEC, V6, P1335, DOI 10.1109/TIFS.2011.2161761
   Zhan Y., 2017, P 5 ACM WORKSH INF H, P165, DOI [10.1145/3082031.3083250, DOI 10.1145/3082031.3083250]
   Zhang H., 2018, ARXIV171009412
   Zhang YJ, 2014, IEEE SIGNAL PROC LET, V21, P275, DOI 10.1109/LSP.2013.2295858
NR 33
TC 6
Z9 6
U1 4
U2 8
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2019
VL 7
BP 80614
EP 80621
DI 10.1109/ACCESS.2019.2923000
PG 8
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA IH8RL
UT WOS:000474773500001
OA gold
DA 2022-02-06
ER

PT J
AU Sadiq, S
   Umer, M
   Ullah, S
   Mirjalili, S
   Rupapara, V
   Nappi, M
AF Sadiq, Saima
   Umer, Muhammad
   Ullah, Saleem
   Mirjalili, Seyedali
   Rupapara, Vaibhav
   Nappi, Michele
TI Discrepancy detection between actual user reviews and numeric ratings of
   Google App store using deep learning
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Review rating prediction; Unbiased rating prediction; Deep learning;
   CNN; Opinion Mining
AB Nowadays online reviews play a significant role in influencing the decision of consumers. Consumers show their experience and information about product quality in their reviews. Product Reviews from Amazon to Restaurant Reviews from Yelp are facing problems with fake reviews and fake numeric ratings. Online reviews typically consist of qualitative (text format) and quantitative (rating) formats. In the case of Google Play store fake numeric ratings can play a big role in the success of apps. People tend to believe that a high-star rating may be significantly attached with a good review. However, user star level rating information does not usually match with text format of review. Despite many efforts to resolve this issue, Apple App Store and Google Play Store are still facing this problem. This study proposes a novel Google App numeric reviews & ratings contradiction prediction framework using Deep Learning approaches. The framework consists of two phases. In the first phase, the polarity of reviews are predicted using sentiment analysis tool to build ground truth. In the second phase, star ratings are predicted from text format of reviews after training deep learning models on ground truth obtained in the first phase. Experimental results demonstrate that based on actual user reviews the proposed framework significantly predicts unbiased star rating of app.
C1 [Sadiq, Saima; Umer, Muhammad; Ullah, Saleem] Khwaja Fareed Univ Engn & Informat Technol, Dept Comp Sci, Rahim Yar Khan, Pakistan.
   [Umer, Muhammad] Islamia Univ Bahawalpur, Dept Comp Sci & Informat Technol, Bahawalpur 63100, Pakistan.
   [Mirjalili, Seyedali] Torrens Univ Australia, Ctr Artificial Intelligence Res & Optimizat, Brisbane, Qld 4006, Australia.
   [Mirjalili, Seyedali] Yonsei Univ, Yonsei Frontier Lab, Seoul, South Korea.
   [Rupapara, Vaibhav] Florida Int Univ, Sch Comp & Informat Sci, Miami, FL 33199 USA.
   [Nappi, Michele] Univ Salerno, Dept Comp Sci, Fisciano, Italy.
C3 Torrens University Australia; Yonsei University; State University System
   of Florida; Florida International University; University of Salerno
RP Umer, M (corresponding author), Khwaja Fareed Univ Engn & Informat Technol, Dept Comp Sci, Rahim Yar Khan, Pakistan.; Rupapara, V (corresponding author), Florida Int Univ, Sch Comp & Informat Sci, Miami, FL 33199 USA.; Nappi, M (corresponding author), Univ Salerno, Dept Comp Sci, Fisciano, Italy.
EM s.kamrran@gmail.com; umersabir1996@gmail.com;
   saleem.ullah@kfueit.edu.pk; ali.mirjalili@laureate.edu.au;
   vaibhav.rupapara.sept@gmail.com; mnappi@unisa.it
RI Mirjalili, Seyedali/P-1372-2018; Rupapara, Vaibhav/AAE-3416-2021; Ullah,
   Dr. Saleem/D-2644-2014
OI Mirjalili, Seyedali/0000-0002-1443-9458; Rupapara,
   Vaibhav/0000-0002-7889-4521; Sadiq, Saima/0000-0002-2611-3738; Ullah,
   Dr. Saleem/0000-0003-3747-1263
CR Ahmad S, 2017, INT J MULTIDISCIP SC, V8, P27
   Akhtar MS, 2020, IEEE COMPUT INTELL M, V15, P64, DOI 10.1109/MCI.2019.2954667
   Anchieta R. T., 2017, P 23 BRAZ S MULT WEB, P217
   Aralikatte R, 2018, PROCEEDINGS OF THE ACM INDIA JOINT INTERNATIONAL CONFERENCE ON DATA SCIENCE AND MANAGEMENT OF DATA (CODS-COMAD'18), P57, DOI 10.1145/3152494.3152500
   Bano M, 2015, INFORM SOFTWARE TECH, V58, P148, DOI 10.1016/j.infsof.2014.06.011
   Basiri ME, 2021, FUTURE GENER COMP SY, V115, P279, DOI 10.1016/j.future.2020.08.005
   Bonta V., 2019, ASIAN J COMPUT SC S2, V8, P1, DOI 10.51983/ajcst-2019.8.S2.2037
   Cambria Erik, 2020, CIKM '20: Proceedings of the 29th International Conference on Information & Knowledge Management, P105, DOI 10.1145/3340531.3412003
   Cambria E, 2017, SOCIO AFFECT COMPUT, V5, P1, DOI 10.1007/978-3-319-55394-8_1
   Chandy R, 2012, P 2 JOINT WICOW AIRW, P56
   Cho K, 2014, ABS14091259 ARXIV, DOI DOI 10.3115/V1/W14-4012
   Ciurumelea A, 2017, 2017 IEEE 24TH INTERNATIONAL CONFERENCE ON SOFTWARE ANALYSIS, EVOLUTION, AND REENGINEERING (SANER), P91, DOI 10.1109/SANER.2017.7884612
   Dhinakaran VT, 2018, INT REQUIR ENG CONF, P170, DOI 10.1109/RE.2018.00026
   Di Nardo F, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9020355
   Ding X., 2008, P 2008 INT C WEB SEA, P231, DOI DOI 10.1145/1341531.1341561
   Du J., 2020, INT C WEB INF SYST E, P795
   Dyer C., 2015, ARXIV PREPRINT ARXIV
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1
   Feldman R., 2007, TEXT MINING HDB ADV
   Guzman E, 2014, INT REQUIR ENG CONF, P153, DOI 10.1109/RE.2014.6912257
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735
   Hochreiter S., 2001, FIELD GUIDE DYNAMICA
   Holla S., 2012, INT J COMPUTER TREND, V3, P486
   Hutto C. J., 2014, P INT AAAI C WEB SOC
   Islam M.M., 2014, P 7 IET INT C POW EL, P1, DOI [10.1177/0954407014557053, DOI 10.1049/CP.2014.0296]
   Jakob N., 2009, P 1 INT CIKM WORKSH, P57, DOI DOI 10.1145/1651461.1651473
   Kim Y., 2014, EMNLP
   Li H, 2018, NATL SCI REV, V5, P24, DOI 10.1093/nsr/nwx110
   Li Yang, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8111248
   Licorish SA, 2015, 2015 24TH AUSTRALASIAN SOFTWARE ENGINEERING CONFERENCE (ASWEC 2015), P78, DOI 10.1109/ASWEC.2015.19
   Liu XC, 2019, INT J MOD PHYS B, V33, DOI 10.1142/S0217979219501297
   Maalej W, 2015, INT REQUIR ENG CONF, P116, DOI 10.1109/RE.2015.7320414
   Mahmud O., 2019, 2019 7 INT C SMART C, P1
   Mao WT, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9020323
   Martens D, 2017, 2017 IEEE/ACM 2ND INTERNATIONAL WORKSHOP ON EMOTION AWARENESS IN SOFTWARE ENGINEERING (SEMOTION 2017), P8, DOI 10.1109/SEmotion.2017.6
   Martin W, 2015, 12TH WORKING CONFERENCE ON MINING SOFTWARE REPOSITORIES (MSR 2015), P123, DOI 10.1109/MSR.2015.19
   Pagano D, 2013, S VIS LANG HUM CEN C, P125, DOI 10.1109/RE.2013.6636712
   Panichella S, 2015, PROC IEEE INT CONF S, P281, DOI 10.1109/ICSM.2015.7332474
   Vu PM, 2015, IEEE INT CONF AUTOM, P749, DOI 10.1109/ASE.2015.85
   Popescu A.-M., 2007, NATURAL LANGUAGE PRO, P9, DOI [DOI 10.1007/978-1-84628-754-1_2, 10. 1007/978-1-84628-754-1_2]
   Pratama Bayu Trisna, 2019, 2019 International Conference on Information and Communications Technology (ICOIACT), P474
   Qiang BH, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9020350
   Rebiai Z, 2019, P 13 INT WORKSH SEM, P297
   Sadiq S, 2021, FUTURE GENER COMP SY, V114, P120, DOI 10.1016/j.future.2020.07.050
   Shah F., 2018, SIMPLE APP REV CLASS, P112, DOI [10.5220/0006855901120119, DOI 10.5220/0006855901120119]
   Singla Z., 2017, 2017 INT C INT COMP, P1
   Suleman M., 2019, URDU NEWS HEADLINE T, P57
   Tang DY, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1340
   Tian Y, 2015, PROC IEEE INT CONF S, P301, DOI 10.1109/ICSM.2015.7332476
   Umer M, 2021, ETRI J, V43, P95, DOI 10.4218/etrij.2019-0443
   Umer M, 2020, IEEE ACCESS, V8, P93782, DOI 10.1109/ACCESS.2020.2994810
   Villarroel L, 2016, PROC INT CONF SOFTW, P14, DOI 10.1145/2884781.2884818
   Zhai C., 2012, MINING TEXT DATA, P415, DOI [10.1007/978-1-4614-3223-4_13, DOI 10.1007/978-1-4614-3223-4_13]
   Zhou SS, 2013, NEUROCOMPUTING, V120, P536, DOI 10.1016/j.neucom.2013.04.017
NR 54
TC 4
Z9 4
U1 9
U2 20
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD NOV 1
PY 2021
VL 181
AR 115111
DI 10.1016/j.eswa.2021.115111
PG 8
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic; Operations Research & Management Science
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Operations Research & Management Science
GA SN8BN
UT WOS:000658511600009
DA 2022-02-06
ER

PT J
AU Kumari, R
   Ashok, N
   Ghosal, T
   Ekbal, A
AF Kumari, Rina
   Ashok, Nischal
   Ghosal, Tirthankar
   Ekbal, Asif
TI Misinformation detection using multitask learning with mutual learning
   for novelty detection and emotion recognition
SO INFORMATION PROCESSING & MANAGEMENT
LA English
DT Article
DE Fake news detection; Novelty prediction; Emotion recognition;
   Multitasking; Deep learning
AB Fake news or misinformation is the information or stories intentionally created to deceive or mislead the readers. Nowadays, social media platforms have become the ripe grounds for misinformation, spreading them in a few minutes, which led to chaos, panic, and potential health hazards among people. The rapid dissemination and a prolific rise in the spread of fake news and misinformation create the most time-critical challenges for the Natural Language Processing (NLP) community. Relevant literature reveals that the presence of an element of surprise in the story is a strong driving force for the rapid dissemination of misinformation, which attracts immediate attention and invokes strong emotional stimulus in the reader. False stories or fake information are written to arouse interest and activate the emotions of people to spread it. Thus, false stories have a higher level of novelty and emotional content than true stories. Hence, Novelty of the news item and recognizing the Emotional state of the reader after reading the item seems two key tasks to tightly couple with misinformation Detection. Previous literature did not explore misinformation detection with mutual learning for novelty detection and emotion recognition to the best of our knowledge. Our current work argues that joint learning of novelty and emotion from the target text makes a strong case for misinformation detection. In this paper, we propose a deep multitask learning framework that jointly performs novelty detection, emotion recognition, and misinformation detection. Our deep multitask model achieves state-of-the-art (SOTA) performance for fake news detection on four benchmark datasets, viz. ByteDance, FNC, Covid-Stance and FNID with 7.73%, 3.69%, 7.95% and 13.38% accuracy gain, respectively. The evaluation shows that our multitask learning framework improves the performance over the single-task framework for four datasets with 7.8%, 28.62%, 11.46%, and 15.66% overall accuracy gain. We claim that textual novelty and emotion are the two key aspects to consider while developing an automatic fake news detection mechanism. The source code is available at https://github.com/Nish-19/Misinformation-Multitask-Attention-NE.
C1 [Kumari, Rina; Ashok, Nischal; Ekbal, Asif] Indian Inst Technol Patna, Comp Sci & Engn Dept, Bihta 801106, Bihar, India.
   [Ghosal, Tirthankar] Charles Univ Prague, Fac Math & Phys, Inst Formal & Appl Math, Prague, Czech Republic.
C3 Indian Institute of Technology (IIT) - Patna; Charles University Prague
RP Kumari, R (corresponding author), Indian Inst Technol Patna, Comp Sci & Engn Dept, Bihta 801106, Bihar, India.
EM rina_1921cs13@iitp.ac.in; 1801cs33@iitp.ac.in; ghosal@ufal.mff.cuni.cz;
   asif.ekbal@gmail.com
OI Kumari, Rina/0000-0002-1590-4673
FU Wipro
FX The authors gratefully acknowledge the project ``HELIOS -Hate,
   Hyperpartisan, and Hyperpluralism Elicitation and Observer System'',
   sponsored by Wipro.
CR Abdul-Mageed M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P718, DOI 10.18653/v1/P17-1067
   Akhtar MS, 2018, IEEE INTELL SYST, V33, P8, DOI 10.1109/MIS.2018.2877279
   Allcott H, 2017, J ECON PERSPECT, V31, P211, DOI 10.1257/jep.31.2.211
   Amplayo RK, 2018, INFORM SCIENCES, V422, P542, DOI 10.1016/j.ins.2017.09.037
   An X., 2020, BIOMEDICAL INFORM TE, P369
   Attardi G., 2020, LANG RESOUR EVAL
   Barr R. A., 2019, FAKE NEWS GRABS OUR
   Becker K, 2017, INFORM PROCESS MANAG, V53, P684, DOI 10.1016/j.ipm.2016.12.008
   Bidgoly A., 2020, FAKE NEWS DETECTION
   Cruz JCB, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P2596
   Bostan L.-A.-M., 2018, P 27 INT C COMP LING, P2104
   Brady WJ, 2017, P NATL ACAD SCI USA, V114, P7313, DOI 10.1073/pnas.1618923114
   Breja M, 2015, NOVEL APPROACH NOVEL
   Chaudhry A. K., 2017, CS224N NATURAL LANGU
   Demszky D., 2020, ARXIV PREPRINT ARXIV
   Devlin J., 2019, NAACLHLT1 NAACLHLT1
   Gang R, 2019, INFORM PROCESS MANAG, V56, P1425, DOI 10.1016/j.ipm.2018.04.003
   Ghanem B, 2020, ACM T INTERNET TECHN, V20, DOI 10.1145/3381750
   Ghosal T., 2018, P 27 INT C COMP LING, P2802
   Ghosal T, 2021, NAT LANG ENG, V27, P427, DOI 10.1017/S1351324920000194
   Giachanou A, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P877, DOI 10.1145/3331184.3331285
   Guo C., 2019, ARXIV PREPRINT ARXIV
   Hanselowski A., 2018, ARXIV180605180
   He XJ, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102258
   Hsu C.-C., 2019, 3391585 SSRN 3391585 SSRN
   Imtiaz Z, 2020, IEEE ACCESS, V8, P21932, DOI 10.1109/ACCESS.2020.2969041
   Islam MS, 2020, AM J TROP MED HYG, V103, P1621, DOI 10.4269/ajtmh.20-0812
   Jain G, 2019, ANN MATH ARTIF INTEL, V85, P21, DOI 10.1007/s10472-018-9612-z
   Jose S.-D. J., 2020, NEW TRENDS USE ARTIF
   Kerner HR, 2019, THIRTY-THIRD AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTY-FIRST INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / NINTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P9484
   Khuroo MS, 2020, INT J ANTIMICROB AG, V56, DOI 10.1016/j.ijantimicag.2020.106101
   Kochkina E., 2018, COLING 2018, P3402
   Kogan S., 2019, 3237763 SSRN 3237763 SSRN
   Kouzy R, 2020, CUREUS, V12, DOI 10.7759/cureus.7255
   Kumar S, 2020, SN APPL SCI, V2, DOI 10.1007/s42452-020-2082-z
   Lee S., 2015, P 2015 C EMP METH NA, P567
   Liew J.S.Y., 2016, P NAACL STUD RES WOR, P73
   Liu S., 2019, P 12 ACM INT C WEB S, P11
   LIU Z., 2019, 2019 28 INT C COMP C, P1, DOI 10.1109/VTCSpring.2019.8746624
   MacCartney B, 2014, TEXT SPEECH LANG TEC, V47, P129, DOI 10.1007/978-94-007-7284-7_8
   Mazumder, 2020, IMPACT RUMORS MISINF
   Mutlu E. C., ASTANCE DATA SET POL
   Mutlu EC, 2020, DATA BRIEF, V33, DOI 10.1016/j.dib.2020.106401
   Pennycook G, 2020, PSYCHOL SCI, V31, P770, DOI 10.1177/0956797620939054
   Pennycook G, 2019, COGNITION, V188, P39, DOI 10.1016/j.cognition.2018.06.011
   Pham L, 2019, P 12 ACM INT C WEB S, P11
   Qin Y., 2016, ARXIV PREPRINT ARXIV
   Rath P. K., 2020, 2020 IEEE 17 IND COU 2020 IEEE 17 IND COU, P1
   Rohit W., 2018, INT J SCI RES COMPUT
   Saikh T., 2017, P 14 INT C NAT LANG P 14 INT C NAT LANG, P131
   Scheufele DA, 2019, P NATL ACAD SCI USA, V116, P7662, DOI 10.1073/pnas.1805871115
   Shu K., 2019, FAKENEWSNET DATA REP
   Shu K, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P395, DOI 10.1145/3292500.3330935
   Slovikovskaya V, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P1211
   Vosoughi S, 2018, SCIENCE, V359, P1146, DOI 10.1126/science.aap9559
   Wang WY, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P422, DOI 10.18653/v1/P17-2067
   Wang YC, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P996
   Wu L., 2019, P 2019 C EMP METH NA, P4644
   Xiaoye S, 2019, THESIS SWISS FEDERAL THESIS SWISS FEDERAL
   Xiong X, 2020, KNOWL-BASED SYST, V194, DOI 10.1016/j.knosys.2020.105544
   Yang K., 2019, ARXIV PREPRINT ARXIV
   Yang R., 2019, ARXIV PREPRINT ARXIV
   Yang Z., 2016, NAACL HLT, P1480
   Cuan-Baltazar JY, 2020, JMIR PUBLIC HLTH SUR, V6, P176, DOI 10.2196/18444
   Zarrabian S., 2020, BASIC CLIN NEUROSCI, P189
   Zhou D., 2016, PROF 21 C EMP METH N
NR 66
TC 2
Z9 2
U1 20
U2 20
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 0306-4573
EI 1873-5371
J9 INFORM PROCESS MANAG
JI Inf. Process. Manage.
PD SEP
PY 2021
VL 58
IS 5
AR 102631
DI 10.1016/j.ipm.2021.102631
PG 15
WC Computer Science, Information Systems; Information Science & Library
   Science
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Information Science & Library Science
GA TS7FR
UT WOS:000679812700008
DA 2022-02-06
ER

PT J
AU Kuehn, KM
   Salter, LA
AF Kuehn, Kathleen M.
   Salter, Leon A.
TI Assessing Digital Threats to Democracy, and Workable Solutions: A Review
   of the Recent Literature
SO INTERNATIONAL JOURNAL OF COMMUNICATION
LA English
DT Review
DE digital democracy; fake news; filter bubbles; echo chambers; hate
   speech; surveillance; surveillance capitalism
ID HATE SPEECH; SOCIAL MEDIA; NEWS; INTERNET; ONLINE; PRIVACY; RESISTANCE;
   ANONYMITY; CIVILITY; NETWORK
AB Concerns surrounding the threats that digital platforms pose to the functioning of Western liberal democracies have grown since the 2016 U.S. election. Yet despite a preponderance of academic work in this area, the precise nature of these threats, empirical solutions for their redress, and their relationship to the wider digital political economy remain undertheorized. This article addresses these gaps with a semisystematic literature review that identifies and defines four prominent threats-fake news, filter bubbles/echo chambers, online hate speech, and surveillance-and constructs a typology of "workable solutions" for combating these threats that highlights the tendency to silo technical, regulatory, or culturally embedded approaches.
C1 [Kuehn, Kathleen M.] Victoria Univ Wellington, Wellington, New Zealand.
   [Salter, Leon A.] Massey Univ, Palmerston North, New Zealand.
C3 Victoria University Wellington; Massey University
RP Kuehn, KM (corresponding author), Victoria Univ Wellington, Wellington, New Zealand.
EM kathleen.kuehn@vuw.ac.nz; l.a.salter@massey.ac.nz
CR Alkiviadou N, 2019, INF COMMUN TECHNOL L, V28, P19, DOI 10.1080/13600834.2018.1494417
   Allcott H, 2017, J ECON PERSPECT, V31, P211, DOI 10.1257/jep.31.2.211
   Andrejevic M, 2019, SURVEILL SOC, V17, P7, DOI 10.24908/ss.v17i1/2.12930
   Bakker P, 2010, TIJDSCHR COMMUNWET, V38, P250
   Baym N., 2010, PERSONAL CONNECTIONS
   Beam MA, 2018, INFORM COMMUN SOC, V21, P940, DOI 10.1080/1369118X.2018.1444783
   Bennett WL, 2012, INFORM COMMUN SOC, V15, P739, DOI 10.1080/1369118X.2012.670661
   Berentson-Shaw J., 2018, MATTER FACT TALKING
   Betkier M., 2018, MOVING CONSENT DATA
   Binns Reuben, 2017, Social Informatics. 9th International Conference, SocInfo 2017. Proceedings: LNCS 10540, P405, DOI 10.1007/978-3-319-67256-4_32
   Bodkin-Andrews G, 2013, PSYCH, V35, P14
   Braithwaite A, 2016, SOC MEDIA SOC, V2, DOI 10.1177/2056305116672484
   Bruns A., 2019, ARE FILTER BUBBLES R
   Bucher T., 2018, SAGE HDB SOCIAL MEDI, P223
   Castells Manuel., 2013, COMMUNICATION POWER
   Ceron A, 2016, SOC INDIC RES, V126, P225, DOI 10.1007/s11205-015-0893-x
   Chandrasekharan Eshwar, 2017, Proceedings of the ACM on Human-Computer Interaction, V1, DOI 10.1145/3134666
   Chen HT, 2018, NEW MEDIA SOC, V20, P3917, DOI 10.1177/1461444818763384
   Christchurch Call, 2019, CHRISTCHURCH CALL AC
   Coleman G, 2019, MEDIA CULT SOC, V41, P565, DOI 10.1177/0163443719843867
   College of St. George, 2018, DEM POSTTR INF AG
   Crawford K, 2016, NEW MEDIA SOC, V18, P410, DOI 10.1177/1461444814543163
   Deb A., 2017, IS SOCIAL MEDIA THRE
   Delort JY, 2011, INT J ELECTRON COMM, V15, P9, DOI 10.2753/JEC1086-4415150302
   Dieter M., 2015, POSTDIGITAL AESTHETI, P163
   Dubois E, 2018, INFORM COMMUN SOC, V21, P729, DOI 10.1080/1369118X.2018.1428656
   Edstrom M, 2016, INT J CRIME JUSTICE, V5, P96, DOI 10.5204/ijcjsd.v5i2.314
   Elliott M., 2019, DIGITAL THREATS DEMO
   Emanuelson E, 2018, ADMIN LAW REV, V70, P209
   European Commission, 2018, MULT APPR DIS REP IN
   Farkas J, 2018, JAVNOST-PUBLIC, V25, P298, DOI 10.1080/13183222.2018.1463047
   Fletcher R., 2018, REUTERS
   Flew T, 2019, J DIGIT MEDIA POLICY, V10, P33, DOI 10.1386/jdmp.10.1.33_1
   Foucault M., 2010, ARCHAEOLOGY KNOWLEDG
   Foucault M., 1991, FOUCAULT EFFECT STUD, P53
   Fuchs C., 2015, CULTURE EC AGE SOCIA
   Fuchs C, 2017, J INF COMMUN ETHICS, V15, P412, DOI 10.1108/JICES-01-2016-0004
   Gagliardone I, 2015, COUNTERING ONLINE HA
   Galan-Garcia P, 2016, LOG J IGPL, V24, P42, DOI 10.1093/jigpal/jzv048
   Gardiner Becky., 2016, GUARDIAN
   Gehl R., 2018, SAGE HDB SOCIAL MEDI, P330
   Gillespie T., 2018, SAGE HDB SOCIAL MEDI
   Gorwa R, 2019, INFORM COMMUN SOC, V22, P854, DOI 10.1080/1369118X.2019.1573914
   Graeber David, 2013, DEMOCRACY PROJECT HI
   Guess A., 2018, EUR RES COUNC, V9, P1
   Guo L, 2020, INFORM COMMUN SOC, V23, P234, DOI 10.1080/1369118X.2018.1499793
   Hille S, 2014, JOURNAL PRACT, V8, P563, DOI 10.1080/17512786.2014.899758
   Himelboim I, 2013, J COMPUT-MEDIAT COMM, V18, P40, DOI 10.1111/jcc4.12001
   Hintz A, 2016, INTERNET POLICY REV, V5, DOI 10.14763/2016.3.424
   Holcomb J., 2015, INVESTIGATIVE JOURNA
   Hutchby I, 2001, SOCIOLOGY, V35, P441, DOI 10.1177/S0038038501000219
   Internet Governance Forum, 2015, REC TERMS SERV HUM R
   Isaak J, 2018, COMPUTER, V51, P56, DOI 10.1109/MC.2018.3191268
   Jakubowicz A., 2017, CYBER RACISM COMMUNI CYBER RACISM COMMUNI
   Jakubowicz A, 2017, COSMOP CIV SOC, V9, P41, DOI 10.5130/ccs.v9i3.5655
   Jenkins H., 2008, CONVERGENCE CULTURE
   Kamara Irene, 2017, European Journal of Law and Technology, V8, P1
   Kim S, 2012, PUBLIC ADMIN REV, V72, P819, DOI 10.1111/j.1540-6210.2012.02593.x
   Klein A., 2017, FANATICISM RACISM RA
   Klonick K., 2015, MD L REV, V75, P1029
   Lanois P., 2016, J INTERNET LAW, V20, P1
   Lewis R., 2018, ALTERNATIVE INFLUENC
   Lu J, 2020, INFORM COMMUN SOC, V23, P252, DOI 10.1080/1369118X.2018.1499794
   Lyon D, 2014, BIG DATA SOC, V1, DOI 10.1177/2053951714541861
   Mackaskill E., 2013, GUARDIAN
   Marda V., 2018, WISDOM CROWD MULTIST
   Massanari A, 2017, NEW MEDIA SOC, V19, P329, DOI 10.1177/1461444815608807
   Massanari AL, 2018, FEM MEDIA STUD, V18, P525, DOI 10.1080/14680777.2018.1447333
   Miller C., 2016, RISE DIGITAL POLITIC
   Moller J, 2018, INFORM COMMUN SOC, V21, P959, DOI 10.1080/1369118X.2018.1444076
   Mueller R.S., 2019, REPORT INVESTIGATION
   Nagle A., 2017, KILL ALL NORMIES ONL
   Narayanan A, 2017, STUD BIG DATA, V32, P45, DOI 10.1007/978-3-319-54024-5_3
   Nelson JL, 2018, NEW MEDIA SOC, V20, P3720, DOI 10.1177/1461444818758715
   Nguyen A., 2019, 1 MONDAY, V24, DOI [10.5210/fm.v24i6.9632, DOI 10.5210/FM.V24I6.9632]
   Nielsen M. M., 2017, EJOURNAL EDEMOCRACY, V9, P68, DOI [10.29379/jedem.v9i2.462, DOI 10.29379/JEDEM.V9I2.462]
   NOELLENE.E, 1974, J COMMUN, V24, P43, DOI 10.1111/j.1460-2466.1974.tb00367.x
   Oboler A, 2018, COSMOP CIV SOC, V10, P99, DOI 10.5130/ccs.v10i2.6035
   Ombler J., 2016, POLICY Q, V12, P20, DOI [10.26686/pq.v12i4.4623, DOI 10.26686/PQ.V12I4.4623]
   Online Hate Prevention Institute, 2012, AB MEM ONL HAT
   Papacharissi Z, 2012, J COMMUN, V62, P266, DOI 10.1111/j.1460-2466.2012.01630.x
   Pariser E., 2011, FILTER BUBBLE WHAT I
   Persily N, 2017, J DEMOCR, V28, P63, DOI 10.1353/jod.2017.0025
   Phelan S, 2019, COMMUN CULT CRIT, V12, P455, DOI 10.1093/ccc/tcz040
   Pohle J, 2017, MEDIA COMMUN-LISBON, V5, P1, DOI 10.17645/mac.v5i1.932
   Poyhtari R, 2014, ANN-ANAL ISTRSKE MED, V24, P513
   Ray R, 2017, ETHNIC RACIAL STUD, V40, P1797, DOI 10.1080/01419870.2017.1335422
   Risch Julian, 2018, P 1 WORKSH TROLL AGG, P166
   Roberts Sarah, 2016, INTERSECTIONAL INTER, DOI DOI 10.1007/S13398-014-0173-7.2
   Rowe I, 2015, INFORM COMMUN SOC, V18, P121, DOI 10.1080/1369118X.2014.940365
   Santana AD, 2014, JOURNAL PRACT, V8, P18, DOI 10.1080/17512786.2013.813194
   Scott B., 2018, DIGITALDECEIT TECHNO
   Shapiro E, 2018, COMMUN ACM, V61, P31, DOI 10.1145/3213766
   Silverman C., 2016, BUZZFEED NEWS 1116
   Sinclair John., 2017, POLIT EC COMMUN, V4, P3
   Sitrin M., 2014, THEY CANT REPRESENT
   Snyder H, 2019, J BUS RES, V104, P333, DOI 10.1016/j.jbusres.2019.07.039
   Srnicek N., 2017, PLATFORM CAPITALISM
   Stohl C, 2018, ELGAR ST HUM RIGHTS, P232
   Stoycheff E, 2019, NEW MEDIA SOC, V21, P602, DOI 10.1177/1461444818801317
   Stoycheff E, 2016, J MASS COMMUN Q, V93, P296, DOI 10.1177/1077699016630255
   Sweet M, 2013, MEDIA INT AUST, P104, DOI 10.1177/1329878X1314900112
   Unsvag E. F., 2018, P 2 WORKSH AB LANG O
   Vosoughi S, 2018, SCIENCE, V359, P1146, DOI 10.1126/science.aap9559
   Walton SC, 2013, COMPUT HUM BEHAV, V29, P1465, DOI 10.1016/j.chb.2013.01.033
   Wizner B., 2017, INT J COMMUNICATION, V11, P897
   Wu W, 2017, ADMIN SOC, V49, P882, DOI 10.1177/0095399716685799
   Ziegler CE, 2018, INT POLITICS, V55, P557, DOI 10.1057/s41311-017-0113-1
   Zimmer Franziska, 2019, Journal of Information Management, V7, P40, DOI 10.1633/JISTaP.2019.7.2.4
   Zuboff S., 2019, AGE SURVEILLANCE CAP
NR 110
TC 5
Z9 5
U1 7
U2 22
PU USC ANNENBERG PRESS
PI LOS ANGELES
PA UNIV SOUTHERN CALIFORNIA, KERCKHOFF HALL, 734 W ADAMS BLVD, MC7725, LOS
   ANGELES, CA 90089 USA
SN 1932-8036
J9 INT J COMMUN-US
JI Int. J. Commun.
PY 2020
VL 14
BP 2589
EP 2610
PG 22
WC Communication
WE Social Science Citation Index (SSCI)
SC Communication
GA QF1KP
UT WOS:000616658300015
DA 2022-02-06
ER

PT J
AU Wang, ZF
   Yan, DQ
   Wang, RD
   Xiang, L
   Wu, TL
AF Wang, Zhifeng
   Yan, Diqun
   Wang, Rangding
   Xiang, Li
   Wu, Tingling
TI Speech Resampling Detection Based on Inconsistency of Band Energy
SO CMC-COMPUTERS MATERIALS & CONTINUA
LA English
DT Article
DE Resampling detection; logarithmic ratio; band energy; robustness
AB Speech resampling is a typical tempering behavior, which is often integrated into various speech forgeries, such as splicing, electronic disguising, quality faking and so on. By analyzing the principle of resampling, we found that, compared with natural speech, the inconsistency between the bandwidth of the resampled speech and its sampling ratio will be caused because the interpolation process in resampling is imperfect. Based on our observation, a new resampling detection algorithm based on the inconsistency of band energy is proposed. First, according to the sampling ratio of the suspected speech, a band-pass Butterworth filter is designed to filter out the residual signal. Then, the logarithmic ratio of band energy is calculated by the suspected speech and the filtered speech. Finally, with the logarithmic ratio, the resampled and original speech can be discriminated. The experimental results show that the proposed algorithm can effectively detect the resampling behavior under various conditions and is robust to MP3 compression.
C1 [Wang, Zhifeng; Yan, Diqun; Wang, Rangding; Xiang, Li; Wu, Tingling] Ningbo Univ, Coll Informat Sci & Engn, Feng Hua Rd 818, Ningbo 315211, Zhejiang, Peoples R China.
C3 Ningbo University
RP Yan, DQ (corresponding author), Ningbo Univ, Coll Informat Sci & Engn, Feng Hua Rd 818, Ningbo 315211, Zhejiang, Peoples R China.
EM yandiqun@nbu.edu.cn
RI Yan, Diqun/AAY-6775-2021
OI Yan, Diqun/0000-0002-5241-7276
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61300055, U1736215, 61672302]; Zhejiang
   Natural Science FoundationNatural Science Foundation of Zhejiang
   Province [LY17F020010, LZ15F020002]; Ningbo Natural Science Foundation
   [2017A610123]; Ningbo University Fund [XKXL1509, XKXL1503]; K.C. Wong
   Magna Fund in Ningbo University
FX This work was supported by the National Natural Science Foundation of
   China (Grant No. 61300055, U1736215, 61672302), Zhejiang Natural Science
   Foundation (Grant No. LY17F020010, LZ15F020002), Ningbo Natural Science
   Foundation (Grant No. 2017A610123), Ningbo University Fund (Grant No.
   XKXL1509, XKXL1503) and K.C. Wong Magna Fund in Ningbo University.
CR ALEGRE F, 2014, INT C BIOM SPEC INT, P1
   Ding Qi, 2010, Journal of Applied Sciences, V28, P142
   Gallagher AC, 2005, 2nd Canadian Conference on Computer and Robot Vision, Proceedings, P65, DOI 10.1109/CRV.2005.33
   GORDON NJ, 1993, IEE PROC-F, V140, P107, DOI 10.1049/ip-f-2.1993.0015
   Gutta S., 2016, 22 NAT C COMM, P1
   [侯丽敏 Hou Limin], 2014, [上海大学学报. 自然科学版, Journal of Shanghai University. Natural Science Edition], V20, P304
   Li TC, 2012, SIGNAL PROCESS, V92, P1637, DOI 10.1016/j.sigpro.2011.12.019
   Popescu AC, 2005, IEEE T SIGNAL PROCES, V53, P3948, DOI 10.1109/TSP.2005.855406
   Popescu AC, 2005, IEEE T SIGNAL PROCES, V53, P758, DOI 10.1109/TSP.2004.839932
   Shanableh T, 2013, DIGIT INVEST, V10, P350, DOI 10.1016/j.diin.2013.10.004
   Sharma B, 2017, IEEE SIGNAL PROC LET, V24, P382, DOI 10.1109/LSP.2017.2662805
   Wu HJ, 2014, IEEE T INF FOREN SEC, V9, P489, DOI 10.1109/TIFS.2014.2301912
   Xia ZH, 2018, IEEE T CLOUD COMPUT, V6, P276, DOI 10.1109/TCC.2015.2491933
   Yao Qiu-ming, 2006, Journal of Computer Applications, V26, P2598
   Zen H, 2009, SPEECH COMMUN, V51, P1039, DOI 10.1016/j.specom.2009.04.004
NR 15
TC 5
Z9 5
U1 0
U2 1
PU TECH SCIENCE PRESS
PI NORCROSS
PA 6825 JIMMY CARTER BLVD, STE 1850, NORCROSS, GA 30071 USA
SN 1546-2218
EI 1546-2226
J9 CMC-COMPUT MATER CON
JI CMC-Comput. Mat. Contin.
PD AUG
PY 2018
VL 56
IS 2
BP 247
EP 259
DI 10.3970/cmc.2018.02902
PG 13
WC Computer Science, Information Systems; Materials Science,
   Multidisciplinary
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Materials Science
GA GT8MI
UT WOS:000444791200005
DA 2022-02-06
ER

PT J
AU Asghar, MZ
   Habib, A
   Habib, A
   Khan, A
   Ali, R
   Khattak, A
AF Asghar, Muhammad Zubair
   Habib, Ammara
   Habib, Anam
   Khan, Adil
   Ali, Rehman
   Khattak, Asad
TI Exploring deep neural networks for rumor detection
SO JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING
LA English
DT Article
DE Rumor detection; Microblogs; Deep learning; BiLSTM; CNN; Social
   networking services; Twitter
ID ATTENTION
AB The widespread propagation of numerous rumors and fake news have seriously threatened the credibility of microblogs. Previous works often focused on maintaining the previous state without considering the subsequent context information. Furthermore, most of the early works have used classical feature representation schemes followed by a classifier. We investigate the rumor detection problem by exploring different Deep Learning models with emphasis on considering the contextual information in both directions: forward and backward, in a given text. The proposed system is based on Bidirectional Long Short-Term Memory with Convolutional Neural Network, effectively classifying the tweet into rumors and non-rumors. Experimental results show that the proposed method outperformed the baseline methods with 86.12% accuracy. Furthermore, the statistical analysis also shows the effectiveness of the proposed model than the comparing methods.
C1 [Asghar, Muhammad Zubair; Habib, Ammara; Habib, Anam] Gomal Univ, Inst Comp & Informat Technol, Dikhan, KP, Pakistan.
   [Khan, Adil] Univ Peshawar, Sch Comp Sci & Technol, SZIC, Dept Comp Sci, Peshawar, Kpk, Pakistan.
   [Ali, Rehman] Univ Peshawar, QACC, Peshawar, Kpk, Pakistan.
   [Khattak, Asad] Zayed Univ, Coll Technol Innovat, Dubai, U Arab Emirates.
C3 University of Peshawar; University of Peshawar; Zayed University
RP Asghar, MZ (corresponding author), Gomal Univ, Inst Comp & Informat Technol, Dikhan, KP, Pakistan.
EM zubair@gu.edu.pk; ammarahabib10@gmail.com; anamhabib19@gmail.com;
   adil.adil25@yahoo.com; rehmanali@uop.edu.pk; asad.khattak@zu.ac.ae
RI Asghar, Muhammad Zubair/M-6411-2015; khan, Adil/E-8567-2017
OI Asghar, Muhammad Zubair/0000-0003-3320-2074; khan,
   Adil/0000-0003-2862-5718
FU Zayed University Cluster Research Award [R18038]
FX This research work was supported by Zayed University Cluster Research
   Award #R18038.
CR Acharya A, 2017, COMP STUDY MACHINE L
   Ahmad S, 2019, HUM-CENTRIC COMPUT I, V9, DOI 10.1186/s13673-019-0185-6
   Ahmed F, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS (ICCE), P265, DOI 10.1109/ICCE.2012.6161859
   Ajao Oluwaseun, 2018, P 9 INT C SOC MED SO, DOI 10.1145/3217804.3217917
   Alayba AM, 2018, LECT NOTES COMPUT SC, V11015, P179, DOI 10.1007/978-3-319-99740-7_12
   Allport G. W., 1947, PSYCHOL RUMOR
   Alzanin SM, 2018, PROCEDIA COMPUT SCI, V142, P294, DOI 10.1016/j.procs.2018.10.495
   Asghar MZ, 2019, COMPUT MATH ORGAN TH, V25, P271, DOI 10.1007/s10588-019-09292-7
   Asghar MZ, 2019, SOFT COMPUT, P1
   Ayutthaya TSN., 2018, 2018 INT JOINT S ART, V2018, P1, DOI DOI 10.1109/ISAI-NLP.2018.8692836
   Barbosa Luciano, 2010, INT C COMP LING, P36
   Ben Veyseh AP, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P2335, DOI 10.1145/3132847.3133116
   Castillo C., 2011, WWW, P675
   Chang K, 2016, I C INF COMM TECH CO, P751, DOI 10.1109/ICTC.2016.7763286
   Chen T, 2017, EXPERT SYST APPL, V72, P221, DOI 10.1016/j.eswa.2016.10.065
   Chen Tong, 2017, ARXIV170405973
   Chen WL, 2018, PATTERN RECOGN LETT, V105, P226, DOI 10.1016/j.patrec.2017.10.014
   Duong CT, 2017, LECT NOTES COMPUT SC, V10538, P125, DOI 10.1007/978-3-319-68155-9_10
   Chiu JPC., 2016, T ASSOC COMPUT LING, V4, P357, DOI [10.1162/tacl_a_00104, DOI 10.1162/TACL_A_00104, 10.3115/1119176.1119204]
   Conroy NJ, 2015, P ASS INF SCI TECHN, V51, P1, DOI [10.1002/pra2.2015.145052010082, DOI 10.1002/PRA2.2015.145052010082]
   Edara D. C., 2019, J AMB INTEL HUM COMP, P1, DOI DOI 10.1007/S12652-019-01399-8
   Gupta A, 2014, LECT NOTES COMPUT SC, V8851, P228, DOI 10.1007/978-3-319-13734-6_16
   Habib A, 2018, 2018 5TH INTERNATIONAL CONFERENCE ON BEHAVIORAL, ECONOMIC, AND SOCIO-CULTURAL COMPUTING (BESC), P233, DOI [10.1109/BESC.2018.00055, 10.1109/BESC.2018.8697323]
   Hamidian S., 2015, P 5 INT C SOC MED TE, P71
   Han H, 2018, IEEE ACCESS, V6, P68302, DOI 10.1109/ACCESS.2018.2879481
   Hosseinimotlagh S, 2018, UNSUPERVISED CONTENT
   Huang CR, 2017, P 8 INT JOINT C NAT, V2, P252
   Huang HF, 2017, BRIT J POLIT SCI, V47, P283, DOI 10.1017/S0007123415000253
   Jaho E, 2014, WWW'14 COMPANION: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P749, DOI 10.1145/2567948.2579324
   Jin ZW, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P795, DOI 10.1145/3123266.3123454
   Jin ZW, 2017, IEEE T MULTIMEDIA, V19, P598, DOI 10.1109/TMM.2016.2617078
   Khan A, 2019, J ROBOT, V2019, DOI 10.1155/2019/2970408
   Kimmey DL, 2015, TWITTER EVENT DETECT
   Kwon S, 2013, IEEE DATA MINING, P1103, DOI 10.1109/ICDM.2013.61
   Lei Zhang, 2018, Data Mining and Big Data. Third International Conference, DMBD 2018. Proceedings: LNCS 10943, P373, DOI 10.1007/978-3-319-93803-5_35
   Li T, 2015, INT C ELECTR MACH SY, P1752, DOI 10.1109/ICEMS.2015.7385324
   Liang G, 2015, IEEE TRANS COMPUT SO, V2, P99, DOI 10.1109/TCSS.2016.2517458
   Liu AN, 2015, P CIKM
   Liu BY, 2019, J ACAD NUTR DIET, V119, P617, DOI 10.1016/j.jand.2018.09.007
   Liu JX, 2019, J APPL GENET, V60, P335, DOI 10.1007/s13353-019-00507-w
   Lopez-Martin M, 2017, IEEE ACCESS, V5, P18042, DOI 10.1109/ACCESS.2017.2747560
   Ma J., 2016, P 25 INT JOINT C ART, P3818
   Ma X., 2016, ARXIV160301354
   Mazzuchelli J, 2012, BMC GENOMICS, V13, DOI 10.1186/1471-2164-13-463
   Nolan AL, 2012, ARSEN ENVIR, P446
   Pham T. T., 2018, STUDY DEEP LEARNING
   Qazvinian V., 2011, P 2011 C EMP METH NA, P1589
   Rani S, 2018, ARAB J SCI ENG, P1
   Rocktaschel T., 2015, ABS150906664 CORR
   Ruchansky N, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P797, DOI 10.1145/3132847.3132877
   Seo E, 2012, PROC SPIE, V8389, DOI 10.1117/12.919823
   Shao C., 2017, ARXIV170707592
   Shen Q., 2017, P 2 INT C INT SCI IC, P164
   Song SR, 2017, PROC CVPR IEEE, P190, DOI 10.1109/CVPR.2017.28
   Tripathy R. M., 2010, P 19 ACM INT C INF K, P1817, DOI DOI 10.1145/1871437.1871737
   Wu K, 2015, IEEE I C EMBED SOFTW, P1518, DOI 10.1109/HPCC-CSS-ICESS.2015.256
   Yang ZF, 2015, 2015 12TH WEB INFORMATION SYSTEM AND APPLICATION CONFERENCE (WISA), P53, DOI 10.1109/WISA.2015.19
   Yu SS, 2017, COMPLEXITY, DOI 10.1155/2017/1703870
   Zeng Y, 2016, LECT NOTES COMPUT SC, V10102, P275, DOI 10.1007/978-3-319-50496-4_23
   Zhang Y., 2017, P 8 WORKSH COMP APPR, P200
   Zhao ZW, 2016, INTERSPEECH, P705, DOI 10.21437/Interspeech.2016-354
   Zhichang Zhang, 2018, Chinese Computational Linguistics and Natural Language Processing Based on Naturally Annotated Big Data. 17th China National Conference, CCL 2018 and 6th International Symposium, NLP-NABD 2018. Proceedings: Lecture Notes in Artificial Intelligence (LNAI 11221), P376, DOI 10.1007/978-3-030-01716-3_31
   Zhou P., 2016, ARXIV161106639
   Zhou X., 2018, ARXIV181200315
   Zhu YH, 2018, FUTURE INTERNET, V10, DOI 10.3390/fi10120116
   Zubiaga A, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3161603
NR 66
TC 15
Z9 15
U1 7
U2 46
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1868-5137
EI 1868-5145
J9 J AMB INTEL HUM COMP
JI J. Ambient Intell. Humaniz. Comput.
PD APR
PY 2021
VL 12
IS 4
BP 4315
EP 4333
DI 10.1007/s12652-019-01527-4
EA OCT 2019
PG 19
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA RZ0MB
UT WOS:000490846100002
DA 2022-02-06
ER

PT J
AU Rosinska, KA
AF Rosinska, Klaudia A.
TI Disinformation in Poland: Thematic Classification Based on Content
   Analysis of Fake News From 2019
SO CYBERPSYCHOLOGY-JOURNAL OF PSYCHOSOCIAL RESEARCH ON CYBERSPACE
LA English
DT Article
DE Content analysis; disinformation; fact-checking; misinformation
AB The paper presents a qualitative study of fake news on Polish-language internet media that seeks to arrive at their thematic classification in order to identify areas particularly vulnerable to disinformation in Poland. Fake news examples from 2019 were selected using popular Polish fact-checking sites (N = 192) and subjected to textual analysis and coding procedure to establish the thematic categories and specific topics most often encountered in this type of disinformation, with the following thematic categories identified in the process: political and economic; social; gossip/rumour; extreme; pseudo-scientific; worldview; historical; and commercial. The study culminates in a critical interpretation of results and discussion of the phenomenon in its Polish and international contexts. Among discussed conclusions is the dominance of content related to the government, Catholic Church, and LGBT issues in the Polish context, as well as the longevity of health-based fake news, especially anti-vaccination content, that points to the global impact of fake news and calls for action to prevent its spread.
C1 [Rosinska, Klaudia A.] Cardinal Stefan Wyszynski Univ, Warsaw, Poland.
C3 Cardinal Stefan Wyszynski University in Warsaw
RP Rosinska, KA (corresponding author), Coll Social & Media Culture CSMC, Media & Comp Sci, Warsaw, Poland.
EM claudia.rosinska@gmail.com
RI Rosinska, Klaudia/ABG-4935-2021
OI Rosinska, Klaudia/0000-0002-0503-9823
FU Institute of Media Education and Journalism at the Cardinal Stefan
   Wyszynski University in Warsaw
FX First and foremost, I want to extend my sincere thanks to Agnieszka
   Polakowska for her translation, conversations and comments that
   significantly improved the manuscript and to Professor Tamara
   Trojanowska for her support of this paper. My gratitude goes to the
   Institute of Media Education and Journalism at the Cardinal Stefan
   Wyszynski University in Warsaw for its financial support of this
   publication. I feel a deep sense of gratitude to Dr. Anna Miotk and Dr.
   Bartlomiej Lodzki for their content analysis and coding procedure and
   the four anonymous reviewers' comments and suggestions. Last but not
   least, I want to thank the editor of this journal, Dr. Lenka Dedkova,
   for her helpful advice.
CR Adali S., 2017, 11 INT AAAI C WEB SO, P759
   Aldwairi M, 2018, PROCEDIA COMPUT SCI, V141, P215, DOI 10.1016/j.procs.2018.10.171
   Allcott H, 2017, J ECON PERSPECT, V31, P211, DOI 10.1257/jep.31.2.211
   Bastos MT, 2019, SOC SCI COMPUT REV, V37, P38, DOI 10.1177/0894439317734157
   Bennett WL, 2018, EUR J COMMUN, V33, P122, DOI 10.1177/0267323118760317
   Ceron W., 2021, ONLINE SOC NETW MED, V21, DOI [10.1016/j.osnem.2020.100116, DOI 10.1016/J.OSNEM.2020.100116]
   Chan MPS, 2017, PSYCHOL SCI, V28, P1531, DOI 10.1177/0956797617714579
   Cinelli M, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-73510-5
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
   Conroy NJ, 2015, P ASS INF SCI TECHN, V51, P1, DOI [10.1002/pra2.2015.145052010082, DOI 10.1002/PRA2.2015.145052010082]
   Davies N., 2014, WYDAWNICTWO ZNAK HOR
   Devitt A, 2007, P 45 ANN M ASS COMP, P984
   Domagala B., 2018, HUMANISTYKA PRZYRODO, V24, P267, DOI [10.31648/hip.2620, DOI 10.31648/HIP.2620]
   Escola-Gascon A, 2021, PSYCHIAT RES, V295, DOI 10.1016/j.psychres.2020.113628
   European Commission, 2018, MULT APPR DIS REP IN
   EUvsDisinfo, 2019, TIND WILL WARN ITS U
   Evelyn K., 2021, THE GUARDIAN 0108
   Garcia-Marin D, 2020, PROF INFORM, V29, DOI 10.3145/epi.2020.jul.11
   Golbeck J, 2018, WEBSCI'18: PROCEEDINGS OF THE 10TH ACM CONFERENCE ON WEB SCIENCE, P17, DOI 10.1145/3201064.3201100
   Golicyn A., 2007, NOWE KLAMSTWA MIEJSC
   Gorwa R., 2017, COMPUTATIONAL PROPAG
   Grinberg N, 2019, SCIENCE, V363, P374, DOI 10.1126/science.aau2706
   Hanska Max., 2017, BREXIT TRUMP MEDIA, P31
   Heine SJ, 2006, PERS SOC PSYCHOL REV, V10, P88, DOI 10.1207/s15327957pspr1002_1
   Henrich J, 2010, BEHAV BRAIN SCI, V33, P61, DOI 10.1017/S0140525X0999152X
   Hsieh HF, 2005, QUAL HEALTH RES, V15, P1277, DOI 10.1177/1049732305276687
   Ireton Ch., 2018, JOURNALISM FAKE NEWS
   Izak K., 2015, PRZEGLAD BEZPIECZENS, V12, P183
   Kai Shu, 2017, ACM SIGKDD Explorations Newsletter, V19, P22, DOI 10.1145/3137597.3137600
   Kaur H., 2020, THE CNN
   Lim C, 2018, RES POLITICS, V5, DOI 10.1177/2053168018786848
   Meyer Robinson., 2018, ATLANTIC
   Mikulska-Jolles A., 2020, FAKE NEWSY DEZINFORM
   Ministerstwo Spraw Wewnetrznych i Administracji, 2020, OSW MIN SPRAW WEWN A
   Narayanan V., 2018, POLARIZATION PARTISA
   Vo N, 2018, ACM/SIGIR PROCEEDINGS 2018, P275, DOI 10.1145/3209978.3210037
   Olteanu A, 2019, FRONT BIG DATA, V2, DOI 10.3389/fdata.2019.00013
   Pennycook G, 2018, J EXP PSYCHOL GEN, V147, P1865, DOI 10.1037/xge0000465
   Pennycook G, 2019, COGNITION, V188, P39, DOI 10.1016/j.cognition.2018.06.011
   Piontek D., 2013, KWARTALNIK NAUKOWY O, V5, P6
   Potthast M, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P231
   Prier Jarred, 2017, STRATEGIC STUDIES Q, V11, P50
   Ratzinger J., 2005, PRAWDA WIARA TOLERAN
   Rose J, 2017, PUBLIC INTEGR, V19, P555, DOI 10.1080/10999922.2017.1285540
   Rubin V.L., 2016, FAKE NEWS TRUTH USIN
   Salaverria R, 2020, PROF INFORM, V29, DOI 10.3145/epi.2020.may.15
   Shahi GK., 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.36190/2020.14
   Silverman Craig, 2016, BUZZFEED NEWS
   Simon Felix, 2020, REUTERS I
   Swierczek M., 2018, PRZEGLAD BEZPIECZENS, V10, P210
   Tambini D., 2017, FAKE NEWS PUBLIC POL
   Tandoc EC, 2021, MEDIA COMMUN-LISBON, V9, P110, DOI 10.17645/mac.v9i1.3331
   Tandoc EC, 2019, SOCIOL COMPASS, V13, DOI 10.1111/soc4.12724
   Vargo CJ, 2018, NEW MEDIA SOC, V20, P2028, DOI 10.1177/1461444817712086
   Wachowicz M. J., 2019, WIEDZA OBRONNA, V1, P226, DOI [10.34752/x40y-nc78, DOI 10.34752/X40Y-NC78]
   Wardle C., 2017, FAKE NEWS ITS COMPLI
   Zhang XC, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.03.004
   Zimdars M., 2016, FALSE MISLEADING CLI
NR 58
TC 0
Z9 0
U1 3
U2 3
PU MASARYKOVA UNIV, FAC SOCIAL STUDIES
PI BRNO
PA JOSTOVA 10, BRNO, 602 00, CZECH REPUBLIC
SN 1802-7962
J9 CYBERPSYCHOLOGY
JI Cyberpsychology
PY 2021
VL 15
IS 4
AR 5
DI 10.5817/CP2021-4-5
PG 21
WC Communication; Psychology, Multidisciplinary
WE Social Science Citation Index (SSCI)
SC Communication; Psychology
GA XB0MY
UT WOS:000721032200001
OA gold
DA 2022-02-06
ER

PT J
AU Shi, C
   Wu, ZY
   Lv, XM
   Ji, Y
AF Shi, Chang
   Wu, Zhenyu
   Lv, Xiaomeng
   Ji, Yang
TI DGTL-Net: A Deep Generative Transfer Learning Network for Fault
   Diagnostics on New Hard Disks
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE AIOps; Industrial applications; Hard disks; Fault diagnostics; Deep
   generative network; Deep transfer network
AB Intelligent fault diagnosis of hard disks becomes significantly important to guarantee reliability of current cloud-based industrial systems. Most intelligent diagnostic methods are commonly based on assumptions that data from different disks are subject to the same distribution and there are sufficient faulty samples for training the models. However, in reality, there are types of hard disks from different manufacturers and their SMART encoding varies widely across manufacturers. It results in distribution discrepancy among disks and influences the generalization of machine learning methods. Moreover, hard disks usually work in healthy state that faulty events rarely happen on most of them, or especially never occur on new ones. Thus, this paper proposes a deep generative transfer learning network (DGTL-Net) for intelligent fault diagnostics on new hard disks. The DGTL-Net combines the deep generative network that generates fake faulty samples and the deep transfer network that solves the problem of distribution discrepancy between hard disks. An iterative end-end training strategy is also proposed for DGTL-Net to get the most optimal parameters of generative and transfer network simultaneously. Experiments have been conducted to prove that our method achieves better performance.
C1 [Shi, Chang; Wu, Zhenyu; Lv, Xiaomeng; Ji, Yang] Beijing Univ Posts & Telecommun, Minist Educ, Engn Res Ctr Informat Network, Beijing 100876, Peoples R China.
C3 Beijing University of Posts & Telecommunications
RP Wu, ZY (corresponding author), Beijing Univ Posts & Telecommun, Minist Educ, Engn Res Ctr Informat Network, Beijing 100876, Peoples R China.
EM shower0512@bupt.edu.cn
OI Wu, Zhenyu/0000-0001-9617-7094
CR [Anonymous], 2020, AIOPS PLATFORMS
   Berndt D. J., 1994, P KDD WORKSH SEATTL, V10, P359
   Botezatu M, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P39, DOI 10.1145/2939672.2939699
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Chigurupati A., 2016, JRELIABILITY MAINTAI
   Ganin Y, 2016, J MACH LEARN RES, V17
   Gretton A, 2012, J MACH LEARN RES, V13, P723
   Guo L, 2019, IEEE T IND ELECTRON, V66, P7316, DOI 10.1109/TIE.2018.2877090
   Li XT, 2019, IEEE T CYBERNETICS, V49, P1680, DOI 10.1109/TCYB.2018.2817480
   Li XX, 2019, INT J PHOTOENERGY, V2019, DOI 10.1155/2019/3725364
   Liu J, 2018, EXPERT SYST APPL, V102, P36, DOI 10.1016/j.eswa.2018.02.017
   Lu WN, 2017, IEEE T IND ELECTRON, V64, P2296, DOI 10.1109/TIE.2016.2627020
   Moon TK, 1996, IEEE SIGNAL PROC MAG, V13, P47, DOI 10.1109/79.543975
   Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281
   Pereira FLF, 2017, 2017 6TH BRAZILIAN CONFERENCE ON INTELLIGENT SYSTEMS (BRACIS), P228, DOI 10.1109/BRACIS.2017.64
   Rauber T. W., 2020, EXPERT SYST APPL, DOI [10.1016/j.eswa.2020.114, DOI 10.1016/J.ESWA.2020.114]
   Schroeder B, 2007, USENIX ASSOCIATION PROCEEDINGS OF THE 5TH USENIX CONFERENCE ON FILE AND STORAGE TECHNOLOGIES ( FAST '07), P1
   Sun X., 2019, P 2019 56 ACM DES, DOI DOI 10.1145/3316781.3317918
   Wang GS, 2017, I C DEPEND SYS NETWO, P25, DOI 10.1109/DSN.2017.26
   Wu J, 2020, EXPERT SYST APPL, V160, DOI 10.1016/j.eswa.2020.113710
   Wu ZG, 2020, IEEE T CYBERNETICS, V50, P1941, DOI 10.1109/TCYB.2018.2885505
   Xiao D., 2019, ARCHIVE P I MECH ENG
   Yang B, 2019, MECH SYST SIGNAL PR, V122, P692, DOI 10.1016/j.ymssp.2018.12.051
   Yang W., 2015, IEEE S REL DISTR SYS
   Zhang W, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17020425
   Zhao ZQ, 2019, IEEE T NEUR NET LEAR, V30, P3212, DOI 10.1109/TNNLS.2018.2876865
NR 26
TC 0
Z9 0
U1 8
U2 10
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD MAY 1
PY 2021
VL 169
AR 114379
DI 10.1016/j.eswa.2020.114379
PG 11
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic; Operations Research & Management Science
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Operations Research & Management Science
GA SV3FJ
UT WOS:000663708000030
DA 2022-02-06
ER

PT J
AU Ocal, A
   Ozbakir, L
AF Ocal, Abdurrahman
   Ozbakir, Lale
TI Supervised deep convolutional generative adversarial networks
SO NEUROCOMPUTING
LA English
DT Article
DE Generative adversarial network; Deep learning; Supervised learning
AB Generative adversarial networks (GANs) are one of the most important generative network models. Using real samples, the GAN generates fake samples from the noise given as input to the network. This popular network model, which has recently emerged and consists of several variants, has different applications in many areas. Some of the studies have been implemented by applying GANs to real-world problems. Another part is aimed at improving the performance of GANs or eliminating the disadvantages observed over time. One of these studies is DCGAN. The importance of DCGAN is that it contributes significantly to balancing GAN training with its convolutional architecture. GAN and naturally DCGAN have an unsupervised network structure. While the network is informed that the samples given as input are real or fake, the category label information is not given to the network. In the present study, a method is proposed, which enables creating a supervised network structure when using multi-categories data set with DCGAN structure. The proposed method ensures that noise can be given a category label and this generated category label information can be used in the output layer. This method, which is easily applicable and effective, is named as Supervised DCGAN (SDCGAN).
   (c) 2021 Elsevier B.V. All rights reserved.
C1 [Ocal, Abdurrahman; Ozbakir, Lale] Erciyes Univ, Ind Engn Dept, Kayseri, Turkey.
C3 Erciyes University
RP Ozbakir, L (corresponding author), Erciyes Univ, Ind Engn Dept, Kayseri, Turkey.
EM lozbakir@erciyes.edu.tr
RI OCAL, Abdurrahman/AAQ-9257-2021
OI OCAL, Abdurrahman/0000-0002-6960-7156
CR Arjovsky M, 2017, ARXIV170107875
   Berthelot D., 2017, ARXIV170310717V4
   Borji A, 2019, COMPUT VIS IMAGE UND, V179, P41, DOI 10.1016/j.cviu.2018.10.009
   Cao YJ, 2019, IEEE ACCESS, V7, P14985, DOI 10.1109/ACCESS.2018.2886814
   Che T., 2017, 5 INT C LEARN REPR I
   Chen X, 2016, ADV NEUR IN, V29
   Creswell A, 2018, IEEE SIGNAL PROC MAG, V35, P53, DOI 10.1109/MSP.2017.2765202
   Dash A., 2017, ARXIV170306412V2
   Denton E. L., 2015, ADV NEURAL INFORM PR, P1486, DOI DOI 10.5555/
   Donahue C., 2018, 6 INT C LEARN REPR I
   Donahue J., 2017, 5 INT C LEARN REPR I
   Ehsani K, 2018, PROC CVPR IEEE, P6144, DOI 10.1109/CVPR.2018.00643
   Faezi MH, 2021, NEUROCOMPUTING, V419, P335, DOI 10.1016/j.neucom.2020.07.089
   Gao B., 2017, ARXIV170400805
   Gao X, 2020, NEUROCOMPUTING, V396, P487, DOI 10.1016/j.neucom.2018.10.109
   Goodfellow I., 2017, ARXIV170100160V4 NIP
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Gulrajani I., 2017, ADV NEURAL INFORM PR, P5769, DOI DOI 10.5555/3295222.3295327
   Heusel M., 2017, ADV NEURAL INFORM PR, P6629
   Hong Y, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3301282
   Ingole K., 2020, J EMERGING TECHNOL I, V7, P269
   Kodali N., 2017, ARXIV PREPRINT ARXIV
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y, 2006, TUTORIAL ENERGY BASE
   Liu SQ, 2019, PHYSICA A, V521, P667, DOI 10.1016/j.physa.2019.01.036
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Lu QW, 2018, NEUROCOMPUTING, V316, P178, DOI 10.1016/j.neucom.2018.07.065
   Lucic M, 2018, ADV NEUR IN, V31
   Luo J, 2021, J INTELL MANUF, V32, P407, DOI 10.1007/s10845-020-01579-w
   Maind S. B., 2014, INT J RECENT INNOVAT, P96, DOI [10.17762/ijritcc.v2i1.2920, DOI 10.17762/IJRITCC.V2I1.2920]
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Mirza M., 2014, ARXIV14111784V1
   Odena A, 2017, PR MACH LEARN RES, V70
   Pan ZQ, 2019, IEEE ACCESS, V7, P36322, DOI 10.1109/ACCESS.2019.2905015
   Radford A., 2016, 4 INT C LEARN REPR I
   Sharma S., 2020, DATA SCI, V4, P310, DOI DOI 10.33564/IJEAST.2020.V04I12.054
   So S, 2019, NANOPHOTONICS-BERLIN, V8, P1255, DOI 10.1515/nanoph-2019-0117
   Spurr A, 2017, LECT NOTES ARTIF INT, V10534, P119, DOI 10.1007/978-3-319-71249-9_8
   Sun JX, 2020, NEURAL NETWORKS, V122, P374, DOI 10.1016/j.neunet.2019.11.003
   Wu ML, 2017, INT CONF RES INNOV
   Xiao H., 2017, P IEEE C COMP VIS PA
   Xu Q., 2018, ARXIV180607755V2
   Zheng YJ, 2018, NEURAL NETWORKS, V102, P78, DOI 10.1016/j.neunet.2018.02.015
NR 44
TC 2
Z9 2
U1 11
U2 21
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0925-2312
EI 1872-8286
J9 NEUROCOMPUTING
JI Neurocomputing
PD AUG 18
PY 2021
VL 449
BP 389
EP 398
DI 10.1016/j.neucom.2021.03.125
PG 10
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA SF5TU
UT WOS:000652818600005
DA 2022-02-06
ER

PT J
AU Horne, CL
AF Horne, Chelsea L.
TI Internet governance in the "post-truth era": Analyzing key topics in
   "fake news" discussions at IGF
SO TELECOMMUNICATIONS POLICY
LA English
DT Article
DE Disinformation; Misinformation; Text mining; Big data; Internet
   governance; Fake news; Internet governance forum (IGF)
AB The governance of information sharing online is a complicated issue, especially in context of varying global perspectives on speech rights, freedom of expression, the role of news media, and core internet values. While discussions of misinformation/disinformation and their like have existed for millennia, 2016 marked a move into what some have called a "post-truth era," where information, both true and not, has become weaponized for political gain. This paper seeks to examine how discussions at the UN Internet Governance Forum unfold by analyzing transcripts of misinformation sessions from 2016 to 2019, asking (1) What key terms are used most often during these discussions? (2) Have and how have these frequent terms evolved over time? Applying the CRISP-DM approach to text mining, I find that overall prominent terms are "internet" and "people," though the frequent terms vary differently when analyzed by year, showing an evolution of the discussion from 2016- "rights" and "journalists"-to 2019- "data" and "content." This study provides insights into the de/refining of the causes, vectors of and remedies to the ongoing information crisis.
C1 [Horne, Chelsea L.] Amer Univ, 4400 Massachusetts Ave NW,237 Battelle Tompkins, Washington, DC 20016 USA.
C3 American University
RP Horne, CL (corresponding author), Amer Univ, 4400 Massachusetts Ave NW,237 Battelle Tompkins, Washington, DC 20016 USA.
EM horne@american.edu
CR Allcott H, 2017, J ECON PERSPECT, V31, P211, DOI 10.1257/jep.31.2.211
   [Anonymous], 2018, FLASH EUROBAROMETER
   Bennett WL, 2018, EUR J COMMUN, V33, P122, DOI 10.1177/0267323118760317
   Bovet A, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-018-07761-2
   Bradshaw S., 2018, GOVT RESPONSES MALIC
   Brummette J, 2018, J MASS COMMUN Q, V95, P497, DOI 10.1177/1077699018769906
   Cogburn D, 2019, P 52 HAW INT C SYST
   Evon D, 2016, SNOPES
   Facebook, 2020, COMM STAND ENF REP
   Farhall K, 2019, POLITICAL ELITES USE, V23
   Fisher Marc., 2016, WASH POST
   Franklin, 2011, MASS MEDIA LAW CASES
   Fung B, 2020, THE CNN
   Gibson A, 2019, SOC MEDIA SOC, V5, DOI 10.1177/2056305119832588
   Gillespie T., 2018, CUSTODIANS INTERNET
   Hanot, 2020, BALANCING ACT COUNTE
   Hindman M., 2018, INFLUENCE CAMPAIGNS
   Internet Governance Forum, 2019, IGF 2019 PART PROGR
   Internet Governance Forum, IGF
   Kang C., 2020, NEW YORK TIMES
   Klonick K, 2018, HARVARD LAW REV, V131, P598
   Mill J. S, 2003, D BROMWICH GEORGE
   Mosseri A., 2018, FACEBOOK NEWSROOM
   Mozur P., 2018, NEW YORK TIMES
   Nahon Karine., 2013, GOING VIRAL
   Newman Nic, 2020, REUTERS I DIGITAL NE
   Oxford word of the year 2016, OXFORD LANGUAGES
   Phillips Kristine., 2018, WASH POST
   Posetti J., 2020, DISINFODEMIC DECIPHE
   Posetti J, 2018, INT CTR JOURNALISTS
   Poynter, GUID ANT ACT WORLD
   Qiu XY, 2019, NAT HUM BEHAV, V3, P102, DOI 10.1038/s41562-018-0507-0
   Roth Y., 2020, TWITTER
   Samuels E., 2020, WASH POST
   SILVERMAN C, 2016, BUZZFEED NEWS 1206
   Strossen N, 2016, J LAW POLICY, V25
   Tandoc EC, 2018, DIGIT JOURNAL, V6, P137, DOI 10.1080/21670811.2017.1360143
   Vaidyanathan S, 2018, ANTISOCIAL MEDIA
   Van Duyn E, 2019, MASS COMMUN SOC, V22, P29, DOI 10.1080/15205436.2018.1511807
   Vosoughi S, 2018, SCIENCE, V359, P1146, DOI 10.1126/science.aap9559
   Wardle Claire, 2017, INFORM DISORDER INTE
   White House T, 2020, EX ORD PREV ONL CENS
   YouGov, 2018, DISC FAK NEWS EC YOU
   Zeid R, 2017, DARKER MORE DANGEROU
   Zuckerberg Mark, 2019, WASH POST
NR 45
TC 0
Z9 0
U1 6
U2 12
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 0308-5961
EI 1879-3258
J9 TELECOMMUN POLICY
JI Telecommun. Policy
PD JUL
PY 2021
VL 45
IS 6
SI SI
AR 102150
DI 10.1016/j.telpol.2021.102150
PG 11
WC Communication; Information Science & Library Science; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Communication; Information Science & Library Science; Telecommunications
GA SK8AQ
UT WOS:000656438100010
DA 2022-02-06
ER

PT J
AU Jukes, S
AF Jukes, Stephen
TI BACK TO THE FUTURE How UK-based news organisations are rediscovering
   objectivity
SO JOURNALISM PRACTICE
LA English
DT Article; Proceedings Paper
CT 6th Biennial Future of Journalism Conference
CY SEP 14-15, 2017
CL Cardiff, WALES
DE journalism; fake news; objectivity; impartiality; social media
ID FAKE NEWS; MEDIA
AB The emergence of "fake news" during the Brexit referendum and Trump election campaign sent news organisations scurrying to establish teams of journalists to debunk deliberately misleading stories and verify facts. This paper examines steps to counter false stories and asks whether normative values of objectivity are about to enjoy a comeback. Typical markers of objectivity (freedom from bias, detachment and fact-based reporting) date back to the nineteenth century and, despite being ingrained in the Anglo-American news culture, have always been subject to challenge. Recently, the growth of partisan and populist media has illustrated deep distrust in traditional news outlets and is questioning whether it is time to jettison objectivity. But are we experiencing a backlash? Through interviews with senior UK-based journalists at legacy news organisations and analysis of editorial policy statements prompted by a UK parliamentary inquiry, the paper explores how fake news is rekindling debate about objectivity and its potential to make quality journalism stand out. It argues that legacy news organisations in the United Kingdom have seized the opportunity to highlight the value of normative practices that draw on familiar components of the objectivity paradigm. But few have the financial strength to bolster the rhetoric with additional editorial resources.
C1 [Jukes, Stephen] Bournemouth Univ, Sch Journalism English & Commun, Fac Media & Commun, Poole, Dorset, England.
C3 Bournemouth University
RP Jukes, S (corresponding author), Bournemouth Univ, Sch Journalism English & Commun, Fac Media & Commun, Poole, Dorset, England.
EM sjukes@bournemouth.ac.uk
OI Jukes, Stephen/0000-0002-4364-4362
CR Adler Stephen, 2017, COVERING TRUMP REUTE
   Allcott H, 2017, J ECON PERSPECT, V31, P211, DOI [DOI 10.1257/jep.31.2.211, DOI 10.1257/JEP.31.2.211]
   Anderson C., 2009, HDB JOURNALISM STUDI, P108
   Bakir Vian, 2017, 3 D, V26, P13
   Boaden Helen, 2016, INDEPENDENT
   Brunt Michael, 2017, CMO             0307
   Brunt Michael, 2016, MEDIUM
   CARLSON M, 2015, BOUNDARIES JOURNALIS
   Collins Damian, 2017, GUARDIAN
   Graves L, 2016, J COMMUN, V66, P102, DOI 10.1111/jcom.12198
   Graves Lucas, 2012, NEW AM
   Greenslade Roy, 2001, GUARDIAN
   Harding James, 2017, GUARDIAN
   Hermida Alfred, 2015, BOUNDARIES JOURNALIS, P37
   Mihailidis P, 2017, AM BEHAV SCI, V61, P441, DOI 10.1177/0002764217701217
   Mindich D.T.Z., 1998, JUST FACTS OBJECTIVI
   Newman N., 2017, REUTERS I DIGITAL NE
   Ofcom, 2017, NEWS CONS UK 2016
   Schudson M., 2001, JOURNALISM, V2, P149, DOI 10.1177/146488490100200201
   Schudson M., 1978, DISCOVERING NEWS SOC
   Schudson Michael, 2002, JOURNALISM SEPTEMBER, P70
   Singer J. B., 2015, BOUNDARIES JOURNALIS, P33
   Snow Jon., 2017, GUARDIAN
   Stencel Mark, 2015, FACT CHECKING JOURNA
   Thompson Mark, 2016, NY TIMES
NR 25
TC 1
Z9 1
U1 4
U2 10
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 1751-2786
EI 1751-2794
J9 JOURNAL PRACT
JI Journal. Pract.
PY 2018
VL 12
IS 8
SI SI
BP 1029
EP 1038
DI 10.1080/17512786.2018.1494512
PG 10
WC Communication
WE Social Science Citation Index (SSCI); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)
SC Communication
GA GT1YY
UT WOS:000444275400010
DA 2022-02-06
ER

PT J
AU Liu, B
   Pun, CM
AF Liu, Bo
   Pun, Chi-Man
TI Exposing splicing forgery in realistic scenes using deep fusion network
SO INFORMATION SCIENCES
LA English
DT Article
DE Forgery detection; Splicing forgery; Deep learning; Deep neural network;
   Fusion; Image forensics; Noise estimation; JPEG Compression
ID IMAGE; LOCALIZATION; FORENSICS
AB Creating fake pictures becomes more accessible than ever, but tampered images are more harmful because the Internet propagates misleading information so rapidly. Reliable digital forensic tools are therefore strongly needed. Traditional methods based on handcrafted features are only useful when tampered images meet specific requirements, and the low detection accuracy prevents them from using in realistic scenes. Recently proposed learning-based methods improve the accuracy, but neural networks usually require to be trained on large labeled databases. This is because commonly used deep and narrow neural networks extract high-level visual features and neglect low-level features where there are abundant forensic cues. To solve the problem, we propose a novel neural network which concentrates on learning low-level forensic features and consequently can detect splicing forgery although the network is trained on a small automatically generated splicing dataset. Furthermore, our fusion network can be easily extended to support new forensic hypotheses without any changes in the network structure. The experimental results show that our method achieves state-of-the-art performance on several benchmark datasets and shows superior generalization capability: our fusion network can work very well even it never sees any pictures in test databases. Therefore, our method can detect splicing forgery in realistic scenes. (C) 2020 Elsevier Inc. All rights reserved.
C1 [Liu, Bo; Pun, Chi-Man] Univ Macau, Dept Comp & Informat Sci, Macau, Peoples R China.
C3 University of Macau
RP Pun, CM (corresponding author), Univ Macau, Dept Comp & Informat Sci, Macau, Peoples R China.
EM cmpun@umac.mo
RI Pun, Chi-Man/C-6567-2013
OI Pun, Chi-Man/0000-0003-1788-3746; Liu, Bo/0000-0002-3164-6299
FU University of Macau [MYRG2018-00035-FST, MYRG2019-00 086FST]; Science
   and Technology Development Fund, Macau SAR [041/2017/A1, 0019/2019/A]
FX This work was partly supported by the University of Macau under Grants:
   MYRG2018-00035-FST and MYRG2019-00 086FST, and the Science and
   Technology Development Fund, Macau SAR (File no. 041/2017/A1,
   0019/2019/A).
CR Amerini I., 2017, P IEEE CVPR WORKSH M
   Amerini I, 2014, IEEE INT WORKS INFOR, P143, DOI 10.1109/WIFS.2014.7084318
   Bianchi T, 2012, IEEE T INF FOREN SEC, V7, P1003, DOI 10.1109/TIFS.2012.2187516
   Bianchi T, 2011, INT CONF ACOUST SPEE, P2444
   Cao G, 2014, IEEE T INF FOREN SEC, V9, P515, DOI 10.1109/TIFS.2014.2300937
   Cozzolino D., 2018, ARXIV180808396
   Cozzolino D, 2014, IEEE IMAGE PROC, P5302, DOI 10.1109/ICIP.2014.7026073
   de Carvalho TJ, 2013, IEEE T INF FOREN SEC, V8, P1182, DOI 10.1109/TIFS.2013.2265677
   Dirik AE, 2009, 2009 16TH IEEE INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOLS 1-6, P1497, DOI 10.1109/ICIP.2009.5414611
   Everingham M., PASCAL VISUAL OBJECT
   Ferrara P, 2012, IEEE T INF FOREN SEC, V7, P1566, DOI 10.1109/TIFS.2012.2202227
   Fontani M, 2013, IEEE T INF FOREN SEC, V8, P593, DOI 10.1109/TIFS.2013.2248727
   Fu HZ, 2012, IEEE T INF FOREN SEC, V7, P1301, DOI 10.1109/TIFS.2012.2195492
   Hsu YF, 2008, CONF REC ASILOMAR C, P1386, DOI 10.1109/ACSSC.2008.5074646
   Huang GL, 2017, IEEE ICC
   Huh M, 2018, P EUR C COMP VIS ECC, P101
   Iakovidou C, 2018, J VIS COMMUN IMAGE R, V54, P155, DOI 10.1016/j.jvcir.2018.05.011
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Korus P., 2016, P IEEE INT WORKSH IN, P1, DOI DOI 10.1109/WIFS.2016.7823898
   Korus P, 2016, IEEE T IMAGE PROCESS, V25, P1312, DOI 10.1109/TIP.2016.2518870
   Krawetz N., 2007, HACKER FACTOR SOLUTI, V6
   Kuo TY, 2016, INFORM SCIENCES, V373, P95, DOI 10.1016/j.ins.2016.08.091
   Li B., 2017, ARXIV171005477
   Li HD, 2017, IEEE T INF FOREN SEC, V12, P1240, DOI 10.1109/TIFS.2017.2656823
   Li WH, 2009, SIGNAL PROCESS, V89, P1821, DOI 10.1016/j.sigpro.2009.03.025
   Lin ZC, 2009, PATTERN RECOGN, V42, P2492, DOI 10.1016/j.patcog.2009.03.019
   Liu B., 2018, P EUR C COMP VIS ECC
   Liu B, 2018, SIGNAL PROCESS-IMAGE, V66, P103, DOI 10.1016/j.image.2018.04.011
   Liu QG, 2011, IEEE T INF FOREN SEC, V6, P1111, DOI 10.1109/TIFS.2011.2139209
   Lyu SW, 2014, INT J COMPUT VISION, V110, P202, DOI 10.1007/s11263-013-0688-y
   Mahdian B, 2009, IMAGE VISION COMPUT, V27, P1497, DOI 10.1016/j.imavis.2009.02.001
   Ng T.-T., 2004, 2032004 ADVENT COL U
   Pun CM, 2018, INFORM SCIENCES, V463, P33, DOI 10.1016/j.ins.2018.06.040
   Salloum R, 2018, J VIS COMMUN IMAGE R, V51, P201, DOI 10.1016/j.jvcir.2018.01.010
   Simonyan K, 2015, ICLR 2015, DOI DOI 10.1109/CVPR.2015.7298594
   Wang BK, 2015, COMPUT INTEL NEUROSC, V2015, DOI 10.1155/2015/525437
   Wang Q, 2016, EURASIP J INF SECUR, DOI 10.1186/s13635-016-0047-y
   Xiao B., 2019, INF SCI
   Ye SM, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P12
   Zampoglou M, 2017, MULTIMED TOOLS APPL, V76, P4801, DOI 10.1007/s11042-016-3795-2
   Zhou Peng, 2018, P IEEE C COMP VIS PA
NR 41
TC 7
Z9 7
U1 2
U2 17
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 0020-0255
EI 1872-6291
J9 INFORM SCIENCES
JI Inf. Sci.
PD JUL
PY 2020
VL 526
BP 133
EP 150
DI 10.1016/j.ins.2020.03.099
PG 18
WC Computer Science, Information Systems
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA LJ3VW
UT WOS:000530096900009
DA 2022-02-06
ER

PT J
AU Dessi, D
   Recupero, DR
   Sack, H
AF Dessi, Danilo
   Recupero, Diego Reforgiato
   Sack, Harald
TI An Assessment of Deep Learning Models and Word Embeddings for Toxicity
   Detection within Online Textual Comments
SO ELECTRONICS
LA English
DT Article
DE deep learning; word embeddings; toxicity detection; binary
   classification
ID SENTIMENT ANALYSIS; CLASSIFICATION
AB Today, increasing numbers of people are interacting online and a lot of textual comments are being produced due to the explosion of online communication. However, a paramount inconvenience within online environments is that comments that are shared within digital platforms can hide hazards, such as fake news, insults, harassment, and, more in general, comments that may hurt someone's feelings. In this scenario, the detection of this kind of toxicity has an important role to moderate online communication. Deep learning technologies have recently delivered impressive performance within Natural Language Processing applications encompassing Sentiment Analysis and emotion detection across numerous datasets. Such models do not need any pre-defined hand-picked features, but they learn sophisticated features from the input datasets by themselves. In such a domain, word embeddings have been widely used as a way of representing words in Sentiment Analysis tasks, proving to be very effective. Therefore, in this paper, we investigated the use of deep learning and word embeddings to detect six different types of toxicity within online comments. In doing so, the most suitable deep learning layers and state-of-the-art word embeddings for identifying toxicity are evaluated. The results suggest that Long-Short Term Memory layers in combination with mimicked word embeddings are a good choice for this task.
C1 [Dessi, Danilo; Sack, Harald] FIZ Karlsruhe Leibniz Inst Informat Infrastruct, Hermann von Helmholtz Pl 1, D-76344 Eggenstein Leopoldshafen, Germany.
   [Dessi, Danilo; Sack, Harald] Karlsruhe Inst Technol, Inst AIFB, Kaiserstr 89, D-76133 Karlsruhe, Germany.
   [Recupero, Diego Reforgiato] Univ Cagliari, Dept Math & Comp Sci, I-09124 Cagliari, Italy.
C3 FIZ Karlsruhe - Leibniz Institut fur Informationsinfrastruktur;
   Helmholtz Association; Karlsruhe Institute of Technology; University of
   Cagliari
RP Dessi, D (corresponding author), FIZ Karlsruhe Leibniz Inst Informat Infrastruct, Hermann von Helmholtz Pl 1, D-76344 Eggenstein Leopoldshafen, Germany.; Dessi, D (corresponding author), Karlsruhe Inst Technol, Inst AIFB, Kaiserstr 89, D-76133 Karlsruhe, Germany.
EM danilo.dessi@fiz-karlsruhe.de; diego.reforgiato@unica.it;
   harald.sack@fiz-karlsruhe.de
OI Dessi, Danilo/0000-0003-3843-3285; Reforgiato Recupero,
   Diego/0000-0001-8646-6183; Sack, Harald/0000-0001-7069-9804
FU NVIDIA Corporation
FX We gratefully acknowledge the support of NVIDIA Corporation with the
   donation of the Titan X GPU used for this research.
CR Atzeni M, 2020, FUTURE GENER COMP SY, V110, P984, DOI 10.1016/j.future.2019.10.012
   Brassard-Gourdeau E, 2019, THIRD WORKSHOP ON ABUSIVE LANGUAGE ONLINE, P1
   Carta S, 2019, KDIR: PROCEEDINGS OF THE 11TH INTERNATIONAL JOINT CONFERENCE ON KNOWLEDGE DISCOVERY, KNOWLEDGE ENGINEERING AND KNOWLEDGE MANAGEMENT - VOL 1: KDIR, P105, DOI 10.5220/0008110901050112
   Cheng KW, 2017, THIRTY-FIRST AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3429
   Dang NC, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9030483
   Dessi Danilo, 2018, Trends and Advances in Information Systems and Technologies. Advances in Intelligent Systems and Computing (746), P1386, DOI 10.1007/978-3-319-77712-2_133
   Dessi D, 2019, SAC '19: PROCEEDINGS OF THE 34TH ACM/SIGAPP SYMPOSIUM ON APPLIED COMPUTING, P2124, DOI 10.1145/3297280.3297620
   Dessi D, 2019, INTEL SYST REF LIBR, V149, P7, DOI 10.1007/978-3-319-94030-4_2
   Dessl D, 2019, COMPUT HUM BEHAV, V92, P468, DOI 10.1016/j.chb.2018.03.004
   Devlin J, 2019, PROC C N AM CHAPTER, P4171, DOI DOI 10.18653/V1/N19-1423
   Dragoni M., 2016, SEM WEB CHALL 3 SEMW, P79
   Dragoni M, 2018, AI COMMUN, V31, P75, DOI 10.3233/AIC-180752
   Dragoni M, 2017, IEEE T AFFECT COMPUT, V8, P457, DOI 10.1109/TAFFC.2017.2717879
   Dridi A, 2019, INT J MACH LEARN CYB, V10, P2045, DOI 10.1007/s13042-017-0727-z
   Dridi A, 2019, INT J MACH LEARN CYB, V10, P2199, DOI 10.1007/s13042-018-0805-x
   Gangemi A, 2014, IEEE COMPUT INTELL M, V9, P20, DOI 10.1109/MCI.2013.2291688
   Georgakopoulos SV, 2018, 10TH HELLENIC CONFERENCE ON ARTIFICIAL INTELLIGENCE (SETN 2018), DOI 10.1145/3200947.3208069
   Goadrich, 2006, P 23 INT C MACH LEAR, P233, DOI DOI 10.1145/1143844.1143874
   Hamdan H., 2015, P 9 INT WORKSH SEM E
   Han X., 2020, P 2020 C EMP METH NA, P7732, DOI [10.18653/v1/2020.emnlp-main.622, DOI 10.18653/V1/2020.EMNLP-MAIN.622]
   Hosseini H., 2017, ARXIV170208138
   Kumar V, 2021, IEEE ACCESS, V9, P7107, DOI 10.1109/ACCESS.2020.3043221
   Lemaitre G, 2017, J MACH LEARN RES, V18
   Lilleberg J, 2015, PROCEEDINGS OF 2015 IEEE 14TH INTERNATIONAL CONFERENCE ON COGNITIVE INFORMATICS & COGNITIVE COMPUTING (ICCI*CC), P136, DOI 10.1109/ICCI-CC.2015.7259377
   Marras, 2020, P 1 WORKSH SMART PER, P33
   MARTENS M, P 14 INT WORKSH NETW, DOI DOI 10.1109/NETGAMES.2015.7382991
   Mikolov T., 2013, P INT C LEARN REPR I, DOI DOI 10.5555/2999792.2999959
   Mikolov T., 2013, ARXIV13013781
   Momtazi S, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P1215
   Morzhov S, 2020, PROC CONF OPEN INNOV, P314, DOI 10.23919/FRUCT48808.2020.9087368
   Pavlopoulos J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P4296
   Peters ME, 2018, P C N AM CHAPT ASS C, DOI DOI 10.18653/V1/N18-1202
   Pinter Yuval, 2017, EMNLP, P102
   Poria S., 2015, P 2015 C EMP METH NA, P2539, DOI DOI 10.18653/V1/D15-1
   Read J, 2011, MACH LEARN, V85, P333, DOI 10.1007/s10994-011-5256-5
   Recupero D.R., P 2 SEMWEBEVAL CHALL, P211, DOI [10.1007/978-3-319-25518-7_18, DOI 10.1007/978-3-319-25518-7_18]
   Recupero D.R., 2017, SEMANTIC WEB CHALLEN, P109, DOI 10.1007/978-3-319-69146-6_10
   Recupero DR, 2014, COMM COM INF SC, V475, P3, DOI 10.1007/978-3-319-12024-9_1
   Recupero DR, 2015, COGN COMPUT, V7, P211, DOI 10.1007/s12559-014-9302-z
   Recupero DR, 2014, LECT NOTES COMPUT SC, V8798, P245, DOI 10.1007/978-3-319-11955-7_28
   Recupero DR, 2019, IEEE COMPUT INTELL M, V14, P77, DOI 10.1109/MCI.2019.2937614
   Reimers N, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P567
   Reyes A, 2012, DATA KNOWL ENG, V74, P1, DOI 10.1016/j.datak.2012.02.005
   Saeed HH, 2018, INT CONF DAT MIN WOR, P1361, DOI 10.1109/ICDMW.2018.00193
   Saif Hassan, 2012, The Semantic Web. 11th International Semantic Web Conference (ISWC 2012). Proceedings, P508, DOI 10.1007/978-3-642-35176-1_32
   Schouten K, 2016, IEEE T KNOWL DATA EN, V28, P813, DOI 10.1109/TKDE.2015.2485209
   Si YQ, 2019, J AM MED INFORM ASSN, V26, P1297, DOI 10.1093/jamia/ocz096
   Srivastava S., 2018, P 1 WORKSH TROLL AGG, P98
   Tang D, 2015, P 2015 C EMP METH NA, P1422, DOI DOI 10.18653/V1/D15-1167
   Tibshirani J., 2010, UNSUPERVISED SENTIME
   Tripathy A, 2016, EXPERT SYST APPL, V57, P117, DOI 10.1016/j.eswa.2016.03.028
   Wright Austin P., 2020, Chinese CHI 2020: The Eighth International Workshop of Chinese CHI, P80, DOI 10.1145/3403676.3403691
   Yin H, 2015, IEEE I C EMBED SOFTW, P1314, DOI 10.1109/HPCC-CSS-ICESS.2015.205
   Zixiu Wu, 2020, ICMI '20 Companion: Companion Publication of the 2020 International Conference on Multimodal Interaction, P497, DOI 10.1145/3395035.3425228
NR 54
TC 2
Z9 2
U1 3
U2 4
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2079-9292
J9 ELECTRONICS-SWITZ
JI Electronics
PD APR
PY 2021
VL 10
IS 7
AR 779
DI 10.3390/electronics10070779
PG 18
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Physics, Applied
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Physics
GA RK5HJ
UT WOS:000638326900001
OA gold, Green Published
DA 2022-02-06
ER

PT J
AU Teymournezhad, K
   Azgomi, H
   Asghari, A
AF Teymournezhad, Kamran
   Azgomi, Hossein
   Asghari, Ali
TI Detection of counterfeit banknotes by security components based on image
   processing and GoogLeNet deep learning network
SO SIGNAL IMAGE AND VIDEO PROCESSING
LA English
DT Article; Early Access
DE Counterfeit banknotes detection; Security component; Image processing;
   Deep learning; GoogLeNet network
ID MATERIALIZED VIEW SELECTION
AB This paper aims to develop a novel method to identify counterfeit banknotes using its security components based on both image processing and GoogLeNet deep learning network. To accomplish this aim, some high-precision security components have been extracted from the banknote images through image processing and machine learning algorithms. In this way, after presenting the trained model to GoogLeNet, the degree of authenticity of each security component is estimated. The proposed method is capable of identifying the security components of the original banknote via 100% accuracy and can report low accuracy for fake and invalid samples. The proposed method is more efficient and practical as compared to similar methods.
C1 [Teymournezhad, Kamran; Asghari, Ali] Shafagh Inst Higher Educ, Dept Comp Engn, Tonekabon, Iran.
   [Azgomi, Hossein] Islamic Azad Univ, Dept Comp Engn, Rasht Branch, Rasht, Iran.
C3 Islamic Azad University
RP Azgomi, H (corresponding author), Islamic Azad Univ, Dept Comp Engn, Rasht Branch, Rasht, Iran.
EM Kamranbhn@shafagh.ac.ir; Azgomi@iaurasht.ac.ir; asghari_ali@aut.ac.ir
OI Asghari, Ali/0000-0001-9508-7433
CR Alshayeji MH., 2015, INT J MULTIMED UBIQU, V10, P225, DOI [10.14257/ijmue.2015.10.11.22, DOI 10.14257/IJMUE.2015.10.11.22]
   Asghari A, 2022, CLUSTER COMPUT, V25, P119, DOI 10.1007/s10586-021-03368-3
   Azgomi H, 2019, APPL INTELL, V49, P3965, DOI 10.1007/s10489-019-01481-w
   Azgomi H, 2018, ENG APPL ARTIF INTEL, V71, P125, DOI 10.1016/j.engappai.2018.02.018
   Baek S, 2018, DIGIT SIGNAL PROCESS, V78, P294, DOI 10.1016/j.dsp.2018.03.015
   Bruna A, 2013, SENSORS-BASEL, V13, P2515, DOI 10.3390/s130202515
   Chakraborty T., 2016, INT J COMPUT ENG RES, V3, P119
   Correia RM, 2018, FORENSIC CHEM, V8, P57, DOI 10.1016/j.forc.2018.02.003
   Gao LG, 2016, IEEE ELECTR DEVICE L, V37, P870, DOI 10.1109/LED.2016.2573140
   Gonzalez RafaelC, 2002, TXB DIGITAL IMAGE PR, VSecond
   Han J, 2012, MOR KAUF D, P1
   Khashman A, 2018, INT C THEOR APPL FUZ
   Kitanovski V, 2018, 2018 14TH INTERNATIONAL CONFERENCE ON SIGNAL IMAGE TECHNOLOGY & INTERNET BASED SYSTEMS (SITIS), P637, DOI 10.1109/SITIS.2018.00103
   Krishna G. N., 2019, INT J INNOVATIVE TEC
   Lamsal S., 2015, P IOE GRAD C PULCH N, V20-22, P160
   Lee S. H., 2018, INT J APPL ENG RES
   Rodrigues ARN, 2019, FORENSIC SCI INT, V302, DOI 10.1016/j.forsciint.2019.06.030
   Scherer D, 2010, LECT NOTES COMPUT SC, V6354, P92, DOI 10.1007/978-3-642-15825-4_10
   Singh M, 2018, INT CONF COMPUT
   Sohrabi MK, 2020, ARCH COMPUT METHOD E, V27, P59, DOI 10.1007/s11831-018-9300-5
   Sohrabi MK, 2019, INT J UNCERTAIN FUZZ, V27, P73, DOI 10.1142/S0218488519500041
   Sohrabi MK, 2019, KNOWL-BASED SYST, V163, P558, DOI 10.1016/j.knosys.2018.09.012
   Sohrabi MK, 2017, TURK J ELECTR ENG CO, V25, P3175, DOI 10.3906/elk-1608-112
   Sohrabi MK, 2017, SCI COMPUT PROGRAM, V145, P1, DOI 10.1016/j.scico.2017.04.006
   Sufri NAJ, 2019, 2019 IEEE 10TH CONTROL AND SYSTEM GRADUATE RESEARCH COLLOQUIUM (ICSGRC), P5, DOI 10.1109/ICSGRC.2019.8837068
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Trinh H.-C, 2020, AS C INT INF DAT SYS
   Yadav R, 2020, MACHINE LEARNING PRE, P173
NR 28
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1863-1703
EI 1863-1711
J9 SIGNAL IMAGE VIDEO P
JI Signal Image Video Process.
DI 10.1007/s11760-021-02104-z
EA JAN 2022
PG 9
WC Engineering, Electrical & Electronic; Imaging Science & Photographic
   Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Imaging Science & Photographic Technology
GA YF2BQ
UT WOS:000741619100001
DA 2022-02-06
ER

PT J
AU Revi, KR
   Wilscy, M
AF Revi, K. Remya
   Wilscy, M.
TI Image forgery detection using deep textural features from local binary
   pattern map
SO JOURNAL OF INTELLIGENT & FUZZY SYSTEMS
LA English
DT Article; Proceedings Paper
CT 5th International Symposium on Intelligent Systems Technologies and
   Applications (ISTA) / International Conference on Applied Soft Computing
   and Communication Networks (ACN)
CY DEC 18-21, 2019
CL Trivandrum, INDIA
DE Deep learning; rotation invariant-local binary pattern; pretrained
   convolutional neural etworks; deep textual features; image forgery
   detection
ID AUTHENTICATION; CLASSIFICATION
AB Nowadays the manipulations of digital images are common due to easy access of many online photo editing applications and image editing softwares. Forged images are widely used in social media for creating deceitful propaganda of an individual or a particular event and for cooking up fake evidences even in court proceedings. Hence ensuring the integrity of digital images is of prime significance and it has become a hot research area. In this paper, a novel technique for image forgery detection is proposed. The method utilizes the layer activation of inception-ResNet-v2, a pretrained Convolutional Neural Network(CNN)to extract the deep textural features from Rotation Invariant - Local Binary Pattern (RI-LBP) map of the chrominance image. Non-negative Matrix Factorization (NMF) technique is used to reduce the dimensionality of the extracted features. The dimensionality reduced features are used to train a quadratic Support Vector Machine(SVM) classifier to classify images into forged or authentic. The method is assessed on four benchmark datasets (CASIA ITDE v1.0, CASIA ITDE v2.0, CUISDE and IFS-TC). Extensive experimental analysis is done and the results show an improved detection accuracy compared to the state-of-the-art methods.
C1 [Revi, K. Remya; Wilscy, M.] APJ Abdul Kalam Technol Univ, Dept Comp Sci & Engn, SAINTGITS Coll Engn, Thiruvananthapuram, Kerala, India.
C3 Saintgits College of Engineering
RP Revi, KR (corresponding author), APJ Abdul Kalam Technol Univ, Dept Comp Sci & Engn, SAINTGITS Coll Engn, Thiruvananthapuram, Kerala, India.
EM remya.revircs16@saintgits.org
CR Al-Hammadi MH, 2013, LECT NOTES COMPUT SC, V8034, P503, DOI 10.1007/978-3-642-41939-3_49
   Alahmadi A, 2017, SIGNAL IMAGE VIDEO P, V11, P81, DOI 10.1007/s11760-016-0899-0
   Alahmadi AA, 2013, IEEE GLOB CONF SIG, P253, DOI 10.1109/GlobalSIP.2013.6736863
   Breiman L., 1984, BIOMETRICS, V1st ed.
   Canziani A., 2017, ARXIV160507678V4
   Cimpoi M, 2016, INT J COMPUT VISION, V118, P65, DOI 10.1007/s11263-015-0872-3
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   Hsu C.-W., 2016, PRACTICAL GUIDE SUPP
   Hsu YF, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P549, DOI 10.1109/ICME.2006.262447
   Hussain M, 2015, INT J ARTIF INTELL T, V24, DOI 10.1142/S0218213015400163
   Isaac MM, 2018, J INTELL FUZZY SYST, V34, P1679, DOI 10.3233/JIFS-169461
   Isaac MM, 2017, MULTIMED TOOLS APPL, V76, P25851, DOI 10.1007/s11042-017-5189-5
   Jing Dong, 2013, 2013 IEEE China Summit and International Conference on Signal and Information Processing (ChinaSIP), P422, DOI 10.1109/ChinaSIP.2013.6625374
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee DD, 2001, ADV NEUR IN, V13, P556
   Levi G, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P503, DOI 10.1145/2823327.2823333
   Lu CS, 2003, IEEE T MULTIMEDIA, V5, P161, DOI 10.1109/TMM.2003.811621
   Lu CS, 2001, IEEE T IMAGE PROCESS, V10, P1579, DOI 10.1109/83.951542
   Muhammad G, 2014, MACH VISION APPL, V25, P985, DOI 10.1007/s00138-013-0547-4
   Nanni L, 2017, PATTERN RECOGN, V71, P158, DOI 10.1016/j.patcog.2017.05.025
   Ng TT, 2004, IEEE IMAGE PROC, P1169
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Rao Y., 2016, P IEEE INT WORKSH IN, P1, DOI [10.1109/WIFS.2016.7823911, DOI 10.1109/WIFS.2016.7823911]
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Rota P, 2016, INT C PATT RECOG, P2503, DOI 10.1109/ICPR.2016.7900012
   Shah H., 2013, IJEIR, V2, P487
   Shi ZN, 2018, IEEE ACCESS, V6, P76437, DOI 10.1109/ACCESS.2018.2883588
   Sutthiwan P, 2011, LECT NOTES COMPUT SC, V6730, P1, DOI 10.1007/978-3-642-24556-5_1
   Szegedy C, 2017, THIRTY-FIRST AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4278
   Vidyadharan DS, 2017, J INTELL FUZZY SYST, V32, P3177, DOI 10.3233/JIFS-169261
   Yosinski J, 2014, ADV NEUR IN, V27
   Zhao XD, 2011, LECT NOTES COMPUT SC, V6526, P12, DOI 10.1007/978-3-642-18405-5_2
   Zhou JH, 2017, LECT NOTES COMPUT SC, V10431, P65, DOI 10.1007/978-3-319-64185-0_6
NR 35
TC 1
Z9 1
U1 0
U2 3
PU IOS PRESS
PI AMSTERDAM
PA NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS
SN 1064-1246
EI 1875-8967
J9 J INTELL FUZZY SYST
JI J. Intell. Fuzzy Syst.
PY 2020
VL 38
IS 5
BP 6391
EP 6401
DI 10.3233/JIFS-179720
PG 11
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA MA1WL
UT WOS:000541708200097
DA 2022-02-06
ER

PT J
AU Dasilva, JP
   Ayerdi, KM
   Galdospin, TM
AF Perez Dasilva, Jesus
   Meso Ayerdi, Koldobika
   Mendiguren Galdospin, Terese
TI Deepfakes on Twitter: Which Actors Control Their Spread?
SO MEDIA AND COMMUNICATION
LA English
DT Article
DE cybersecurity; deepfake; fake news; NodeXL; social media; Social Network
   Analysis; Twitter
ID SOCIAL NETWORK ANALYSIS; FAKE NEWS; INFORMATION; HASHTAG
AB The term deepfake was first used in a Reddit post in 2017 to refer to videos manipulated using artificial intelligence techniques and since then it is becoming easier to create such fake videos. A recent investigation by the cybersecurity company Deeptrace in September 2019 indicated that the number of what is known as fake videos had doubled in the last nine months and that most were pornographic videos used as revenge to harm many women. The report also highlighted the potential of this technology to be used in political campaigns such as in Gabon and Malaysia. In this sense, the phenomenon of deepfake has become a concern for governments because it poses a short-term threat not only to politics, but also for fraud or cyberbullying. The starting point of this research was Twitter's announcement of a change in its protocols to fight fake news and deepfakes. We have used the Social Network Analysis technique, with visualization as a key component, to analyze the conversation on Twitter about the deepfake phenomenon. NodeXL was used to identify main actors and the network of connections between all these accounts. In addition, the semantic networks of the tweets were analyzed to discover hidden patterns of meaning. The results show that half of the actors who function as bridges in the interactions that shape the network are journalists and media, which is a sign of the concern that this sophisticated form of manipulation generates in this collective.
C1 [Perez Dasilva, Jesus; Meso Ayerdi, Koldobika; Mendiguren Galdospin, Terese] Univ Basque Country, Dept Journalism 2, Leioa 48940, Spain.
C3 University of Basque Country
RP Dasilva, JP (corresponding author), Univ Basque Country, Dept Journalism 2, Leioa 48940, Spain.
EM jesusangel.perez@ehu.eus; koldo.meso@ehu.eus; terese.mendiguren@ehu.eus
RI Perez Dasilva, Jesus Angel/H-1961-2015
OI Perez Dasilva, Jesus Angel/0000-0002-3383-4859
FU Spanish Ministry of Science, Innovation and Universities ("News,
   Networks and Users in the Hybrid Media System: Shared Creation and
   Dissemination of News in Online Media") [RTI2018-095775-B-C41]; Basque
   GovernmentBasque Government [IT1112-16]
FX The authors would like to thank the three anonymous reviewers as well as
   the Academic Editors for their valuable feedback on the manuscript. This
   research was supported by the Spanish Ministry of Science, Innovation
   and Universities ("News, Networks and Users in the Hybrid Media System:
   Shared Creation and Dissemination of News in Online Media,"
   RTI2018-095775-B-C41). It was carried out within the Consolidated
   Research Group 'Gureiker' (A) (IT1112-16), funded by the Basque
   Government.
CR Aguilar-Gallegos N, 2016, ESTUD GERENC, V32, P197, DOI 10.1016/j.estger.2016.06.006
   Ahmed W, 2019, ONLINE INFORM REV, V43, P149, DOI 10.1108/OIR-03-2018-0093
   Alba Davey, 2020, NEW YORK TIMES
   Atkin M., 2019, MEDIUM
   Bennett WL, 2018, EUR J COMMUN, V33, P122, DOI 10.1177/0267323118760317
   Benson P., 2016, DISCOURSE YOUTUBE MU, DOI [10.4324/9781315646473, DOI 10.4324/9781315646473]
   Borgatti SP, 2009, SCIENCE, V323, P892, DOI 10.1126/science.1165821
   Boyd MS, 2014, J PRAGMATICS, V72, P46, DOI 10.1016/j.pragma.2014.03.002
   Brubaker PJ, 2018, PUBLIC RELAT REV, V44, P342, DOI 10.1016/j.pubrev.2018.04.010
   Brucato B, 2015, SURVEILL SOC, V13, P455
   Chadwick A, 2018, NEW MEDIA SOC, V20, P4255, DOI 10.1177/1461444818769689
   Chesney R., 2019, FOREIGN AFFAIRS
   Clauset A, 2004, PHYS REV E, V70, DOI 10.1103/PhysRevE.70.066111
   Dossis M., 2015, P ARSA ADV RES SCI A, P242
   Evans M, 2016, MEDIA WAR CONFL, V9, P325, DOI 10.1177/1750635216643113
   Fagan K., 2018, BUSINESS INSIDER
   Fernandez D., 2019, DATAHACK
   Fletcher J, 2018, THEATRE J, V70, P455, DOI 10.1353/tj.2018.0097
   Freeman L., 2004, DEV SOCIAL NETWORK A
   Gibbs W. J., 2015, CONT RES METHODS DAT
   Guera D, 2018, 2018 15TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P127
   Hanitzsch T, 2018, INT J PRESS/POLIT, V23, P3, DOI 10.1177/1940161217740695
   Hansen DL, 2011, ANALYZING SOCIAL MEDIA NETWORKS WITH NODEXL: INSIGHTS FROM A CONNECTED WORLD, P1
   Harel D., 2000, P WORKING C ADV VISU, P282, DOI [10.1145/345513.345353, DOI 10.1145/345513.345353]
   Hasan HR, 2019, IEEE ACCESS, V7, P41596, DOI 10.1109/ACCESS.2019.2905689
   Kaleel SB, 2015, J COMPUT SCI-NETH, V6, P47, DOI 10.1016/j.jocs.2014.11.004
   Kietzmann J, 2020, BUS HORIZONS, V63, P135, DOI 10.1016/j.bushor.2019.11.006
   Korshunov P, 2018, EUR SIGNAL PR CONF, P2375, DOI 10.23919/EUSIPCO.2018.8553270
   Li Y., 2018, ARXIV
   Li Y., 2018, ARXIV
   Maddocks Sophie, 2020, PORN STUDIES, V0, P1, DOI DOI 10.1080/23268743.2020.1757499
   Mehta I., 2020, THE NEXT WEB
   Newman EJ, 2015, J EXP PSYCHOL LEARN, V41, P1337, DOI 10.1037/xlm0000099
   Nielsen, 2018, REUTERS I DIGITAL NE
   Otte E, 2002, J INF SCI, V28, P441, DOI 10.1177/016555102762202123
   Pandhi G., 2020, REPORT
   Paolillo J. C., 2008, P 41 HAW INT C SYST, P156, DOI 10.1109/HICSS.2008.415
   Patrini G., 2019, DEEPTRACE
   Pennycook G, 2018, J EXP PSYCHOL GEN, V147, P1865, DOI 10.1037/xge0000465
   Perez-Dasilva JA, 2020, PROF INFORM, V29, DOI 10.3145/epi.2020.may.08
   Rense S., 2018, ESQUIRE
   Ricaurte P., 2015, REV VIRTUALIS, V6, P165
   Riechmann D., 2018, WCJB
   Robertson A., 2020, VERGE
   Robertson A., 2018, VERGE
   Rojecki A, 2016, NEW MEDIA SOC, V18, P25, DOI 10.1177/1461444814535724
   Rutenberg J., 2017, NY TIMES
   Seo S, 2019, WIRELESS PERS COMMUN, V107, P1355, DOI 10.1007/s11277-018-5745-y
   Smith M., 2010, NODEXL FREE OPEN NET
   Solomon S, 2007, AR4 CLIMATE CHANGE 2007: THE PHYSICAL SCIENCE BASIS, P1
   Sora Carles, 2018, HIPERTEXT NET, V17, P1, DOI DOI 10.HTTPS://D0I.0RG/10.31009/HIPERTEXT.NET.2018.I17.01
   Stover D, 2018, B ATOM SCI, V74, P283, DOI 10.1080/00963402.2018.1486618
   Tolson Andrew., 2010, CRIT DISCOURSE STUD, V7, P277, DOI [10.1080/17405904.2010.511834, DOI 10.1080/17405904.2010.511834]
   Vaccari C, 2020, SOC MEDIA SOC, V6, DOI 10.1177/2056305120903408
   Verweij P, 2012, JOURNAL PRACT, V6, P680, DOI 10.1080/17512786.2012.667272
   Vincent J., 2019, VERGE
   Waisbord S, 2018, JOURNALISM STUD, V19, P1866, DOI 10.1080/1461670X.2018.1492881
   Westerlund M, 2019, TECHNOL INNOV MANAG, V9, P39, DOI 10.22215/timreview/1282
   Wolfe AW, 1997, AM ETHNOL, V24, P219, DOI 10.1525/ae.1997.24.1.219
   Wukich C, 2013, RISK HAZARDS CRISIS, V4, P83, DOI 10.1002/rhc3.12036
   Yadlin-Segal A, 2021, CONVERGENCE-US, V27, P36, DOI 10.1177/1354856520923963
NR 61
TC 1
Z9 1
U1 13
U2 18
PU COGITATIO PRESS
PI LISBON
PA RUA FIALHO ALMEIDA 14, 2 ESQ, LISBON, 1070-129, PORTUGAL
SN 2183-2439
J9 MEDIA COMMUN-LISBON
JI Media Commun.
PY 2021
VL 9
IS 1
BP 301
EP 312
DI 10.17645/mac.v9i1.3433
PG 12
WC Communication
WE Social Science Citation Index (SSCI)
SC Communication
GA QR8IM
UT WOS:000625456900008
OA Green Published, gold
DA 2022-02-06
ER

PT J
AU Li, X
   Zhang, W
   Ding, Q
AF Li, Xiang
   Zhang, Wei
   Ding, Qian
TI Cross-Domain Fault Diagnosis of Rolling Element Bearings Using Deep
   Generative Neural Networks
SO IEEE TRANSACTIONS ON INDUSTRIAL ELECTRONICS
LA English
DT Article
DE Deep learning; domain adaptation (DA); fault diagnosis; generative model
ID EMPIRICAL MODE DECOMPOSITION; FEATURES
AB Despite the recent advances on intelligent fault diagnosis of rolling element bearings, existing research works mostly assume training and testing data are drawn from the same distribution. However, due to variation of operating condition, domain shift phenomenon generally exists, which results in significant diagnosis performance deterioration. To address cross-domain problems, latest research works preferably apply domain adaptation techniques on marginal data distributions. However, it is usually assumed that sufficient testing data are available for training, that is not in accordance with most transfer tasks in real industries where only data inmachine healthy condition can be collected in advance. This paper proposes a novel cross-domain fault diagnosis method based on deep generative neural networks. By artificially generating fake samples for domain adaptation, the proposed method is able to provide reliable cross-domain diagnosis results when testing data in machine fault conditions are not available for training. The experimental results suggest that the proposed method offers a promising approach for industrial applications.
C1 [Li, Xiang] Northeastern Univ, Coll Sci, Shenyang 110819, Liaoning, Peoples R China.
   [Li, Xiang] Northeastern Univ, Key Lab Vibrat & Control Aeroprop Syst, Minist Educ, Shenyang 110819, Liaoning, Peoples R China.
   [Zhang, Wei] Shenyang Aerosp Univ, Sch Aerosp Engn, Shenyang 110136, Liaoning, Peoples R China.
   [Ding, Qian] Tianjin Univ, Dept Mech, Tianjin 300072, Peoples R China.
C3 Northeastern University - China; Northeastern University - China;
   Shenyang Aerospace University; Tianjin University
RP Li, X (corresponding author), Northeastern Univ, Coll Sci, Shenyang 110819, Liaoning, Peoples R China.; Li, X (corresponding author), Northeastern Univ, Key Lab Vibrat & Control Aeroprop Syst, Minist Educ, Shenyang 110819, Liaoning, Peoples R China.
EM xiangli@mail.neu.edu.cn; zw_7126257@163.com; qding@tju.edu.cn
RI Li, Xiang/W-6389-2019
OI Li, Xiang/0000-0003-0569-2176
FU Fundamental Research Funds for the Central UniversitiesFundamental
   Research Funds for the Central Universities [N170503012, N170308028]
FX This work was supported by the Fundamental Research Funds for the
   Central Universities under Grant N170503012 and Grant N170308028.
CR Abdeljaber O, 2017, J SOUND VIB, V388, P154, DOI 10.1016/j.jsv.2016.10.043
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Chen XF, 2018, FRONT MECH ENG-PRC, V13, P264, DOI 10.1007/s11465-018-0472-3
   Csurka G., 2017, ARXIV170205374
   Ding SX, 2014, ADV IND CONTROL, P175, DOI 10.1007/978-1-4471-6410-4_10
   Du WL, 2014, MECH SYST SIGNAL PR, V43, P57, DOI 10.1016/j.ymssp.2013.09.003
   Fergus R, 2015, P C NEUR INF PROC SY
   Ghahramani Zoubin, 2015, ARXIV150503906
   Glorot X., 2010, P 13 INT C ART INT S, P249
   Gong B., 2013, P INT C MACH LEARN, P222
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Gretton  A., 2012, PTIMAL KERNEL CHOICE
   Gretton A, 2012, J MACH LEARN RES, V13, P723
   Hinton G., 2015, ARXIVABS150302531
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Jegadeeshwaran R, 2015, MECH SYST SIGNAL PR, V52-53, P436, DOI 10.1016/j.ymssp.2014.08.007
   Jin XH, 2014, IEEE T IND ELECTRON, V61, P2441, DOI 10.1109/TIE.2013.2273471
   Kingma D. P, 2015, ARXIV14126980
   Krizhevsky A., 2012, ADV NEURAL INF PROCE, P1097, DOI DOI 10.1145/3065386
   Lee YO, 2017, IEEE INT CONF BIG DA, P3248, DOI 10.1109/BigData.2017.8258307
   Lei YG, 2016, IEEE T IND ELECTRON, V63, P3137, DOI 10.1109/TIE.2016.2519325
   Li WH, 2013, IEEE T INSTRUM MEAS, V62, P869, DOI 10.1109/TIM.2013.2245180
   Li X, 2018, NEUROCOMPUTING, V310, P77, DOI 10.1016/j.neucom.2018.05.021
   Li X, 2018, RELIAB ENG SYST SAFE, V172, P1, DOI 10.1016/j.ress.2017.11.021
   Long M., 2015, INT C MACH LEARN PML, P97
   Lu WN, 2017, IEEE T IND ELECTRON, V64, P2296, DOI 10.1109/TIE.2016.2627020
   Muruganatham B, 2013, MECH SYST SIGNAL PR, V35, P150, DOI 10.1016/j.ymssp.2012.08.019
   Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281
   Radford A., 2015, ARXIV151106434
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Salakhutdinov R, 2015, ANNU REV STAT APPL, V2, P361, DOI 10.1146/annurev-statistics-010814-020120
   Shen F, 2015, PROGNOST SYST HEALT
   Smith WA, 2015, MECH SYST SIGNAL PR, V64-65, P100, DOI 10.1016/j.ymssp.2015.04.021
   Sun WJ, 2017, IEEE T IND INFORM, V13, P1350, DOI 10.1109/TII.2017.2672988
   Sun WJ, 2016, MEASUREMENT, V89, P171, DOI 10.1016/j.measurement.2016.04.007
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Tran VT, 2013, MECH SYST SIGNAL PR, V38, P601, DOI 10.1016/j.ymssp.2013.02.001
   van Wyk BJ, 2009, PATTERN RECOGN LETT, V30, P595, DOI 10.1016/j.patrec.2008.12.012
   Wang X., 2014, ADV NEURAL INFORM PR, P1898
   Xie J., 2016, P IEEE INT C PROGN H IEEE INT C PROGN HLT, P1, DOI DOI 10.1109/ICPHM.2016.7542845
   Yosinski J, 2014, ADV NEUR IN, V27
   Zhang W, 2018, MECH SYST SIGNAL PR, V100, P439, DOI 10.1016/j.ymssp.2017.06.022
   Zhang W, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17020425
   Zhang XL, 2015, NEUROCOMPUTING, V167, P260, DOI 10.1016/j.neucom.2015.04.069
   Zhang XY, 2015, MEASUREMENT, V69, P164, DOI 10.1016/j.measurement.2015.03.017
NR 45
TC 143
Z9 148
U1 40
U2 337
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0278-0046
EI 1557-9948
J9 IEEE T IND ELECTRON
JI IEEE Trans. Ind. Electron.
PD JUL
PY 2019
VL 66
IS 7
BP 5525
EP 5534
DI 10.1109/TIE.2018.2868023
PG 10
WC Automation & Control Systems; Engineering, Electrical & Electronic;
   Instruments & Instrumentation
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Automation & Control Systems; Engineering; Instruments & Instrumentation
GA HO1KD
UT WOS:000460663300053
DA 2022-02-06
ER

PT J
AU Mayer, O
   Stamm, MC
AF Mayer, Owen
   Stamm, Matthew C.
TI Exposing Fake Images With Forensic Similarity Graphs
SO IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING
LA English
DT Article
DE Forensics; Forgery; Image edge detection; Deep learning; Feature
   extraction; Transform coding; Image coding; Multimedia forensics;
   forgery detection; deep learning; community detection
ID DIGITAL FORGERIES; NETWORKS; LOCALIZATION
AB In this paper, we propose new image forgery detection and localization algorithms by recasting these problems as graph-based community detection problems. To do this, we introduce a novel graph-based representation of an image, which we call the Forensic Similarity Graph, that captures key forensic relationships among regions in the image. In this representation, small image patches are represented by graph vertices with edges assigned according to the forensic similarity between patches. Localized tampering introduces unique structure into this graph, which aligns with a concept called "community structure" in graph-theory literature. In the Forensic Similarity Graph, communities correspond to the tampered and unaltered regions in the image. As a result, forgery detection is performed by identifying whether multiple communities exist, and forgery localization is performed by partitioning these communities. We present two community detection techniques, adapted from literature, to detect and localize image forgeries. We experimentally show that our proposed community detection methods outperform existing state-of-the-art forgery detection and localization methods, which do not capture such community structure.
C1 [Mayer, Owen; Stamm, Matthew C.] Drexel Univ, Dept Elect & Comp Engn, Philadelphia, PA 19104 USA.
C3 Drexel University
RP Mayer, O (corresponding author), Drexel Univ, Dept Elect & Comp Engn, Philadelphia, PA 19104 USA.
EM om82@drexel.edu; mcs382@drexel.edu
FU National Science FoundationNational Science Foundation (NSF) [1553610]
FX This work was supported by the National Science Foundation under Grant
   1553610. Any opinions, findings and conclusions or recommendations
   expressed in this material are those of the authors and do not
   necessarily reflect those of the National Science Foundation.
CR Amerini I, 2017, IEEE COMPUT SOC CONF, P1865, DOI 10.1109/CVPRW.2017.233
   Bappy JH, 2019, IEEE T IMAGE PROCESS, V28, P3286, DOI 10.1109/TIP.2019.2895466
   Barni M, 2017, J VIS COMMUN IMAGE R, V49, P153, DOI 10.1016/j.jvcir.2017.09.003
   Bayar B, 2018, IEEE T INF FOREN SEC, V13, P2691, DOI 10.1109/TIFS.2018.2825953
   Bianchi T, 2012, IEEE T INF FOREN SEC, V7, P1003, DOI 10.1109/TIFS.2012.2187516
   Blondel VD, 2008, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2008/10/P10008
   Bondi L, 2017, IEEE COMPUT SOC CONF, P1855, DOI 10.1109/CVPRW.2017.232
   Chen M, 2007, LECT NOTES COMPUT SC, V4567, P342
   Chung F. R. K., 1997, CBMS REGIONAL C SERI, V92, P6
   Clauset A, 2004, PHYS REV E, V70, DOI 10.1103/PhysRevE.70.066111
   Cozza D., 2015, 2015 IEEE 42nd Photovoltaic Specialist Conference (PVSC). Proceedings, P1, DOI 10.1109/PVSC.2015.7355795
   Cozzolino D., 2016, P 2016 IEEE INT WORK, P1, DOI [10.1109/WIFS.2016.7823921, 10.1109/WIFS.2016.7823921., DOI 10.1109/WIFS.2016.7823921]
   Cozzolino D, 2020, IEEE T INF FOREN SEC, V15, P144, DOI 10.1109/TIFS.2019.2916364
   Cozzolino D, 2018, EUR SIGNAL PR CONF, P1372, DOI 10.23919/EUSIPCO.2018.8553581
   Csardi G, 2006, INT J COMPLEX SYST, V1695
   de Carvalho TJ, 2013, IEEE T INF FOREN SEC, V8, P1182, DOI 10.1109/TIFS.2013.2265677
   Diestel R., 2005, GRADUATE TEXTS MATH
   Farid H., 2005, P ACM MULT SEC WORKS, P1, DOI DOI 10.1145/1073170.1073171
   Farid H, 2009, IEEE T INF FOREN SEC, V4, P154, DOI 10.1109/TIFS.2008.2012215
   FIEDLER M, 1973, CZECH MATH J, V23, P298
   Fortunato S, 2007, P NATL ACAD SCI USA, V104, P36, DOI 10.1073/pnas.0605965104
   Fortunato S, 2010, PHYS REP, V486, P75, DOI 10.1016/j.physrep.2009.11.002
   Girvan M, 2002, P NATL ACAD SCI USA, V99, P7821, DOI 10.1073/pnas.122653799
   Hosseini MDM, 2019, IEEE SIGNAL PROC LET, V26, P976, DOI 10.1109/LSP.2019.2913530
   Hsu Y.-F., 2006, P IEEE INT C MULT EX, P49
   Huh M, 2018, LECT NOTES COMPUT SC, V11215, P106, DOI 10.1007/978-3-030-01252-6_7
   Johnson MK, 2006, P 8 WORKSH MULT SEC, P48
   KAMADA T, 1989, INFORM PROCESS LETT, V31, P7, DOI 10.1016/0020-0190(89)90102-6
   Korus P, 2017, IEEE T INF FOREN SEC, V12, P809, DOI 10.1109/TIFS.2016.2636089
   Li HD, 2019, IEEE I CONF COMP VIS, P8300, DOI 10.1109/ICCV.2019.00839
   Lukas J, 2006, PROC SPIE, V6072, DOI 10.1117/12.640109
   Matern F, 2020, IEEE T INF FOREN SEC, V15, P1303, DOI 10.1109/TIFS.2019.2935913
   Mayer O, 2020, IEEE T INF FOREN SEC, V15, P1331, DOI 10.1109/TIFS.2019.2924552
   Mayer O, 2018, PROCEEDINGS OF THE 6TH ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY (IH&MMSEC'18), P79, DOI 10.1145/3206004.3206022
   Mayer O, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2012, DOI 10.1109/ICASSP.2018.8462585
   Mayer O, 2018, IEEE T INF FOREN SEC, V13, P1762, DOI 10.1109/TIFS.2018.2799421
   NEWMAN MEJ, 2004, PHYS REV E 2, V69, DOI DOI 10.1103/PHYSREVE.69.026113
   Oikawa MA, 2016, IEEE T INF FOREN SEC, V11, P5, DOI 10.1109/TIFS.2015.2442527
   Pons P, 2005, LECT NOTES COMPUT SC, V3733, P284
   Popescu AC, 2005, IEEE T SIGNAL PROCES, V53, P758, DOI 10.1109/TSP.2004.839932
   Raghavan UN, 2007, PHYS REV E, V76, DOI 10.1103/PhysRevE.76.036106
   Rattigan M.J., 2007, INT C MACH LEARN, P783, DOI DOI 10.1145/1273496.1273595
   Reichardt J, 2006, PHYS REV E, V74, DOI 10.1103/PhysRevE.74.016110
   Sah P, 2014, BMC BIOINFORMATICS, V15, DOI 10.1186/1471-2105-15-220
   Salloum R, 2018, J VIS COMMUN IMAGE R, V51, P201, DOI 10.1016/j.jvcir.2018.01.010
   Shullani D, 2017, EURASIP J INF SECUR, DOI 10.1186/s13635-017-0067-2
   Stamm MC, 2013, IEEE ACCESS, V1, P167, DOI 10.1109/ACCESS.2013.2260814
   Stamm MC, 2010, IEEE T INF FOREN SEC, V5, P492, DOI 10.1109/TIFS.2010.2053202
   Verdoliva L, 2020, IEEE J-STSP, V14, P910, DOI 10.1109/JSTSP.2020.3002101
   von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z
   Wang Q, 2016, EURASIP J INF SECUR, DOI 10.1186/s13635-016-0047-y
   Wang SY, 2019, IEEE I CONF COMP VIS, P10071, DOI 10.1109/ICCV.2019.01017
   Wu Y, 2019, PROC CVPR IEEE, P9535, DOI 10.1109/CVPR.2019.00977
   Yang J, 2013, IEEE DATA MINING, P1151, DOI 10.1109/ICDM.2013.167
   Ye SM, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P12
   Zhou P, 2018, PROC CVPR IEEE, P1053, DOI 10.1109/CVPR.2018.00116
NR 56
TC 6
Z9 6
U1 2
U2 10
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1932-4553
EI 1941-0484
J9 IEEE J-STSP
JI IEEE J. Sel. Top. Signal Process.
PD AUG
PY 2020
VL 14
IS 5
BP 1049
EP 1064
DI 10.1109/JSTSP.2020.3001516
PG 16
WC Engineering, Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA NG8BM
UT WOS:000564205000012
OA Green Submitted
DA 2022-02-06
ER

PT J
AU Dadkhah, S
   Shoeleh, F
   Yadollahi, MM
   Zhang, XC
   Ghorbani, AA
AF Dadkhah, Sajjad
   Shoeleh, Farzaneh
   Yadollahi, Mohammad Mehdi
   Zhang, Xichen
   Ghorbani, Ali A.
TI A real-time hostile activities analyses and detection system
SO APPLIED SOFT COMPUTING
LA English
DT Article
DE Fake news detection; Natural language processing; Hostile detection; Bot
   detection; Social network analysis
ID FAKE NEWS
AB Over recent years, the development of online social media has dramatically changed the way people connect and share information. It is undeniable that social platform has promoted the quickest type of spread for fake stories. Almost all the current online fact-checking sources and researches are concentrating on the validating political content and context. The proposed system in this paper provides a complete visual data analytics methods to assist users in achieving a comprehensive understanding of malicious activities at multiple levels such as adversary's behavior, victim's behavior, content, and context level. In this paper, we investigate a variety of datasets from different aspects such as role, vulnerabilities, influential level, and distribution pattern. The proposed method in this paper focuses on automatic fake/hostile activity detection by utilizing a variety of machine learning (ML) techniques, deep learning models, natural language processes (NLP), and social network analysis (SNA) techniques. Different auxiliary models, such as bot detection, user credibility, and text readability, are deployed to generate additional influential features. The classification performance of ten different machine learning algorithms using a variety of well-known datasets is evaluated by utilizing 10-fold cross-validation. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Dadkhah, Sajjad; Shoeleh, Farzaneh; Yadollahi, Mohammad Mehdi; Zhang, Xichen; Ghorbani, Ali A.] Univ New Brunswick UNB, Fac Comp Sci, Canadian Inst Cybersecur CIC, Fredericton, NB, Canada.
RP Dadkhah, S (corresponding author), Univ New Brunswick UNB, Fac Comp Sci, Canadian Inst Cybersecur CIC, Fredericton, NB, Canada.
EM sdadkhah@unb.ca; fshoeleh@unb.ca; m.yadollahi@unb.ca;
   xichen.zhang@unb.ca; ghorbani@unb.ca
FU Canadian Institute for Cybersecurity (CIC)
FX The authors would like to thank Canadian Institute for Cybersecurity
   (CIC) for its financial and educational support.
CR Adali S., 2017, 11 INT AAAI C WEB SO, P759
   Ahmed Hadeer, 2018, Security and Privacy, V1, DOI 10.1002/spy2.9
   Ajao Oluwaseun, 2018, P 9 INT C SOC MED SO, DOI 10.1145/3217804.3217917
   Allcott H, 2017, J ECON PERSPECT, V31, P211, DOI 10.1257/jep.31.2.211
   Barron-Cedeno A., 2020, ARXIV PREPRINT ARXIV
   Barron-Cedeno A, 2019, THIRTY-THIRD AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTY-FIRST INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / NINTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P9847
   Basiri ME, 2021, FUTURE GENER COMP SY, V115, P279, DOI 10.1016/j.future.2020.08.005
   Batagelj V., 2003, ARXIV PREPRINT ARXIV
   Ben Veyseh AP, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P2335, DOI 10.1145/3132847.3133116
   Bengio Y, 2001, ADV NEUR IN, V13, P932
   Berkhin P, 2005, INTERNET MATH, V2, P73, DOI 10.1080/15427951.2005.10129098
   Bessi A, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0118093
   Bharadwaj P, 2019, INT J NAT LANG COMPU
   Blondel VD, 2008, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2008/10/P10008
   Bojanowski P., 2017, TACL, V5, P135, DOI [DOI 10.1162/TACL_A_00051, 10.1162/tacl_a_00051]
   Bovet A., 2019, INFLUENCE FAKE NEWS
   Burfoot C., P ACL IJCNLP 2009 C, P161
   Chu Z, 2012, IEEE T DEPEND SECURE, V9, P811, DOI 10.1109/TDSC.2012.75
   Chunaev P, 2020, COMPUT SCI REV, V37, DOI 10.1016/j.cosrev.2020.100286
   COLEMAN TF, 1983, SIAM J NUMER ANAL, V20, P187, DOI 10.1137/0720013
   Conti M., 2017, CONT DIG FOR INV, P1
   Cresci S, 2017, WWW'17 COMPANION: PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P963, DOI 10.1145/3041021.3055135
   Cresci S, 2015, DECIS SUPPORT SYST, V80, P56, DOI 10.1016/j.dss.2015.09.003
   Dantzig G, 2003, LINEAR INEQUALITIES, V38, P225
   Darnton R, 2018, TRUE HIST FAKE NEWS
   David Newman Jey, 2010, NAACL HLT 2010, P100
   de Alfaro L., 2018, ARXIV180208066
   De Meo P., 2011, Proceedings of the 2011 11th International Conference on Intelligent Systems Design and Applications (ISDA), P88, DOI 10.1109/ISDA.2011.6121636
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   Dong MQ, 2018, LECT NOTES COMPUT SC, V11233, P199, DOI 10.1007/978-3-030-02922-7_14
   FREEMAN LC, 1977, SOCIOMETRY, V40, P35, DOI 10.2307/3033543
   Greene D., 2006, P ICML, V148, P377
   Guo CX, 2019, IEEE I CONF COMP VIS, P3908, DOI 10.1109/ICCV.2019.00401
   Gupta S, 2018, 2018 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM), P278, DOI 10.1109/ASONAM.2018.8508408
   Han J, 2012, MOR KAUF D, P1
   Helmstetter S, 2018, 2018 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM), P274, DOI 10.1109/ASONAM.2018.8508520
   Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328
   Ipsos Public Affairs, 2019, CIGI IPSOS GLOBAL SU
   Jin ZW, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P795, DOI 10.1145/3123266.3123454
   Jin ZW, 2017, IEEE T MULTIMEDIA, V19, P598, DOI 10.1109/TMM.2016.2617078
   Kai Shu, 2017, ACM SIGKDD Explorations Newsletter, V19, P22, DOI 10.1145/3137597.3137600
   Kantepe M, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND ENGINEERING (UBMK), P630, DOI 10.1109/UBMK.2017.8093483
   Kapitanov AI, 2018, PROCEEDINGS OF THE 2018 IEEE CONFERENCE OF RUSSIAN YOUNG RESEARCHERS IN ELECTRICAL AND ELECTRONIC ENGINEERING (EICONRUS), P1517, DOI 10.1109/EIConRus.2018.8317386
   Karimi H., 2018, P 27 INT C COMP LING, P1546
   Kellner Ansgar, 2020, EuroSec '20: Proceedings of the 13th European workshop on Systems Security, P25, DOI 10.1145/3380786.3391399
   Kim J, 2018, ROU FOC BUS MANAG, P3
   Kleinberg JM, 1999, ACM COMPUT SURV, V31
   Kwon S, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0168344
   Ma J., 2016, P 25 INT JOINT C ART, P3818
   Madabushi H. T., 2020, ARXIV PREPRINT ARXIV
   Maronikolakis A., 2020, ARXIV200413878
   Marwick A., 2017, MEDIA MANIPULATION D
   McCallum A. K., 2002, MALLET MACHINE LEARN
   Merity Stephen, 2017, ARXIV PREPRINT ARXIV
   Mikolov T., 2013, P INT C LEARN REPR I, DOI DOI 10.5555/2999792.2999959
   Mitra T., 2015, ICWSM, P258
   Morris Meredith Ringel, 2012, P ACM 2012 C COMP SU, P441, DOI [10.1145/, DOI 10.1145/2145204.2145274]
   Nakov P., 2019, P 2019 C EMP METH NA, P5640, DOI DOI 10.18653/V1/D19
   Nguyen Vo, 2017, 2017 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM), P363, DOI 10.1145/3110025.3110068
   Olivieri AC, 2019, PROCEEDINGS OF THE 52ND ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES, P5196
   Patil R., 2020, ARXIV PREPRINT ARXIV
   Pennington J., 2014, EMNLP, P1532, DOI [10.3115/v1/D14-1162, DOI 10.3115/V1/D14-1162]
   Provan JS, 1996, ALGORITHMICA, V15, P351
   Qazvinian V., 2011, P 2011 C EMP METH NA, P1589
   Rashkin Hannah, 2017, P 2017 C EMPIRICAL M, P2931
   Rasool T, 2019, INT CONF COMPUT AUTO, P73, DOI 10.1145/3313991.3314008
   Rath B., 2017, P 2017 IEEE ACM INT, P179
   Reis JCS, 2019, IEEE INTELL SYST, V34, P76, DOI 10.1109/MIS.2019.2899143
   Riedel B., 2017, SIMPLE TOUGH TO BEAT
   Rozin P, 2001, PERS SOC PSYCHOL REV, V5, P296, DOI 10.1207/S15327957PSPR0504_2
   Ruchansky N, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P797, DOI 10.1145/3132847.3132877
   Ruz GA, 2020, FUTURE GENER COMP SY, V106, P92, DOI 10.1016/j.future.2020.01.005
   SABIDUSSI G, 1966, PSYCHOMETRIKA, V31, P581, DOI 10.1007/BF02289527
   Samonte, 2018, P 2018 INT C INT EBU, P108, DOI DOI 10.1145/3230348.3230354
   Santia G., 2018, INT AAAI C WEB SOC M
   Savyan PV, 2017, INT CONF ADV COMPU, P220, DOI 10.1109/ICoAC.2017.8441402
   Shu K., 2020, P INT AAAI C WEB SOC, V14, P626
   Shu K, 2020, BIG DATA-US, V8, P171, DOI 10.1089/big.2020.0062
   Shu K, 2019, PROCEEDINGS OF THE 2019 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2019), P436, DOI 10.1145/3341161.3342927
   Shu K, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P395, DOI 10.1145/3292500.3330935
   Shu K, 2019, PROCEEDINGS OF THE TWELFTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'19), P312, DOI 10.1145/3289600.3290994
   Subramanian Samanth, 2017, WIRED
   Tacchini E., 2017, ARXIV170407506, DOI DOI 10.1257/JEP.31.2.211
   Thorne J., 2018, FEVER LARGE SCALE DA, P809, DOI 10.18653/v1/N18-1074
   Traylor T, 2019, IEEE INT C SEMANT CO, P445, DOI [10.1109/ICOSC.2019.8665593, 10.1109/ICSC.2019.00086]
   Vosoughi S, 2018, SCIENCE, V359, P1146, DOI 10.1126/science.aap9559
   Wang WY, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P422, DOI 10.18653/v1/P17-2067
   Wang YQ, 2020, AAAI CONF ARTIF INTE, V34, P516
   Wang YQ, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P849, DOI 10.1145/3219819.3219903
   Wu L, 2018, WSDM'18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P637, DOI 10.1145/3159652.3159677
   Xu W., 2019, TWITTER API TUTORIAL
   Yang S, 2019, THIRTY-THIRD AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTY-FIRST INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / NINTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P5644
   Yu, 2018, ARXIV180508751
   Yu SS, 2017, COMPLEXITY, DOI 10.1155/2017/1703870
   Zhang Y, 2009, 2009 WRI INTERNATIONAL CONFERENCE ON COMMUNICATIONS AND MOBILE COMPUTING: CMC 2009, VOL 2, P71, DOI 10.1109/CMC.2009.190
   Zhi S, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P2555, DOI 10.1145/3132847.3133182
   ZHOU X, 2019, INFECT DIS POVERTY
   Zhou XY, 2020, LECT NOTES ARTIF INT, V12085, P354, DOI 10.1007/978-3-030-47436-2_27
   Zubiaga A., 2016, ARXIV161007363
NR 99
TC 2
Z9 2
U1 4
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1568-4946
EI 1872-9681
J9 APPL SOFT COMPUT
JI Appl. Soft. Comput.
PD JUN
PY 2021
VL 104
AR 107175
DI 10.1016/j.asoc.2021.107175
PG 28
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA RO9QN
UT WOS:000641373800002
DA 2022-02-06
ER

PT J
AU Mangaokar, N
   Prakash, A
AF Mangaokar, Neal
   Prakash, Atul
TI Dispelling Misconceptions and Characterizing the Failings of Deepfake
   Detection
SO IEEE SECURITY & PRIVACY
LA English
DT Article; Early Access
DE Videos; Information integrity; Faces; Generators; Codes; Generative
   adversarial networks; Tools
C1 [Mangaokar, Neal] Univ Michigan, Ann Arbor, MI 48109 USA.
   [Prakash, Atul] Univ Michigan, Comp Sci & Engn, Ann Arbor, MI 48109 USA.
C3 University of Michigan System; University of Michigan; University of
   Michigan System; University of Michigan
RP Mangaokar, N (corresponding author), Univ Michigan, Ann Arbor, MI 48109 USA.
EM nealmgkr@umich.edu; aprakash@eecs.umich.edu
CR [Anonymous], 2019, INTRO FACESWAPS LATE
   Arik SO, 2018, ADV NEURAL INFORM PR, P10019
   Carlini N., 2017, P 10 ACM WORKSH ART, P3, DOI DOI 10.1145/3128572.3140444
   Carlini N., 2020, P IEEE CVF C COMP VI, P2804
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Christopher N., 2020, VICE
   Damiani J, 2019, FORBES
   Hasan HR, 2019, IEEE ACCESS, V7, P41596, DOI 10.1109/ACCESS.2019.2905689
   Mangaokar N, 2020, 2020 5TH IEEE EUROPEAN SYMPOSIUM ON SECURITY AND PRIVACY (EUROS&P 2020), P139, DOI 10.1109/EuroSP48549.2020.00017
   Pu JM, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P981, DOI 10.1145/3442381.3449978
   Ruiz N., 2020, P EUR C COMP VIS, P236, DOI [10.1007/978-3-030-66823-5_14, DOI 10.1007/978-3-030-66823-5_14]
   Satter R., 2020, REUTERS JUL
   Zakharov E, 2019, IEEE I CONF COMP VIS, P9458, DOI 10.1109/ICCV.2019.00955
   Zellers R., 2019, ADV NEURAL INFORM PR
   Zhu Y., 2021, ARXIV210504932
NR 15
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1540-7993
EI 1558-4046
J9 IEEE SECUR PRIV
JI IEEE Secur. Priv.
DI 10.1109/MSEC.2021.3099782
EA OCT 2021
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XR7AI
UT WOS:000732376700001
DA 2022-02-06
ER

PT J
AU Farkas, J
   Schou, J
   Neumayer, C
AF Farkas, Johan
   Schou, Jannick
   Neumayer, Christina
TI Cloaked Facebook pages: Exploring fake Islamist propaganda in social
   media
SO NEW MEDIA & SOCIETY
LA English
DT Article
DE Cloaked; Denmark; disinformation; Facebook; hate speech; Islamophobia;
   propaganda; racism; social media; social network sites
ID MUHAMMAD CARTOONS; HATE SPEECH; DENMARK; RACISM; INTERNET
AB This research analyses cloaked Facebook pages that are created to spread political propaganda by cloaking a user profile and imitating the identity of a political opponent in order to spark hateful and aggressive reactions. This inquiry is pursued through a multisited online ethnographic case study of Danish Facebook pages disguised as radical Islamist pages, which provoked racist and anti-Muslim reactions as well as negative sentiments towards refugees and immigrants in Denmark in general. Drawing on Jessie Daniels' critical insights into cloaked websites, this research furthermore analyses the epistemological, methodological and conceptual challenges of online propaganda. It enhances our understanding of disinformation and propaganda in an increasingly interactive social media environment and contributes to a critical inquiry into social media and subversive politics.
C1 [Farkas, Johan; Schou, Jannick] IT Univ Copenhagen, Copenhagen, Denmark.
   [Neumayer, Christina] IT Univ Copenhagen, Digital Design Dept, Digital Media & Commun, Copenhagen, Denmark.
C3 IT University Copenhagen; IT University Copenhagen
RP Neumayer, C (corresponding author), IT Univ Copenhagen, Digital Design, Rued Langgaards Vej 7, DK-2300 Copenhagen S, Denmark.
EM chne@itu.dk
RI Farkas, Johan/AAP-5251-2020
OI Farkas, Johan/0000-0003-2272-7174; Neumayer,
   Christina/0000-0002-2655-5691; Neumayer, Christina/0000-0003-0450-2983
CR Adams SA, 2010, INT J MED INFORM, V79, P391, DOI 10.1016/j.ijmedinf.2010.01.006
   ALI W, 2011, FEAR INC ROOTS ISLAM
   Andersen, 2016, TV2
   Andreassen Rikke, 2007, ER YNDIGT LAND MEDIE
   Andrejevic M, 2013, INFOGLUT TOO MUCH IN
   Arnstad H, 2015, FASCISM, V4, P194, DOI 10.1163/22116257-00402002
   Askanius T, 2015, JAVNOST-PUBLIC, V22, P55, DOI 10.1080/13183222.2015.1017249
   Atton C, 2006, NEW MEDIA SOC, V8, P573, DOI 10.1177/1461444806065653
   Becker H., 1949, AM SOCIOL REV, V14, P221, DOI DOI 10.2307/2086855
   Ben-David A, 2016, INT J COMMUN-US, V10, P1167
   Boyd DM, 2007, J COMPUT-MEDIAT COMM, V13, P210, DOI 10.1111/j.1083-6101.2007.00393.x
   Bruns Axel, 2013, 1 MONDAY, V18, P10, DOI DOI 10.5210/FM.V18I10.4879
   Caiani M., 2014, CYBERACTIVISM PARTIC, P182
   Castells Manuel, 2012, NETWORKS OUTRAGE HOP
   Champoux Valerie, 2012, Journal of Business Strategy, V33, P22, DOI 10.1108/02756661211206717
   Chao EC, 2015, CRIT SOCIOL, V41, P57, DOI 10.1177/0896920513508662
   Christensen C, 2011, COMMUN REV, V14, P155, DOI 10.1080/10714421.2011.597235
   Citron DK, 2011, BOSTON U LAW REV, V91, P1435
   Coretti L, 2015, J ITAL CINE MEDIA ST, V3, P305, DOI 10.1386/jicms.3.3.305_1
   Daniels, 2009, CYBER RACISM WHITE S
   Daniels J., 2014, CYBERACTIVISM PARTIC, P140
   Daniels J, 2013, NEW MEDIA SOC, V15, P695, DOI 10.1177/1461444812462849
   Daniels J, 2009, NEW MEDIA SOC, V11, P659, DOI 10.1177/1461444809105345
   Ellison NB., 2013, OXFORD HDB INTERNET, P151, DOI DOI 10.1093/OXFORDHB/9780199589074.013.0008
   Espersen S, 2013, POLITIKEN
   Facebook, 2017, FAC COMM STAND
   Foxman A. H., 2013, VIRAL HATE CONTAININ
   Galis V, 2012, SCI CULT-UK, V21, P335, DOI 10.1080/09505431.2011.644783
   Good KD, 2013, NEW MEDIA SOC, V15, P557, DOI 10.1177/1461444812458432
   Hervik P., 2011, ANNOYING DIFFERENCE
   Hine C., 2015, ETHNOGRAPHY INTERNET
   Horsti K, 2017, NEW MEDIA SOC, V19, P1440, DOI 10.1177/1461444816642169
   Linde-Laursen A, 2007, CONTEMP ISLAM, V1, P265, DOI 10.1007/s11562-007-0022-y
   Lindekilde L, 2009, ETHNICITIES, V9, P291, DOI 10.1177/1468796809337434
   Mager A, 2009, NEW MEDIA SOC, V11, P1123, DOI 10.1177/1461444809341700
   MARCUS GE, 1995, ANNU REV ANTHROPOL, V24, P95, DOI 10.1146/annurev.an.24.100195.000523
   Matusitz J, 2016, J APPL SEC RES, V11, P18, DOI 10.1080/19361610.2016.1104276
   Mazurski L, 2015, DIGITAL MEDIA STRATE, P161
   Mihailovic Alexander, 2015, DIGITAL MEDIA STRATE, P83
   Moestrup JHR, 2015, TV2
   Morozov E., 2011, NET DELUSION DARK SI, V1
   Mortensen M, 2015, JOURNAL PRACT, V9, P536, DOI 10.1080/17512786.2015.1030140
   Mouritsen P, 2013, ETHNIC RACIAL STUD, V36, P691, DOI 10.1080/01419870.2011.598233
   Neumayer C., 2016, ROUTLEDGE COMPANION, P296
   Newman N., 2015, REUTERS I DIGITAL NE
   Nielsen AS, 2015, AFFECTIVITY AND RACE: STUDIES FROM NORDIC CONTEXTS, P43
   Nielsen SB, 2015, DR NYHEDER      0519
   Papacharissi Z, 2009, NEW MEDIA SOC, V11, P199, DOI 10.1177/1461444808099577
   Phillips W, 2013, TELEV NEW MEDIA, V14, P494, DOI 10.1177/1527476412452799
   Roberts Sarah, 2016, INTERSECTIONAL INTER, DOI DOI 10.1007/S13398-014-0173-7.2
   Rojecki A, 2016, NEW MEDIA SOC, V18, P25, DOI 10.1177/1461444814535724
   Rossi L., 2016, SOCIAL MEDIA USE POL
   Schou J, 2016, KOME, V4, P36, DOI 10.17646/KOME.2016.13
   Schwartz SA, 2015, SOC MEDIA SOC, V1, DOI 10.1177/2056305115622480
   Shein E, 2013, COMMUN ACM, V56, P20, DOI 10.1145/2500468.2500474
   Shin J, 2017, NEW MEDIA SOC, V19, P1214, DOI 10.1177/1461444816634054
   Simpson P. A., 2015, DIGITAL MEDIA STRATE, P123
   Skovhus PR, 2015, INFORMATION
   Stempel C, 2007, JOURNALISM MASS COMM, V84, P353, DOI 10.1177/107769900708400210
   Titley, 2011, CRISES MULTICULTURAL
   Uldam J, 2015, EURO CRISIS PRESS
   Warf B, 2016, SPACE POLITY, V20, P143, DOI 10.1080/13562576.2015.1112113
   Yilmaz F, 2012, CURR SOCIOL, V60, P368, DOI 10.1177/0011392111426192
   Yilmaz F, 2011, COMMUN STUD, V62, P5, DOI 10.1080/10510974.2011.533340
   [No title captured]
NR 65
TC 40
Z9 41
U1 5
U2 55
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 1461-4448
EI 1461-7315
J9 NEW MEDIA SOC
JI New Media Soc.
PD MAY
PY 2018
VL 20
IS 5
BP 1850
EP 1867
DI 10.1177/1461444817707759
PG 18
WC Communication
WE Social Science Citation Index (SSCI)
SC Communication
GA GF6SR
UT WOS:000432098300010
DA 2022-02-06
ER

PT J
AU Lingam, G
   Rout, RR
   Somayajulu, DVLN
AF Lingam, Greeshma
   Rout, Rashmi Ranjan
   Somayajulu, D. V. L. N.
TI Adaptive deep Q-learning model for detecting social bots and influential
   users in online social networks
SO APPLIED INTELLIGENCE
LA English
DT Article
DE Social bot; Deep Q-learning; Twitter; Online social networks
ID NEURAL-NETWORKS; TRUST
AB In an online social network (like Twitter), a botmaster (i.e., leader among a group of social bots) establishes a social relationship among legitimate participants to reduce the probability of social bot detection. Social bots generate fake tweets and spread malicious information by manipulating the public opinion. Therefore, the detection of social bots in an online social network is an important task. In this paper, we consider social attributes, such as tweet-based attributes, user profile-based attributes and social graph-based attributes for detecting the social bots among legitimate participants. We design a deep Q-network architecture by incorporating a Deep Q-Learning (DQL) model using the social attributes in the Twitter network for detection of social bots based on updating Q-value function (i.e., state-action value function). We consider each social attribute of a user as a state and the learning agent's movement from one state to another state is considered as an action. For Q-value function, we consider all the state-action pairs in order to construct the state transition probability values between the state-action pairs. In the proposed DQL algorithm, the learning agent chooses a specific learning action with an optimal Q-value in each state for social bot detection. Further, we also propose an approach that identifies the most influential users (which are influenced by the social bots) based on tweets and the users' interactions. The experimentation using the datasets collected from Twitter network illustrates the efficacy of proposed model.
C1 [Lingam, Greeshma; Rout, Rashmi Ranjan; Somayajulu, D. V. L. N.] Natl Inst Technol, Comp Sci & Engn, Warangal 506004, Andhra Pradesh, India.
   [Somayajulu, D. V. L. N.] Informat Technol Design & Mfg IIITDM, Kurnool 518002, Andhra Pradesh, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Warangal
RP Lingam, G (corresponding author), Natl Inst Technol, Comp Sci & Engn, Warangal 506004, Andhra Pradesh, India.
EM greeshma243@gmail.com; rashmi.iitkgp@gmail.com; somadvlns@gmail.com
OI ROUT, RASHMI RANJAN/0000-0003-3457-6633
CR Al-Zoubi AM, 2018, KNOWL-BASED SYST, V153, P91, DOI 10.1016/j.knosys.2018.04.025
   Albladi SM, 2018, HUM-CENT COMPUT INFO, V8, DOI 10.1186/s13673-018-0128-7
   Alshahrani M, 2018, J BIG DATA-GER, V5, DOI 10.1186/s40537-018-0137-4
   Ashfaq A. B., 2016, J COMPUTER VIROLOGY, P1
   BALTAZAR J, 2009, TREND MICRORESEARCH, V5, P10
   Barushka A., 2018, APPL INTELL, P1
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Boshmaf Y, 2011, 27TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE (ACSAC 2011), P93
   Cesarano F, 2006, HIST PERSP MOD ECON, P21, DOI 10.1017/CBO9780511618093.003
   Cheng ZY, 2013, ACM T INTEL SYST TEC, V4, DOI 10.1145/2414425.2414427
   Chowdhury Sudipta, 2017, Journal of Big Data, V4, DOI 10.1186/s40537-017-0074-7
   Chu Z, 2012, IEEE T DEPEND SECURE, V9, P811, DOI 10.1109/TDSC.2012.75
   Cresci S, 2017, WWW'17 COMPANION: PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P963, DOI 10.1145/3041021.3055135
   Dickerson JP, 2014, 2014 PROCEEDINGS OF THE IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2014), P620, DOI 10.1109/ASONAM.2014.6921650
   Ferrara E, 2016, COMMUN ACM, V59, P96, DOI 10.1145/2818717
   Francois-Lavet V., 2015, CORRABS151202011
   Freitas C, 2016, SOC NETW ANAL MIN, V6, DOI 10.1007/s13278-016-0331-3
   Gadaleta M, 2017, IEEE T COGN COMMUN, V3, P703, DOI 10.1109/TCCN.2017.2755007
   Gilani Z, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16 COMPANION), P37, DOI 10.1145/2872518.2889360
   Halfaker A, 2012, COMPUTER, V45, P79, DOI 10.1109/MC.2012.82
   Islam R., 2017, ARXIV170804133
   Ji YD, 2016, COMPUT SECUR, V58, P230, DOI 10.1016/j.cose.2016.01.007
   Kaufmann M., 2010, INT C NAT LANG PROC
   Kudugunta S, 2018, INFORM SCIENCES, V467, P312, DOI 10.1016/j.ins.2018.08.019
   Kusy M, 2015, IEEE T NEUR NET LEAR, V26, P2163, DOI 10.1109/TNNLS.2014.2376703
   Lee K., 2011, P 5 INT AAAI C WEBL, P185
   Lee S, 2013, IEEE T DEPEND SECURE, V10, P183, DOI 10.1109/TDSC.2013.3
   Lee S, 2013, COMPUT COMMUN, V36, P320, DOI 10.1016/j.comcom.2012.10.003
   Leibo JZ, 2017, AAMAS'17: PROCEEDINGS OF THE 16TH INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS AND MULTIAGENT SYSTEMS, P464
   Lingam G, 2018, COMPUT ELECTR ENG, V66, P174, DOI 10.1016/j.compeleceng.2017.10.017
   Liu W, 2017, PATTERN RECOGNITION
   Ma QQ, 2017, STEM CELLS BIOL REG, P1, DOI 10.1007/978-3-319-51617-2_1
   Perera RDW, 2010, IEEE MILIT COMMUN C, P2186, DOI 10.1109/MILCOM.2010.5680493
   Sheikhahmadi A, 2017, PHYSICA A, V486, P517, DOI 10.1016/j.physa.2017.05.098
   Sirivianos M, 2011, IEEE INFOCOM SER, P2300, DOI 10.1109/INFCOM.2011.5935047
   Subrahmanian VS, 2008, IEEE INTELL SYST, V23, P43, DOI 10.1109/MIS.2008.57
   Subrahmanian VS, 2016, COMPUTER, V49, P38, DOI 10.1109/MC.2016.183
   Tang R, 2018, NEUROCOMPUTING, V314, P1, DOI 10.1016/j.neucom.2018.03.043
   Teng TH, 2015, IEEE T NEUR NET LEAR, V26, P889, DOI 10.1109/TNNLS.2014.2327636
   Venkatachalam N, 2017, MULTIMED TOOLS APPL, V76, P6079, DOI 10.1007/s11042-016-3555-3
   Wagner C., 2012, MAKING SENSE MICROPO, V2, P1951
   Wang B., 2017, NAT CCF C NAT LANG P, P477
   Wei QL, 2017, IEEE T CYBERNETICS, V47, P1224, DOI 10.1109/TCYB.2016.2542923
   Wei W, 2012, IEEE INFOCOM SER, P1951, DOI 10.1109/INFCOM.2012.6195572
   Yan GH, 2013, COMPUT NETW, V57, P540, DOI 10.1016/j.comnet.2012.07.016
   Zhang J., 2016, IEEE T DEPENDABLE SE
   Zhang JX, 2016, IEEE ACM T NETWORK, V24, P2866, DOI 10.1109/TNET.2015.2494059
NR 47
TC 14
Z9 14
U1 5
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0924-669X
EI 1573-7497
J9 APPL INTELL
JI Appl. Intell.
PD NOV
PY 2019
VL 49
IS 11
BP 3947
EP 3964
DI 10.1007/s10489-019-01488-3
PG 18
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JJ3GM
UT WOS:000494049700013
DA 2022-02-06
ER

PT J
AU Jain, DK
   Kumar, A
   Shrivastava, A
AF Jain, Deepak Kumar
   Kumar, Akshi
   Shrivastava, Akshat
TI CanarDeep: a hybrid deep neural model with mixed fusion for rumour
   detection in social data streams
SO NEURAL COMPUTING & APPLICATIONS
LA English
DT Article; Early Access
DE Rumour; Social data streams; Deep learning; Data fusion
AB The unrelenting trend of doctored narratives, content spamming, fake news and rumour dissemination on social media can lead to grave consequences that range from online intimidating and trolling to lynching and riots in real- life. It has therefore become vital to use computational techniques that can detect rumours, do fact-checking and inhibit its amplification. In this paper, we put forward a model for rumour detection in streaming data on social platforms. The proposed CanarDeep model is a hybrid deep neural model that combines the predictions of a hierarchical attention network (HAN) and a multi-layer perceptron (MLP) learned using context-based (text + meta-features) and user-based features, respectively. The concatenated context feature vector is generated using feature-level fusion strategy to train HAN. Eventually, a decision-level late fusion strategy using logical OR combines the individual classifier prediction and outputs the final label as rumour or non-rumour. The results demonstrate improved performance to the existing state-of-the-art approach on the benchmark PHEME dataset with a 4.45% gain in F1-score. The model can facilitate well-time intervention and curtail the risk of widespread rumours in streaming social media by raising an alert to the moderators.
C1 [Jain, Deepak Kumar] Chongqing Univ Posts & Telecommun, Key Lab Intelligent Air Ground Cooperat Control U, Coll Automat, Chongqing, Peoples R China.
   [Kumar, Akshi] Netaji Subhas Univ Technol, Dept Informat Technol, Delhi, India.
   [Shrivastava, Akshat] Delhi Technol Univ, Dept Comp Sci & Engn, Delhi, India.
C3 Chongqing University of Posts & Telecommunications; Netaji Subhas
   University of Technology; Delhi Technological University
RP Kumar, A (corresponding author), Netaji Subhas Univ Technol, Dept Informat Technol, Delhi, India.
EM akshi.kumar@nsut.ac.in
OI Kumar, Akshi/0000-0003-4263-7168
CR Alrubaian M, 2019, IEEE ACCESS, V7, P2828, DOI 10.1109/ACCESS.2018.2886314
   Bhattacharjee U, 2019, INT CONF COMMUN SYST, P726, DOI 10.1109/COMSNETS.2019.8711427
   Bounegru L, 2018, FIELD GUIDE FAKE NEW
   Cao J., 2018, ARXIV PREPRINT ARXIV
   Chen C, 2017, FUTURE GENER COMP SY, V72, P319, DOI 10.1016/j.future.2016.05.036
   Chen T, 2018, LECT NOTES ARTIF INT, V11154, P40, DOI 10.1007/978-3-030-04503-6_4
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   Guo H, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P943, DOI 10.1145/3269206.3271709
   Hand DJ, 2012, INT STAT REV, V80, P400, DOI 10.1111/j.1751-5823.2012.00183.x
   Kumar Akshi, 2019, International Conference on Innovative Computing and Communications. Proceedings of ICICC-2018. Lecture Notes in Networks and Systems (LNNS 56), P213, DOI 10.1007/978-981-13-2354-6_23
   Kumar A., 2021, TURKISH J COMPUT MAT, V12, P4110
   Kumar A, 2020, INT C INT COMP SMART, P1269
   Kumar A, 2020, INT J ADV SCI TECHNO, V29, P14682
   Kumar A, 2021, MULTIMED TOOLS APPL, DOI 10.1007/s11042-021-11262-8
   Kumar A, 2021, WIREL COMMUN MOB COM, V2021, DOI 10.1155/2021/2939334
   Kumar A, 2020, ALGO INTELL SY, P239, DOI 10.1007/978-981-15-0222-4_21
   Kumar A, 2021, MULTIMEDIA SYST, DOI [10.1007/s00530-020-00747-5, 10.1007/3418_2020_67]
   Li GH, 2020, WORLD WIDE WEB, V23, P693, DOI 10.1007/s11280-019-00717-6
   Ma J., 2016, P 25 INT JOINT C ART, P3818
   Otter DW, 2021, IEEE T NEUR NET LEAR, V32, P604, DOI 10.1109/TNNLS.2020.2979670
   Peters ME, 2018, P C N AM CHAPT ASS C, DOI DOI 10.18653/V1/N18-1202
   Saito T, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0118432
   Sangwan SR, 2020, MULTIMEDIA SYST, DOI 10.1007/s00530-020-00661-w
   Takahashi T, 2012, JOINT INT CONF SOFT, P452, DOI 10.1109/SCIS-ISIS.2012.6505254
   Ting FF, 2017, 2017 INT C ROB AUT S, P1
   Tu Ngoc Nguyen, 2017, Social Informatics. 9th International Conference, SocInfo 2017. Proceedings: LNCS 10540, P141, DOI 10.1007/978-3-319-67256-4_13
   Vijeev A, 2018, 2018 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P337, DOI 10.1109/ICACCI.2018.8554371
   Yang Z., 2016, NAACL HLT, P1480
   Young T, 2018, IEEE COMPUT INTELL M, V13, P55, DOI 10.1109/MCI.2018.2840738
   Zubiaga A, 2017, INT C SOC INF, P109
   Zubiaga A., 2016, PHEME DATASET RUMOUR
   Zubiaga A, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3161603
NR 32
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0941-0643
EI 1433-3058
J9 NEURAL COMPUT APPL
JI Neural Comput. Appl.
DI 10.1007/s00521-021-06743-8
EA JAN 2022
PG 12
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA YD2GB
UT WOS:000740194200007
PM 35035107
OA Bronze, Green Published
DA 2022-02-06
ER

PT J
AU Ilias, L
   Roussaki, I
AF Ilias, Loukas
   Roussaki, Ioanna
TI Detecting malicious activity in Twitter using deep learning techniques
SO APPLIED SOFT COMPUTING
LA English
DT Article
DE Social media; Twitter; Bot detection; Feature extraction; Feature
   selection; Machine learning; Deep learning; Attention mechanism; Natural
   Language Processing
ID NEURAL-NETWORKS; SPAMMERS
AB Undoubtedly, social media, such as Facebook and Twitter, constitute a major part of our everyday life due to the incredible possibilities they offer to their users. However, Twitter and generally online social networks (OSNs) are increasingly used by automated accounts, widely known as bots, due to their immense popularity across a wide range of user categories. Their main purpose is the dissemination of fake news, the promotion of specific ideas and products, the manipulation of the stock market and even the diffusion of sexually explicit material. Therefore, the early detection of bots in social media is quite essential. In this paper, two methods are introduced targeting this that are mainly based on Natural Language Processing (NLP) to distinguish legitimate users from bots. In the first method, a feature extraction approach is proposed for identifying accounts posting automated messages. After applying feature selection techniques and dealing with imbalanced datasets, the subset of features selected is fed in machine learning algorithms. In the second method, a deep learning architecture is proposed to identify whether tweets have been posted by real users or generated by bots. To the best of the authors' knowledge, there is no prior work on using an attention mechanism for identifying bots. The introduced approaches have been evaluated over a series of experiments using two large real Twitter datasets and demonstrate valuable advantages over other existing techniques targeting the identification of malicious users in social media. (C) 2021 The Authors. Published by Elsevier B.V.
C1 [Ilias, Loukas; Roussaki, Ioanna] Natl Tech Univ Athens NTUA, Sch Elect & Comp Engn, Athens, Greece.
RP Roussaki, I (corresponding author), Natl Tech Univ Athens NTUA, Sch Elect & Comp Engn, Athens, Greece.
EM loukasil97@gmail.com; ioanna.roussaki@cn.ntua.gr
OI Ilias, Loukas/0000-0002-4483-4264
FU National Infrastructures for Research and Technology S.A. (GRNET) in the
   National HPC facility-ARIS,Greece [pa200501]
FX This work was supported with processing resources granted by the
   National Infrastructures for Research and Technology S.A. (GRNET) in the
   National HPC facilityARIS, Greeceunder project ID pa200501.
CR Abadi M., 2015, TENSORFLOW LARGE SCA
   Alom Z, 2020, ONLINE SOC NETW MEDI, V18, DOI [10.1016/j.osnem.2020.100079, DOI 10.1016/J.OSNEM.2020.100079]
   Amleshwaram AA, 2013, INT CONF COMMUN SYST
   [Anonymous], PROC 2014 C EMPIRICA, DOI [DOI 10.3115/V1/D14-1162, 10.3115/v1/d14-1162]
   Ashour M, 2018, PROCEEDINGS OF 2018 13TH INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING AND SYSTEMS (ICCES), P190, DOI 10.1109/ICCES.2018.8639297
   Bahdanau D., 2014, ARXIV PREPRINT ARXIV
   Baziotis C., 2017, P 11 INT WORKSH SEM, P747, DOI DOI 10.18653/V1/S17-2126
   Chollet F., 2015, GITHUB REPOS
   Cox D. D.
   Cresci S, 2018, IEEE T DEPEND SECURE, V15, P561, DOI 10.1109/TDSC.2017.2681672
   Cresci S, 2017, WWW'17 COMPANION: PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P963, DOI 10.1145/3041021.3055135
   Davis CA, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16 COMPANION), P273, DOI 10.1145/2872518.2889302
   Fazil M, 2018, IEEE T INF FOREN SEC, V13, P2707, DOI 10.1109/TIFS.2018.2825958
   Gajalakshmi P, 2018, 2018 2ND INTERNATIONAL CONFERENCE ON COMPUTER, COMMUNICATION, AND SIGNAL PROCESSING (ICCCSP): SPECIAL FOCUS ON TECHNOLOGY AND INNOVATION FOR SMART ENVIRONMENT, P170
   Gong QY, 2018, IEEE COMMUN MAG, V56, P21, DOI 10.1109/MCOM.2018.1700575
   Herzallah W, 2018, J INF SCI, V44, P230, DOI 10.1177/0165551516684296
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735
   Hutto C. J., 2014, P INT AAAI C WEB SOC
   Jurak P, 2018, P GLOB INT THINGS SU, P1
   Kaubiyal J, 2019, P 3 INT C BIG DAT IN, P135
   Khaled S, 2018, IEEE INT CONF BIG DA, P3672, DOI 10.1109/BigData.2018.8621913
   Khalil H, 2020, 2020 3 INT C COMP MA, DOI 10.1109/iCoMET48670.2020.9074131
   Kingma DP, 2015, 3 INT C LEARN REPR I, DOI DOI 10.1145/1830483.1830503
   Knauth J., 2019, P INT C REC ADV NAT, P550
   Koggalahewa D. Niranjan, 2020, P AUSTR COMP SCI WEE, P1
   Kosmanos D., 2019, P 4 S E EUR DES AUT, P1
   Kudugunta S, 2018, INFORM SCIENCES, V467, P312, DOI 10.1016/j.ins.2018.08.019
   Lee K., 2011, 5 INT AAAI C WEBL SO
   Lemaitre G, 2017, J MACH LEARN RES, V18
   Li H.-Y., 2020, ARXIV PREPRINT ARXIV
   Lingam G, 2019, APPL INTELL, V49, P3947, DOI 10.1007/s10489-019-01488-3
   Liu L., 2016, ARXIV160408504
   Loria S, 2018, TEXTBLOB DOCUMENTATI, V2
   Martinelli F., 2019, 2019 INT JOINT C NEU, P1
   McKinney W., 2010, P 9 PYTH SCI C, P56, DOI [10.25080/Majora-92bf1922-00a, DOI 10.25080/MAJORA-92BF1922-00A]
   Miller Z, 2014, INFORM SCIENCES, V260, P64, DOI 10.1016/j.ins.2013.11.016
   Orabi M, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102250
   Pasricha N., 2019, 27 AIAI IR C ART INT
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Wald Randall, 2013, 2013 IEEE 14th International Conference on Information Reuse & Integration (IRI), P416, DOI 10.1109/IRI.2013.6642501
   Wang B., 2015, ARXIV PREPRINT ARXIV
   Wei F, 2019, 2019 FIRST IEEE INTERNATIONAL CONFERENCE ON TRUST, PRIVACY AND SECURITY IN INTELLIGENT SYSTEMS AND APPLICATIONS (TPS-ISA 2019), P101, DOI 10.1109/TPS-ISA48467.2019.00021
NR 43
TC 3
Z9 3
U1 7
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1568-4946
EI 1872-9681
J9 APPL SOFT COMPUT
JI Appl. Soft. Comput.
PD AUG
PY 2021
VL 107
AR 107360
DI 10.1016/j.asoc.2021.107360
PG 19
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA SO4AE
UT WOS:000658916600006
OA hybrid
DA 2022-02-06
ER

PT J
AU Kula, S
   Kozik, R
   Choras, M
AF Kula, Sebastian
   Kozik, Rafal
   Choras, Michal
TI Implementation of the BERT-derived architectures to tackle
   disinformation challenges
SO NEURAL COMPUTING & APPLICATIONS
LA English
DT Article; Early Access
DE Fake news detection; Natural Language Processing; Neural networks;
   Machine Learning; Security
AB Recent progress in the area of modern technologies confirms that information is not only a commodity but can also become a tool for competition and rivalry among governments and corporations, or can be applied by ill-willed people to use it in their hate speech practices. The impact of information is overpowering and can lead to many socially undesirable phenomena, such as panic or political instability. To eliminate the threats of fake news publishing, modern computer security systems need flexible and intelligent tools. The design of models meeting the above-mentioned criteria is enabled by artificial intelligence and, above all, by the state-of-the-art neural network architectures, applied in NLP tasks. The BERT neural network belongs to this type of architectures. This paper presents Transformer-based hybrid architectures applied to create models for detecting fake news.
C1 [Kula, Sebastian; Kozik, Rafal; Choras, Michal] UTP Univ Sci & Technol, Kaliskiego 7, PL-85976 Bydgoszcz, Poland.
   [Kula, Sebastian] Kazimierz Wielki Univ UKW, Bydgoszcz, Poland.
C3 Bydgoszcz University of Science & Technology
RP Choras, M (corresponding author), UTP Univ Sci & Technol, Kaliskiego 7, PL-85976 Bydgoszcz, Poland.
EM chorasm@utp.edu.pl
FU SocialTruth project from the European Union's Horizon 2020 research and
   innovation programme [825477]
FX This work is supported by SocialTruth project (http://socialtruth.eu),
   which has received funding from the European Union's Horizon 2020
   research and innovation programme under grant agreement No. 825477.
CR Ahmed Hadeer, 2018, Security and Privacy, V1, DOI 10.1002/spy2.9
   Akbik A, RELEASES FLAIRNLP FL RELEASES FLAIRNLP FL
   Akbik A, 2019, PROC 2019 C N AM CHA, P54, DOI 10.18653/v1/N19-4010
   Choras M, 2021, APPL SOFT COMPUT, V101, DOI 10.1016/j.asoc.2020.107050
   Choras M, 2019, 14TH INTERNATIONAL CONFERENCE ON AVAILABILITY, RELIABILITY AND SECURITY (ARES 2019), DOI 10.1145/3339252.3341497
   Das SD, 2021, ABS210103545 CORR ABS210103545 CORR
   Devlin Jacob, 2019, BERT PRETRAINING DEE, P4171
   Dong X, 2019, ABS190605659 CORR ABS190605659 CORR
   Dowlagar S, 2021, ABS210109007 CORR ABS210109007 CORR
   Felber T, 2021, ABS210103717 CORR ABS210103717 CORR
   Gautam A, 2021, ABS210111425 CORR ABS210111425 CORR
   Gielczyk Agata, 2019, Computer Information Systems and Industrial Management. 18th International Conference, CISIM 2019. Proceedings: Lecture Notes in Computer Science (LNCS 11703), P144, DOI 10.1007/978-3-030-28957-7_13
   Glazkova A, 2020, ABS201211967 CORR ABS201211967 CORR
   Jwa H, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9194062
   Koloski B, 2021, ABS210103988 CORR ABS210103988 CORR
   Kozik R., 2020, CISIS ADV INTELLIGEN, P208
   Ksieniewicz P, 2019, LECT NOTES COMPUT SC, V11872, P332, DOI 10.1007/978-3-030-33617-2_34
   Kula Sebastian, 2020, Computational Science - ICCS 2020. 20th International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12140), P653, DOI 10.1007/978-3-030-50423-6_49
   Kula S., 2020, CISIS, P239
   Li Q, 2020, ABS200800364 CORR ABS200800364 CORR
   Liu Yinhan, 2019, ABS190711692 CORR
   Muller M, 2020, ABS200507503 CORR ABS200507503 CORR
   Patwa P, 2020, ABS201103327 CORR ABS201103327 CORR
   Patwa P, P 1 WORKSH COMB ONL P 1 WORKSH COMB ONL
   Pierre S, FAKE NEWS CLASSIFICA
   Sanh Victor, 2019, ABS191001108 CORR
   Vaswani A, 2017, ARXIV170603762COMMEN
   Vlad G.-A., 2019, P 2 WORKSH NAT LANG, P148
   Wang YQ, 2020, AAAI CONF ARTIF INTE, V34, P516
   Zellers R, 2019, ADV NEURAL INFORM PR, P9051
NR 30
TC 1
Z9 1
U1 7
U2 7
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0941-0643
EI 1433-3058
J9 NEURAL COMPUT APPL
JI Neural Comput. Appl.
DI 10.1007/s00521-021-06276-0
EA JUL 2021
PG 13
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TM7SJ
UT WOS:000675747400003
PM 34316097
OA Green Published, hybrid
DA 2022-02-06
ER

PT J
AU Lingam, G
   Rout, RR
   Somayajulu, DVLN
   Ghosh, SK
AF Lingam, Greeshma
   Rout, Rashmi Ranjan
   Somayajulu, D. V. L. N.
   Ghosh, Soumya K.
TI Particle Swarm Optimization on Deep Reinforcement Learning for Detecting
   Social Spam Bots and Spam-Influential Users in Twitter Network
SO IEEE SYSTEMS JOURNAL
LA English
DT Article
DE Deep Q-learning (DQL); particle swarm optimization (PSO); reinforcement
   learning; social spam bot; spam-influential users (SIU)
AB In online social networks (OSNs), detection of malicious social bots is an important research challenge to provide legitimacy of user profiles and trustworthy service ratings. Further, spam-influential users must be minimal to control the fake information-spread in OSNs. Learning from example patterns using supervised learning may not provide accurate results in cases where existing data items are biased and bot behavior dynamically changes over a period of time. Moreover, deep reinforcement learning provides improved learning by repeated interactions with the environment. However, a typical deep reinforcement leaning algorithm converges slower to find an optimal sequence of actions to reach out a goal state. In this article, we design a particle swarm optimization (PSO) based deep Q-learning algorithm for detecting social spam bots by integrating PSO with Q-value function. In addition, spam-influential users are identified using the proposed spam influence minimization model and it helps in restricting the flow of illegitimate tweets in Twitter network. Further, an influential community detection algorithm has been proposed to reduce the spreading of spam content through influential communities in Twitter network. Experimental results illustrate the efficacy of our proposed algorithms by considering two Twitter datasets and performance metrics such as precision, recall, and modularity.
C1 [Lingam, Greeshma; Rout, Rashmi Ranjan; Somayajulu, D. V. L. N.] Natl Inst Technol NIT, Dept Comp Sci & Engn, Warangal 506004, Andhra Pradesh, India.
   [Somayajulu, D. V. L. N.] IIITDM, Kurnool 518007, India.
   [Ghosh, Soumya K.] Indian Inst Technol IIT Kharagpur, Dept Comp Sci & Engn, Kharagpur 721302, W Bengal, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Warangal; Indian Institute of Information Technology, Design
   & Manufacturing, Kancheepuram; Indian Institute of Technology System
   (IIT System); Indian Institute of Technology (IIT) - Kharagpur
RP Lingam, G (corresponding author), Natl Inst Technol NIT, Dept Comp Sci & Engn, Warangal 506004, Andhra Pradesh, India.
EM greeshma.lingam@student.nitw.ac.in; rashrr@nitw.ac.in; soma@nitw.ac.in;
   skg@cse.iitkgp.ac.in
CR Alam S, 2014, 2014 IEEE CONGRESS ON EVOLUTIONARY COMPUTATION (CEC), P2955, DOI 10.1109/CEC.2014.6900644
   Barushka A, 2018, APPL INTELL, V48, P3538, DOI 10.1007/s10489-018-1161-y
   Budak C., 2011, P 20 INT C WORLD WID, P665, DOI DOI 10.1145/1963405.1963499
   Cai CY, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENCE AND SECURITY INFORMATICS (ISI), P128, DOI 10.1109/ISI.2017.8004887
   Choo E, 2017, J COMPUT SECUR, V25, P283, DOI 10.3233/JCS-16941
   Cresci S, 2017, WWW'17 COMPANION: PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P963, DOI 10.1145/3041021.3055135
   Dang Q, 2017, DATA MIN KNOWL DISC, V31, P573, DOI 10.1007/s10618-016-0479-5
   Daniel F, 2019, IEEE INTERNET COMPUT, V23, P40, DOI 10.1109/MIC.2019.2893137
   Das PK, 2016, ENG SCI TECHNOL, V19, P651, DOI 10.1016/j.jestch.2015.09.009
   Du WB, 2017, IEEE T CIRCUITS-II, V64, P467, DOI 10.1109/TCSII.2016.2595597
   Ernst, ARXIV151202011
   Fang ZY, 2019, IEEE ACCESS, V7, P48867, DOI 10.1109/ACCESS.2019.2908033
   Ferrara E, 2016, COMMUN ACM, V59, P96, DOI 10.1145/2818717
   He Q, 2020, IEEE SYST J, V14, P1874, DOI 10.1109/JSYST.2019.2922373
   Hein D, 2017, ENG APPL ARTIF INTEL, V65, P87, DOI 10.1016/j.engappai.2017.07.005
   Jagielski M, 2018, P IEEE S SECUR PRIV, P19, DOI 10.1109/SP.2018.00057
   Jiao JT, 2017, IEEE T INFORM THEORY, V63, P6774, DOI 10.1109/TIT.2017.2733537
   Kempe D., 2015, THEOR COMPUT, V11, P105, DOI DOI 10.1145/956750.956769
   Lee K., 2011, P 5 INT AAAI C WEBL, P185
   Li SH, 2015, ACM TRANS MANAG INF, V6, DOI 10.1145/2676869
   Li YL, 2020, IEEE T CYBERNETICS, V50, P2002, DOI 10.1109/TCYB.2019.2927410
   Liangliang Zhang, 2019, 2019 IEEE Fourth International Conference on Data Science in Cyberspace (DSC). Proceedings, P264, DOI 10.1109/DSC.2019.00047
   Lim M, 2021, J KING SAUD UNIV-COM, V33, P1202, DOI 10.1016/j.jksuci.2019.07.010
   Lin YG, 2021, IEEE T SYST MAN CY-S, V51, P3725, DOI 10.1109/TSMC.2019.2930908
   Lin YG, 2019, IEEE T VEH TECHNOL, V68, P9220, DOI 10.1109/TVT.2019.2930667
   Lingam G, 2019, INT CONF COMPUT
   Lingam G, 2019, APPL INTELL, V49, P3947, DOI 10.1007/s10489-019-01488-3
   Lingam G, 2018, INT CONF IND INF SYS, P280, DOI 10.1109/ICIINFS.2018.8721318
   Madisetty S, 2018, IEEE T COMPUT SOC SY, V5, P973, DOI 10.1109/TCSS.2018.2878852
   Newman MEJ, 2013, PHYS REV E, V88, DOI 10.1103/PhysRevE.88.042822
   Nguyen ND, 2017, IEEE ACCESS, V5, P27091, DOI 10.1109/ACCESS.2017.2777827
   Samma H, 2016, APPL SOFT COMPUT, V43, P276, DOI 10.1016/j.asoc.2016.01.006
   Shen MC, 2019, IEEE INT CONF ROBOT, P3384, DOI 10.1109/ICRA.2019.8794389
   Shi PN, 2019, IEEE ACCESS, V7, P28855, DOI 10.1109/ACCESS.2019.2901864
   Su YS, 2021, IEEE T SYST MAN CY-S, V51, P2833, DOI 10.1109/TSMC.2019.2917215
   Subrahmanian VS, 2016, COMPUTER, V49, P38, DOI 10.1109/MC.2016.183
   Tang R, 2018, NEUROCOMPUTING, V314, P1, DOI 10.1016/j.neucom.2018.03.043
   Van Der Walt E, 2018, IEEE ACCESS, V6, P6540, DOI 10.1109/ACCESS.2018.2796018
   Wan PF, 2021, IEEE T KNOWL DATA EN, V33, P2548, DOI 10.1109/TKDE.2019.2954901
   Wang HZ, 2019, IEEE ACCESS, V7, P17480, DOI 10.1109/ACCESS.2019.2894756
   Wang YD, 2019, IEEE ACCESS, V7, P39974, DOI 10.1109/ACCESS.2019.2902846
   Wang Z, 2018, KNOWL INF SYST, V55, P571, DOI 10.1007/s10115-017-1068-7
   Wen S, 2015, IEEE T COMPUT, V64, P640, DOI 10.1109/TC.2013.2295802
   Yu C, 2015, IEEE T NEUR NET LEAR, V26, P3083, DOI 10.1109/TNNLS.2015.2403394
   Zhang L, 2018, IEEE ACCESS, V6, P2559, DOI 10.1109/ACCESS.2017.2784370
   Zhang YY, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/807527
   Zhou N, 2020, WORLD WIDE WEB, V23, P75, DOI 10.1007/s11280-019-00697-7
NR 47
TC 0
Z9 0
U1 11
U2 14
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1932-8184
EI 1937-9234
J9 IEEE SYST J
JI IEEE Syst. J.
PD JUN
PY 2021
VL 15
IS 2
BP 2281
EP 2292
DI 10.1109/JSYST.2020.3034416
PG 12
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Operations Research & Management Science; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Operations Research & Management Science;
   Telecommunications
GA SP3DJ
UT WOS:000659552700076
DA 2022-02-06
ER

PT J
AU Xu, ZY
   Guo, YJ
   Saleh, JH
AF Xu, Zhaoyi
   Guo, Yanjie
   Saleh, Joseph Homer
TI Tackling Small Data Challenges in Visual Fire Detection: A Deep
   Convolutional Generative Adversarial Network Approach
SO IEEE ACCESS
LA English
DT Article
DE Visualization; Training; Generators; Generative adversarial networks;
   Computer architecture; Computational modeling; Gallium nitride; Deep
   convolutional generative adversarial network; self-supervised learning;
   visual fire detection
ID NEURAL-NETWORKS; SURVEILLANCE
AB Fire detection technologies remain a critical component of building automation. With the recent significant advances in computer vision, visual fire detection methods have been developed and integrated into building surveillance systems. Overfitting and accuracy challenges remain in fire detection when training datasets are limited. In this work, we tackle these challenges by developing a deep convolutional generative adversarial network (DCGAN) for highly accurate visual fire detection when training images are limited. Our model addresses three types of errors in visual fire detection with small training datasets: model overfitting, fire probability overestimation, and fire probability underestimation. The DCGAN includes a generator of fake fire images for self-supervised learning (SSL) and a discriminator for image classification. We designed computational experiments with high-quality datasets to test and validate our model against other supervised learning approaches. We also benchmarked the performance of the DCGAN against a best-in-class deep visual fire detection model. The results show that our model significantly outperforms other fire detection models on all performance metrics when trained with the same small dataset. The results demonstrate that the DCGAN effectively mitigates the three types of error when the training dataset is limited.
C1 [Xu, Zhaoyi; Guo, Yanjie; Saleh, Joseph Homer] Georgia Inst Technol, Sch Aerosp Engn, Atlanta, GA 30332 USA.
C3 University System of Georgia; Georgia Institute of Technology
RP Xu, ZY (corresponding author), Georgia Inst Technol, Sch Aerosp Engn, Atlanta, GA 30332 USA.
EM zxu328@gatech.edu
RI Xu, Zhaoyi/ABB-5876-2021
OI Guo, Yanjie/0000-0002-1115-7383; saleh, jospeh
   homer/0000-0001-7590-9399; Xu, Zhaoyi/0000-0002-8498-3483
FU Space Technology Research Institute through the National Aeronautics and
   Space Administration's (NASA's) Space Technology Research Grants Program
FX This work was supported by the Space Technology Research Institute
   through the National Aeronautics and Space Administration's (NASA's)
   Space Technology Research Grants Program.
CR Ansari A., 2019, ARXIV PREPRINT ARXIV, P1905
   Bojanowski Piotr, 2017, ARXIV170705776
   Brock A., 2018, LARGE SCALE GAN TRAI, DOI DOI 10.1016/J.VETIMM.2015.04.007
   Celik Turgay, 2007, 2007 15th European Signal Processing Conference (EUSIPCO), P1794
   Chaoxia CY, 2020, IEEE ACCESS, V8, P58923, DOI 10.1109/ACCESS.2020.2982994
   Chen TH, 2004, IEEE IMAGE PROC, P1707
   Chintala S, 2015, ARXIV151106434
   Dailey M. N., 2012, P IEEE INT C EL ENG, P1
   Forsyth David A, 2002, COMPUTER VISION MODE
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Gudivada V., 2017, INT J ADV SOFTWARE, V10, P1
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang XC, 2020, IEEE ACCESS, V8, P77951, DOI 10.1109/ACCESS.2020.2990224
   Iandola F.N., 2016, ARXIV160207360
   Kim J.-H., 2019, IEEE ACCESS, V7
   King DB, 2015, ACS SYM SER, V1214, P1
   Kingma DP, 2019, FOUND TRENDS MACH LE, V12, P4, DOI 10.1561/2200000056
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu Z, 2003, J FIRE PROTECT ENG, V13, P129
   Maas A. L., 2013, P 30 INT C MACH LEAR, V28, P1
   Mao WT, 2018, FIRE TECHNOL, V54, P531, DOI 10.1007/s10694-017-0695-6
   Muhammad K, 2019, IEEE T IND INFORM, V15, P3113, DOI 10.1109/TII.2019.2897594
   Muhammad K, 2019, IEEE T SYST MAN CY-S, V49, P1419, DOI 10.1109/TSMC.2018.2830099
   Muhammad K, 2018, IEEE ACCESS, V6, P18174, DOI 10.1109/ACCESS.2018.2812835
   Muhammad K, 2018, NEUROCOMPUTING, V288, P30, DOI 10.1016/j.neucom.2017.04.083
   Rafiee A, 2011, 2011 3rd International Conference on Computer Research and Development (ICCRD 2011), P262, DOI 10.1109/ICCRD.2011.5764295
   Ravanbakhsh M, 2019, IEEE WINT CONF APPL, P1896, DOI 10.1109/WACV.2019.00206
   Roque G, 2020, IEEE ACCESS, V8, P114900, DOI 10.1109/ACCESS.2020.3003848
   Sharma J, 2017, COMM COM INF SC, V744, P183, DOI 10.1007/978-3-319-65172-9_16
   Shen DQ, 2018, CONFERENCE PROCEEDINGS OF 2018 4TH INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND ROBOTICS (ICCAR), P416, DOI 10.1109/ICCAR.2018.8384711
   Simonyan K, 2015, ICLR 2015, DOI DOI 10.1109/CVPR.2015.7298594
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Szeliski R, 2011, TEXTS COMPUT SCI, P1, DOI 10.1007/978-1-84882-935-0
   Voulodimos A, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/7068349
   Wu ZY, 2020, IEEE ACCESS, V8, P132466, DOI 10.1109/ACCESS.2020.3010212
   Xie YK, 2020, IEEE ACCESS, V8, P81904, DOI 10.1109/ACCESS.2020.2991338
   Xu G, 2019, IEEE ACCESS, V7, P29471, DOI 10.1109/ACCESS.2019.2902606
   Yang H, 2019, IEEE ACCESS, V7, P169257, DOI 10.1109/ACCESS.2019.2953558
   Zhang QJ, 2016, ADV SOC SCI EDUC HUM, V47, P568
   Zhou ZH, 2018, NATL SCI REV, V5, P44, DOI 10.1093/nsr/nwx106
   Zinkevich M., 2018, P SYSML C, P1
NR 42
TC 1
Z9 1
U1 6
U2 12
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2021
VL 9
BP 3936
EP 3946
DI 10.1109/ACCESS.2020.3047764
PG 11
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA PS1CU
UT WOS:000607669100001
OA gold
DA 2022-02-06
ER

PT J
AU Wu, LW
   Rao, Y
   Yu, HL
   Wang, YM
   Ambreen, N
AF Wu Lianwei
   Rao Yuan
   Yu Hualei
   Wang Yiming
   Ambreen, Nazir
TI A Multi-semantics Classification Method Based on Deep Learning for
   Incredible Messages on Social Media
SO CHINESE JOURNAL OF ELECTRONICS
LA English
DT Article
DE Information credibility evaluation; Rumor detection; Social media; Text
   classification
AB How to classify incredible messages has attracted great attention from academic and industry nowadays. The recent work mainly focuses on one type of incredible messages (a.k.a rumors or fake news) and achieves some success to detect them. The existing problem is that incredible messages have different types on social media, and rumors or fake news cannot represent all incredible messages. Based on this, in the paper, we divide messages on social media into five types based on three dimensions of information evaluation metrics. And a novel method is proposed based on deep learning for classifying the five types of incredible messages on social media. More specifically, we use attention mechanism to obtain deep text semantic features and strengthen emotional semantics features, meanwhile, construct universal meta-data as auxiliary features, concatenating them for incredible messages classification. A series of experiments on two representative real-world datasets demonstrate that the proposed method outperforms the state-of-the-art methods.
C1 [Wu Lianwei; Rao Yuan; Yu Hualei; Wang Yiming; Ambreen, Nazir] Xi An Jiao Tong Univ, Sch Software Engn, Lab Social Intelligence & Complex Data Proc, Xian 710049, Shaanxi, Peoples R China.
C3 Xi'an Jiaotong University
RP Rao, Y (corresponding author), Xi An Jiao Tong Univ, Sch Software Engn, Lab Social Intelligence & Complex Data Proc, Xian 710049, Shaanxi, Peoples R China.
EM stayhungry@stu.xjtu.edu.cn; yuanrao@163.com;
   ambreen.nazir_@ciitwah.edu.pk
RI Nazir, Ambreen/AAA-3084-2022
OI Nazir, Ambreen/0000-0002-1764-7375; Wu, Lianwei/0000-0003-1451-9295
FU World-Class Universities(Disciplines) [PY3A022]; Characteristic
   Development Guidance Funds for the Central Universities [PY3A022];
   National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [F020807]; Ministry of Education Fund Project
   "Cloud Number Integration Science and Education Innovation"
   [2017B00030]; Basic Scientific Research Operating Expenses of Central
   Universities [ZDYF2017006]; Shaanxi Provincial Science and Technology
   Department Collaborative Innovation Project [2015XT-21]; Shaanxi Soft
   Science Key Project [2013KRZ10]
FX This work is supported by the World-Class Universities(Disciplines) and
   the Characteristic Development Guidance Funds for the Central
   Universities(No.PY3A022), the National Natural Science Foundation of
   China (No.F020807), Ministry of Education Fund Project "Cloud Number
   Integration Science and Education Innovation" (No.2017B00030), Basic
   Scientific Research Operating Expenses of Central Universities
   (No.ZDYF2017006), Shaanxi Provincial Science and Technology Department
   Collaborative Innovation Project (No.2015XT-21), and Shaanxi Soft
   Science Key Project (No.2013KRZ10).
CR Bandanau D., 2014, ARXIV14090473
   Bessi A, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0118093
   Castillo C., 2011, WWW, P675
   Choi YK, 2017, INTERNET RES, V27, P495, DOI 10.1108/IntR-07-2016-0198
   Gupta A, 2014, LECT NOTES COMPUT SC, V8851, P228, DOI 10.1007/978-3-319-13734-6_16
   Hermann KM, 2015, ADV NEUR IN, V28
   Hu YH, 2018, PHYSICA A, V502, P331, DOI 10.1016/j.physa.2018.02.096
   Imran M, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), P507, DOI 10.1145/3184558.3186242
   Kahne J, 2017, AM EDUC RES J, V54, P3, DOI 10.3102/0002831216679817
   Kapferer J., 2017, RUMORS USES INTERPRE
   Kim S., 2015, P INT C INF KNOWL MA, P1131
   Kwon S, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0168344
   Lazer DMJ, 2018, SCIENCE, V359, P1094, DOI 10.1126/science.aao2998
   Li JW, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1566
   Li S, 2013, P 51 ANN M ASS COMP, V2, P217
   Ma J., 2015, P 24 ACM INT C INF K, V19-23, P1751, DOI DOI 10.1145/2806416.2806607
   Mikolov T., 2013, ARXIV13013781
   Paulus R., 2017, ARXIV170504304
   Popat K, 2017, WWW'17 COMPANION: PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P1003, DOI 10.1145/3041021.3055133
   Qin YM, 2018, CHINESE J ELECTRON, V27, P514, DOI 10.1049/cje.2018.03.008
   Sedhai S, 2018, IEEE T COMPUT SOC SY, V5, P169, DOI 10.1109/TCSS.2017.2773581
   Shengyun Sun, 2013, Web Technologies and Applications. 15th Asia-Pacific Web Conference, APWeb 2013. Proceedings, P120, DOI 10.1007/978-3-642-37401-2_14
   Tandoc EC, 2018, DIGIT JOURNAL, V6, P137, DOI 10.1080/21670811.2017.1360143
   Tseng S, 1999, COMMUN ACM, V42, P39, DOI 10.1145/301353.301402
   Vaswani A, 2017, ADV NEUR IN, P5998
   Viviani M, 2017, WIRES DATA MIN KNOWL, V7, DOI 10.1002/widm.1209
   Volkova S, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), P575, DOI 10.1145/3184558.3188728
   Wang B, 2017, IEEE T KNOWL DATA EN, V29, P2168, DOI 10.1109/TKDE.2017.2728064
   Wang WY, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P422, DOI 10.18653/v1/P17-2067
   Wang YM, 2017, 2017 13TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS), P452, DOI 10.1109/CIS.2017.00105
   Wu K, 2015, PROC INT CONF DATA, P651, DOI 10.1109/ICDE.2015.7113322
   Wu LW, 2018, LECT NOTES COMPUT SC, V11186, P323, DOI 10.1007/978-3-030-01159-8_31
   Xu K., 2015, ICML, V14, P77
   Zhao Z, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P1395, DOI 10.1145/2736277.2741637
   Zhou Guorui, 2017, ARXIV170606978
NR 35
TC 6
Z9 6
U1 2
U2 33
PU TECHNOLOGY EXCHANGE LIMITED HONG KONG
PI BEIJING
PA BLDG#13, PUHUINANLI, SOUTH YUYUANTAN RD, HAIDIAN DIST, BEIJING, 00000,
   PEOPLES R CHINA
SN 1022-4653
EI 2075-5597
J9 CHINESE J ELECTRON
JI Chin. J. Electron.
PD JUL
PY 2019
VL 28
IS 4
BP 754
EP 763
DI 10.1049/cje.2019.05.002
PG 10
WC Engineering, Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA IM0OH
UT WOS:000477687600012
DA 2022-02-06
ER

PT J
AU Wu, LW
   Rao, Y
   Nazir, A
   Jin, HL
AF Wu, Lianwei
   Rao, Yuan
   Nazir, Ambreen
   Jin, Haolin
TI Discovering differential features: Adversarial learning for information
   credibility evaluation
SO INFORMATION SCIENCES
LA English
DT Article
DE Information credibility evaluation; Fake news detection; Adversarial
   networks; Reinforcement learning
ID FAKE NEWS
AB A series of deep learning approaches extract a large number of credibility features to detect fake news on the Internet. However, these extracted features still suffer from many irrelevant and noisy features that restrict severely the performance of the approaches. In this paper, we propose a novel model based on Adversarial Networks and inspirited by the Shared-Private model (ANSP), which aims at reducing common, irrelevant features from the extracted features for information credibility evaluation. Specifically, ANSP involves two tasks: one is to prevent the binary classification of true and false information for capturing common features relying on adversarial networks guided by reinforcement learning. Another extracts credibility features (henceforth, private features) from multiple types of credibility information and compares with the common features through two strategies, i.e., orthogonality constraints and KL-divergence for making the private features more differential. Experiments first on two six-label LIAR and Weibo datasets demonstrate that ANSP achieves state-of-the-art performance, boosting the accuracy by 2.1%, 3.1%, respectively and then on four-label Twitter16 validate the robustness of the model with 1.8% performance improvements. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Wu, Lianwei; Rao, Yuan; Nazir, Ambreen; Jin, Haolin] Xi An Jiao Tong Univ, Sch Software Engn, Social Intelligence & Complex Data Proc, Xian, Peoples R China.
C3 Xi'an Jiaotong University
RP Rao, Y (corresponding author), Xi An Jiao Tong Univ, Sch Software Engn, Social Intelligence & Complex Data Proc, Xian, Peoples R China.
EM stayhungry@stu.xjtu.edu.cn; raoyuan@mail.xjtu.edu.cn;
   ambreen.nazir@stu.xjtu.edu.cn; jinhaolin@stu.xjtu.edu.cn
RI Nazir, Ambreen/AAA-3084-2022
OI Nazir, Ambreen/0000-0002-1764-7375
FU World-Class Universities; Characteristic Development Guidance Funds for
   the Central Universities [PY3A022]; Shenzhen Science and Technology
   Project [JCYJ201803061708 36595]; National Natural Science Fund of
   ChinaNational Natural Science Foundation of China (NSFC) [F020807];
   Ministry of Education Fund Project "Cloud Number Integration Science and
   Education Innovation" [20171300030]; Basic Scientific Research Operating
   Expenses of Central Universities [ZDYF2017006]
FX This work has received funding from "the World-Class Universities
   (Disciplines) and the Characteristic Development Guidance Funds for the
   Central Universities" (PY3A022), Shenzhen Science and Technology Project
   (JCYJ201803061708 36595), the National Natural Science Fund of China
   (No. F020807), Ministry of Education Fund Project "Cloud Number
   Integration Science and Education Innovation" (No.20171300030), Basic
   Scientific Research Operating Expenses of Central Universities
   (No.ZDYF2017006). We would like to thanks them for providing support.
CR Ajao O, 2019, INT CONF ACOUST SPEE, P2507, DOI 10.1109/ICASSP.2019.8683170
   Allcott H, 2017, J ECON PERSPECT, V31, P211, DOI 10.1257/jep.31.2.211
   Bousmalis K., 2016, ADV NEURAL INFORM PR
   Buechel S., 2018, P 2018 C N AM COMP L, V1, P1907
   Castillo C., 2011, WWW, P675
   Chen XX, 2019, J NEUROSURG, V130, P1906, DOI 10.3171/2017.12.JNS172178
   Conti E., 2018, ADV NEURAL INFORM PR, P5027
   Crammer K, 2002, J MACH LEARN RES, V2, P265, DOI 10.1162/15324430260185628
   De Sarkar Sohan, 2018, 27 INT C COMP LING C, P3371
   Ghenai Amira, 2018, Proceedings of the ACM on Human-Computer Interaction, V2, DOI 10.1145/3274327
   GLYNN PW, 1990, COMMUN ACM, V33, P75, DOI 10.1145/84537.84552
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Grinberg N, 2019, SCIENCE, V363, P374, DOI 10.1126/science.aau2706
   Henderson P, 2018, THIRTY-SECOND AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTIETH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / EIGHTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P3207
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735
   Huang CR, 2017, P 8 INT JOINT C NAT, V2, P252
   Jin ZW, 2016, THIRTIETH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2972
   Karimi H., 2018, P 27 INT C COMP LING, P1546
   Kenter T, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1403, DOI 10.1145/3077136.3082062
   Kim, 2014, ARXIV14085882, P1746, DOI [10.3115/v1/d14, 10.3115/v1/D14-1181]
   Kudugunta S, 2018, INFORM SCIENCES, V467, P312, DOI 10.1016/j.ins.2018.08.019
   Kwon S, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0168344
   Lample G, 2017, THIRTY-FIRST AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2140
   Lan OY, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P6049, DOI 10.1109/ICASSP.2018.8462669
   Lazer DMJ, 2018, SCIENCE, V359, P1094, DOI 10.1126/science.aao2998
   Li SH, 2019, THIRTY-THIRD AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTY-FIRST INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / NINTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P4213
   Li T, 2015, INT C ELECTR MACH SY, P1752, DOI 10.1109/ICEMS.2015.7385324
   Liu JC, 2017, PROC CVPR IEEE, P4123, DOI 10.1109/CVPR.2017.439
   Liu PF, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1, DOI 10.18653/v1/P17-1001
   Liu SY, 2018, INFORM SCIENCES, V439, P1, DOI 10.1016/j.ins.2018.01.044
   Liu Y, 2018, THIRTY-SECOND AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTIETH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / EIGHTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P354
   Lu JS, 2017, ADV NEUR IN, V30
   Ma J., 2016, P 25 INT JOINT C ART, P3818
   Ma J, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), P585, DOI 10.1145/3184558.3188729
   Ma J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1980
   Ma J, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P708, DOI 10.18653/v1/P17-1066
   Mikolov T., 2013, ARXIV13013781
   Morstatter F, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), P621, DOI 10.1145/3184558.3188733
   Potthast M, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P231
   Rashkin Hannah, 2017, P 2017 C EMPIRICAL M, P2931
   Rathore S, 2017, INFORM SCIENCES, V421, P43, DOI 10.1016/j.ins.2017.08.063
   Reis JCS, 2019, IEEE INTELL SYST, V34, P76, DOI 10.1109/MIS.2019.2899143
   Ribeiro M., 2017, SHEEP WOLVES CHARACT
   Ruchansky N, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P797, DOI 10.1145/3132847.3132877
   Shu K., 2019, ARXIV190413355
   Shu K., 2019, 33 AAAI C ART INT
   Sutton RS, 2000, ADV NEUR IN, V12, P1057
   Tacchini E., 2017, ARXIV170407506, DOI DOI 10.1257/JEP.31.2.211
   Trottier L, 2017, ARXIV171100111
   Tseng S, 1999, COMMUN ACM, V42, P39, DOI 10.1145/301353.301402
   Vosoughi S, 2018, SCIENCE, V359, P1146, DOI 10.1126/science.aap9559
   Wang WY, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P422, DOI 10.18653/v1/P17-2067
   Wang YQ, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P849, DOI 10.1145/3219819.3219903
   Wang YM, 2017, 2017 13TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS), P452, DOI 10.1109/CIS.2017.00105
   WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696
   Wu L., 2019, P 2019 C EMP METH NA, P4644
   Wu L, 2018, WSDM'18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P637, DOI 10.1145/3159652.3159677
   Wu LW, 2018, LECT NOTES COMPUT SC, V11186, P323, DOI 10.1007/978-3-030-01159-8_31
   Yang DD, 2018, PHYSICA A, V503, P640, DOI 10.1016/j.physa.2018.02.128
   Yu LT, 2017, THIRTY-FIRST AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2852
   Yu P.-D., 2018, IEEE ACM INT C ADV S, P175
   Zhang T., 2018, AAAI
   Zhang YY, 2014, PROCEEDINGS OF THE TWENTY-EIGHTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1369
   Zhao Z, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P1395, DOI 10.1145/2736277.2741637
NR 64
TC 9
Z9 9
U1 0
U2 18
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 0020-0255
EI 1872-6291
J9 INFORM SCIENCES
JI Inf. Sci.
PD APR
PY 2020
VL 516
BP 453
EP 473
DI 10.1016/j.ins.2019.12.040
PG 21
WC Computer Science, Information Systems
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KO3FB
UT WOS:000515432200027
OA Green Submitted
DA 2022-02-06
ER

PT J
AU Jain, S
   Seth, G
   Paruthi, A
   Soni, U
   Kumar, G
AF Jain, Saksham
   Seth, Gautam
   Paruthi, Arpit
   Soni, Umang
   Kumar, Girish
TI Synthetic data augmentation for surface defect detection and
   classification using deep learning
SO JOURNAL OF INTELLIGENT MANUFACTURING
LA English
DT Article; Early Access
DE Surface defects; Classification; Convolutional neural network;
   Generative adversarial network; Deep learning
ID STEEL STRIP
AB Deep learning techniques, especially Convolutional Neural Networks (CNN), dominate the benchmarks for most computer vision tasks. These state-of-the-art results are typically obtained through supervised learning, for which large annotated datasets are required. However, acquiring such datasets for manufacturing applications remains a challenging proposition due to the time and costs involved in their collection. To overcome this disadvantage, a novel framework is proposed for data augmentation by creating synthetic images using Generative Adversarial Networks (GANs). The generator synthesizes new surface defect images from random noise which is trained over time to get realistic fakes. These synthetic images can be used further for training of classification algorithms. Three GAN architectures are trained, and the entire data augmentation pipeline is implemented for the Northeastern University (China) Classification (NEU-CLS) dataset for hot-rolled steel strips from NEU Surface Defect Database. The classification accuracy of a simple CNN architecture is measured on synthetic augmented data and further it is compared with similar state-of-the-arts. It is observed that the proposed GANs-based augmentation scheme significantly improves the performance of CNN for classification of surface defects. The classically augmented CNN yields sensitivity and specificity of 90.28% and 98.06% respectively. In contrast, the synthetically augmented CNN yields better results, with sensitivity and specificity of 95.33% and 99.16% respectively. Also, the use of GANs is demonstrated to disentangle the representation space and to add additional domain knowledge through synthetic augmentation that can be difficult to replicate through classic augmentation. The proposed framework demonstrates high generalization capability. It may be applied to other supervised surface inspection tasks, and thus facilitate the development of advanced vision-based inspection instruments for manufacturing applications.
C1 [Jain, Saksham; Seth, Gautam; Paruthi, Arpit; Soni, Umang] Netaji Subhas Univ Technol, New Delhi, India.
   [Kumar, Girish] Delhi Technol Univ, New Delhi, India.
C3 Netaji Subhas University of Technology; Delhi Technological University
RP Soni, U (corresponding author), Netaji Subhas Univ Technol, New Delhi, India.
EM umangsoni.1@gmail.com
OI Soni, Umang/0000-0003-3583-311X
CR Antoniou Antreas, 2018, INT C ART NEUR NETW
   Arjovsky M, 2017, ARXIV170107875
   Arjovsky M., 2017, ADV NEURAL INFORM PR, P5769
   Badmos O, 2020, J INTELL MANUF, V31, P885, DOI 10.1007/s10845-019-01484-x
   Berthelot D., 2017, ARXIV170310717
   Bousmalis K, 2017, PROC CVPR IEEE, P95, DOI 10.1109/CVPR.2017.18
   Carreira-Perpinan M.A, 2005, AISTATS, V10, P33
   Chen X., 2016, ADV NEURAL INFORM PR, DOI DOI 10.1007/S00542-016-3060-7
   Chintala S, 2015, ARXIV151106434
   Davtalab O, 2020, J INTELL MANUF, DOI 10.1007/s10845-020-01684-w
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   DEVADAS C, 1991, METALL TRANS A, V22, P335, DOI 10.1007/BF02656802
   Dong Yang, 2017, Medical Image Computing and Computer Assisted Intervention - MICCAI 2017. 20th International Conference. Proceedings: LNCS 10435, P507, DOI 10.1007/978-3-319-66179-7_58
   Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316
   Feng S, 2019, MATER DESIGN, V162, P300, DOI 10.1016/j.matdes.2018.11.060
   Frid-Adar M, 2018, I S BIOMED IMAGING, P289, DOI 10.1109/ISBI.2018.8363576
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Grzenda M, 2019, J INTELL MANUF, V30, P933, DOI 10.1007/s10845-018-1413-z
   Hao RY, 2021, J INTELL MANUF, V32, P1833, DOI 10.1007/s10845-020-01670-2
   HINTON GE, 1995, SCIENCE, V268, P1158, DOI 10.1126/science.7761831
   Hjelm Devon, 2018, ICLR
   Huang Y., 2018, VISUAL COMPUT
   Izadi A, 2018, INT J GEOM METHODS M, V15, DOI 10.1142/S0219887818500846
   Kingma DP, 2014, 2 INT C LEARN REPR I, P1
   Lai YTK, 2018, IEEE ASME INT C ADV, P1444, DOI 10.1109/AIM.2018.8452228
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li JA, 2017, PROC CVPR IEEE, P1951, DOI 10.1109/CVPR.2017.211
   Luo J, 2021, J INTELL MANUF, V32, P407, DOI 10.1007/s10845-020-01579-w
   Madani A, 2018, PROC SPIE, V10574, DOI 10.1117/12.2293971
   Mao Xudong, 2017, P IEEE INT C COMP VI
   Mirza M., 2014, ARXIV14111784, P1
   Moeskops P, 2017, LECT NOTES COMPUT SC, V10553, P56, DOI 10.1007/978-3-319-67558-9_7
   Mohammed Safwan K. P., 2017, SPIE MED IMAGING
   Odena A, 2017, PR MACH LEARN RES, V70
   Pan J., 2017, CVPR SCEN UND WORKSH
   Richter SR, 2016, LECT NOTES COMPUT SC, V9906, P102, DOI 10.1007/978-3-319-46475-6_7
   Scime L, 2018, ADDIT MANUF, V19, P114, DOI 10.1016/j.addma.2017.11.009
   Sermanet P., 2014, P INT C LEARN REPR
   Shrivastava A, 2017, PROC CVPR IEEE, P2242, DOI 10.1109/CVPR.2017.241
   Song K., 2019, NEU SURFACE DEFECT D
   Song KC, 2013, APPL SURF SCI, V285, P858, DOI 10.1016/j.apsusc.2013.09.002
   Song Kechen, 2014, J COMPUT INFORM SYST, V10, P3049, DOI DOI 10.12733/JCIS10026
   Sun TH, 2016, J INTELL MANUF, V27, P639, DOI 10.1007/s10845-014-0902-y
   Tabernik D, 2020, J INTELL MANUF, V31, P759, DOI 10.1007/s10845-019-01476-x
   Tian Y, 2017, MASTER CHINESE CALLI
   Wolterink JM, 2017, IEEE T MED IMAGING, V36, P2536, DOI 10.1109/TMI.2017.2708987
   Yu HL, 2013, INT J ADV MANUF TECH, V67, P1161, DOI 10.1007/s00170-012-4556-7
   Zhai W, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1283, DOI 10.1109/ICASSP.2018.8462364
   Zhang ZF, 2017, PROC CVPR IEEE, P4352, DOI 10.1109/CVPR.2017.463
   Zhao J. J., 2017, P INT C LEARN REPR T
   Zhu X., 2018, ADV KNOWLEDGE DISCOV
NR 51
TC 4
Z9 4
U1 16
U2 38
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0956-5515
EI 1572-8145
J9 J INTELL MANUF
JI J. Intell. Manuf.
DI 10.1007/s10845-020-01710-x
EA NOV 2020
PG 14
WC Computer Science, Artificial Intelligence; Engineering, Manufacturing
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OS9VM
UT WOS:000590504300001
DA 2022-02-06
ER

PT J
AU Chen, JL
   Ma, YW
   Tsai, SY
AF Chen, Jiann-Liang
   Ma, Yi-Wei
   Tsai, Song-Yun
TI Intelligent Classifier for Identify Reliable On-Demand Messages
SO JOURNAL OF INTERNET TECHNOLOGY
LA English
DT Article
DE Deep learning; Long Short Term Memory (LSTM) algorithm; Natural language
   processing; Fake news; On-demand message
AB Accurately extracting useful messages from bodies of information is important. This work proposes an intelligent system, called AI@nti-Fake system, to categories social news and determine whether it is true or false. The news is preprocessed using a Natural Language Processing technique. The text sentiment analysis in the on-demand message is analyzed to identify the fake news. A dataset from the International Workshop on Semantic Evaluation is used in this study. The on-demand message is related to the public's attention, and the analyzed text sentiment is identified as positive, neutral or negative. The accuracies of the proposed AI@nti-Fake system in the training stage and the real data test can reach 90% and 80%, respectively. The F1-Score of the proposed approach and two others methods are 78.50, 64.84 and 64.59, respectively. The results of the analysis reveal that the F1-Score of our approach can get better performance in classifying on-demand messages and detecting disinformation. The proposed AI@nti-Fake system, which is based on social media analysis and the judgment of sentiment may have applications in business.
C1 [Chen, Jiann-Liang; Ma, Yi-Wei; Tsai, Song-Yun] Natl Taiwan Univ Sci & Technol, Dept Elect Engn, Taipei, Taiwan.
C3 National Taiwan University of Science & Technology
RP Ma, YW (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Elect Engn, Taipei, Taiwan.
EM lchen@mail.ntust.edu.tw; ywma@mail.ntust.edu.tw; sul1221122su@gmail.com
FU National Taiwan University of Science and Technology under Ministry of
   Science and Technology, Taiwan [MOST 108-2221-E-011-068-MY2]
FX This work is a partial result of project No. MOST 108-2221-E-011-068-MY2
   conducted by National Taiwan University of Science and Technology under
   the sponsorship of Ministry of Science and Technology, Taiwan.
CR Bengio Y., 2011, ICML, P513, DOI DOI 10.1177/1753193411430810
   Dovdon E., 2017, 11 INT WORKSH SEM EV, P644
   Feldman R., 2007, TEXT MINING HDB ADV
   Hagen M., 2015, 9 INT WORKSH SEM EV, P582
   Hassanpour S, 2019, NEUROPSYCHOPHARMACOL, V44, P487, DOI 10.1038/s41386-018-0247-x
   Keyes R, 2004, POSTTRUTH ERA DISHON
   Manning C., 1999, FDN STAT NATURAL LAN
   Manzoor Syed Ishfaq, 2019, 2019 3rd International Conference on Trends in Electronics and Informatics (ICOEI). Proceedings, P230, DOI 10.1109/ICOEI.2019.8862770
   Nguyen DT, 2015, MOBILE NETW APPL, V20, P475, DOI 10.1007/s11036-014-0557-0
   Peng J, 2017, CONCURR COMP-PRACT E, V29, DOI 10.1002/cpe.4013
   Russell S. J., 2016, ARTIFICIAL INTELLIGE
   Severyn A., 2015, PROCEEDINGS OF THE 9, P464
   Traylor T, 2019, IEEE INT C SEMANT CO, P445, DOI [10.1109/ICOSC.2019.8665593, 10.1109/ICSC.2019.00086]
   Zhong H., 2016, IJCAI, P3952
NR 14
TC 0
Z9 0
U1 0
U2 1
PU LIBRARY & INFORMATION CENTER, NAT DONG HWA UNIV
PI HUALIEN
PA LIBRARY & INFORMATION CENTER, NAT DONG HWA UNIV, HUALIEN, 00000, TAIWAN
SN 1607-9264
EI 2079-4029
J9 J INTERNET TECHNOL
JI J. Internet Technol.
PY 2020
VL 21
IS 7
BP 1993
EP 1997
DI 10.3966/160792642020122107013
PG 5
WC Computer Science, Information Systems; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA PR3BA
UT WOS:000607113300013
DA 2022-02-06
ER

PT J
AU Iosifidis, P
   Andrews, L
AF Iosifidis, Petros
   Andrews, Leighton
TI Regulating the internet intermediaries in a post-truth world: Beyond
   media policy?
SO INTERNATIONAL COMMUNICATION GAZETTE
LA English
DT Article
DE Algorithms; big data; Facebook; fake news; Google; information
   utilities; internet; platform; regulation; social media
ID PRIVACY
AB The regulation of internet intermediaries such as Facebook and Google has drawn increasing academic, journalistic and political attention since the 'fake news' controversies following UK's Brexit vote and Donald Trump's election victory in 2016. This article examines the pressure for a new regulatory framework for the information intermediaries both within and outside the media industry, notably in Europe, noting that the range of issues thrown up by the operations of the information intermediaries now engage a wider focus than media policy per se, including data and privacy policy, national security, hate speech and other issues. The concept of 'fake news' emerges as only one of the drivers of policy change: the dominance of information intermediaries such as Facebook and Google in respect of the digital advertising market and data monopolisation may be even more significant. The article asks whether a new concept of 'information utilities' may be appropriate to capture their increasingly dominant role.
C1 [Iosifidis, Petros] City Univ London, London, England.
   [Andrews, Leighton] Cardiff Business Sch, Cardiff, Wales.
C3 City University London; Cardiff University
RP Iosifidis, P (corresponding author), City Univ London, Dept Sociol, Northampton Square, London EC1V 0HB, England.
EM P.losifidis@city.ac.uk
CR Allcott H, 2017, J ECON PERSPECT, V31, P211, DOI 10.1257/jep.31.2.211
   Andrews L, 2017, FAKE NEWS THREAT REA
   Andrews L, 2017, WHY REGULATORS COMP
   [Anonymous], 2017, REUTERS
   [Anonymous], 2017, BBC
   [Anonymous], 2017, FACEBOOK
   [Anonymous], 2017, ECONOMIST
   [Anonymous], 2017, GUARDIAN
   Assemblee Nationale, 2018, PROP LOI REL LUTT FA
   Baron E, 2017, MARY MEEKERS INTERNE
   Bell E, 2017, COLUMBIA JOURNALISM, V21
   Bloomberg, 2016, BLOOMBERG
   Bowcott O., 2017, GUARDIAN
   Boyd D, 2010, NETWORKED SELF IDENT, P39, DOI DOI 10.1162/DMAL.9780262524834.119
   boyd D, 2014, ITS COMPLICATED SOCI
   Boyd D, 2012, INFORM COMMUN SOC, V15, P662, DOI 10.1080/1369118X.2012.678878
   Cadwalladr C., 2017, The Observer
   Cadwalladr C., 2016, OBSERVER
   Canadian Broadcasting Corporation, 2017, SUPR COURT SAYS WOM
   Carr M., 2016, US POWER INTERNET IN
   Chaykowski K, 2016, FORBES
   Chazan Guy, 2017, FINANCIAL TIMES
   Collins R, 2009, 3 MYTHS INTERNET GOV
   Conseil Nationale de Numerique, 2017, CONS CONF LER PLAT N
   Coyle D., 2016, MAKING MOST PLATFORM
   Coyle D., 2016, FINANCIAL TIMES
   Cummings D, 2017, SPECTATOR
   Cunningham S., 2013, SCREEN DISTRIBUTION
   Dahlberg L, 2009, GLOBALIZATION AND UTOPIA - CRITICAL ESSAYS, P176
   Deuze M, 2007, MEDIA WORK
   Dutton R, 2017, COMMUNITY-MAKING IN EARLY STUART THEATRES: STAGE AND AUDIENCE, P13
   eMarketer, 2017, GOOGL FAC INCR THEIR
   Enders Analysis, 2016, UK DIG FOR 2016 2018
   Epstein D, 2014, J INFORM POLICY, V4, P144, DOI 10.5325/jinfopoli.4.2014.0144
   Esteve A, 2017, INT DATA PRIV LAW, V7, P36, DOI 10.1093/idpl/ipw026
   European Commission, 2017, ANT COMM FIN GOOGL E
   European Commission, 2018, FIN REP HIGH LEV EXP
   European Commission, 2017, PUBL CONS FAK NEWS O
   Evans B, 2017, FACEBOOK SNAPCHAT ME
   Evans B., 2016, MOBILE IS EATING WOR
   Fioretti J, 2017, REUTERS
   Foster R., 2012, NEWS PLURALITY DIGIT
   Fuchs C., 2014, SOCIAL MEDIA CRITICA
   Fuchs C., 2013, PRODUCING INTERNET C, P25
   FUCHS C, 2015, ROUTLEDGE COMPANION, P00165
   Fuchs C, 2017, TRIPLEC-COMMUN CAPIT, V15, P1
   GANDY O, 1993, THE PANOPTIC SORT
   GANDY OH, 1993, CRIT STUD MASS COMM, V10, P70, DOI 10.1080/15295039309366849
   Halpern S, 2016, NEW YORK REV BOOKS
   Hampton KN, 2016, HILL
   Helberger Natali, 2015, Info, V17, P50, DOI 10.1108/info-05-2015-0034
   Helberger Natali, 2014, CONVERGENCE INFORM I
   Hern A, 2016, GUARDIAN
   House of Commons Select Committee on Culture Media and Sport, 2017, FAK NEW INQ LAUNCH
   House of Lords Select Committee on Artificial Intelligence, 2018, 100 HL
   Ingram Mathew, 2015, FACEBOOK HAS TAKEN G
   Iosifidis P, 2016, PALGR GLOB MED POL, P1, DOI 10.1057/978-1-137-41030-6
   Iosifidis P, 2018, JAVNOST-PUBLIC, V25, P110, DOI 10.1080/13183222.2018.1418962
   Kaiser R, 2014, BROOKINGS       1016
   Kantrowitz A, 2016, BUZZFEED
   Knutson R, 2017, WALL STREET J
   Lippmann W, 1921, PUBLIC OPIN, DOI [10.4324/9781315127736, DOI 10.4324/9781315127736]
   Lomas N, 2016, TECHCRUNCH
   Lomas N., 2017, TECHCRUNCH
   Lomas N, 2017, GERMANYS SOCIAL MEDI
   Lublin JS, 2017, WALL ST J       0711
   Luckerson V., 2015, TIME
   Mansell Robin, 2015, INTERMEDIA, V43, P20
   Media Reform Coalition, 2016, SUPP NEW NEWS PROV V
   MIT Technology Review and Oracle, 2016, RIS DAT CAP
   Moore M., 2016, TECH GIANTS CIVIC PO
   Morozov E, 2017, OBSERVER
   Morozov E, 2015, NEW LEFT REV, P45
   Morrissey B., 2017, DIGIDAY         0619
   Mosseri A, 2016, FACEBOOK
   Mostrous A., 2017, TIMES
   Mulgan G, 2017, NESTA
   Napoli Philip., 2017, 1 MONDAY
   Neff J., 2017, ADVERTISING AGE
   Nicas J, 2016, GOOGLE FACEBOOK TAKE
   Nielsen RK, 2018, NEW MEDIA SOC, V20, P1600, DOI 10.1177/1461444817701318
   Office of the Director of National Intelligence, 2017, BACKGR ASS RUSS ACT
   Pariser, 2011, FILTER BUBBLE WHAT I
   Pasquale F., 2015, BLACK BOX SOC
   Patrick, 2017, ALTERNATIVE WAR
   Pew Research Center, 2016, NEWS USE SOCIAL MEDI, DOI DOI 13/2016/05/PJ_2016.05.26_SOCIAL-MEDIA-AND-NEWS_FINAL-1.PDF
   Picard RobertG., 2017, ESSENTIAL PRINCIPLES
   Ponsford Dominic, 2017, PRESS GAZETTE
   Reagan G, 2009, OBSERVER
   Reuters, 2016, FORTUNE
   Reuters Institute for the Study of Journalism, 2016, DIGITAL NEWS REPORT
   Ribas MC, 2016, SOLETRAS, P5
   Schlesinger P, 2009, MEDIA LSE ELECT WORK
   Scrnicek N, 2017, PLATFORM CAPITALISM
   Semerad T, 2013, SALT LAKE TRIBUNE
   Shemenski J, 2016, IS SOCIAL MEDIA NEW
   Silverman C., 2016, TEENS BALKANS ARE DU
   Smith G, 2017, CYBERLEAGUE     0521
   Solon O., 2017, OBSERVER
   Stahle M, 2017, SECRET SWEDISH TROLL
   Stangel L, 2017, NEWSPAPERS WILL LOBB
   Sweney, 2018, GUARDIAN
   Tambini, 2017, LSE MEDIA POLICY PRO
   Tambini D., 2017, LSE MEDIA POLICY PRO
   Tan E., 2017, CAMPAIGN
   Taplin J, 2017, MOVE FAST BREAK THIN
   Taylor Emily, 2016, GLOBAL COMMISSION IN, V24, P1
   The Royal Society, 2017, DAT MAN US GOV 21 CE
   Thompson B, 2017, STRATECHERY BLOG
   Tiku N, 2017, WIRED
   Trappel J., 2015, EUROPEAN MEDIA CRISI
   Tufekci Z., 2017, TWITTER TEAR GAS POW
   Tufekci Zeynep, 2015, FACEBOOKS ALGORITHM
   Vestager M, 2018, TECHNOLOGY SERVES PE
   Vestager M, 2018, COMPETITION FAIR DEA
   Visual Capitalist, 2016, CHART SLOW DEATH TRA
   Vizard S., 2017, MARKETING WEEK
   Wardle C., 2017, FAKE NEWS ITS COMPLI
   White S, 2018, ITS TIME REGULATE SO
   Wu T., 2016, ATTENTION MERCHANTS
   Wu YY, 2015, P NATL ACAD SCI USA, V112, P1036, DOI 10.1073/pnas.1418680112
   Zanger D, 2017, IND OPINION IS HONES
   Zuboff S, 2015, J INF TECHNOL-UK, V30, P75, DOI 10.1057/jit.2015.5
   Zuckerberg M., 2017, BUILDING GLOBAL COMM
NR 124
TC 5
Z9 6
U1 6
U2 51
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 1748-0485
EI 1748-0493
J9 INT COMMUN GAZ
JI Int. Commun. Gaz.
PD APR
PY 2020
VL 82
IS 3
BP 211
EP 230
DI 10.1177/1748048519828595
PG 20
WC Communication
WE Social Science Citation Index (SSCI)
SC Communication
GA KZ1PI
UT WOS:000523041300001
OA Green Accepted
DA 2022-02-06
ER

PT J
AU Xu, ZP
   Liu, JR
   Lu, W
   Xu, BZ
   Zhao, XF
   Li, B
   Huang, JW
AF Xu, Zhaopeng
   Liu, Jiarui
   Lu, Wei
   Xu, Bozhi
   Zhao, Xianfeng
   Li, Bin
   Huang, Jiwu
TI Detecting facial manipulated videos based on set convolutional neural
   networks
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Digital video forensics; Deepfake; Set convolutional neural network; Set
   reduce
AB With the boom of artificial intelligence, facial manipulation technology is becoming more simple and more numerous. At the same time, the technology also has a large and profound negative impact on face forensics, such as Deepfakes. In this paper, in order to aggregate multiframe features to detect facial manipulation videos, we solve facial manipulated video detection from set perspective and propose a novel framework based on set, which is called set convolutional neural network (SCNN). Three instances of the proposed framework SCNN are implemented and evaluated on the Deepfake TIMIT dataset, FaceForensics++ dataset and DFDC Preview datset. The results show that the method outperforms previous methods and can achieve state-of-the-art performance on both datasets. As a perspective, the proposed method is a fusion promotion of single-frame digital video forensics network.
C1 [Xu, Zhaopeng; Liu, Jiarui; Lu, Wei; Xu, Bozhi] Sun Yat Sen Univ, Sch Comp Sci & Engn, Guangdong Key Lab Informat Secur Technol, Minist Educ,Key Lab Machine Intelligence & Adv Co, Guangzhou 510006, Peoples R China.
   [Zhao, Xianfeng] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China.
   [Li, Bin; Huang, Jiwu] Shenzhen Univ, Guangdong Key Lab Intelligent Informat Proc, Shenzhen Key Lab Media Secur, Shenzhen 518060, Peoples R China.
   [Li, Bin; Huang, Jiwu] Shenzhen Univ, Guangdong Lab Art Intelligence & Digital Econ SZ, Shenzhen 518060, Peoples R China.
   [Huang, Jiwu] Shenzhen Inst Art Intelligence & Robot Soc, Shenzhen 518060, Peoples R China.
C3 Sun Yat Sen University; Chinese Academy of Sciences; Institute of
   Information Engineering, CAS; Shenzhen University; Shenzhen University
RP Lu, W (corresponding author), Sun Yat Sen Univ, Sch Comp Sci & Engn, Guangdong Key Lab Informat Secur Technol, Minist Educ,Key Lab Machine Intelligence & Adv Co, Guangzhou 510006, Peoples R China.
EM xuzhp8@mail2.sysu.edu.cn; liujr9@mail2.sysu.edu.cn;
   luwei3@mail.sysu.edu.cn; xuzhp8@mail2.sysu.edu.cn;
   zhaoxianfeng@iie.ac.cn; libin@szu.edu.cn; jwhuang@szu.edu.cn
RI Zhao, Xianfeng/AAE-7278-2021
OI Zhao, Xianfeng/0000-0002-5617-8399
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [U2001202, 62072480, U1736118]; National Key
   R&D Program of China [2019QY2202, 2019QY(Y)0207]; Key Areas R&D Program
   of Guangdong, China [2019B010136002]; Key Scientific Research Program of
   Guangzhou, China [201804020068]
FX This work is supported by the National Natural Science Foundation of
   China (No. U2001202, No. 62072480, No. U1736118) , the National Key R&D
   Program of China (No. 2019QY2202 , No. 2019QY(Y)0207) , the Key Areas
   R&D Program of Guangdong, China (No. 2019B010136002) , the Key
   Scientific Research Program of Guangzhou, China (No. 201804020068) .
CR Afchar D, 2018, IEEE INT WORKS INFOR
   [Anonymous], 2019, FACESWAP GITHUB
   [Anonymous], 2019, DEEPFAKES GITHUB
   Antipov G, 2017, IEEE IMAGE PROC, P2089, DOI 10.1109/ICIP.2017.8296650
   Averbuch-Elor H, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130818
   Bansal A, 2018, LECT NOTES COMPUT SC, V11209, P122, DOI 10.1007/978-3-030-01228-1_8
   Bappy JH, 2019, IEEE T IMAGE PROCESS, V28, P3286, DOI 10.1109/TIP.2019.2895466
   Carvalho T, 2016, IEEE T INF FOREN SEC, V11, P720, DOI 10.1109/TIFS.2015.2506548
   Ciftci U.A., 2019, ARXIV190102212
   Conotter V, 2014, IEEE IMAGE PROC, P248, DOI 10.1109/ICIP.2014.7025049
   Dale K, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024164
   de Carvalho TJ, 2013, IEEE T INF FOREN SEC, V8, P1182, DOI 10.1109/TIFS.2013.2265677
   Dolhansky B., 2019, DEEPFAKE DETECTION C
   Dang-Nguyen DT, 2012, IEEE INT WORKS INFOR, P252, DOI 10.1109/WIFS.2012.6412658
   Garrido P, 2015, COMPUT GRAPH FORUM, V34, P193, DOI 10.1111/cgf.12552
   Garrido P, 2014, PROC CVPR IEEE, P4217, DOI 10.1109/CVPR.2014.537
   Guarnera L, 2020, IEEE ACCESS, V8, P165085, DOI 10.1109/ACCESS.2020.3023037
   Guera D, 2018, 2018 15TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P127
   Huang R, 2017, IEEE I CONF COMP VIS, P2458, DOI 10.1109/ICCV.2017.267
   Karras T., 2017, ARXIV171010196
   Khodabakhsh A, 2018, 2018 INTERNATIONAL CONFERENCE OF THE BIOMETRICS SPECIAL INTEREST GROUP (BIOSIG)
   Kirchner M, 2013, DIGITAL IMAGE RORENS
   Korshunov P., 2018, DEEPFAKES NEW THREAT
   Kumar P, 2020, IEEE WINT CONF APPL, P2578, DOI 10.1109/WACV45572.2020.9093628
   Li LZ, 2020, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR42600.2020.00505
   [李艳歌 Li Yange], 2018, [高分子通报, Polymer Bulletin], P46
   Li YZ, 2018, IEEE INT WORKS INFOR
   LIU MY, 2017, ADV NEURAL INFORM PR
   Lu YY, 2018, LECT NOTES COMPUT SC, V11216, P293, DOI 10.1007/978-3-030-01258-8_18
   Nguyen HH, 2019, INT CONF ACOUST SPEE, P2307, DOI 10.1109/ICASSP.2019.8682602
   Raghavendra R, 2017, IEEE COMPUT SOC CONF, P1822, DOI 10.1109/CVPRW.2017.228
   Rahmouni Nicolas, 2017, P IEEE WORKSH INF FO, P1, DOI DOI 10.1109/WIFS.2017.8267647
   Rossler A, 2019, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2019.00009
   Sabour S., 2017, NIPS, P3856
   Sanderson C, 2009, LECT NOTES COMPUT SC, V5558, P199, DOI 10.1007/978-3-642-01793-3_21
   THIES J, 2016, PROC CVPR IEEE, P2387, DOI DOI 10.1109/CVPR.2016.262
   Thies J, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818056
   Upchurch P, 2017, PROC CVPR IEEE, P6090, DOI 10.1109/CVPR.2017.645
   Verdoliva L, 2020, IEEE J-STSP, V14, P910, DOI 10.1109/JSTSP.2020.3002101
   Zhang W, 2020, ARXIV200505535
   Zhou P, 2017, IEEE COMPUT SOC CONF, P1831, DOI 10.1109/CVPRW.2017.229
NR 41
TC 0
Z9 0
U1 3
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2021
VL 77
AR 103119
DI 10.1016/j.jvcir.2021.103119
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TM2UA
UT WOS:000675405700016
DA 2022-02-06
ER

PT J
AU Li, CS
   Li, RQ
   Yuan, Y
   Wang, GR
   Xu, D
AF Li, Changsheng
   Li, Rongqing
   Yuan, Ye
   Wang, Guoren
   Xu, Dong
TI Deep Unsupervised Active Learning via Matrix Sketching
SO IEEE TRANSACTIONS ON IMAGE PROCESSING
LA English
DT Article
DE Image reconstruction; Image processing; Data models; Task analysis;
   Learning systems; Kernel; Manifolds; Unsupervised active learning;
   matrix sketching; self-supervised learning; data reconstruction
ID ALGORITHMS; APPROXIMATION
AB Most existing unsupervised active learning methods aim at minimizing the data reconstruction loss by using the linear models to choose representative samples for manually labeling in an unsupervised setting. Thus these methods often fail in modelling data with complex non-linear structure. To address this issue, we propose a new deep unsupervised Active Learning method for classification tasks, inspired by the idea of Matrix Sketching, called ALMS. Specifically, ALMS leverages a deep auto-encoder to embed data into a latent space, and then describes all the embedded data with a small size sketch to summarize the major characteristics of the data. In contrast to previous approaches that reconstruct the whole data matrix for selecting the representative samples, ALMS aims to select a representative subset of samples to well approximate the sketch, which can preserve the major information of data meanwhile significantly reducing the number of network parameters. This makes our algorithm alleviate the issue of model overfitting and readily cope with large datasets. Actually, the sketch provides a type of self-supervised signal to guide the learning of the model. Moreover, we propose to construct an auxiliary self-supervised task by classifying real/fake samples, in order to further improve the representation ability of the encoder. We thoroughly evaluate the performance of ALMS on both single-label and multi-label classification tasks, and the results demonstrate its superior performance against the state-of-the-art methods. The code can be found at https://github.com/lrq99/ALMS.
C1 [Li, Changsheng; Li, Rongqing; Yuan, Ye; Wang, Guoren] Beijing Inst Technol, Sch Comp Sci & Technol, Beijing 100081, Peoples R China.
   [Xu, Dong] Univ Sydney, Sch Elect & Informat Engn, Sydney, NSW 2006, Australia.
C3 Beijing Institute of Technology; University of Sydney
RP Li, CS (corresponding author), Beijing Inst Technol, Sch Comp Sci & Technol, Beijing 100081, Peoples R China.
EM lcs@bit.edu.cn; lirongqing99@gmail.com; yuan-ye@bit.edu.cn;
   wanggrbit@126.com; dong.xu@sydney.edu.au
FU National Natural Science Foundation of China (NSFC)National Natural
   Science Foundation of China (NSFC) [62122013, U2001211, 61806044]
FX This work was supported by the National Natural Science Foundation of
   China (NSFC) under Grant 62122013, Grant U2001211, and Grant 61806044.
CR Achlioptas D, 2007, J ACM, V54, DOI 10.1145/1219092.1219097
   Ahmed MM, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0119491
   Andrzejak RG, 2001, PHYS REV E, V64, DOI 10.1103/PhysRevE.64.061907
   Arora S, 2006, LECT NOTES COMPUT SC, V4110, P272
   Bachrach Y, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P2016
   Balzano L, 2010, NIPS WORKSH LOW RANK
   Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214
   Boutell MR, 2004, PATTERN RECOGN, V37, P1757, DOI 10.1016/j.patcog.2004.03.009
   Boutsidis C, 2009, PROCEEDINGS OF THE TWENTIETH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P968
   Cai D, 2012, IEEE T KNOWL DATA EN, V24, P707, DOI 10.1109/TKDE.2011.104
   Chattopadhyay R., 2013, P 30 INT C MACH LEAR, P253
   Dietterich TG, 1997, ARTIF INTELL, V89, P31, DOI 10.1016/S0004-3702(96)00034-3
   Drineas P, 2005, J MACH LEARN RES, V6, P2153
   Drineas P, 2003, SIAM PROC S, P223
   Drineas P, 2011, INFORM PROCESS LETT, V111, P385, DOI 10.1016/j.ipl.2011.01.010
   Dua D., 2017, UCI MACHINE LEARNING
   Finn C, 2017, PR MACH LEARN RES, V70
   Frieze A, 2004, J ACM, V51, P1025, DOI 10.1145/1039488.1039494
   Geifman Y, 2019, ADV NEUR IN, V32
   Ghashami M, 2016, SIAM J COMPUT, V45, P1762, DOI 10.1137/15M1009718
   He K., 2020, PROC IEEECVF C COMPU
   He XF, 2010, IEEE T IMAGE PROCESS, V19, P254, DOI 10.1109/TIP.2009.2032342
   Hu Yao, 2013, P 23 INT JOINT C ART, P1415
   Huang S. J., 2017, P 26 INT JOINT C ART, P1879
   Kandemir Melih., 2019, P 28 INT JOINT C ART, P2470
   King DB, 2015, ACS SYM SER, V1214, P1
   Leng C, 2015, PROC CVPR IEEE, P2503, DOI 10.1109/CVPR.2015.7298865
   Li CS, 2020, IEEE T NEUR NET LEAR, V31, P2294, DOI 10.1109/TNNLS.2019.2924023
   Li CS, 2019, IEEE T PATTERN ANAL, V41, P1382, DOI 10.1109/TPAMI.2018.2840980
   Li CS, 2018, IEEE T NEUR NET LEAR, V29, P2660, DOI 10.1109/TNNLS.2017.2697767
   Li Changsheng, 2020, ARXIV PREPRINT ARXIV
   Li Q, 2017, PATTERN RECOGN LETT, V92, P81, DOI 10.1016/j.patrec.2017.04.022
   Liang YY, 2020, PR MACH LEARN RES, V108, P467
   Liberty E, 2007, P NATL ACAD SCI USA, V104, P20167, DOI 10.1073/pnas.0709640104
   Liberty E, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P581, DOI 10.1145/2487575.2487623
   Liu JG, 2009, PROC CVPR IEEE, P1996
   Melville Prem, 2004, P 21 INT C MACH LEAR, P584, DOI DOI 10.1145/1015330.1015385
   MISRA J, 1982, SCI COMPUT PROGRAM, V2, P143, DOI 10.1016/0167-6423(82)90012-0
   Morgan CJ, 2017, AM J PHYSIOL-LUNG C, V313, pL873, DOI 10.1152/ajplung.00238.2017
   Mroueh Y, 2017, PR MACH LEARN RES, V54, P567
   Nie Feiping, 2013, P 23 INT JOINT C ART
   Papailiopoulos D, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P997, DOI 10.1145/2623330.2623698
   Paul S., 2015, ADV NEURAL INFORM PR, P406
   Roy Nicholas, 2001, P 18 INT C MACH LEAR, P441
   Sajnani H., 2012, CLASSIFYING YELP REV
   Sarlos T, 2006, ANN IEEE SYMP FOUND, P143
   Schuurmans, 2007, ADV NEURAL INFORM PR, P593
   Sener O, 2018, C TRACK P, P1
   Sharan V, 2018, ADV NEUR IN, V31
   Shi Lei, 2016, P IJCAI, P1997
   Shui CJ, 2020, PR MACH LEARN RES, V108
   Snell J., 2017, PROC NEURIPS, P4077, DOI DOI 10.5555/3294996.3295163
   Snoek C. G. M., 2006, P 14 ANN ACM INT C M, P421, DOI DOI 10.1145/1180639.1180727
   Song Z, 2019, ADV NEUR IN, V32
   Tang JH, 2012, IEEE T IMAGE PROCESS, V21, P2354, DOI 10.1109/TIP.2011.2180916
   Ting D, 2018, INT CONF MANAGE DATA, P1129, DOI 10.1145/3183713.3183759
   Vempala Santosh S., 2005, RANDOM PROJECTION ME, V65
   Wang GA, 2019, IEEE T IMAGE PROCESS, V28, P316, DOI 10.1109/TIP.2018.2867913
   Wang Z, 2015, ACM T KNOWL DISCOV D, V9, DOI 10.1145/2700408
   Wei ZW, 2015, SIGMOD'15: PROCEEDINGS OF THE 2015 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P795, DOI 10.1145/2723372.2749443
   Yang P., 2019, P INT JOINT C ART IN, P4078, DOI [10.24963/ijcai.2019/566, DOI 10.24963/IJCAI.2019/566]
   You XG, 2014, IEEE T IMAGE PROCESS, V23, P3203, DOI 10.1109/TIP.2014.2327805
   Yu K., P 23 INT C MACH LEAR, P1081, DOI [10.1145/1143844.1143980, DOI 10.1145/1143844.1143980]
   Yu K., 2008, P INT ACM SIGIR C RE, P635
   Zhang B, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2014.2302675
   Zhang LH, 2020, IEEE T IMAGE PROCESS, V29, P2258, DOI 10.1109/TIP.2019.2945679
   Zhang LJ, 2011, IEEE T PATTERN ANAL, V33, P2026, DOI 10.1109/TPAMI.2011.20
   Zhang LN, 2017, IEEE T IMAGE PROCESS, V26, P969, DOI 10.1109/TIP.2016.2635440
   Zhang M.-L., 2010, P 16 ACM SIGKDD INT, P999, DOI DOI 10.1145/1835804.1835930
   Zhang ML, 2007, PATTERN RECOGN, V40, P2038, DOI 10.1016/j.patcog.2006.12.019
   Zhang ML, 2014, IEEE T KNOWL DATA EN, V26, P1819, DOI 10.1109/TKDE.2013.39
   Zhang Y, 2010, ACM T KNOWL DISCOV D, V4, DOI 10.1145/1839490.1839495
   Zhao G, 2021, PR MACH LEARN RES, V130
   Zhou ZH., 2015, ADV NEURAL INFORM PR, P1774
   Zhou ZH, 2012, ARTIF INTELL, V176, P2291, DOI 10.1016/j.artint.2011.10.002
   Zhu FY, 2015, PROCEEDINGS OF THE TWENTY-NINTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3217
   Zhu Y, 2018, IEEE T KNOWL DATA EN, V30, P1081, DOI 10.1109/TKDE.2017.2785795
NR 77
TC 0
Z9 0
U1 2
U2 2
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1057-7149
EI 1941-0042
J9 IEEE T IMAGE PROCESS
JI IEEE Trans. Image Process.
PY 2021
VL 30
BP 9280
EP 9293
DI 10.1109/TIP.2021.3124317
PG 14
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WW2QL
UT WOS:000717767800003
PM 34739378
DA 2022-02-06
ER

PT J
AU Kohli, A
   Gupta, A
AF Kohli, Aditi
   Gupta, Abhinav
TI Detecting DeepFake, FaceSwap and Face2Face facial forgeries using
   frequency CNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE First keyword; Second keyword; More
AB The face of a person plays a vital role in any communication or visual content. To enhance this visual content, popular and easy accessible editing tools are used. However, there malicious usage is spreading disharmony in the society, by tampering video evidences, defaming a person's image etc. Therefore a robust detection method is required to authenticate the visual content. Thus, a novel method is proposed to detect facial forgeries. The proposed method extracts faces from a target video and convert them into frequency domain using two dimensional global discrete Cosine transform (2D- GDCT). Thereafter, a 3 layered frequency convolutional neural network (fCNN) is employed to detect forged facial image. The proposed method is trained and tested on FaceForensics++ dataset and Celeb-DF(v2) dataset. In addition, its robustness is evaluated on standardized benchmark dataset and compared with the state-of-the-art methods to prove its effectiveness.
C1 [Kohli, Aditi; Gupta, Abhinav] Jaypee Inst Informat Technol, Dept Elect & Commun Engn, A-10,Sect 62, Noida 201309, Uttar Pradesh, India.
C3 Jaypee Institute of Information Technology (JIIT)
RP Gupta, A (corresponding author), Jaypee Inst Informat Technol, Dept Elect & Commun Engn, A-10,Sect 62, Noida 201309, Uttar Pradesh, India.
EM abhinav.gupta@jiit.ac.in
OI GUPTA, ABHINAV/0000-0002-1939-5407
CR Afchar D, 2018, IEEE INT WORKS INFOR
   Baek JY, 2020, IEEE ACCESS, V8, P45421, DOI 10.1109/ACCESS.2020.2968612
   Bayar B., 2016, P 4 ACM WORKSH INF H, P5, DOI DOI 10.1145/2909827.2930786
   Bianco S, 2018, IEEE ACCESS, V6, P64270, DOI 10.1109/ACCESS.2018.2877890
   Cozzolino Davide, 2017, P 5 ACM WORKSH INF H, P159, DOI DOI 10.1145/3082031.3083247
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Frith C, 2009, PHILOS T R SOC B, V364, P3453, DOI 10.1098/rstb.2009.0142
   Guera D, 2018, 2018 15TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P127
   Hu HL, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON NETWORKING, ARCHITECTURE AND STORAGE (NAS)
   Khodabakhsh A, 2018, 2018 INTERNATIONAL CONFERENCE OF THE BIOMETRICS SPECIAL INTEREST GROUP (BIOSIG)
   KIM HYEON-ZOO, 2018, [ASSOCIATION CULTURELLE FRANC0-COREENNE, 프랑스 문화 연구], V37, P1, DOI 10.18022/acfco.2018.37.1.001
   Li YT, 2020, ACM T SENSOR NETWORK, V16, DOI 10.1145/3397179
   Li YZ, 2020, PROC CVPR IEEE, P3204, DOI 10.1109/CVPR42600.2020.00327
   Li Yuezun, 2018, 2018 IEEE INT WORKSH, P1, DOI DOI 10.1109/WIFS.2018.8630787
   Li Yuezun, 2019, IEEE C COMP VIS PATT
   Matern F, 2019, IEEE WINT CONF APPL, P83, DOI 10.1109/WACVW.2019.00020
   Mo HX, 2018, PROCEEDINGS OF THE 6TH ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY (IH&MMSEC'18), P43, DOI 10.1145/3206004.3206009
   Nguyen HH, 2019, INT CONF ACOUST SPEE, P2307, DOI 10.1109/ICASSP.2019.8682602
   Rahmouni Nicolas, 2017, P IEEE WORKSH INF FO, P1, DOI DOI 10.1109/WIFS.2017.8267647
   Rossler A, 2019, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2019.00009
   Schlegl T, 2017, LECT NOTES COMPUT SC, V10265, P146, DOI 10.1007/978-3-319-59050-9_12
   Suwajanakorn S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073640
   THIES J, 2016, PROC CVPR IEEE, P2387, DOI DOI 10.1109/CVPR.2016.262
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wu J, 2016, ADV NEURAL INFORM PR, P82, DOI DOI 10.5555/3157096.3157106
   Yang Li-Chia Szu-Yu, 2017, ARXIV170310847, P324
   Yang X, 2019, INT CONF ACOUST SPEE, P8261, DOI 10.1109/ICASSP.2019.8683164
   Yoo D, 2016, LECT NOTES COMPUT SC, V9912, P517, DOI 10.1007/978-3-319-46484-8_31
   Zhang X., 2019, 2019 IEEE INT WORKSH, P1, DOI DOI 10.1109/WIFS47025.2019.9035107
   Zhou P, 2017, IEEE COMPUT SOC CONF, P1831, DOI 10.1109/CVPRW.2017.229
NR 30
TC 0
Z9 0
U1 8
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 18461
EP 18478
DI 10.1007/s11042-020-10420-8
EA FEB 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000619425300003
DA 2022-02-06
ER

PT J
AU Helal, F
AF Helal, Fethi
TI 'The people want horizontal ellipsis : ' the populist specter in the
   Tunisian President's inaugural speech
SO CRITICAL DISCOURSE STUDIES
LA English
DT Article; Early Access
DE People; populism; spatial cognition; critical metaphor analysis; word
   frequency; inaugural address; Tunisia; Arab Spring
AB This paper combines insights from Deictic Space Theory and Conceptual Metaphor Theory to analyze the Tunisian President's inaugural speech following his victory in the October 2019 elections. Detailed critical discourse analysis of the deictic exponents and the metaphorical image schemas employed in the text showed a Manichean opposition between the pure/good people (Us) versus the corrupt/evil 'elites' (Them), nostalgia to a pristine revolutionary moment, a pan-Arab discourse which anchors the Israeli-Palestinian conflict close to the local geography and a radical form of populism, which grounds sovereignty within a transcendent theocratic cosmology. It is suggested that the upsurge of populism in Tunisian politics could be explained by the disenchantment with the deficient and rather 'fake' Islamo-nationalist consensus politics, the inappropriate neoliberal policies imposed by fund-raising bodies like the International Monetary Fund (IMF) and the World Bank (WB) as well as the fragmentation, if not total erosion, of viable public spaces for rational deliberation and decision-making processes as a result of the 'digital era.'
C1 [Helal, Fethi] Univ Manouba, Dept English, Fac Letters Arts & Humanities, Manouba, Tunisia.
C3 Universite de la Manouba
RP Helal, F (corresponding author), Univ Manouba, Dept English, Fac Letters Arts & Humanities, Manouba, Tunisia.
EM fethi_helal@yahoo.fr
CR Abulof U, 2015, NATIONS NATL, V21, P658, DOI 10.1111/nana.12137
   Achcar G., 2019, MONDE DIPLOMATIQUE
   Anderson L, 2018, PHILOS SOC CRIT, V44, P478, DOI 10.1177/0191453718757841
   Aslanidis P., 2017, OXFORD HDB POPULISM, P305, DOI 10.1093/oxfordhb/9780198803560.001.0001
   Benveniste E., 1966, PROBL MES LINGUISTIQ, V1
   Bhler, 1934, THEORY LANGUAGE REPR
   Bobin Frederic, 2019, MONDE
   Charteris-Black J, 2006, DISCOURSE SOC, V17, P563, DOI 10.1177/0957926506066345
   Chilton P, 2014, LANGUAGE, SPACE AND MIND: THE CONCEPTUAL GEOMETRY OF LINGUISTIC MEANING, P1, DOI 10.1017/CBO9780511845703
   Chilton P., 2017, TOWARD NEURO COGNITI, V160-161, P237, DOI [10.3917/ls.160.0237, DOI 10.3917/LS.160.0237]
   Chilton P, 2017, J LANG POLIT, V16, P582, DOI 10.1075/jlp.17031.chi
   Chilton Paul, 2002, POLITICS TEXT TALK A
   Culioli A., 1990, LINGUISTIQUE L NONCI, V1
   European Electoral Observation Mission, 2019, ELECTIONS PR SIDENTI
   Hart C, 2015, CRIT DISCOURSE STUD, V12, P238, DOI 10.1080/17405904.2015.1013479
   Helal F, 2019, DISCOURSE COMMUN, V13, P415, DOI 10.1177/1750481319842454
   Helal F, 2019, CRIT DISCOURSE STUD, V16, P179, DOI 10.1080/17405904.2018.1538888
   Hibou B., 2009, REV DHISTOIRE MODERN, V56, P30
   Johnson Mark, 1987, BODY MIND
   Laclau Ernesto., 2005, POPULIST REASON
   Lakoff G., 2008, METAPHORS WE LIVE
   March Andrew F., 2015, POLIT THEORY, V43, P838
   McCarthy R, 2019, MIDDLE EASTERN STUD, V55, P261, DOI 10.1080/00263206.2018.1538969
   Miller CarolynR., 1992, RHETORIC DOING ESSAY, P310
   Mudde Cas, 2017, POPULISM VERY SHORT
   Muller JW, 2016, WHAT IS POPULISM?, P1, DOI 10.9783/9780812293784
   Pakulski J., 2018, ZOON POLITIKON, V1, P1, DOI [10.4467/2543408XZOP.18.001.10057, DOI 10.4467/2543408XZOP.18.001.10057]
   Piketty T, 2020, CAPITAL IDEOLOGY
   Richardson JE, 2017, EXPLORAT FAR RIGHT, V5, P1, DOI 10.1057/s41293-017-0051-y
   Safi M, 2019, GUARDIAN
   Smaldone T, 2015, INQUIRIES J STUDENT, V7
   Wodak R., 2015, POLITICS FEAR WHAT R
   Wodak R, 2017, J LANG POLIT, V16, P471, DOI 10.1075/jlp.17042.krz
   Zizek S, 2006, CRIT INQUIRY, V32, P551, DOI 10.1086/505378
NR 34
TC 0
Z9 0
U1 2
U2 3
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 1740-5904
EI 1740-5912
J9 CRIT DISCOURSE STUD
JI Crit. Discourse Stud.
DI 10.1080/17405904.2021.1879886
EA FEB 2021
PG 19
WC Communication
WE Social Science Citation Index (SSCI)
SC Communication
GA QE0BR
UT WOS:000615873600001
DA 2022-02-06
ER

PT J
AU Saba, T
   Rehman, A
   Sadad, T
   Mehmood, Z
AF Saba, Tanzila
   Rehman, Amjad
   Sadad, Tariq
   Mehmood, Zahid
TI Copy-move image forged information detection and localisation in digital
   images using deep convolutional network
SO JOURNAL OF INFORMATION SCIENCE
LA English
DT Article; Early Access
DE Digital security; fake information; forgery detection; ResNet101;
   transfer learning
AB Image tempering is one of the significant issues in the modern era. The use of powerful tools for image editing with advanced technology and its widespread on social media raised questions on data integrity. Currently, the protection of images is uncertain and a severe concern, mainly when it transfers over the Internet. Thus, it is essential to detect an anomaly in images through artificial intelligence techniques. The simple way of image forgery is called copy-move, where a part of an image is replicated in the same image to hide unwanted content of the image. However, image processing through handcrafted features usually looks for pattern concerns with duplicate content, limiting their employment for huge data classification. On the other side, deep learning approaches achieve promising results, but their performance depends on training data with fine-tuning of hyperparameters. Thus, we proposed a custom convolutional neural network (CNN) architecture with a pre-trained model ResNet101 through a transfer learning approach. For this purpose, both models are trained on five different datasets. In both cases, the impact of the model is evaluated through accuracy, precision, recall, F-score and achieved the highest 98.4% accuracy using the Coverage dataset.
C1 [Saba, Tanzila; Rehman, Amjad] Prince Sultan Univ, Artificial Intelligence & Data Analyt Lab, CCIS, Riyadh 11586, Saudi Arabia.
   [Sadad, Tariq] Int Islamic Univ, Dept CS & SE, Islamabad, Pakistan.
   [Mehmood, Zahid] Univ Engn & Technol, Dept Comp Engn, Taxila, Pakistan.
C3 Prince Sultan University; University of Engineering & Technology Taxila
RP Rehman, A (corresponding author), Prince Sultan Univ, Artificial Intelligence & Data Analyt Lab, CCIS, Riyadh 11586, Saudi Arabia.
EM drrehman70@gmail.com
OI Rehman, Amjad/0000-0002-3817-2655
FU research project 'Copy-Move Forgery Detection from Images Using Circular
   Block-based Local Intensity Order Pattern Features and Similarity
   Measure', Prince Sultan University, Riyadh Saudi Arabia under Artificial
   Intelligence Data Analytics Research Lab. [SEED-CCIS-2020{23}]
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship and/or publication of this article: This work
   was supported by the research project `Copy-Move Forgery Detection from
   Images Using Circular Block-based Local Intensity Order Pattern Features
   and Similarity Measure', Prince Sultan University, Riyadh Saudi Arabia,
   [SEED-CCIS-2020{23}] under Artificial Intelligence & Data Analytics
   Research Lab. CCIS. The authors are thankful for the support.
CR Adnan MM, 2021, IEEE ACCESS, V9, P50253, DOI 10.1109/ACCESS.2021.3068897
   Agarwal R, 2020, MULTIMED TOOLS APPL, V79, P7355, DOI 10.1007/s11042-019-08495-z
   Ahmad AM, 2014, J INTELL SYST, V23, P451, DOI 10.1515/jisys-2014-0007
   Alberry Hesham A., 2018, Future Computing and Informatics Journal, V3, P159, DOI 10.1016/j.fcij.2018.03.001
   Alkawaz MH, 2018, NEURAL COMPUT APPL, V30, P183, DOI 10.1007/s00521-016-2663-3
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   Ardizzone E, 2015, IEEE T INF FOREN SEC, V10, P2084, DOI 10.1109/TIFS.2015.2445742
   Bilal M, 2020, ARAB J SCI ENG, V45, P2975, DOI 10.1007/s13369-019-04238-2
   Bilal M, 2021, AUST J FORENSIC SCI, V53, P459, DOI 10.1080/00450618.2020.1715479
   Castro M, 2020, DATA BRIEF, V28, DOI 10.1016/j.dib.2019.104864
   Chen HP, 2020, IEEE ACCESS, V8, P36863, DOI 10.1109/ACCESS.2020.2974804
   Ferreira WD, 2020, COMPUT ELECTR ENG, V85, DOI 10.1016/j.compeleceng.2020.106685
   Gani G, 2020, J INF SECUR APPL, V54, DOI 10.1016/j.jisa.2020.102510
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Mahmood T, 2018, J VIS COMMUN IMAGE R, V53, P202, DOI 10.1016/j.jvcir.2018.03.015
   Meena KB, 2020, J INF SECUR APPL, V52, DOI 10.1016/j.jisa.2020.102481
   Meethongjan K, 2013, J INTELL SYST, V22, P197, DOI 10.1515/jisys-2013-0010
   Muzaffer G, 2019, 2019 SCIENTIFIC MEETING ON ELECTRICAL-ELECTRONICS & BIOMEDICAL ENGINEERING AND COMPUTER SCIENCE (EBBT)
   Nawaz M, 2021, J INTELL FUZZY SYST, V40, P10351, DOI 10.3233/JIFS-191700
   Nodehi A, 2014, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2014-112
   Rao Y, 2016, IEEE INT WORKS INFOR
   Renza D, 2019, ORIGINAL TAMPERED IM
   Rodriguez-Ortega Y, 2021, J IMAGING, V7, DOI 10.3390/jimaging7030059
   Sharif U, 2019, ARTIF INTELL REV, V52, P901, DOI 10.1007/s10462-018-9636-0
   Tewfik AH, 2000, IEEE SIGNAL PROC MAG, V17, P17, DOI 10.1109/MSP.2000.879336
   Thakur Rahul, 2019, 2019 2nd International Conference on Power Energy, Environment and Intelligent Control (PEEIC), P561, DOI 10.1109/PEEIC47157.2019.8976868
   Tinnathi S, 2021, J VIS COMMUN IMAGE R, V74, DOI 10.1016/j.jvcir.2020.102966
   Wafi, 2020, P 8 INT S DIG FOR SE
   Waheed SR, 2016, MICROSC RES TECHNIQ, V79, P431, DOI 10.1002/jemt.22646
   Wen BH, 2016, IEEE IMAGE PROC, P161, DOI 10.1109/ICIP.2016.7532339
   Yu LY, 2016, MULTIMED TOOLS APPL, V75, P1159, DOI 10.1007/s11042-014-2362-y
NR 31
TC 0
Z9 0
U1 3
U2 3
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 0165-5515
EI 1741-6485
J9 J INF SCI
JI J. Inf. Sci.
AR 01655515211050024
DI 10.1177/01655515211050024
EA DEC 2021
PG 10
WC Computer Science, Information Systems; Information Science & Library
   Science
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Information Science & Library Science
GA XQ5AB
UT WOS:000731556400001
DA 2022-02-06
ER

PT J
AU Wahl-Jorgensen, K
   Carlson, M
AF Wahl-Jorgensen, Karin
   Carlson, Matt
TI Conjecturing Fearful Futures: Journalistic Discourses on Deepfakes
SO JOURNALISM PRACTICE
LA English
DT Article
DE Artificial intelligence; deepfakes; fake news; journalistic authority;
   misinformation; trust in journalism
AB This paper investigates journalistic discourses on "deepfakes" as the future of fake news. We analyze journalistic discourses on deepfakes over an 18-month period from 1 January 2018, when a GoogleTrends search demonstrates that the term first began to circulate, to 1 July 2019, shortly after an altered video of Nancy Pelosi, the US Speaker of the House, circulated on social media. Based on a comprehensive thematic analysis of English-language news stories on the topic, drawn from Nexis UK, we suggest that journalistic responses to deepfakes reveal deeper anxieties both about the future of the information environment and journalism's role within this environment. Concerns that the audiovisual nature of deepfakes makes them inherently more believable than previous fake news forms leads to worries over the impending weaponization of deepfakes by resource-rich "bad actors." At stake is the trustworthiness of media content, and journalists' role in providing verified content to the public. We argue that journalists conjure up speculative worst-case scenarios around deepfakes-what we refer to as "conjectured specifity" to highlight the vital importance of journalism as a bulwark against fabrication and a defender of truth.
C1 [Wahl-Jorgensen, Karin] Cardiff Univ, Cardiff Sch Journalism Media & Culture, Cardiff, Wales.
   [Carlson, Matt] Univ Minnesota, Minneapolis, MN USA.
C3 Cardiff University; University of Minnesota System; University of
   Minnesota Twin Cities
RP Wahl-Jorgensen, K (corresponding author), Cardiff Univ, Cardiff Sch Journalism Media & Culture, Cardiff, Wales.
EM wahl-jorgensenk@cardiff.ac.uk
CR Braun V., 2012, APA HDB RES METHODS, DOI DOI 10.1037/13620-004
   Bruns A., 2019, ARE FILTER BUBBLES R
   CARLSON M, 2015, BOUNDARIES JOURNALIS
   Carlson M., 2017, JOURNALISTIC AUTHORI
   Carlson M, 2020, INFORM COMMUN SOC, V23, P374, DOI 10.1080/1369118X.2018.1505934
   Carlson M, 2018, NEW MEDIA SOC, V20, P1755, DOI 10.1177/1461444817706684
   Carlson M, 2015, DIGIT JOURNAL, V3, P416, DOI 10.1080/21670811.2014.976412
   Carlson M, 2009, JOURNAL PRACT, V3, P125, DOI 10.1080/17512780802681140
   Chalaby Jean, 1998, INVENTION JISM
   Clayton J., 2021, BBC NEWS
   Corner J, 2017, MEDIA CULT SOC, V39, DOI 10.1177/0163443717726743
   Creech B, 2019, JOURNAL PRACT, V13, P263, DOI 10.1080/17512786.2018.1472526
   Diakopoulos N, 2021, NEW MEDIA SOC, V23, P2072, DOI 10.1177/1461444820925811
   Dobber T, 2021, INT J PRESS/POLIT, V26, P69, DOI 10.1177/1940161220944364
   Ekstr?m M., 2017, MEDIATED POLITICS EU, P201
   Fereday J., 2006, INT J QUAL METHODS, V5, P80, DOI DOI 10.1177/160940690600500107
   Fine Gary Alan., 2009, AUTHORS STORM METEOR
   Gottfried J., 2019, PEW RES CTR REPORT
   Grice A., 2017, INDEPENDENT
   Hao K., 2020, MIT TECHNOL REV
   Hyde J, 2006, J COMMUN INQ, V30, P229, DOI 10.1177/0196859906287934
   Jack Caroline., 2017, DATA SOC
   Johnson BG, 2018, JOURNAL PRACT, V12, P817, DOI 10.1080/17512786.2017.1349546
   Kavanagh J., 2018, RAND CORPORATION BRI
   Lewis J., 2005, CITIZENS CONSUMERS
   Lowrey W, 2018, JOURNALISM, V19, P129, DOI 10.1177/1464884916670931
   Maddocks S., 2020, PORN STUDIES
   McCarthy C., 2019, SPECTATOR US
   McNair B., 1998, SOCIOLOGY JISM
   Mirsky Y, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3425780
   Neiger, 2007, JOURNALISM, V8, P309
   Newton J., 2013, BURDEN VISUAL TRUTH
   Nielsen RK, 2018, NEW MEDIA SOC, V20, P1600, DOI 10.1177/1461444817701318
   Pariser, 2011, FILTER BUBBLE WHAT I
   Phillips T., 2018, GUARDIAN
   Schwartz A.B., 2015, BROADCAST HYSTERIA
   Silverman Craig, 2016, BUZZFEED NEWS
   Tamul DJ, 2018, J MASS COMMUN Q, V95, P96, DOI 10.1177/1077699016681466
   Tandoc EC, 2019, JOURNAL PRACT, V13, P673, DOI 10.1080/17512786.2018.1562958
   Tandoc EC, 2018, DIGIT JOURNAL, V6, P137, DOI 10.1080/21670811.2017.1360143
   Tenenboim-Weinblatt K, 2015, COMMUN RES, V42, P1047, DOI 10.1177/0093650214558260
   Tenenboim-Weinblatt K, 2013, COMMUN THEOR, V23, P91, DOI 10.1111/comt.12006
   Thomas R.J., 2018, NEWSP RES J, V39, P350, DOI [10.1177/0739532918796228, DOI 10.1177/0739532918796228]
   Thornton, 2000, J MASS MEDIA ETHICS, V15, P89, DOI DOI 10.1207/S15327728JMME1502_3
   Vaccari C, 2020, SOC MEDIA SOC, V6, DOI 10.1177/2056305120903408
   Vos TP, 2018, JOURNALISM STUD, V19, P2001, DOI 10.1080/1461670X.2018.1492879
   Waisbord S, 2018, JOURNALISM STUD, V19, P1866, DOI 10.1080/1461670X.2018.1492881
   Ward SJA, 2009, INT COMMUN ASSOC HAN, P295
   Wardle C, 2017, INFORM DISORDER INTE
   Weaver DA, 2008, J MASS COMMUN Q, V85, P515, DOI 10.1177/107769900808500303
NR 50
TC 0
Z9 0
U1 7
U2 14
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 1751-2786
EI 1751-2794
J9 JOURNAL PRACT
JI Journal. Pract.
PD JUL 3
PY 2021
VL 15
IS 6
SI SI
BP 803
EP 820
DI 10.1080/17512786.2021.1908838
EA APR 2021
PG 18
WC Communication
WE Social Science Citation Index (SSCI)
SC Communication
GA TY1ZF
UT WOS:000637268000001
OA Bronze
DA 2022-02-06
ER

PT J
AU Lu, YJ
   Liu, YJ
   Fei, JW
   Xia, ZH
AF Lu, Yujiang
   Liu, Yaju
   Fei, Jianwei
   Xia, Zhihua
TI Channel-Wise Spatiotemporal Aggregation Technology for Face Video
   Forensics
SO SECURITY AND COMMUNICATION NETWORKS
LA English
DT Article
AB Recent progress in deep learning, in particular the generative models, makes it easier to synthesize sophisticated forged faces in videos, leading to severe threats on social media about personal privacy and reputation. It is therefore highly necessary to develop forensics approaches to distinguish those forged videos from the authentic. Existing works are absorbed in exploring frame-level cues but insufficient in leveraging affluent temporal information. Although some approaches identify forgeries from the perspective of motion inconsistency, there is so far not a promising spatiotemporal feature fusion strategy. Towards this end, we propose the Channel-Wise Spatiotemporal Aggregation (CWSA) module to fuse deep features of continuous video frames without any recurrent units. Our approach starts by cropping the face region with some background remained, which transforms the learning objective from manipulations to the difference between pristine and manipulated pixels. A deep convolutional neural network (CNN) with skip connections that are conducive to the preservation of detection-helpful low-level features is then utilized to extract frame-level features. The CWSA module finally makes the real or fake decision by aggregating deep features of the frame sequence. Evaluation against a list of large facial video manipulation benchmarks has illustrated its effectiveness. On all three datasets, FaceForensics++, Celeb-DF, and DeepFake Detection Challenge Preview, the proposed approach outperforms the state-of-the-art methods with significant advantages.
C1 [Lu, Yujiang] Nanjing Univ Informat Sci Technol, Changwang Sch Honors, Nanjing 210044, Peoples R China.
   [Liu, Yaju; Fei, Jianwei] Nanjing Univ Informat Sci Technol, Sch Comp & Software, Nanjing 210044, Peoples R China.
   [Xia, Zhihua] Nanjing Univ Informat Sci Technol, Jiangsu Collaborat Innovat Ctr Atmospher Environm, Jiangsu Engn Ctr Network Monitoring, Engn Res Ctr Digital Forens,Minist Educ,Sch Comp, Nanjing 210044, Peoples R China.
C3 Nanjing University of Information Science & Technology; Nanjing
   University of Information Science & Technology; Nanjing University of
   Information Science & Technology
RP Xia, ZH (corresponding author), Nanjing Univ Informat Sci Technol, Jiangsu Collaborat Innovat Ctr Atmospher Environm, Jiangsu Engn Ctr Network Monitoring, Engn Res Ctr Digital Forens,Minist Educ,Sch Comp, Nanjing 210044, Peoples R China.
EM xia_zhihua@163.com
OI Fei, Jianwei/0000-0002-1243-3909; Lu, Yujiang/0000-0003-1501-6454
FU Jiangsu Basic Research Programs-Natural Science Foundation [BK20181407];
   National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [U1936118, 61672294, U1836208, 61702276,
   61772283, 61602253, 61601236]; Six Peak Talent Project of Jiangsu
   Province [R2016L13]; Qinglan Project of Jiangsu Province; "333" Project
   of Jiangsu ProvinceNatural Science Foundation of Jiangsu Province;
   National Key R&D Program of China [2018YFB1003205]; Priority Academic
   Program Development of Jiangsu Higher Education Institutions (PAPD)
   fund; Collaborative Innovation Center of Atmospheric Environment and
   Equipment Technology (CICAEET) fund, China
FX This work was supported in part by the Jiangsu Basic Research
   Programs-Natural Science Foundation under grant no. BK20181407, in part
   by the National Natural Science Foundation of China under grant nos.
   U1936118, 61672294, U1836208, 61702276, 61772283, 61602253, and
   61601236, in part by Six Peak Talent Project of Jiangsu Province
   (R2016L13), Qinglan Project of Jiangsu Province, and "333" Project of
   Jiangsu Province, in part by National Key R&D Program of China under
   grant 2018YFB1003205, in part by the Priority Academic Program
   Development of Jiangsu Higher Education Institutions (PAPD) fund, and in
   part by the Collaborative Innovation Center of Atmospheric Environment
   and Equipment Technology (CICAEET) fund, China.
CR Afchar D., 2018, 2018 IEEE INT WORKSH, P1, DOI DOI 10.1109/WIFS.2018.8630761
   Agarwal S, 2020, IEEE INT WORKS INFOR, DOI 10.1109/WIFS49906.2020.9360904
   Albright M., 2018, DETECTING GAN GENERA
   Amerini I, 2019, IEEE INT CONF COMP V, P1205, DOI 10.1109/ICCVW.2019.00152
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Cozza D., 2015, 2015 IEEE 42nd Photovoltaic Specialist Conference (PVSC). Proceedings, P1, DOI 10.1109/PVSC.2015.7355795
   Cozzolino D., 2019, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPRW47913.2019
   Dolhansky B., 2019, DEEPFAKE DETECTION C
   Durall Ricard, 2019, ARXIV191100686
   FERNANDES S, P IEEE INT C COMPUTE, DOI DOI 10.1109/ICCVW.2019.00213
   Howard A. G., 2017, ARXIV170404861
   Kumar A, 2020, IEEE POW ENER SOC GE
   Li LZ, 2020, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR42600.2020.00505
   Li YJ, 2019, IEEE INT C BIOINFORM, P303, DOI 10.1109/BIBM47256.2019.8982964
   Li YZ, 2018, IEEE INT WORKS INFOR
   Lukas J, 2006, IEEE T INF FOREN SEC, V1, P205, DOI 10.1109/TIFS.2006.873602
   Lyu S., P IEEE C COMPUTER VI, P46
   Mandelli S, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2106, DOI 10.1109/ICASSP.2018.8461904
   Nataraj L, 2019, ELECT IMAGING, V2019, P532, DOI DOI 10.2352/ISSN.2470-1173.2019.5.MWSF-532
   Rossler A, 2019, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2019.00009
   Sabir Ekraam, 2019, INTERFACES GUI, P80
   SZEGEDY C, 2016, PROC CVPR IEEE, P2818, DOI DOI 10.1109/CVPR.2016.308
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tan S, 2018, DETECTION DEEP NETWO
   Verdoliva L., 2019, SPOC SPOOFING CAMERA
   Wang R., 2020, P INT JOINT C ART IN, P3444
   Yu ZT, 2021, IEEE T PATTERN ANAL, V43, P3005, DOI 10.1109/TPAMI.2020.3036338
   Zakharov E, 2019, IEEE I CONF COMP VIS, P9458, DOI 10.1109/ICCV.2019.00955
   Zhang X., 2019, 2019 IEEE INT WORKSH, P1, DOI DOI 10.1109/WIFS47025.2019.9035107
   Zhao G., 2021, DEEP LEARNING FACE A
   Zhou TF, 2021, PROC CVPR IEEE, P5774, DOI 10.1109/CVPR46437.2021.00572
NR 31
TC 0
Z9 0
U1 1
U2 1
PU WILEY-HINDAWI
PI LONDON
PA ADAM HOUSE, 3RD FL, 1 FITZROY SQ, LONDON, WIT 5HE, ENGLAND
SN 1939-0114
EI 1939-0122
J9 SECUR COMMUN NETW
JI Secur. Commun. Netw.
PD AUG 29
PY 2021
VL 2021
AR 5524930
DI 10.1155/2021/5524930
PG 13
WC Computer Science, Information Systems; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA UN2ZI
UT WOS:000693887300003
OA gold
DA 2022-02-06
ER

PT J
AU Olaniyan, A
   Akpojivi, U
AF Olaniyan, Akintola
   Akpojivi, Ufuoma
TI Transforming communication, social media, counter-hegemony and the
   struggle for the soul of Nigeria
SO INFORMATION COMMUNICATION & SOCIETY
LA English
DT Article
DE Social media; regulation; fake news; citizen journalism; Nigeria; press;
   freedom
AB The emergence of information communication technologies has transformed communication in Nigeria. The mass media once regarded as the most vocal and vibrant press in Africa is losing public trust as people easily source for critical information from social media instead of the media due to their patrimonial relationship with the state. The potentials of these information communication technologies in holding government accountable and enhancing journalism practice has endangers the state. Consequently, attempts by the state at regulating social media and the mass media through draconian bills such as protection from internet falsehood and manipulation bill of 2019, and the National Communication for the prohibition of Hate Speech bill 2019. Using Habermas notion of the public sphere coupled with semi-structured interviews with 12 media practitioners, this paper examines ways in which such regulatory frameworks have impacted on both the media and democratic cultures of the Nigerian state. The paper argues that social media and its convergence in the newsroom has expounded the democratic culture due to its affordances of speedy and accountability. However, the potentials of social media and its affordance has been misused. Consequently, the contestation between the state, public and media on how social media and its convergence in the newsroom can be effectively regulated. The media and public do not trust the state as they blame the state for the rise of fake news (misinformation and disinformation). On the other hand, the state has blamed the desire for profit and commodification of news for the rise of fake news.
C1 [Olaniyan, Akintola; Akpojivi, Ufuoma] Univ Witwatersrand, Media Studies Dept, Johannesburg, South Africa.
C3 University of Witwatersrand
RP Akpojivi, U (corresponding author), Univ Witwatersrand, Media Studies Dept, Johannesburg, South Africa.
EM fuoteg@yahoo.com
RI Akpojivi, Ufuoma/W-3174-2018; Akpojivi, Ufuoma/P-7982-2019
OI Akpojivi, Ufuoma/0000-0002-9349-2977; Akpojivi,
   Ufuoma/0000-0002-9349-2977; Olaniyan, Akintola/0000-0002-3143-8721
CR Adesina D., 2019, COMMUNICATION   0119
   Adeyeye J., 2019, COMMUNICATION   1217
   Agre P., 1998, 1 MONDAY, V3, DOI [10.5210/fm.v3i2.581, DOI 10.5210/FM.V3I2.581]
   Akpojivi U., 2018, MEDIA REFORMS DEMOCR
   Alcott H., 2017, J EC PERSPECTIVES
   Allejandro J., 2010, JOURNALISM AGE SOCIA
   Amnesty International, 2019, NIG BILLS HAT SPEECH
   Ayo-Adenrele A., 2020, COMMUNICATION   0116
   BOURNE R, 2015, NIGERIA NEW HIST TUR
   Boyle L., 2017, DAILY MAIL
   Braun V., 2006, QUAL RES PSYCHOL, V3, P77, DOI DOI 10.1191/1478088706QP063OA
   Burns A., 2011, NEWS ONLINE TRANSFOR
   CARPENTIER N, 2006, JOURNALISM STUD, V7, P964, DOI DOI 10.1080/14616700600980728
   Carson James, 2019, TELEGRAPH
   Castells Manuel, 2009, COMMUNICATION POWER
   Charles A, 2000, QUESTIONS MODERNITY, pXI
   Cohen-Alagor R., 2001, SPEECH MEDIA ETHICS
   Creswell J., 2009, RES DESIGN QUALITATI
   Dare S., 2011, RISE CITIZEN JOURNAL
   Davey-Attlee F., 2017, CNN
   Dickson E., 2019, COMMUNICATION   1221
   Earle S., 2017, TIME
   Erezi D., 2019, GUARDIAN
   Ferrara Emilio, 2018, First Monday, V22, DOI 10.5210/fm.v22i18.8005
   Ferrara E., 2016, 1 MONDAY, V21
   Fosu M, 2015, J APPL JOURNAL MEDIA, V4, P277, DOI 10.1386/ajms.4.2.277_1
   Fuchs C, 2013, TRIPLEC-COMMUN CAPIT, V11, P237
   Godwin A. C., 2013, DAILY POST      1205
   Habermas J., 1962, STRUCTURAL TRANSFORM
   Habermas J, 1984, THEORY COMMUNICATIVE, V1
   Hachten W. A., 1971, MUFFLED DRUMS NEWS M
   Hirst M, 2017, POLITICAL EC COMMUNI, V5, P82
   Kolawole S., 2019, COMMUNICATION   1223
   Kperogi F. A., 2018, PARTICIPATORY POLITI
   Lee P., 2016, PEOPLE POWERED MEDIA
   Lindlof T.R., 2011, QUALITATIVE COMMUNIC, V3rd ed
   MACKAY I., 1964, BROADCASTING NIGERIA
   Maringues M., 2001, NIGERIA ABACHA YEARS
   McNair B., 1998, SOCIOLOGY JISM
   McNair B, 2011, COMMUN SOC-SER, P3
   Mohammed M., 2004, WHO OWNS MEDIA GLOBA
   Moskalenko V, 2019, ASIA COMMUN PHOTON
   Mutsvairo B., 2016, DIGITAL ACTIVISM SOC, P3
   Newman N., 2009, RISE SOCIAL MEDIA IT
   Nyamnjoh F., 2005, RHODES JOURNALISM RE, V2005
   Obadare E., 1999, ISSUE J OPINION, V27, DOI 10.2307/1167003
   Obijiofor L., 2015, NEW TECHNOLOGIES DEV
   Oladeinde A., 2019, COMMUNICATION   1220
   Olagunju L., 2019, COMMUNICATION   1220
   Olaniyan A., 2014, THESIS
   Olorunyomi D., 2019, COMMUNICATION   1029
   Olowolagba F., 2019, DAILY POST      0606
   Olukotun A, 2010, AFRICA CONNECTS, P155
   Omilana T., 2019, ALJAZEERA
   Omu F., 1996, JOURNALISM IN NIGERI
   Omu F., 1974, J HIST SOC NIGERIA, V7, P521
   Oni D., 2019, COMMUNICATION   1215
   Onyenankeya K, 2020, MEDIA WATCH, V11, P97, DOI [10.15655/mw/2020/v11i1/49758, DOI 10.15655/MW/2020/V11I1/49758]
   Oso L., 2011, MASS MEDIA SOC NIGER
   Oso L., 2018, WATCHDOGS CAPTURED M
   Saldana J., 2009, CODING MANUAL QUALIT
   Seib P, 2012, REAL-TIME DIPLOMACY: POLITICS AND POWER IN THE SOCIAL MEDIA ERA, P1, DOI 10.1057/9781137010902
   Silverman C., 2016, BUZZFEED NEWS 0125
   Sotade N., 2019, COMMUNICATION   0115
   Sowore M., 2019, COMMUNICATION   0109
   Stiglitz J. E., 2017, SERVICE POWER MEDIA, P9
   Subramanian Samanth, 2017, WIRED
   Tufekci Z., 2017, TWITTER TEAR GAS POW
   Umoru H., 2015, SENATE PROPOSES 2 YE
   Valtysson B., 2012, J GLOBAL SUSTAINABLE, V10
   VANSTEENDAM E, 2012, STUD WRIT, pR
   Wasserman H, 2019, AFR JOURNAL STUD, V40, P107, DOI 10.1080/23743670.2019.1627230
   White A., 2017, ETHICAL JOURNALISM N
   Woolley Samuel C., 2016, First Monday, V21, DOI 10.5210/fm.v21i4.6161
   Yin RK., 2011, QUALITATIVE RES STAR
NR 75
TC 0
Z9 0
U1 3
U2 19
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 1369-118X
EI 1468-4462
J9 INFORM COMMUN SOC
JI Info. Commun. Soc.
PD FEB 17
PY 2021
VL 24
IS 3
SI SI
BP 422
EP 437
DI 10.1080/1369118X.2020.1804983
EA AUG 2020
PG 16
WC Communication; Sociology
WE Social Science Citation Index (SSCI)
SC Communication; Sociology
GA QR0TE
UT WOS:000561977500001
DA 2022-02-06
ER

PT J
AU Seo, JW
   Jung, HG
   Lee, SW
AF Seo, Jin-Woo
   Jung, Hong-Gyu
   Lee, Seong-Whan
TI Self-augmentation: Generalizing deep networks to unseen classes for
   few-shot learning
SO NEURAL NETWORKS
LA English
DT Article
DE Few-shot learning; Classification; Generalization; Knowledge
   distillation
ID RECOGNITION; TRACKING
AB Few-shot learning aims to classify unseen classes with a few training examples. While recent works have shown that standard mini-batch training with carefully designed training strategies can improve generalization ability for unseen classes, well-known problems in deep networks such as memorizing training statistics have been less explored for few-shot learning. To tackle this issue, we propose self-augmentation that consolidates self-mix and self-distillation. Specifically, we propose a regional dropout technique called self-mix, in which a patch of an image is substituted into other values in the same image. With this dropout effect, we show that the generalization ability of deep networks can be improved as it prevents us from learning specific structures of a dataset. Then, we employ a backbone network that has auxiliary branches with its own classifier to enforce knowledge sharing. This sharing of knowledge forces each branch to learn diverse optimal points during training. Additionally, we present a local representation learner to further exploit a few training examples of unseen classes by generating fake queries and novel weights. Experimental results show that the proposed method outperforms the state-of-the-art methods for prevalent few-shot benchmarks and improves the generalization ability. (c) 2021 Elsevier Ltd. All rights reserved.
C1 [Seo, Jin-Woo; Jung, Hong-Gyu] Korea Univ, Dept Brain & Cognit Engn, Seoul 02841, South Korea.
   [Lee, Seong-Whan] Korea Univ, Dept Artificial Intelligence, Seoul 02841, South Korea.
C3 Korea University; Korea University
RP Lee, SW (corresponding author), Korea Univ, Dept Artificial Intelligence, Seoul 02841, South Korea.
EM sw.lee@korea.ac.kr
OI Jung, Hong-Gyu/0000-0003-3149-2354
FU Institute for Information & communications Technology Planning &
   Evaluation (IITP) - Korea government (MSIT) [2017-0-01779, 2019-0-01371,
   20190-00079]
FX This work was supported by Institute for Information & communications
   Technology Planning & Evaluation (IITP) grant funded by the Korea
   government (MSIT) (No. 2017-0-01779, A machine learning and statistical
   inference framework for explainable artificial intelligence, No.
   2019-0-01371, Development of brain-inspired AI with human-like
   intelligence, and No. 20190-00079, Artificial Intelligence Graduate
   School Program, Korea University).
CR Bertinetto L., 2019, PROC INT C LEARN REP, P1
   Chen W, 2020, ENG COMPUT-GERMANY, V36, P1101, DOI 10.1007/s00366-019-00752-x
   Cubuk Ekin D., 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW). Proceedings, P3008, DOI 10.1109/CVPRW50498.2020.00359
   DeVries T., 2017, ARXIV170804552
   Dvornik N, 2019, IEEE I CONF COMP VIS, P3722, DOI 10.1109/ICCV.2019.00382
   Finn C, 2017, PR MACH LEARN RES, V70
   Gidaris S, 2019, IEEE I CONF COMP VIS, P8058, DOI 10.1109/ICCV.2019.00815
   Gidaris S, 2019, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2019.00011
   Gidaris S, 2018, PROC CVPR IEEE, P4367, DOI 10.1109/CVPR.2018.00459
   Guo C., 2017, P 34 C MACH LEARN
   Han-Jia Ye, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8805, DOI 10.1109/CVPR42600.2020.00883
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton G, 2015, ARXIV150302531, V14, P38, DOI DOI 10.4140/TCP.N.2015.249
   Hou RB, 2019, ADV NEUR IN, V32
   Kang D, 2014, PATTERN RECOGN, V47, P3750, DOI 10.1016/j.patcog.2014.06.004
   Krizhevsky A., 2009, CIFAR 10 CIFAR 100 D
   Lan X, 2018, ADV NEUR IN, V31
   Lee K, 2019, PROC CVPR IEEE, P10649, DOI 10.1109/CVPR.2019.01091
   Lee SW, 1999, IEEE T SYST MAN CY C, V29, P285, DOI 10.1109/5326.760572
   Li HT, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317874
   Lifchitz Y, 2019, PROC CVPR IEEE, P9250, DOI 10.1109/CVPR.2019.00948
   Liu Y, 2020, NEURAL NETWORKS, V121, P1, DOI 10.1016/j.neunet.2019.08.023
   Muller R., 2019, ARXIV190602629
   Neyshabur B., 2017, ADV NEURAL INFORM PR
   Oreshkin BN, 2018, ADV NEUR IN, V31
   Pereyra Gabriel, 2017, ARXIV PREPRINT ARXIV, DOI DOI 10.1109/ICUWB.2017.8250956
   Qi H, 2018, PROC CVPR IEEE, P5822, DOI 10.1109/CVPR.2018.00610
   Ravi S, 2017, PROC INT C LEARN REP, P24
   Ren M., 2018, ICLR, P1, DOI DOI 10.1109/IPFA.2018.8452547
   Roh MC, 2007, PATTERN RECOGN, V40, P931, DOI 10.1016/j.patcog.2006.06.014
   Roh MC, 2010, PATTERN RECOGN LETT, V31, P639, DOI 10.1016/j.patrec.2009.11.017
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Rusu A. A., 2019, ICLR, P1
   Snell J., 2017, PROC NEURIPS, P4077, DOI DOI 10.5555/3294996.3295163
   Sun DW, 2019, PROC CVPR IEEE, P6990, DOI 10.1109/CVPR.2019.00716
   Sun QR, 2019, PROC CVPR IEEE, P403, DOI 10.1109/CVPR.2019.00049
   Sung F, 2018, PROC CVPR IEEE, P1199, DOI 10.1109/CVPR.2018.00131
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Thulasidasan S, 2019, ADV NEUR IN, V32
   Tokozume Y, 2018, PROC CVPR IEEE, P5486, DOI 10.1109/CVPR.2018.00575
   Ukita J, 2020, NEURAL NETWORKS, V125, P185, DOI 10.1016/j.neunet.2020.02.009
   Verma V., 2018, P INT C MACH LEARN
   Vinyals O., 2016, NIPS, P3637
   Wah C., 2011, CALTECH UCSD BIRDS 2
   Wallraven C., 2003, BIOL MOTIVATED COMPU
   Xing C, 2019, ADV NEUR IN, V32
   Yun S, 2019, IEEE I CONF COMP VIS, P6022, DOI 10.1109/ICCV.2019.00612
   Zhan C., 2017, IEEE WIREL COMMUN
   Zhang Chi, 2020, P IEEE CVF C COMP VI
   Zhang H., 2018, 6 INT C LEARN REPR I, P1
   Zhang Y, 2018, PROC CVPR IEEE, P4320, DOI 10.1109/CVPR.2018.00454
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
   Zhu HY, 2020, PATTERN RECOGN, V107, DOI 10.1016/j.patcog.2020.107354
NR 53
TC 4
Z9 4
U1 3
U2 10
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0893-6080
EI 1879-2782
J9 NEURAL NETWORKS
JI Neural Netw.
PD JUN
PY 2021
VL 138
BP 140
EP 149
DI 10.1016/j.neunet.2021.02.007
PG 10
WC Computer Science, Artificial Intelligence; Neurosciences
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Neurosciences & Neurology
GA RN9CZ
UT WOS:000640651000011
PM 33652370
OA Green Submitted
DA 2022-02-06
ER

PT J
AU Xue, ZX
AF Xue, Zhixiang
TI Semi-supervised convolutional generative adversarial network for
   hyperspectral image classification
SO IET IMAGE PROCESSING
LA English
DT Article
DE neural nets; pattern classification; geophysical image processing;
   learning (artificial intelligence); image classification; semisupervised
   generative adversarial training strategy; deep residual network;
   labelled samples; widely used hyperspectral images; classification
   performance; training samples; hyperspectral image classification;
   insufficient annotated samples; semisupervised convolutional generative
   adversarial network classification model; generative adversarial
   framework; adversarial game; generator captures data distribution; fake
   samples; three-dimensional convolutional neural network; fake cube
   samples; trained discriminator
ID SPECTRAL-SPATIAL CLASSIFICATION; NEURAL-NETWORKS
AB To solve the problem of insufficient annotated samples in hyperspectral image classification, the semi-supervised convolutional generative adversarial network classification model is proposed in this study. The generative adversarial framework constructs an adversarial game, where the generator captures data distribution and generates fake samples, while the discriminator determines whether the input comes from generated or training data. In the proposed method, a deep three-dimensional (3D) convolutional neural network is used to generate the so-called fake cube samples and another 3D deep residual network is designed to discriminate the inputs. Furthermore, the generated samples, labelled and unlabelled samples are put into the discriminator for joint training, and the trained discriminator can determine the authenticity of the sample and the class label. This semi-supervised generative adversarial training strategy can effectively improve the generalisation capability of the deep residual network where the labelled samples are limited. Three widely used hyperspectral images are utilised to evaluate the classification performance of the proposed method: Indian Pines, Pavia University, and Salinas-A. The classification results reveal that the proposed model can improve the classification performance and achieve competitive results compared with the state-of-art methods, especially when there are few training samples.
C1 [Xue, Zhixiang] Informat Engn Univ, Zhengzhou 450052, Peoples R China.
C3 PLA Information Engineering University
RP Xue, ZX (corresponding author), Informat Engn Univ, Zhengzhou 450052, Peoples R China.
EM xuegeeker@163.com
OI Xue, Zhixiang/0000-0003-2463-4342
CR Audebert N, 2018, INT GEOSCI REMOTE SE, P4359, DOI 10.1109/IGARSS.2018.8518321
   Barman B, 2019, IET IMAGE PROCESS, V13, P1266, DOI 10.1049/iet-ipr.2018.6496
   Benediktsson JA, 2005, IEEE T GEOSCI REMOTE, V43, P480, DOI 10.1109/TGRS.2004.842478
   Chen YS, 2014, IEEE J-STARS, V7, P2094, DOI 10.1109/JSTARS.2014.2329330
   Dai Zihang, 2017, ADV NEURAL INFORM PR
   Dalla Mura M, 2011, IEEE GEOSCI REMOTE S, V8, P542, DOI 10.1109/LGRS.2010.2091253
   Deng F, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18093153
   Foody GM, 2004, PHOTOGRAMM ENG REM S, V70, P627, DOI 10.14358/PERS.70.5.627
   Gewali U.B., 2018, ARXIV COMPUTER VISIO
   Ghamisi P, 2018, IEEE GEOSC REM SEN M, V6, P10, DOI 10.1109/MGRS.2018.2854840
   Ghamisi P, 2017, IEEE GEOSC REM SEN M, V5, P37, DOI 10.1109/MGRS.2017.2762087
   Ghamisi P, 2015, IEEE T GEOSCI REMOTE, V53, P2335, DOI 10.1109/TGRS.2014.2358934
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Gu YF, 2017, IEEE T GEOSCI REMOTE, V55, P6547, DOI 10.1109/TGRS.2017.2729882
   HE KM, 2015, PROC CVPR IEEE, P5353, DOI [DOI 10.1109/CVPR.2015.7299173, 10.1109/CVPR.2015.7299173]
   He L, 2018, IEEE T GEOSCI REMOTE, V56, P1579, DOI 10.1109/TGRS.2017.2765364
   He Z, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9101042
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Hu W, 2015, J SENSORS, V2015, DOI 10.1155/2015/258619
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Karaca AC, 2012, INT GEOSCI REMOTE SE, P4970, DOI 10.1109/IGARSS.2012.6352496
   Li John Zenghong, 2012, ISRN Otolaryngol, V2012, P708974, DOI 10.5402/2012/708974
   Li W, 2017, IEEE T GEOSCI REMOTE, V55, P844, DOI 10.1109/TGRS.2016.2616355
   Li WX, 2017, SUSTAINABILITY-BASEL, V9, DOI 10.3390/su9010152
   Liu B, 2019, IEEE T GEOSCI REMOTE, V57, P2290, DOI 10.1109/TGRS.2018.2872830
   Metz L., 2016, P 4 INT C LEARNING R
   Salimans T., 2016, ADV NEURAL INFORM PR, P2234
   Simonyan K, 2015, ICLR 2015, DOI DOI 10.1109/CVPR.2015.7298594
   Wu J, 2016, ADV NEURAL INFORM PR, P82, DOI DOI 10.5555/3157096.3157106
   Yao KS, 2013, INTERSPEECH, P2523
   Yue J, 2015, REMOTE SENS LETT, V6, P468, DOI 10.1080/2150704X.2015.1047045
   Zhan Y, 2018, INT GEOSCI REMOTE SE, P5756, DOI 10.1109/IGARSS.2018.8518846
   Zhan Y, 2018, IEEE GEOSCI REMOTE S, V15, P212, DOI 10.1109/LGRS.2017.2780890
   Zhao WZ, 2016, IEEE T GEOSCI REMOTE, V54, P4544, DOI 10.1109/TGRS.2016.2543748
   Zhong ZL, 2020, IEEE T CYBERNETICS, V50, P3318, DOI 10.1109/TCYB.2019.2915094
   Zhong ZL, 2018, IEEE T GEOSCI REMOTE, V56, P847, DOI 10.1109/TGRS.2017.2755542
   Zhu L, 2018, IEEE T GEOSCI REMOTE, V56, P5046, DOI 10.1109/TGRS.2018.2805286
NR 37
TC 2
Z9 2
U1 6
U2 29
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1751-9659
EI 1751-9667
J9 IET IMAGE PROCESS
JI IET Image Process.
PD MAR 27
PY 2020
VL 14
IS 4
BP 709
EP 719
DI 10.1049/iet-ipr.2019.0869
PG 11
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Imaging Science & Photographic Technology
GA KW1WN
UT WOS:000520961700014
DA 2022-02-06
ER

PT J
AU Ghanem, B
   Rosso, P
   Rangel, F
AF Ghanem, Bilal
   Rosso, Paolo
   Rangel, Francisco
TI An Emotional Analysis of False Information in Social Media and News
   Articles
SO ACM TRANSACTIONS ON INTERNET TECHNOLOGY
LA English
DT Article
DE Fake news; suspicious news; false information; emotional analysis
ID FACT
AB Fake news is risky, since it has been created to manipulate readers' opinions and beliefs. In this work, we compared the language of false news to the real one of real news from an emotional perspective, considering a set of false information types (propaganda, hoax, clickbait, and satire) from social media and online news article sources. Our experiments showed that false information has different emotional patterns in each of its types, and emotions play a key role in deceiving the reader. Based on that, we proposed an LSTM neural network model that is emotionally infused to detect false news.
C1 [Ghanem, Bilal; Rosso, Paolo] Univ Politecn Valencia, Valencia, Spain.
   [Rangel, Francisco] Symanto Res, Nurnberg, Germany.
C3 Universitat Politecnica de Valencia
RP Ghanem, B (corresponding author), Univ Politecn Valencia, Valencia, Spain.
EM bigha@doctor.upv.es; prosso@dsic.upv.es; kico.rangel@gmail.com
OI Ghanem, Bilal/0000-0001-7973-8574
FU Spanish MICINNSpanish Government [PGC2018-096212B-C31]
FX The work of the second author was partially funded by the Spanish MICINN
   under the research project MISMISFAKEnHATE on Misinformation and
   Miscommunication in social media: FAKEnews and HATE speech
   (PGC2018-096212B-C31).
CR Arnold M.B., 1960, EMOTION PERSONALITY
   Bhatt G, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), P1353, DOI 10.1145/3184558.3191577
   de Albornoz JC, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3562
   Castillo C., 2011, WWW, P675
   Chakraborty A, 2016, PROCEEDINGS OF THE 2016 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING ASONAM 2016, P9, DOI 10.1109/ASONAM.2016.7752207
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   Fast E, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P4647, DOI 10.1145/2858036.2858535
   Frenda Simona, 2018, P 3 WORKSH EV HUM LA, V2150, P260
   Ghanem B., 2018, P 1 WORKSH FACT EXTR, P66
   Ghanem Bilal, 2018, P C LABS EV FOR CLEF
   Hanselowski A., 2018, ARXIV180605180
   Farias DIH, 2016, ACM T INTERNET TECHN, V16, DOI 10.1145/2930663
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735
   Karadzhov G., 2017, P INT C REC ADV NAT, P344, DOI DOI 10.26615/978-954-452-049-6_046
   Karduni Alireza, 2018, P 12 INT AAAI C WEB
   Kochkina E., 2018, ARXIV180603713
   Kumar S, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16), P591, DOI 10.1145/2872427.2883085
   Li X, 2011, PROC INT CONF DATA, P63, DOI 10.1109/ICDE.2011.5767859
   Livio Mario, 2017, WHY WHAT MAKES US CU
   Ma J., 2016, P 25 INT JOINT C ART, P3818
   Nyhan B, 2010, POLIT BEHAV, V32, P303, DOI 10.1007/s11109-010-9112-2
   Parrott W. G., 2001, EMOTIONS SOCIAL PSYC
   Plutchik R, 2001, AM SCI, V89, P344, DOI 10.1511/2001.4.344
   Popat K, 2018, ARXIV180906416
   Popat K, 2016, CIKM'16: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P2173, DOI 10.1145/2983323.2983661
   Poria S, 2013, IEEE INTELL SYST, V28, P31, DOI 10.1109/MIS.2013.4
   Qazvinian V., 2011, P 2011 C EMP METH NA, P1589
   Raffel C., 2015, ARXIV151208756
   Rangel F, 2016, INFORM PROCESS MANAG, V52, P73, DOI 10.1016/j.ipm.2015.06.003
   Rashkin Hannah, 2017, P 2017 C EMPIRICAL M, P2931
   RUBIN Victoria L., 2015, P 78 ASIS T ANN M IN, P83
   Ruchansky N, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P797, DOI 10.1145/3132847.3132877
   Tausczik YR, 2010, J LANG SOC PSYCHOL, V29, P24, DOI 10.1177/0261927X09351676
   Turney P., 2010, P NAACL HLT 2010 WOR, P26
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Volkova S, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P647, DOI 10.18653/v1/P17-2102
   Vosoughi S, 2018, SCIENCE, V359, P1146, DOI 10.1126/science.aap9559
   Wang A.P., 2013, 27 PAC AS C LANG INF, P349
   Zannettou S, 2018, ARXIV180403461
   Zhao Z, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P1395, DOI 10.1145/2736277.2741637
NR 40
TC 25
Z9 25
U1 14
U2 28
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1533-5399
EI 1557-6051
J9 ACM T INTERNET TECHN
JI ACM Trans. Internet. Technol.
PD MAY
PY 2020
VL 20
IS 2
AR 19
DI 10.1145/3381750
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA OJ1BU
UT WOS:000583703300012
OA Green Submitted, Green Published
DA 2022-02-06
ER

PT J
AU Kaddoura, S
   Chandrasekaran, G
   Popescu, DE
   Duraisamy, JH
AF Kaddoura, Sanaa
   Chandrasekaran, Ganesh
   Popescu, Daniela Elena
   Duraisamy, Jude Hemanth
TI A systematic literature review on spam content detection and
   classification
SO PEERJ COMPUTER SCIENCE
LA English
DT Review
DE Spam Content; Machine learning; Deep learning; Natural language
   processing; Social media analysis; Classification; Text mining; Data
   mining
ID OPINION SPAM; DEEP; FRAMEWORK; NETWORK
AB The presence of spam content in social media is tremendously increasing, and therefore the detection of spam has become vital. The spam contents increase as people extensively use social media, i.e., Facebook, Twitter, YouTube, and E-mail. The time spent by people using social media is overgrowing, especially in the time of the pandemic. Users get a lot of text messages through social media, and they cannot recognize the spam content in these messages. Spam messages contain malicious links, apps, fake accounts, fake news, reviews, rumors, etc. To improve social media security, the detection and control of spam text are essential. This paper presents a detailed survey on the latest developments in spam text detection and classification in social media. The various techniques involved in spam detection and classification involving Machine Learning, Deep Learning, and text-based approaches are discussed in this paper. We also present the challenges encountered in the identification of spam with its control mechanisms and datasets used in existing works involving spam detection.
C1 [Kaddoura, Sanaa] Zayed Univ, Abu Dhabi, U Arab Emirates.
   [Chandrasekaran, Ganesh] Sri Eshwar Coll Engn, Elect & Commun Engn, Coimbatore, Tamil Nadu, India.
   [Popescu, Daniela Elena] Univ Oradea, Fac Elect Engn & Informat Technol, Oradea, Romania.
   [Duraisamy, Jude Hemanth] Karunya Inst Technol & Sci, Elect & Commun Engn, Coimbatore, Tamil Nadu, India.
C3 Zayed University; University of Oradea; Karunya Institute of Technology
   & Sciences
RP Duraisamy, JH (corresponding author), Karunya Inst Technol & Sci, Elect & Commun Engn, Coimbatore, Tamil Nadu, India.
EM judehemanth@karunya.edu
FU Zayed University-Start-up research grant [R20081]
FX This work was funded by Zayed University-Start-up research grant (Grant
   number R20081). The funders had no role in study design, data collection
   and analysis, decision to publish, or preparation of the manuscript.
CR AbdulNabi I, 2021, PROCEDIA COMPUT SCI, V184, P853, DOI 10.1016/j.procs.2021.03.107
   Abiramasundari S, ANN ROMANIAN SOC CEL, V25, P18
   Ahmad SBS, 2021, MULTIMED TOOLS APPL, V80, P11583, DOI 10.1007/s11042-020-10405-7
   Aiyar Shreyas, 2018, Procedia Computer Science, V132, P174, DOI 10.1016/j.procs.2018.05.181
   Al-Zoubi AM, 2018, KNOWL-BASED SYST, V153, P91, DOI 10.1016/j.knosys.2018.04.025
   Alauthman M., 2020, INT J EMERGING TREND, V8, P1979, DOI [10.30534/ijeter/2020/83852020, DOI 10.30534/IJETER/2020/83852020]
   Albalawi Y, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00488-w
   Alharthi R, 2021, INFORM SYST, V99, DOI 10.1016/j.is.2021.101740
   Almeida TA, 2012, STUD COMPUT INTELL, V394, P199
   Alom Z, 2020, ONLINE SOC NETW MEDI, V18, DOI [10.1016/j.osnem.2020.100079, DOI 10.1016/J.OSNEM.2020.100079]
   Barushka A, 2019, ARTIF INTELL, V559, P340
   Basyar I, 2020, J COMPUTER SCI, V16, P559
   Bathla Gourav, 2021, 2021 8th International Conference on Signal Processing and Integrated Networks (SPIN), P1160, DOI 10.1109/SPIN52536.2021.9566048
   Bauer E., 2018, OUTRAGEOUS EMAIL SPA
   Benevenuto F., 2010, COLLABORATION ELECT, V6, P12, DOI DOI 10.1109/ICDE.2012.16
   Biggio B, 2011, PATTERN RECOGN LETT, V32, P1436, DOI 10.1016/j.patrec.2011.03.022
   Chen C, 2015, IEEE ICC, P7065, DOI 10.1109/ICC.2015.7249453
   Chu Z, 2012, DETECTING SOCIAL SPA, P455
   Ciltik A, 2008, PATTERN RECOGN LETT, V29, P19, DOI 10.1016/j.patrec.2007.07.018
   Crawford M, 2021 IEEE 22 INT C I, P248
   Daisy SJS, 2021, MATER TODAY-PROC, V47, P446, DOI 10.1016/j.matpr.2021.04.630
   Dedeturk BK, 2020, APPL SOFT COMPUT, V91, DOI 10.1016/j.asoc.2020.106229
   Dewan P, 2015, ANN CONF PRIV SECUR, P85, DOI 10.1109/PST.2015.7232958
   Dhawan Sanjeev, 2018, Procedia Computer Science, V132, P429, DOI 10.1016/j.procs.2018.05.156
   Fattahi J, 2020, SPAML BIMODAL ENSEMB
   Feng B, 2018, IEEE NETWORK, V32, P15, DOI 10.1109/MNET.2018.1700406
   Fuad MM, 2004, P 7 INT C COMP INF T
   HaCohen-Kerner Y, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0232525
   Fusilier DH, 2015, LECT NOTES COMPUT SC, V9042, P285, DOI 10.1007/978-3-319-18117-2_21
   Ho-Dac NN, 2013, J MARKETING, V77, P37, DOI 10.1509/jm.11.0011
   Horne BD, 2017, THIS JUST FAKE NEWS, P9
   Hossain F, 2021, 2021 IEEE INTERNATIONAL IOT, ELECTRONICS AND MECHATRONICS CONFERENCE (IEMTRONICS), P552, DOI 10.1109/IEMTRONICS52119.2021.9422508
   Inuwa-Dutse I, 2018, NEUROCOMPUTING, V315, P496, DOI 10.1016/j.neucom.2018.07.044
   Jain A, 2018, THWARTING SPAM FACEB
   Jin X, 2011, PROC VLDB ENDOW, V4, P1458
   Junnarkar Akash, 2021, Proceedings of the Third International Conference on Intelligent Communication Technologies and Virtual Mobile Networks (ICICV 2020), P693, DOI 10.1109/ICICV50876.2021.9388530
   Kanaris I, 2006, LECT NOTES COMPUT SC, V3955, P95
   Kim H, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9112347
   Kim SM, 2009, PROCEEDINGS OF THE 2009 SIXTH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: NEW GENERATIONS, VOLS 1-3, P376, DOI 10.1109/ITNG.2009.119
   Klassen M., 2013, TWITTER DATA PREPROC
   Klosowski P, 2018, SIG P ALGO ARCH ARR, P223, DOI 10.23919/SPA.2018.8563389
   Kontsewaya Y, 2021, PROCEDIA COMPUTER SC, V190, P479
   Koprinska I, 2007, INFORM SCIENCES, V177, P2167, DOI 10.1016/j.ins.2006.12.005
   Kumar N, 2018, J MANAGE INFORM SYST, V35, P350, DOI 10.1080/07421222.2018.1440758
   Lai SW, 2015, PROCEEDINGS OF THE TWENTY-NINTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2267
   Lee K, 2010, P 19 INT C WORLD WID, P1566, DOI DOI 10.1145/1772690.1772843
   Liu L, 2016, DETECTING SMART SPAM
   Liu YC, 2019, NEUROCOMPUTING, V366, P276, DOI 10.1016/j.neucom.2019.08.013
   Liu YC, 2018, EXPERT SYST APPL, V112, P148, DOI 10.1016/j.eswa.2018.06.028
   Liu YX, 2022, INFORM SYST, V103, DOI 10.1016/j.is.2021.101865
   Luo Q, 2011, 2011 INT C COMP INF, P398
   Ma J, IJCAI 16 P 25 INT JO
   Makkar A, 2020, FUTURE GENER COMP SY, V108, P467, DOI 10.1016/j.future.2020.03.004
   Mani S, 2018, MACHINE LEARNING DAT
   Mateen M, 2017, INT BHURBAN C APPL S, P466, DOI 10.1109/IBCAST.2017.7868095
   Mazikua SB, 2020, J SW JIAOTONG U, V55, P1, DOI [10.35741/issn.0258-2724, DOI 10.35741/ISSN.0258-2724]
   McCord M., 2011, Autonomic and Trusted Computing. Proceedings 8th International Conference (ATC 2011), P175, DOI 10.1007/978-3-642-23496-5_13
   Mendez JR, 2006, LECT NOTES ARTIF INT, V4065, P106
   Mendez JR, 2005, C SPAN ASS ART INT, P449
   Mohale P, 2018, AFR C INF SYST TECHN
   Mohammed S, 2013, INT J HYBRID INFORM, V6, P15
   Mukherjee A, 2013, 7 INT AAAI C WEBL SO, V7, P1
   Nayak R, 2021, MATER TODAY-PROC, V4, P862, DOI [10.1016/j.matpr.2021.03.147, DOI 10.1016/J.MATPR.2021.03.147]
   Neisari A, 2021, COMPUT SECUR, V106, DOI 10.1016/j.cose.2021.102274
   Okunade OA, 2017, ARID ZONE J ENG TECH, V13, P391
   Ott M, 2013, P NAACL HLT 2013, P497
   Pennington J., 2014, EMNLP, P1532, DOI [10.3115/v1/D14-1162, DOI 10.3115/V1/D14-1162]
   Rathore S, 2018, APPL SOFT COMPUT, V67, P920, DOI 10.1016/j.asoc.2017.09.032
   Raza M, 2021, 35TH INTERNATIONAL CONFERENCE ON INFORMATION NETWORKING (ICOIN 2021), P327, DOI 10.1109/ICOIN50884.2021.9334020
   Rouse M., 2015, SPLOG SPAM BLOG
   Ruskanda FZ, 2019, INDONESIA J COMPUTIN, V4, DOI [10.21108/INDOJC.2019.4.1.284, DOI 10.21108/INDOJC.2019.4.1.284]
   Saeed RMK, 2022, J KING SAUD UNIV-COM, V34, P1407, DOI 10.1016/j.jksuci.2019.10.002
   Saidani N, 2020, COMPUT SECUR, V94, DOI 10.1016/j.cose.2020.101716
   Saini S, 2017, LECT NOTES COMPUT SC, V10244, P366, DOI 10.1007/978-3-319-59105-6_31
   Salminen J, 2022, J RETAIL CONSUM SERV, V64, DOI 10.1016/j.jretconser.2021.102771
   Sandulescu V, 2015, WWW'15 COMPANION: PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P971, DOI 10.1145/2740908.2742570
   Satapathy R, 2017, INT CONF DAT MIN WOR, P407, DOI 10.1109/ICDMW.2017.59
   Serrano-Guerrero J, 2015, INFORM SCIENCES, V311, P18, DOI 10.1016/j.ins.2015.03.040
   Seth S, 2017, 2017 13TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY AND INTERNET-BASED SYSTEMS (SITIS), P346, DOI 10.1109/SITIS.2017.91
   Shahariar GM, 2019, 2019 IEEE 10TH ANNUAL INFORMATION TECHNOLOGY, ELECTRONICS AND MOBILE COMMUNICATION CONFERENCE (IEMCON), P27, DOI 10.1109/IEMCON.2019.8936148
   Sharma Neha, 2018, Procedia Computer Science, V132, P377, DOI 10.1016/j.procs.2018.05.198
   Sharma VD, 2021, MATER TODAY-PROC, V2, P1491, DOI [10.1016/j.matpr.2020.12.377, DOI 10.1016/J.MATPR.2020.12.377]
   Shrivastava Jitendra Nath, 2014, International Journal of Intelligent Systems and Applications, V6, P54, DOI 10.5815/ijisa.2014.02.07
   Singh A, 2021, 2021 11TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE & ENGINEERING (CONFLUENCE 2021), P164, DOI 10.1109/Confluence51648.2021.9377061
   Song J, 2011, LECT NOTES COMPUT SC, V6961, P301, DOI 10.1007/978-3-642-23644-0_16
   Song Peng, 2019, 2019 International Conference on Computer Network, Electronic and Automation (ICCNEA). Proceedings, P229, DOI 10.1109/ICCNEA.2019.00052
   Statista, 2017, NUMB E MAIL US WORLD
   Stringhini G, 2010, 26TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE (ACSAC 2010), P1
   Tai KS, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1556
   Tang XY, 2020, INFORM SCIENCES, V526, P274, DOI 10.1016/j.ins.2020.03.063
   Tong X, 2021, IEEE SENS J, V21, P25409, DOI 10.1109/JSEN.2021.3092728
   Torfi A, 2020, NATURAL LANGUAGE PRO
   Vanetti M, 2013, IEEE T KNOWL DATA EN, V25, P285, DOI 10.1109/TKDE.2011.230
   Venkatraman S, 2020, J SUPERCOMPUT, V76, P756, DOI 10.1007/s11227-019-02913-7
   Wang G., 2011, 2011 IEEE 11 INT C D, P1242, DOI [10.1109/ICDM.2011.124, DOI 10.1109/ICDM.2011.124]
   Watcharenwong N, 2017, INT JOINT CONF COMP
   Weilong Mo, 2019, Journal of Physics: Conference Series, V1237, DOI 10.1088/1742-6596/1237/2/022026
   Wu CH, 2009, EXPERT SYST APPL, V36, P4321, DOI 10.1016/j.eswa.2008.03.002
   Wu T, 2017, P AUSTR COMP SCI WEE, P1
   Xinbo Ban, 2018, 2018 International Symposium on Security and Privacy in Social Networks and Big Data (SocialSec), P208, DOI 10.1109/SocialSec.2018.8760377
   Xu GX, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/5567991
   Zhang L, 2004, ACM TRANS ASIAN LANG, V3, P243, DOI DOI 10.1145/1039621.1039625
   Zheng XH, 2016, J SUPERCOMPUT, V72, P2991, DOI 10.1007/s11227-015-1437-5
   Zhuang X, 2021, FUTURE GENER COMP SY, V118, P94, DOI 10.1016/j.future.2020.12.023
NR 104
TC 0
Z9 0
U1 0
U2 0
PU PEERJ INC
PI LONDON
PA 341-345 OLD ST, THIRD FLR, LONDON, EC1V 9LL, ENGLAND
EI 2376-5992
J9 PEERJ COMPUT SCI
JI PeerJ Comput. Sci.
PD JAN 20
PY 2022
VL 8
AR e830
DI 10.7717/peerj-cs.830
PG 28
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA YL8WZ
UT WOS:000746168900001
OA gold
DA 2022-02-06
ER

PT J
AU Gao, Y
   Lu, WN
   Si, XB
   Lan, Y
AF Gao, Yan
   Lu, Weining
   Si, Xiaobei
   Lan, Yu
TI Deep Model-Based Semi-Supervised Learning Way for Outlier Detection in
   Wireless Capsule Endoscopy Images
SO IEEE ACCESS
LA English
DT Article
DE Convolutional neural network; long short term memory network; outlier
   detection; semi-supervised; wireless capsule endoscopy
ID FAULT-DETECTION
AB Wireless capsule endoscopy (WCE) has become an irreplaceable tool for diagnosing small intestinal diseases, and detecting the outliers in WCE images automatically remains as a hot research topic. Considering the difficulties in obtaining sufficient labeled WCE data, it is necessary to develop the diagnosis model which works well with only little labeled or even unlabeled training samples. In this paper, a novel semi-supervised deep-structured framework is introduced to solve the problem of outlier detection in WCE images. The key idea of our model is to mine the anomalous graphical patterns existed in the image by analyzing the spatial-scale trends of sequential image regions. Three main contributions are concluded: 1) we integrate a convolutional neural network into long short term memory network, so that the intrinsic differences between outliers and normal instances could be captured. Besides, 2) a assessment model is built by using various signs of anomaly occurrence and fake outliers knowledge learned during the training stage, which enhances the outlier alarm accuracy significantly. Furthermore, 3) a nest-structured training method is proposed, which helps our model achieving efficient training process. Experimental results on the real WCE images demonstrate the effectiveness of our model.
C1 [Gao, Yan; Si, Xiaobei; Lan, Yu] Beijing Jishuitan Hosp, Dept Gastroenterol, Beijing 100035, Peoples R China.
   [Lu, Weining] Tsinghua Univ, Beijing Natl Res Ctr Informat Sci & Technol, Beijing 100084, Peoples R China.
C3 Tsinghua University
RP Lan, Y (corresponding author), Beijing Jishuitan Hosp, Dept Gastroenterol, Beijing 100035, Peoples R China.
EM lany_2020@163.com
OI Si, Xiaobei/0000-0002-3134-2295
FU Beijing JST Research Funding by Beijing Jishuitan (JST) Hospital, China
   [YGQ-201911]
FX This work was supported by the Beijing JST Research Funding under Grant
   YGQ-201911, which is provided by Beijing Jishuitan (JST) Hospital,
   China.
CR Alexandre LA, 2008, INT CONF BIOMED, P38, DOI 10.1109/BMEI.2008.246
   Bakator Mihalj, 2018, Multimodal Technologies and Interaction, V2, DOI 10.3390/mti2030047
   Bchir O., 2018, P COMP SCI INF TECHN, P402
   Chandola V, 2009, ACM COMPUT SURV, V41, DOI 10.1145/1541880.1541882
   Chatfield K, 2014, P BRIT MACH VIS C, P1
   Fan SH, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aad51c
   Fernandez-Francos D, 2013, COMPUT IND ENG, V64, P357, DOI 10.1016/j.cie.2012.10.013
   Fu YA, 2014, IEEE J BIOMED HEALTH, V18, P636, DOI 10.1109/JBHI.2013.2257819
   Ghosh T., 2014, P IEEE S SIGN PROC I, P1
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735
   Huang J, 2016, J PROCESS CONTR, V39, P88, DOI 10.1016/j.jprocont.2016.01.001
   Jia X, 2017, 2017 IEEE 14TH INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING (ISBI 2017), P179, DOI 10.1109/ISBI.2017.7950496
   Jia X, 2016, IEEE ENG MED BIO, P639, DOI 10.1109/EMBC.2016.7590783
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   KODOGIANNIS V, 2007, INT J INFORM TECHNOL, V0013, P00046
   Krizhevsky A., 2012, ADV NEURAL INF PROCE, P1097, DOI DOI 10.1145/3065386
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li BP, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO 2009), VOLS 1-4, P1490, DOI 10.1109/ROBIO.2009.5420969
   Lipton Z.C., 2015, ARXIV150600019
   Liu X., 2018, P SOC PHOTO-OPT INS
   Lu WN, 2018, IEEE T INSTRUM MEAS, V67, P1679, DOI 10.1109/TIM.2018.2800978
   Lu WN, 2017, IEEE T IMAGE PROCESS, V26, P4321, DOI 10.1109/TIP.2017.2713048
   Ma HH, 2013, IND ENG CHEM RES, V52, P2389, DOI 10.1021/ie302042c
   Mathew M, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON ELECTRONICS AND COMMUNICATION SYSTEMS (ICECS), P1730, DOI 10.1109/ECS.2015.7124882
   Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI [10.1146/annurev-bioeng-071516-044442, 10.1146/annurev-bioeng-071516044442]
   Simonyan K, 2015, ICLR 2015, DOI DOI 10.1109/CVPR.2015.7298594
   Song Yale, 2013, P 23 INT JOINT C ART, P1685
   Souaidi M, 2019, MULTIMED TOOLS APPL, V78, P13091, DOI 10.1007/s11042-018-6086-2
   Tuba E, 2017, IEEE IJCNN, P4579, DOI 10.1109/IJCNN.2017.7966437
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yuan YX, 2017, MED PHYS, V44, P1379, DOI 10.1002/mp.12147
   Zhai SF, 2016, PR MACH LEARN RES, V48
   Zhao B, 2017, INT J AUTOM COMPUT, V14, P119, DOI 10.1007/s11633-017-1053-3
   Zhao ZQ, 2019, IEEE T NEUR NET LEAR, V30, P3212, DOI 10.1109/TNNLS.2018.2876865
NR 34
TC 1
Z9 1
U1 2
U2 5
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2020
VL 8
BP 81621
EP 81632
DI 10.1109/ACCESS.2020.2991115
PG 12
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA ML5CH
UT WOS:000549483200009
OA gold
DA 2022-02-06
ER

PT J
AU Shehzad, F
   Javaid, N
   Almogren, A
   Ahmed, A
   Gulfam, SM
   Radwan, A
AF Shehzad, Faisal
   Javaid, Nadeem
   Almogren, Ahmad
   Ahmed, Abrar
   Gulfam, Sardar Muhammad
   Radwan, Ayman
TI A Robust Hybrid Deep Learning Model for Detection of Non-Technical
   Losses to Secure Smart Grids
SO IEEE ACCESS
LA English
DT Article
DE Feature extraction; Logic gates; Smart grids; History; Time series
   analysis; Support vector machines; Generative adversarial networks;
   Electricity theft detection; gated recurrent unit; GoogLeNet;
   non-technical losses; smart grids; SGCC
AB For dealing with the electricity theft detection in the smart grids, this article introduces a hybrid deep learning model. The model tackles various issues such as class imbalance problem, curse of dimensionality and low theft detection rate of the existing models. The model integrates the benefits of both GoogLeNet and gated recurrent unit (GRU). The one dimensional electricity consumption (EC) data is fed into GRU to remember the periodic patterns of electricity consumption. Whereas, GoogLeNet model is leveraged to extract the latent features from the two dimensional weekly stacked EC data. Furthermore, the time least square generative adversarial network (TLSGAN) is proposed to solve the class imbalance problem. The TLSGAN uses unsupervised and supervised loss functions to generate fake theft samples, which have high resemblance with real world theft samples. The standard generative adversarial network only updates the weights of those points that are available at the wrong side of the decision boundary. Whereas, TLSGAN even modifies the weights of those points that are available at the correct side of decision boundary that prevent the model from vanishing gradient problem. Moreover, dropout and batch normalization layers are utilized to enhance model's convergence speed and generalization ability. The proposed model is compared with different state-of-the-art classifiers including multilayer perceptron (MLP), support vector machine, naive bayes, logistic regression, MLP-long short term memory network and wide and deep convolutional neural network. It outperforms all classifiers by achieving 96% and 97% precision-recall area under the curve and receiver operating characteristics area under the curve, respectively.
C1 [Shehzad, Faisal; Javaid, Nadeem] COMSATS Univ Islamabad, Dept Comp Sci, Islamabad 44000, Pakistan.
   [Almogren, Ahmad] King Saud Univ, Coll Comp & Informat Sci, Dept Comp Sci, Riyadh 11633, Saudi Arabia.
   [Ahmed, Abrar; Gulfam, Sardar Muhammad] COMSATS Univ Islamabad, Dept Elect & Comp Engn, Islamabad 44000, Pakistan.
   [Radwan, Ayman] Univ Aveiro, Inst Telecomunicacoes, P-3810193 Aveiro, Portugal.
C3 COMSATS University Islamabad (CUI); King Saud University; COMSATS
   University Islamabad (CUI); Universidade de Aveiro
RP Javaid, N (corresponding author), COMSATS Univ Islamabad, Dept Comp Sci, Islamabad 44000, Pakistan.; Almogren, A (corresponding author), King Saud Univ, Coll Comp & Informat Sci, Dept Comp Sci, Riyadh 11633, Saudi Arabia.
EM nadeemjavaidqau@gmail.com; ahalmogren@ksu.edu.sa
RI Javaid, Nadeem/B-8835-2014; Almogren, Ahmad S/F-1365-2014
OI Javaid, Nadeem/0000-0003-3777-8249; Almogren, Ahmad
   S/0000-0002-8253-9709; Radwan, Ayman/0000-0003-1935-6077
FU King Saud University, Riyadh, Saudi ArabiaKing Saud University
   [RSP-2021/184]; FCT/MEC through the Programa Operacional Regional do
   Centro; European Union through European Social Fund (ESF) under
   Investigador FCT [IF/FCT-IF/01393/2015/CP1310/CT0002]
FX This work was supported by King Saud University, Riyadh, Saudi Arabia,
   through the Researchers Supporting Project under Grant RSP-2021/184. The
   work of Ayman Radwan was supported in part by FCT/MEC through the
   Programa Operacional Regional do Centro, and in part by European Union
   through European Social Fund (ESF) under Investigador FCT Grant 5G-AHEAD
   IF/FCT-IF/01393/2015/CP1310/CT0002.
CR Amin S., 2012, INT C DEC GAM THEOR, P264
   Arango LG, 2016, INT C HARMON QUAL PO, P557, DOI 10.1109/ICHQP.2016.7783346
   Aslam S, 2018, SUSTAINABILITY-BASEL, V10, DOI 10.3390/su10041245
   Aslam Z, 2020, IEEE ACCESS, V8, P221767, DOI 10.1109/ACCESS.2020.3042636
   Avila NF, 2018, IEEE T POWER SYST, V33, P7171, DOI 10.1109/TPWRS.2018.2853162
   Bhat RR, 2016, 2016 15TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2016), P272, DOI [10.1109/ICMLA.2016.0052, 10.1109/ICMLA.2016.107]
   Buzau MM, 2020, IEEE T POWER SYST, V35, P1254, DOI 10.1109/TPWRS.2019.2943115
   Chung J., 2014, ARXIV14123555
   Coma-Puig B, 2019, ENERGIES, V12, DOI 10.3390/en12091748
   Ding N, 2019, COMPUT ELECTR ENG, V79, DOI 10.1016/j.compeleceng.2019.106458
   Ghori KM, 2020, IEEE ACCESS, V8, P16033, DOI 10.1109/ACCESS.2019.2962510
   Gunturi SK, 2021, ELECTR POW SYST RES, V192, DOI 10.1016/j.epsr.2020.106904
   Hasan MN, 2019, ENERGIES, V12, DOI 10.3390/en12173310
   Hu TY, 2021, IEEE T NEUR NET LEAR, V32, P1866, DOI 10.1109/TNNLS.2020.2994116
   Huang CJ, 2021, INT J ENERG RES, V45, P2511, DOI 10.1002/er.5945
   Huang YF, 2021, INT J ELEC POWER, V125, DOI 10.1016/j.ijepes.2020.106448
   Iqbal Z, 2018, ENERGIES, V11, DOI 10.3390/en11041002
   Javaid N., 2020, IEEE ACCESS, V8
   Jokar P, 2016, IEEE T SMART GRID, V7, P216, DOI 10.1109/TSG.2015.2425222
   Khoo B, 2011, WIREL TELECOMM SYMP
   Kong XY, 2021, INT J ELEC POWER, V125, DOI 10.1016/j.ijepes.2020.106544
   Li B, 2018, LECT NOTES COMPUT SC, V10954, P172, DOI 10.1007/978-3-319-95930-6_17
   Li S, 2019, J ELECTR COMPUT ENG, V2019, DOI 10.1155/2019/4136874
   Lo CH, 2013, IEEE T EMERG TOP COM, V1, P33, DOI 10.1109/TETC.2013.2274043
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Buzau MM, 2019, IEEE T SMART GRID, V10, P2661, DOI 10.1109/TSG.2018.2807925
   Punmiya R, 2019, IEEE T SMART GRID, V10, P2326, DOI 10.1109/TSG.2019.2892595
   Ramos CCO, 2018, IEEE T SMART GRID, V9, P676, DOI 10.1109/TSG.2016.2560801
   Saeed MS, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8080860
   Sun C, 2017, IEEE I CONF COMP VIS, P843, DOI 10.1109/ICCV.2017.97
   Taft LM, 2009, J BIOMED INFORM, V42, P356, DOI 10.1016/j.jbi.2008.09.001
   Yu JX, 2021, AGR WATER MANAGE, V245, DOI 10.1016/j.agwat.2020.106649
   Zheng ZB, 2018, IEEE T IND INFORM, V14, P1606, DOI 10.1109/TII.2017.2785963
NR 33
TC 0
Z9 0
U1 8
U2 8
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2021
VL 9
BP 128663
EP 128678
DI 10.1109/ACCESS.2021.3113592
PG 16
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA UU5LR
UT WOS:000698842100001
OA gold
DA 2022-02-06
ER

PT J
AU Gong, MG
   Yang, YL
   Zhan, T
   Niu, XD
   Li, SW
AF Gong, Maoguo
   Yang, Yuelei
   Zhan, Tao
   Niu, Xudong
   Li, Shuwei
TI A Generative Discriminatory Classified Network for Change Detection in
   Multispectral Imagery
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE
   SENSING
LA English
DT Article
DE Change detection; deep learning; generative adversarial networks (GANs);
   multispectral imagery
ID UNSUPERVISED CHANGE DETECTION
AB Multispectral image change detection based on deep learning generally needs a large amount of training data. However, it is difficult and expensive to mark a large amount of labeled data. To deal with this problem, we propose a generative discriminatory classified network (GDCN) for multispectral image change detection, in which labeled data, unlabeled data, and new fake data generated by generative adversarial networks are used. The GDCN consists of a discriminatory classified network (DCN) and a generator. The DCN divides the input data into changed class, unchanged class, and extra class, i.e., fake class. The generator recovers the real data from input noises to provide additional training samples so as to boost the performance of the DCN. Finally, the bitemporal multispectral images are input to the DCN to get the final change map. Experimental results on the real multispectral imagery datasets demonstrate that the proposed GDCN trained by unlabeled data and a small amount of labeled data can achieve competitive performance compared with existing methods.
C1 [Gong, Maoguo; Yang, Yuelei; Zhan, Tao; Niu, Xudong] Xidian Univ, Sch Elect Engn, Minist Educ, Key Lab Intelligent Percept & Image Understanding, Xian 710071, Shaanxi, Peoples R China.
   [Li, Shuwei] Southeast Univ, Sch Elect Sci & Engn, Nanjing 210096, Jiangsu, Peoples R China.
C3 Xidian University; Southeast University - China
RP Gong, MG (corresponding author), Xidian Univ, Sch Elect Engn, Minist Educ, Key Lab Intelligent Percept & Image Understanding, Xian 710071, Shaanxi, Peoples R China.
EM gong@ieee.org; 1259437724@qq.com; OMEGAZhanT@gmail.com;
   xudong.niu@qq.com; 840142797@qq.com
OI Zhan, Tao/0000-0002-9283-4488
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61772393]; National Key Research and
   Development Program of China [2017YFB0802200]; Key Research and
   Development Program of Shaanxi Province [2018ZDXM-GY-045]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61772393, in part by the National Key
   Research and Development Program of China under Grant 2017YFB0802200,
   and in part by the Key Research and Development Program of Shaanxi
   Province under Grant 2018ZDXM-GY-045.
CR Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P218, DOI 10.1109/TGRS.2006.885408
   Bruzzone L, 2002, IEEE T IMAGE PROCESS, V11, P452, DOI 10.1109/TIP.2002.999678
   Deng JS, 2008, INT J REMOTE SENS, V29, P4823, DOI 10.1080/01431160801950162
   Glorot X., 2011, JMLR WORKSHOP C, V15, P315, DOI DOI 10.1.1.208.6449
   Gokaraju B., 2015, 2015 IEEE APPL IM PA 2015 IEEE APPL IM PA, P1
   Gong MG, 2017, IEEE GEOSCI REMOTE S, V14, P2310, DOI 10.1109/LGRS.2017.2762694
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2017, IEEE T GEOSCI REMOTE, V55, P2658, DOI 10.1109/TGRS.2017.2650198
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Huszar F., 2015, ARXIV151105101
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   KITTLER J, 1986, PATTERN RECOGN, V19, P41, DOI 10.1016/0031-3203(86)90030-0
   Kolassa J, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9111179
   Krinidis S, 2010, IEEE T IMAGE PROCESS, V19, P1328, DOI 10.1109/TIP.2010.2040763
   Krizhevsky A., 2012, ADV NEURAL INF PROCE, P1097, DOI DOI 10.1145/3065386
   Le QV, 2013, INT CONF ACOUST SPEE, P8595, DOI 10.1109/ICASSP.2013.6639343
   Liu J, 2016, SOFT COMPUT, V20, P4645, DOI 10.1007/s00500-014-1460-0
   Liu L., 2008, P INT WORKSH ED TECH, V1, P353
   Lu D, 2004, INT J REMOTE SENS, V25, P2365, DOI 10.1080/0143116031000139863
   Mirza M, 2014, ARXIV PREPRINT ARXIV
   Nielsen AA, 2007, IEEE T IMAGE PROCESS, V16, P463, DOI 10.1109/TIP.2006.888195
   Odena A., 2016, ARXIV160601583
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Papernot Nicolas, 2016, ARXIV161005755
   Radford A., 2015, ARXIV151106434
   Radke RJ, 2005, IEEE T IMAGE PROCESS, V14, P294, DOI 10.1109/TIP.2004.838698
   ROSENFIELD GH, 1986, PHOTOGRAMM ENG REM S, V52, P223
   Rosin PL, 2003, PATTERN RECOGN LETT, V24, P2345, DOI 10.1016/S0167-8655(03)00060-6
   Salimans T., 2016, ADV NEURAL INFORM PR, P2234
   Souly N, 2017, IEEE I CONF COMP VIS, P5689, DOI 10.1109/ICCV.2017.606
   Springenberg Jost Tobias, 2015, ARXIV151106390
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Wang Q, 2013, PATTERN RECOGN LETT, V34, P34, DOI 10.1016/j.patrec.2012.06.002
   Wang XL, 2016, LECT NOTES COMPUT SC, V9908, P318, DOI 10.1007/978-3-319-46493-0_20
   Yetgin Z, 2012, IEEE T GEOSCI REMOTE, V50, P1919, DOI 10.1109/TGRS.2011.2168230
   Yi ZL, 2017, IEEE I CONF COMP VIS, P2868, DOI 10.1109/ICCV.2017.310
   Yuan Y, 2015, IEEE T NEUR NET LEAR, V26, P2222, DOI 10.1109/TNNLS.2014.2359471
   Zhang F, 2015, IEEE T GEOSCI REMOTE, V53, P2175, DOI 10.1109/TGRS.2014.2357078
   Zhang H, 2016, IEEE GEOSCI REMOTE S, V13, P1666, DOI 10.1109/LGRS.2016.2601930
   Zhu J.-Y., 2017, ARXIV170310593
NR 44
TC 25
Z9 26
U1 8
U2 39
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JAN
PY 2019
VL 12
IS 1
SI SI
BP 321
EP 333
DI 10.1109/JSTARS.2018.2887108
PG 13
WC Engineering, Electrical & Electronic; Geography, Physical; Remote
   Sensing; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Physical Geography; Remote Sensing; Imaging Science &
   Photographic Technology
GA HJ3MD
UT WOS:000457074900026
DA 2022-02-06
ER

PT J
AU Verdoliva, L
AF Verdoliva, Luisa
TI Media Forensics and DeepFakes: An Overview
SO IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING
LA English
DT Article
DE Media; Forensics; Face; Tools; Information integrity; Videos; Deep
   learning; Deep learning; deepfakes; digital image forensics; video
   forensics
ID EXPOSING DIGITAL FORGERIES; IMAGE FORENSICS; JPEG DETECTION;
   LOCALIZATION; IDENTIFICATION; NOISE; AUTHENTICATION; STEGANALYSIS;
   FRAMEWORK; ALGORITHM
AB With the rapid progress in recent years, techniques that generate and manipulate multimedia content can now provide a very advanced level of realism. The boundary between real and synthetic media has become very thin. On the one hand, this opens the door to a series of exciting applications in different fields such as creative arts, advertising, film production, and video games. On the other hand, it poses enormous security threats. Software packages freely available on the web allow any individual, without special skills, to create very realistic fake images and videos. These can be used to manipulate public opinion during elections, commit fraud, discredit or blackmail people. Therefore, there is an urgent need for automated tools capable of detecting false multimedia content and avoiding the spread of dangerous false information. This review paper aims to present an analysis of the methods for visual media integrity verification, that is, the detection of manipulated images and videos. Special emphasis will be placed on the emerging phenomenon of deepfakes, fake media created through deep learning tools, and on modern data-driven forensic methods to fight them. The analysis will help highlight the limits of current forensic tools, the most relevant issues, the upcoming challenges, and suggest future directions for research.
C1 [Verdoliva, Luisa] Univ Federico II Naples, Dept Ind Engn, I-80125 Naples, Italy.
C3 University of Naples Federico II
RP Verdoliva, L (corresponding author), Univ Federico II Naples, Dept Ind Engn, I-80125 Naples, Italy.
EM verdoliv@unina.it
FU Google Faculty Research AwardGoogle Incorporated; Air Force Research
   Laboratory; Defense Advanced Research Projects AgencyUnited States
   Department of DefenseDefense Advanced Research Projects Agency (DARPA)
   [FA8750-16-2-0204]; PREMIER project - Italian Ministry of Education,
   University, and Research within the PRIN 2017 program
FX We gratefully acknowledge the support of this research by a Google
   Faculty Research Award. In addition, this material is based on research
   sponsored by the Air Force Research Laboratory and the Defense Advanced
   Research Projects Agency under agreement number FA8750-16-2-0204.
   TheU.S. Government is authorized to reproduce and distribute reprints
   forGovernmental purposes notwithstanding any copyright notation thereon.
   The views and conclusions contained herein are those of the authors and
   should not be interpreted as necessarily representing the official
   policies or endorsements, either expressed or implied, of the Air Force
   Research Laboratory and the Defense Advanced Research Projects Agency or
   the U.S. Government. This work is also supported by the PREMIER project,
   funded by the Italian Ministry of Education, University, and Research
   within the PRIN 2017 program.
CR Abu-El-Haija S., 2016, ARXIV160908675
   Afchar D., 2018, 2018 IEEE INT WORKSH, P1, DOI DOI 10.1109/WIFS.2018.8630761
   Agarwal S, 2017, IEEE INT WORKS INFOR
   Agarwal S, 2018, INT CONF CONTEMP, P383
   Al Shaya O, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18113801
   Albright M, 2019, 2019 IEEE CVF C COMP CVPR WORKSH MED FOR, P96
   Amerini I, 2019, IEEE INT CONF COMP V, P1205, DOI 10.1109/ICCVW.2019.00152
   Amerini I, 2017, IEEE COMPUT SOC CONF, P1865, DOI 10.1109/CVPRW.2017.233
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   Artaud C, 2018, INT C PATT RECOG, P13, DOI 10.1109/ICPR.2018.8545428
   Averbuch-Elor H, 2017, ACM T GRAPH IN PRESS, V36, P1
   Bahrami K, 2015, IEEE T INF FOREN SEC, V10, P999, DOI 10.1109/TIFS.2015.2394231
   Bappy JH, 2019, IEEE T IMAGE PROCESS, V28, P3286, DOI 10.1109/TIP.2019.2895466
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Barni M, 2019, INT CONF ACOUST SPEE, P8286, DOI 10.1109/ICASSP.2019.8683772
   Barni M, 2017, J VIS COMMUN IMAGE R, V49, P153, DOI 10.1016/j.jvcir.2017.09.003
   Barni M, 2010, IEEE INT SYMP CIRC S, P1687, DOI 10.1109/ISCAS.2010.5537505
   Barni M., 2019, ARXIV191212640V1
   Barni M, 2018, EUR SIGNAL PR CONF, P962, DOI 10.23919/EUSIPCO.2018.8553305
   Bayar Y, 2016, TRANSYLV REV ADM SCI, P5
   Bayram S, 2005, IEEE IMAGE PROC, P2793
   Bayram S, 2006, J ELECTRON IMAGING, V15, DOI 10.1117/1.2401138
   Bera A, 2018, IEEE COMPUT SOC CONF, P1152, DOI 10.1109/CVPRW.2018.00151
   Bestagini P, 2013, IEEE INT WORKSH MULT, P488, DOI 10.1109/MMSP.2013.6659337
   Bi XL, 2019, IEEE COMPUT SOC CONF, P30, DOI 10.1109/CVPRW.2019.00010
   Bianchi T., 2015, HDB DIGITAL FORENSIC
   Bianchi T, 2012, IEEE T INF FOREN SEC, V7, P1003, DOI 10.1109/TIFS.2012.2187516
   Biggio B, 2018, PATTERN RECOGN, V84, P317, DOI 10.1016/j.patcog.2018.07.023
   Bohme R., 2012, DIGIT IMAGE FORENSIC
   Boididou C, 2018, INT J MULTIMED INF R, V7, P71, DOI 10.1007/s13735-017-0143-x
   Bondi L, 2017, IEEE COMPUT SOC CONF, P1855, DOI 10.1109/CVPRW.2017.232
   Boneh D, 2019, IEEE SECUR PRIV, V17, P64, DOI 10.1109/MSEC.2019.2934193
   Boroumand M., 2018, ELECT IMAG
   Brock Andrew, 2019, INT C LEARN REPR
   Cao H, 2009, IEEE T INF FOREN SEC, V4, P899, DOI 10.1109/TIFS.2009.2033749
   Carlini N., 2020, P IEEE CVF C COMP VI, P2804
   Cattaneo G, 2014, 2014 17TH INTERNATIONAL CONFERENCE ON NETWORK-BASED INFORMATION SYSTEMS (NBIS 2014), P279, DOI 10.1109/NBiS.2014.82
   Chakraborty S, 2018, IEEE SMARTWORLD UBIQ, P1, DOI [DOI 10.1109/UIC-ATC.2017.8397411, 10.1109/UIC-ATC.2017.8397411]
   Chan C, 2019, IEEE I CONF COMP VIS, P5932, DOI 10.1109/ICCV.2019.00603
   Chen Chen, 2019, IEEE T INF FORENSICS, DOI DOI 10.1109/TIFS.2019.2945198
   Chen M, 2008, IEEE T INF FOREN SEC, V3, P74, DOI 10.1109/TIFS.2007.916285
   Chen M, 2007, LECT NOTES COMPUT SC, V4567, P342
   Chen YL, 2011, IEEE T INF FOREN SEC, V6, P396, DOI 10.1109/TIFS.2011.2106121
   Chen ZP, 2017, IEEE INT WORKS INFOR
   Chierchia Giovanni, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P6231, DOI 10.1109/ICASSP.2014.6854802
   Chierchia G, 2014, IEEE T INF FOREN SEC, V9, P554, DOI 10.1109/TIFS.2014.2302078
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Chung J, 2017, NEURIPS
   Ciftci U.A., 2019, ARXIV190102212
   Conotter V, 2014, IEEE IMAGE PROC, P248, DOI 10.1109/ICIP.2014.7025049
   Cox IJ., 2008, DIGITAL WATERMARKING, V2
   Cozza D., 2015, 2015 IEEE 42nd Photovoltaic Specialist Conference (PVSC). Proceedings, P1, DOI 10.1109/PVSC.2015.7355795
   Cozzolino D., 2019, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPRW47913.2019
   Cozzolino D., 2016, P 2016 IEEE INT WORK, P1, DOI [10.1109/WIFS.2016.7823921, 10.1109/WIFS.2016.7823921., DOI 10.1109/WIFS.2016.7823921]
   Cozzolino D, 2020, IEEE T INF FOREN SEC, V15, P144, DOI 10.1109/TIFS.2019.2916364
   Cozzolino D, 2018, EUR SIGNAL PR CONF, P1372, DOI 10.23919/EUSIPCO.2018.8553581
   Cozzolino D, 2017, LECT NOTES COMPUT SC, V10485, P569, DOI 10.1007/978-3-319-68548-9_52
   Cozzolino D, 2015, IEEE T INF FOREN SEC, V10, P2284, DOI 10.1109/TIFS.2015.2455334
   Cozzolino D, 2014, IEEE IMAGE PROC, P5297, DOI 10.1109/ICIP.2014.7026072
   Cozzolino D, 2014, IEEE IMAGE PROC, P5302, DOI 10.1109/ICIP.2014.7026073
   Cozzolino D, 2013, LECT NOTES COMPUT SC, V8157, P259, DOI 10.1007/978-3-642-41184-7_27
   Cozzolino Davide, 2018, ARXIV181202510
   Cozzolino Davide, 2017, P 5 ACM WORKSH INF H, P159, DOI DOI 10.1145/3082031.3083247
   D'Amiano L, 2019, IEEE T CIRC SYST VID, V29, P669, DOI 10.1109/TCSVT.2018.2804768
   D'Avino D., 2017, ELECT IMAGE, V2017, P92
   Dang H, 2020, PROC CVPR IEEE, P5780, DOI 10.1109/CVPR42600.2020.00582
   Dang-Nguyen D.T., 2015, P 6 ACM MULT SYST C, P219, DOI [10.1145/2713168.2713194, DOI 10.1145/2713168.2713194]
   Das N, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P196, DOI 10.1145/3219819.3219910
   de Carvalho TJ, 2013, IEEE T INF FOREN SEC, V8, P1182, DOI 10.1109/TIFS.2013.2265677
   DEMPSTER AP, 1967, ANN MATH STAT, V38, P325, DOI 10.1214/aoms/1177698950
   Dias Z., 2011, IEEE INT WORKSH INF, P1
   Ding X, 2018, IEEE T CIRC SYST VID, V28, P1497, DOI 10.1109/TCSVT.2017.2676162
   Dirik AE, 2009, 2009 16TH IEEE INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOLS 1-6, P1497, DOI 10.1109/ICIP.2009.5414611
   Dolhansky B., 2019, DEEPFAKE DETECTION C
   Dong J., 2006, P INT WORKSH DIG WAT, P177
   Du Mengnan, 2019, ARXIV190905999
   Dang-Nguyen TT, 2015, IEEE T INF FOREN SEC, V10, P1752, DOI 10.1109/TIFS.2015.2427778
   Dufour, 2019, DEEPFAKES DETECTION
   Durall Ricard, 2020, P IEEE CVF C COMP VI
   Engstrom L., 2019, ARXIV190600945V2
   Fan ZG, 2003, IEEE T IMAGE PROCESS, V12, P230, DOI 10.1109/TIP.2002.807361
   Farid H., 2006, TR2006583 DARTM COLL
   Farid H., 2003, IEEE COMP VIS PATT R, P1
   Farid H, 2016, PHOTO FORENSICS, P1
   Farid H, 2009, IEEE SIGNAL PROC MAG, V26, P16, DOI 10.1109/MSP.2008.931079
   Farid H, 2009, IEEE T INF FOREN SEC, V4, P154, DOI 10.1109/TIFS.2008.2012215
   Fernandes S, 2019, IEEE INT CONF COMP V, P1721, DOI 10.1109/ICCVW.2019.00213
   Fernando T, 2019, ARXIV191107844
   Ferrand P, 2015, EURASIP J WIREL COMM, P1, DOI 10.1186/s13638-014-0239-4
   Ferrara P, 2012, IEEE T INF FOREN SEC, V7, P1566, DOI 10.1109/TIFS.2012.2202227
   Fontani M, 2013, IEEE T INF FOREN SEC, V8, P593, DOI 10.1109/TIFS.2013.2248727
   Frank J, 2020, PR MACH LEARN RES, V119
   Fridrich AJ., 2003, P DIG FOR RES WORKSH
   Fridrich J, 2003, P DIG FOR RES WORKSH, V2, P1
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Fried O, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323028
   Fu DD, 2007, PROC SPIE, V6505, DOI 10.1117/12.704723
   Fu HZ, 2012, IEEE T INF FOREN SEC, V7, P1301, DOI 10.1109/TIFS.2012.2195492
   Galdamez C, 2017, WIRELESS OPTIC COMM
   Gallagher AC, 2008, PROC CVPR IEEE, P253
   Gironi A., 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P6226, DOI 10.1109/ICASSP.2014.6854801
   Gloe T., 2010, J DIGIT FORENSIC PRA, V3, P150, DOI DOI 10.1080/15567281.2010.531500
   Gloe T., 2007, P 15 INT C MULT, P78, DOI DOI 10.1145/1291233.1291252
   Gloe T, 2010, PROC SPIE, V7541, DOI 10.1117/12.839034
   Goljan M, 2011, IEEE T INF FOREN SEC, V6, P227, DOI 10.1109/TIFS.2010.2099220
   Guan HY, 2019, IEEE WINT CONF APPL, P63, DOI 10.1109/WACVW.2019.00018
   GUERA D, 2019, ARXIV190608743
   Guera D, 2017, IEEE COMPUT SOC CONF, P1840, DOI 10.1109/CVPRW.2017.230
   Guera David, 2018, 15 IEEE INT C ADV VI, P1, DOI [DOI 10.1109/AVSS.2018.8639163, 10.1109/AVSS.2018.8639163]
   Nguyen HD, 2019, PROCEEDINGS OF THE 2019 FIFTH INTERNATIONAL WORKSHOP ON SERVERLESS COMPUTING (WOSC '19), P1, DOI 10.1145/3366623.3368133
   Hasan HR, 2019, IEEE ACCESS, V7, P41596, DOI 10.1109/ACCESS.2019.2905689
   He JF, 2006, LECT NOTES COMPUT SC, V3953, P423
   He K., 2016, DEEP RESIDUAL LEARNI, DOI DOI 10.1109/CVPR.2016.90
   He PS, 2019, IEEE IMAGE PROC, P2299, DOI 10.1109/ICIP.2019.8803740
   He ZW, 2012, PATTERN RECOGN, V45, P4292, DOI 10.1016/j.patcog.2012.05.014
   Heller Silvan, 2018, ABS180404866 CORR
   Ho JS, 2010, IEEE INT CON MULTI, P1475, DOI 10.1109/ICME.2010.5582951
   Hosler BC, 2019, IEEE ACCESS, V7, P76937, DOI 10.1109/ACCESS.2019.2922145
   Hsu CC, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P170, DOI 10.1109/MMSP.2008.4665069
   Hsu YF, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P549, DOI 10.1109/ICME.2006.262447
   Hsu YF, 2010, IEEE T INF FOREN SEC, V5, P816, DOI 10.1109/TIFS.2010.2077628
   Huang GL, 2018, ASIA PAC CONF ANTEN, P70, DOI 10.1109/APCAP.2018.8538301
   Huang He, 2018, ARXIV VOL ABS1803044
   Huh M, 2018, LECT NOTES COMPUT SC, V11215, P106, DOI 10.1007/978-3-030-01252-6_7
   Iakovidou C, 2018, J VIS COMMUN IMAGE R, V54, P155, DOI 10.1016/j.jvcir.2018.05.011
   Isola P., 2017, P IEEE C COMPUTER VI, P5967, DOI DOI 10.1109/CVPR.2017.632
   Iuliani M, 2019, IEEE T INF FOREN SEC, V14, P635, DOI 10.1109/TIFS.2018.2859760
   Jiang LM, 2020, PROC CVPR IEEE, P2886, DOI 10.1109/CVPR42600.2020.00296
   Jiang XH, 2018, IEEE T INF FOREN SEC, V13, P170, DOI 10.1109/TIFS.2017.2745687
   Johnson MK, 2007, IEEE T INF FOREN SEC, V2, P450, DOI 10.1109/TIFS.2007.903848
   Johnson MK, 2006, P 8 WORKSH MULT SEC, P48
   Karras T., 2019, ARXIV191204958
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Kaur N, 2020, FORENSIC SCI MED PAT, V16, P481, DOI 10.1007/s12024-020-00230-7
   Kee E, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487236
   Kee E, 2011, IEEE T INF FOREN SEC, V6, P1066, DOI 10.1109/TIFS.2011.2128309
   Kennedy L., 2008, P ACM INT C MULT, P349
   Khattar D, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P2915, DOI 10.1145/3308558.3313552
   Khodabakhsh A, 2018, 2018 INTERNATIONAL CONFERENCE OF THE BIOMETRICS SPECIAL INTEREST GROUP (BIOSIG)
   Kim D, 2018, IEEE SIGNAL PROC LET, V25, DOI 10.1109/LSP.2017.2782363
   KIM HYEON-ZOO, 2018, [ASSOCIATION CULTURELLE FRANC0-COREENNE, 프랑스 문화 연구], V37, P1, DOI 10.18022/acfco.2018.37.1.001
   Kirchner M, 2008, IEEE T INF FOREN SEC, V3, P582, DOI 10.1109/TIFS.2008.2008214
   Kirchner M, 2008, MM&SEC'08: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2008, P11, DOI 10.1145/1411328.1411333
   Kobayashi M, 2010, IEEE T INF FOREN SEC, V5, P883, DOI 10.1109/TIFS.2010.2074194
   Korshunov P., 2019, P ICML WORKSH DET AU, P1
   Korshunov P., 2018, DEEPFAKES NEW THREAT
   Korus P., 2016, P IEEE INT WORKSH IN, P1, DOI DOI 10.1109/WIFS.2016.7823898
   Korus P, 2019, PROC CVPR IEEE, P8613, DOI 10.1109/CVPR.2019.00882
   Korus P, 2017, DIGIT SIGNAL PROCESS, V71, P1, DOI 10.1016/j.dsp.2017.08.009
   Korus P, 2016, IEEE T IMAGE PROCESS, V25, P1312, DOI 10.1109/TIP.2016.2518870
   Laine, 2018, INT C LEARN REPR
   Li H., 2020, SIG PROCESS, V174, P1
   Li HD, 2019, IEEE I CONF COMP VIS, P8300, DOI 10.1109/ICCV.2019.00839
   Li HD, 2018, IEEE T CIRC SYST VID, V28, P31, DOI 10.1109/TCSVT.2016.2599849
   Li J, 2019, ARXIV191205790
   Li Lingzhi, 2019, ARXIV191213458V1
   Li WH, 2009, SIGNAL PROCESS, V89, P1821, DOI 10.1016/j.sigpro.2009.03.025
   Li Y., 2019, ARXIV190609288V1
   Li YZ, 2018, IEEE INT WORKS INFOR
   Li YZ, 2020, PROC CVPR IEEE, P3204, DOI 10.1109/CVPR42600.2020.00327
   Li Yuezun, 2019, IEEE C COMP VIS PATT
   Lin ZC, 2005, PROC CVPR IEEE, P1087
   Lin ZC, 2009, PATTERN RECOGN, V42, P2492, DOI 10.1016/j.patcog.2009.03.019
   Liu YQ, 2019, IEEE T INF FOREN SEC, V14, P2551, DOI 10.1109/TIFS.2019.2902826
   Liu Zhengzhe, 2020, P IEEE CVF C COMP VI, P8060, DOI DOI 10.1109/CVPR42600.2020.00808
   Longtin C, 2021, PHYSIOTHER THEOR PR, V37, P1264, DOI 10.1080/09593985.2019.1698083
   Lorch B, 2019, IH&MMSEC '19: PROCEEDINGS OF THE ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, P101, DOI 10.1145/3335203.3335722
   Lukas J, 2006, PROC SPIE, V6072, DOI 10.1117/12.640109
   Luo WQ, 2007, INT CONF ACOUST SPEE, P217
   Lyu S, 2005, IEEE T SIGNAL PROCES, V53, P845, DOI 10.1109/TSP.2004.839896
   Lyu SW, 2014, INT J COMPUT VISION, V110, P202, DOI 10.1007/s11263-013-0688-y
   Mahdian B, 2009, IMAGE VISION COMPUT, V27, P1497, DOI 10.1016/j.imavis.2009.02.001
   Mahfoudi G, 2019, EUR SIGNAL PR CONF
   Marra F, 2018, SIGNAL PROCESS-IMAGE, V65, P240, DOI 10.1016/j.image.2018.04.007
   Marra F, 2014, IEEE IMAGE PROC, P5307, DOI 10.1109/ICIP.2014.7026074
   Marra F., 2019, ARXIV190906751
   Marra F, 2019, IEEE INT WORKS INFOR
   Marra F, 2019, 2019 2ND IEEE CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2019), P506, DOI 10.1109/MIPR.2019.00103
   Marra F, 2018, IEEE 1ST CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2018), P384, DOI 10.1109/MIPR.2018.00084
   Marra F, 2015, PROC SPIE, V9409, DOI 10.1117/12.2182173
   Matern F, 2019, IEEE WINT CONF APPL, P83, DOI 10.1109/WACVW.2019.00020
   Mayer O, 2020, IEEE J-STSP, V14, P1049, DOI 10.1109/JSTSP.2020.3001516
   Mayer O, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2012, DOI 10.1109/ICASSP.2018.8462585
   Mayer O, 2018, IEEE T INF FOREN SEC, V13, P1762, DOI 10.1109/TIFS.2018.2799421
   McCloskey S, 2019, IEEE IMAGE PROC, P4584, DOI 10.1109/ICIP.2019.8803661
   Milani S, 2012, APSIPA TRANS SIGNAL, V1, DOI 10.1017/ATSIP.2012.2
   Moreira D, 2018, IEEE T IMAGE PROCESS, V27, P6109, DOI 10.1109/TIP.2018.2865674
   Mullan P, 2017, IEEE IMAGE PROC, P1507, DOI 10.1109/ICIP.2017.8296533
   Nam SH, 2019, IEEE IMAGE PROC, P111, DOI 10.1109/ICIP.2019.8802966
   Nataraj L, 2019, ELECT IMAGING, V2019, P532, DOI DOI 10.2352/ISSN.2470-1173.2019.5.MWSF-532
   Neekhara P., 2020, ARXIV PREPRINT ARXIV
   Neves J., 2019, ARXIV191105351V2
   Ng T., 2004, DATA SET AUTHENTIC S
   Ng TT, 2009, IEEE INT WORKS INFOR, P161, DOI 10.1109/WIFS.2009.5386461
   Nguyen HH, 2019, INT CONF ACOUST SPEE, P2307, DOI 10.1109/ICASSP.2019.8682602
   Nirkin Y, 2019, IEEE I CONF COMP VIS, P7183, DOI 10.1109/ICCV.2019.00728
   Nirkin Y, 2018, IEEE INT CONF AUTOMA, P98, DOI 10.1109/FG.2018.00024
   Novozamsky A, 2020, IEEE WINT CONF APPL, P71, DOI 10.1109/WACVW50321.2020.9096940
   Papadopoulou O, 2019, ONLINE INFORM REV, V43, P72, DOI 10.1108/OIR-03-2018-0101
   Park JH, 2018, POULTRY SCI, V97, P2854, DOI 10.3382/ps/pey151
   Park T, 2019, PROC CVPR IEEE, P2332, DOI 10.1109/CVPR.2019.00244
   Pasquini C, 2017, IEEE T INF FOREN SEC, V12, P2890, DOI 10.1109/TIFS.2017.2725201
   Piva A., 2012, ISRN SIGNAL PROCESS, P1
   Popescu AC, 2005, IEEE T SIGNAL PROCES, V53, P3948, DOI 10.1109/TSP.2005.855406
   Popescu AC, 2004, LECT NOTES COMPUT SC, V3200, P128
   Qian SJ, 2019, IEEE I CONF COMP VIS, P10032, DOI 10.1109/ICCV.2019.01013
   Qian YL, 2015, PROC SPIE, V9409, DOI 10.1117/12.2083479
   Rahmouni Nicolas, 2017, P IEEE WORKSH INF FO, P1, DOI DOI 10.1109/WIFS.2017.8267647
   Rao Y., 2016, P IEEE INT WORKSH IN, P1, DOI [10.1109/WIFS.2016.7823911, DOI 10.1109/WIFS.2016.7823911]
   Reed S, 2016, PR MACH LEARN RES, V48
   Rocha A, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1978802.1978805
   Rossler A, 2019, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2019.00009
   Rossler A., 2018, FACEFORENSICS LARGE
   Ryu SJ, 2013, IEEE T INF FOREN SEC, V8, P1355, DOI 10.1109/TIFS.2013.2272377
   Sabir Ekraam, 2019, INTERFACES GUI, P80
   Salloum R, 2018, J VIS COMMUN IMAGE R, V51, P201, DOI 10.1016/j.jvcir.2018.01.010
   Shetty R, 2018, ADV NEUR IN, V31
   Shullani D, 2017, EURASIP J INF SECUR, DOI 10.1186/s13635-017-0067-2
   Silva E, 2015, J VIS COMMUN IMAGE R, V29, P16, DOI 10.1016/j.jvcir.2015.01.016
   Singh Priyanka, 2019, CVPR WORKSH, P11
   Sohrawardi SJ, 2019, PROCEEDINGS OF THE 2019 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'19), P2613, DOI 10.1145/3319535.3363269
   Stamm M., 2011, IEEE ACCESS, V1, P167
   Suwajanakorn S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073640
   Swaminathan A, 2008, IEEE T INF FOREN SEC, V3, P101, DOI 10.1109/TIFS.2007.916010
   SZEGEDY C, 2016, PROC CVPR IEEE, P2818, DOI DOI 10.1109/CVPR.2016.308
   Szegedy C, 2015, ARXIV14094842, P1, DOI [10.1109/CVPR.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tan FW, 2018, IEEE WINT CONF APPL, P1519, DOI 10.1109/WACV.2018.00170
   THIES J, 2016, PROC CVPR IEEE, P2387, DOI DOI 10.1109/CVPR.2016.262
   Thies J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323035
   Tralic Dijana, 2013, Proceedings of the 2013 55th International Symposium. ELMAR-2013, P49
   Vazquez-Padin D, 2012, IEEE INT WORKS INFOR, P151, DOI 10.1109/WIFS.2012.6412641
   Vazquez-Padin D, 2020, IEEE T INF FOREN SEC, V15, P1815, DOI 10.1109/TIFS.2019.2951313
   Verdoliva L., 2019, SPOC SPOOFING CAMERA
   Verdoliva L, 2014, IEEE INT WORKS INFOR, P149, DOI 10.1109/WIFS.2014.7084319
   Wang Q, 2016, EURASIP J INF SECUR, DOI 10.1186/s13635-016-0047-y
   Wang SY, 2019, IEEE I CONF COMP VIS, P10071, DOI 10.1109/ICCV.2019.01017
   Wang Sheng-Yu, 2020, CVPR, V7
   Wang TC, 2019, ADV NEUR IN, V32
   Wang W., 2006, P 8 WORKSH MULT SEC, P37, DOI DOI 10.1145/1161366.1161375
   Wen BH, 2016, IEEE IMAGE PROC, P161, DOI 10.1109/ICIP.2016.7532339
   Wu PW, 2019, IEEE I CONF COMP VIS, P5913, DOI 10.1109/ICCV.2019.00601
   Wu Y, 2018, LECT NOTES COMPUT SC, V11210, P170, DOI 10.1007/978-3-030-01231-1_11
   Wu Y, 2019, PROC CVPR IEEE, P9535, DOI 10.1109/CVPR.2019.00977
   Wu Y, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1480, DOI 10.1145/3123266.3123411
   Wu Y, 2018, IEEE WINT CONF APPL, P1907, DOI 10.1109/WACV.2018.00211
   Xu XK, 2013, IEEE IMAGE PROC, P4422, DOI 10.1109/ICIP.2013.6738911
   Xuan XS, 2019, LECT NOTES COMPUT SC, V11818, P134, DOI 10.1007/978-3-030-31456-9_15
   Yang C, 2017, PROC CVPR IEEE, P4076, DOI 10.1109/CVPR.2017.434
   Yang X, 2019, IH&MMSEC '19: PROCEEDINGS OF THE ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, P113, DOI 10.1145/3335203.3335724
   Yang X, 2019, INT CONF ACOUST SPEE, P8261, DOI 10.1109/ICASSP.2019.8683164
   Yarlagadda SK, 2018, IEEE SW SYMP IMAG, P9, DOI 10.1109/SSIAI.2018.8470343
   Yerushalmy I, 2011, INT J COMPUT VISION, V92, P71, DOI 10.1007/s11263-010-0403-1
   Yu N, 2019, IEEE I CONF COMP VIS, P7555, DOI 10.1109/ICCV.2019.00765
   Yuxing Wu, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P2674, DOI 10.1109/ICASSP.2014.6854085
   Zakharov E, 2019, IEEE I CONF COMP VIS, P9458, DOI 10.1109/ICCV.2019.00955
   Zampoglou M, 2015, IEEE INT CONF MULTI
   Zampoglou M, 2017, MULTIMED TOOLS APPL, V76, P4801, DOI 10.1007/s11042-016-3795-2
   Zhang X, 2019, IEEE INT WORKS INFOR
   Zhao XD, 2013, IEEE IMAGE PROC, P4462, DOI 10.1109/ICIP.2013.6738919
   Zhen Y, 2020, IEEE T INF FOREN SEC, V15, P620, DOI 10.1109/TIFS.2019.2926777
   Zhong JL, 2020, IEEE T INF FOREN SEC, V15, P2134, DOI 10.1109/TIFS.2019.2957693
   Zhou P, 2020, AAAI CONF ARTIF INTE, V34, P13058
   Zhou P, 2018, PROC CVPR IEEE, P1053, DOI 10.1109/CVPR.2018.00116
   Zhou P, 2017, IEEE COMPUT SOC CONF, P1831, DOI 10.1109/CVPRW.2017.229
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu X., 2019, ARXIV191200527V1
NR 268
TC 43
Z9 45
U1 2
U2 2
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1932-4553
EI 1941-0484
J9 IEEE J-STSP
JI IEEE J. Sel. Top. Signal Process.
PD AUG
PY 2020
VL 14
IS 5
BP 910
EP 932
DI 10.1109/JSTSP.2020.3002101
PG 23
WC Engineering, Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA NG8BM
UT WOS:000564205000002
OA Green Submitted
DA 2022-02-06
ER

PT J
AU Lozano, MG
   Brynielsson, J
   Franke, U
   Rosell, M
   Tjornhammar, E
   Varga, S
   Vlassov, V
AF Lozano, Marianela Garcia
   Brynielsson, Joel
   Franke, Ulrik
   Rosell, Magnus
   Tjornhammar, Edward
   Varga, Stefan
   Vlassov, Vladimir
TI Veracity assessment of online data
SO DECISION SUPPORT SYSTEMS
LA English
DT Article
DE Veracity assessment; Credibility; Data quality; Online data; Social
   media; Fake news
ID INFORMATION CREDIBILITY; SOCIAL NETWORKS
AB Fake news, malicious rumors, fabricated reviews, generated images and videos, are today spread at an unprecedented rate, making the task of manually assessing data veracity for decision-making purposes a daunting task. Hence, it is urgent to explore possibilities to perform automatic veracity assessment. In this work we review the literature in search for methods and techniques representing state of the art with regard to computerized veracity assessment. We study what others have done within the area of veracity assessment, especially targeted towards social media and open source data, to understand research trends and determine needs for future research.
   The most common veracity assessment method among the studied set of papers is to perform text analysis using supervised learning. Regarding methods for machine learning much has happened in the last couple of years related to the advancements made in deep learning. However, very few papers make use of these advancements. Also, the papers in general tend to have a narrow scope, as they focus on solving a small task with only one type of data from one main source. The overall veracity assessment problem is complex, requiring a combination of data sources, data types, indicators, and methods. Only a few papers take on such a broad scope, thus, demonstrating the relative immaturity of the veracity assessment domain.
C1 [Lozano, Marianela Garcia; Brynielsson, Joel; Rosell, Magnus; Tjornhammar, Edward] FOI Swedish Def Res Agcy, SE-16490 Stockholm, Sweden.
   [Lozano, Marianela Garcia; Brynielsson, Joel; Tjornhammar, Edward; Varga, Stefan; Vlassov, Vladimir] KTH Royal Inst Technol, SE-10044 Stockholm, Sweden.
   [Franke, Ulrik] RISE Res Inst Sweden, POB 1263, SE-16429 Kista, Sweden.
   [Varga, Stefan] Swedish Armed Forces Headquarters, SE-10785 Stockholm, Sweden.
C3 FOI - Swedish Defence Research Agency; Royal Institute of Technology;
   RISE Research Institutes of Sweden
RP Lozano, MG (corresponding author), FOI Swedish Def Res Agcy, SE-16490 Stockholm, Sweden.; Lozano, MG (corresponding author), KTH Royal Inst Technol, SE-10044 Stockholm, Sweden.
EM mgl@kth.se; joel@kth.se; ulrik.franke@ri.se; magnus.rosell@foi.se;
   edwardt@kth.se; svarga@kth.se; vladv@kth.se
FU Swedish Armed Forces' research and development program; European Union
   Horizon 2020 program [832921]
FX We gratefully acknowledge the help obtained from the librarian Alexis
   Wiklund, for performing the initial database literature searches. This
   work was supported by the Swedish Armed Forces' research and development
   program and the European Union Horizon 2020 program (grant agreement no.
   832921).
CR Abbasi Mohammad-Ali, 2013, Social Computing, Behavioral-Cultural Modeling and Prediction. 6th International Conference, SBP 2013. Proceedings, P441, DOI 10.1007/978-3-642-37210-0_48
   ABDULRAHMAN A, 2000, HAW INT C SYST SCI M, V33, P9, DOI DOI 10.1109/HICSS.2000.926814
   Aker Ahmet, 2017, Social Informatics. 9th International Conference, SocInfo 2017. Proceedings: LNCS 10540, P53, DOI 10.1007/978-3-319-67256-4_6
   Dang A, 2016, PROCEEDINGS OF THE 2016 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING ASONAM 2016, P777, DOI 10.1109/ASONAM.2016.7752326
   Ball Leslie, 2014, J MARKETING ANAL, V2, P187, DOI DOI 10.1057/JMA.2014.15
   Banerjee S., 2017, P INT C SOC MED SOC, P1
   Bennett-Woods D., 2005, ETHICS GLANCE
   Berti-Equille L., 2015, SYNTHESIS LECT DATA, V7, P1
   Berti-Equille L, 2015, PROCEEDINGS 2015 IEEE INTERNATIONAL CONFERENCE ON BIG DATA, P2628, DOI 10.1109/BigData.2015.7364062
   Bodnar T, 2014, IEEE INT CONF BIG DA, P636, DOI 10.1109/BigData.2014.7004286
   Buntain C, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON SMART CLOUD (SMARTCLOUD), P208, DOI 10.1109/SmartCloud.2017.40
   Castillo C, 2013, INTERNET RES, V23, P560, DOI 10.1108/IntR-05-2012-0095
   Chang K, 2016, I C INF COMM TECH CO, P751, DOI 10.1109/ICTC.2016.7763286
   Cheng O.K., 2014, 2014 INT C ADV ICT I
   Ciampaglia G. L., 2015, PLOS ONE, V10, P1, DOI DOI 10.1371/J0UMAL.P0NE.0128193
   Claverie-Berge I., 2012, SOLUTIONS BIG DATA I
   Conroy N. J., 2015, P 78 ASIS T ANN M IN
   Das Bhattacharjee S, 2017, IEEE INT CONF BIG DA, P556, DOI 10.1109/BigData.2017.8257971
   De Marneffe MC, 2006, P LREC, P449
   Debattista J, 2015, 2015 IEEE/ACM 2ND INTERNATIONAL SYMPOSIUM ON BIG DATA COMPUTING (BDC), P92, DOI 10.1109/BDC.2015.34
   Elias D, 2016, TRANSP RES PROC, V14, P2035, DOI 10.1016/j.trpro.2016.05.171
   Fang XS, 2017, WWW'17 COMPANION: PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P777, DOI 10.1145/3041021.3054212
   Figueira A, 2016, ADV INTELL SYST, V444, P89, DOI 10.1007/978-3-319-31232-3_9
   Fontanarava J, 2017, 2017 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE (WI 2017), P863, DOI 10.1145/3106426.3106464
   Fontanarava J, 2017, PR INT CONF DATA SC, P658, DOI 10.1109/DSAA.2017.51
   Gambetta D, 2000, TRUST MAKING BREAKIN, V13, P213
   Garcia-Ulloa DA, 2017, PROC VLDB ENDOW, V10, P1562, DOI 10.14778/3137628.3137662
   Giasemidis Georgios, 2016, Social Informatics. 8th International Conference, SocInfo 2016. Proceedings: LNCS 10046, P185, DOI 10.1007/978-3-319-47880-7_12
   Ginsca AL, 2015, FOUND TRENDS INF RET, V9, P355, DOI 10.1561/1500000046
   Guo QZ, 2016, LECT NOTES COMPUT SC, V9545, P131, DOI 10.1007/978-3-319-29175-8_12
   Gupta A, 2014, LECT NOTES COMPUT SC, V8851, P228, DOI 10.1007/978-3-319-13734-6_16
   Hardalov M, 2016, LECT NOTES ARTIF INT, V9883, P172, DOI 10.1007/978-3-319-44748-3_17
   Igawa RA, 2016, INFORM SCIENCES, V332, P72, DOI 10.1016/j.ins.2015.10.039
   Ionescu B., 2015, ACM MULTIMEDIA SYSTE, P207
   Ito J, 2015, WWW'15 COMPANION: PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P953, DOI 10.1145/2740908.2742569
   Jaho E, 2014, WWW'14 COMPANION: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P749, DOI 10.1145/2567948.2579324
   Jain P, 2016, PROCEEDINGS OF THE 2016 2ND INTERNATIONAL CONFERENCE ON CONTEMPORARY COMPUTING AND INFORMATICS (IC3I), P553, DOI 10.1109/IC3I.2016.7918025
   Jain S, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2015, DOI 10.1109/ICACCI.2016.7732347
   Jamil NBCE, 2015, PROCEDIA COMPUT SCI, V72, P390, DOI 10.1016/j.procs.2015.12.154
   Janssen B, 2017, WEBIST: PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON WEB INFORMATION SYSTEMS AND TECHNOLOGIES, P187, DOI 10.5220/0006185101870195
   Jeong S, 2016, INFORM SCIENCES, V369, P481, DOI 10.1016/j.ins.2016.07.033
   Jin ZW, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P795, DOI 10.1145/3123266.3123454
   Jin ZW, 2016, THIRTIETH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2972
   Jin ZW, 2017, IEEE T MULTIMEDIA, V19, P598, DOI 10.1109/TMM.2016.2617078
   Jin ZW, 2014, IEEE DATA MINING, P230, DOI 10.1109/ICDM.2014.91
   Kakol M, 2017, INFORM PROCESS MANAG, V53, P1043, DOI 10.1016/j.ipm.2017.04.003
   Kim YA, 2013, KNOWL-BASED SYST, V37, P438, DOI 10.1016/j.knosys.2012.09.002
   Kitchenham B. A., 2007, EBSE200701 KEEL U DU
   Kong Lingpeng, 2014, C EMP METH NAT LANG, P1001, DOI DOI 10.3115/V1/D14-1108
   Kumar TKA, 2016, INT CONF BIG DATA, P129, DOI 10.1109/BIGCOMP.2016.7425811
   Kumar KPK, 2016, COMPUTING, V98, P583, DOI 10.1007/s00607-015-0472-7
   Kumar KPK, 2014, HUM-CENT COMPUT INFO, V4, DOI 10.1186/s13673-014-0014-x
   Kumar S, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16), P591, DOI 10.1145/2872427.2883085
   Laney D, 2001, META GROUP RES NOTE
   Lee C, 2016, INT C PATT RECOG, P745, DOI 10.1109/ICPR.2016.7899724
   Lendvai P., 2016, P 1 INT WORKSH SEM C
   Levchuk G, 2017, PROC SPIE, V10207, DOI 10.1117/12.2263546
   Levchuk G, 2015, 2015 IEEE WINTER APPLICATIONS AND COMPUTER VISION WORKSHOPS (WACVW), P1, DOI 10.1109/WACVW.2015.12
   Li RH, 2015, PROCEDIA COMPUT SCI, V72, P314, DOI 10.1016/j.procs.2015.12.146
   Lim WY, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P787, DOI 10.1145/3132847.3132995
   Lioma C, 2017, ICTIR'17: PROCEEDINGS OF THE 2017 ACM SIGIR INTERNATIONAL CONFERENCE THEORY OF INFORMATION RETRIEVAL, P91, DOI 10.1145/3121050.3121072
   Litou Iouliana, 2017, Online Social Networks and Media, V2, P19, DOI 10.1016/j.osnem.2017.07.001
   Liu XM, 2017, IEEE INT CONF BIG DA, P1483, DOI 10.1109/BigData.2017.8258082
   Liu XM, 2016, CIKM'16: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P207, DOI 10.1145/2983323.2983363
   Loper E., 2002, ARXIVCS0205028
   Lovelace R, 2016, GEOGR ANAL, V48, P59, DOI 10.1111/gean.12081
   Lozano MG, 2017, DECIS SUPPORT SYST, V99, P18, DOI 10.1016/j.dss.2017.05.006
   Lozano MG, 2015, IEEE INT CONGR BIG, P199, DOI 10.1109/BigDataCongress.2015.36
   Lukoianova T., 2014, ADV CLASSIFICATION R, V24, P4
   Manning CD, 2014, PROCEEDINGS OF 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, P55, DOI 10.3115/v1/p14-5010
   Marsh S. P., 1994, THESIS
   Middleton SE, 2016, ACM T INFORM SYST, V34, DOI 10.1145/2842604
   Mikolov T., 2013, NIPS, V26, P3111
   Mitra T., 2015, ICWSM, P258
   Mitra T, 2017, CSCW'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING, P126, DOI 10.1145/2998181.2998351
   Mukherjee S, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P65, DOI 10.1145/2623330.2623714
   Namihira Y, 2013, 2013 INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY & INTERNET-BASED SYSTEMS (SITIS), P909, DOI 10.1109/SITIS.2013.148
   O'Leary DE, 2011, DECIS SUPPORT SYST, V51, P821, DOI 10.1016/j.dss.2011.01.016
   Paryani J, 2017, LECT NOTES ARTIF INT, V10449, P417, DOI 10.1007/978-3-319-67077-5_40
   Pasternack Jeff, 2013, P 22 INT C WORLD WID, P1009, DOI DOI 10.1145/2488388.2488476
   Pennebaker J.W., 2001, MAHWAY LAWRENCE ERLB
   Pennington J, 2014, EMNLP, P1532, DOI 10.3115/v1/D14-1162
   Ros SP, 2015, ACM T INTERNET TECHN, V15, DOI 10.1145/2797139
   Popat K, 2016, CIKM'16: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P2173, DOI 10.1145/2983323.2983661
   Ramachandramurthy S., 2015, SCI WORLD J, V2015
   Rao P, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY (CIT), P407, DOI 10.1109/CIT.2016.29
   Rath B., 2017, P 2017 IEEE ACM INT, P179
   Reuter C., 2017, P 14 ISCRAM C ALB FR
   Saez-Trumper Diego, 2014, P HT, P316
   Sampson J, 2016, CIKM'16: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P2377, DOI 10.1145/2983323.2983697
   Schroeck M., 2012, IBM GLOBAL BUSINESS, V12, P1, DOI DOI 10.1002/9781119204183.ch1
   Shi BX, 2016, KNOWL-BASED SYST, V104, P123, DOI 10.1016/j.knosys.2016.04.015
   Shiralkar P, 2017, IEEE DATA MINING, P859, DOI 10.1109/ICDM.2017.105
   Sirivianos M, 2014, ACM T WEB, V8, DOI 10.1145/2543711
   Snow D., 2012, ADDING 4 V BIG DATA
   Tolosi L., 2016, P 10 INT AAAI C WEB, P151
   Torky M., 2011, CREDIBILITY INVESTIG
   Vartapetiance A, 2014, SOC NETW ANAL MIN, V4, DOI 10.1007/s13278-014-0166-8
   Viviani M, 2017, WIRES DATA MIN KNOWL, V7, DOI 10.1002/widm.1209
   Viviani M, 2017, INT J INTELL SYST, V32, P481, DOI 10.1002/int.21844
   Viviani M, 2017, LECT NOTES ARTIF INT, V10147, P197, DOI 10.1007/978-3-319-52962-2_17
   Vosoughi S, 2017, ACM T KNOWL DISCOV D, V11, DOI 10.1145/3070644
   Wang R. Y., 1996, Journal of Management Information Systems, V12, P5
   Wang TH, 2015, J ENERGY CHEM, V24, P503, DOI 10.1016/j.jechem.2015.07.002
   Wang XZ, 2015, J SYST SOFTWARE, V102, P226, DOI 10.1016/j.jss.2014.07.023
   Webb H, 2016, ACM T INFORM SYST, V34, DOI 10.1145/2893478
   Wiegand S, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16 COMPANION), P751, DOI 10.1145/2872518.2890095
   Xie BL, 2016, LECT NOTES COMPUT SC, V9955, P483, DOI 10.1007/978-3-319-46298-1_31
   Yan SR, 2015, INFORM SCIENCES, V318, P51, DOI 10.1016/j.ins.2014.09.036
   Yang YK, 2015, INT JOINT CONF COMP, P41, DOI 10.1109/JCSSE.2015.7219767
   Yao S, 2016, IPSN P 15 ACM IEEE INT C, P1
   Yao SC, 2016, INT CON DISTR COMP S, P467, DOI 10.1109/ICDCS.2016.75
   Zhang D, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA), P1076, DOI 10.1109/BigData.2016.7840710
   Zhang ZL, 2015, HEALTH INFO LIBR J, V32, P195, DOI 10.1111/hir.12115
   Zhao B, 2017, ANN GIS, V23, P1, DOI 10.1080/19475683.2017.1280536
   Zhao L, 2016, COMPUT COMMUN, V76, P1, DOI 10.1016/j.comcom.2015.08.001
   Zhao Z, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P1395, DOI 10.1145/2736277.2741637
   Zhi S, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P2555, DOI 10.1145/3132847.3133182
   Zubiaga A, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0150989
   [No title captured]
NR 120
TC 19
Z9 19
U1 7
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0167-9236
EI 1873-5797
J9 DECIS SUPPORT SYST
JI Decis. Support Syst.
PD FEB
PY 2020
VL 129
AR 113132
DI 10.1016/j.dss.2019.113132
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Operations Research & Management Science
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Operations Research & Management Science
GA KH9GG
UT WOS:000510956500001
OA Green Published, hybrid
DA 2022-02-06
ER

PT J
AU Shelke, NA
   Kasana, SS
AF Shelke, Nitin Arvind
   Kasana, Singara Singh
TI A comprehensive survey on passive techniques for digital video forgery
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video forgery detection; Inter-frame forgery; Intra-frame forgery;
   Passive techniques; Video anti-forensics; Deepfake detection
ID DETECTION ALGORITHM; FRAME DELETION; DUPLICATION FORGERY; TAMPERING
   DETECTION; LOCALIZATION; FORENSICS; INCONSISTENCY; MOTION
AB Digital videos are one of the most widespread forms of multimedia in day to day life. These are widely transferred over social networking websites such as Facebook, Instagram, WhatsApp, YouTube, etc. through the Internet. Availability of modern and easy to use editing tools have facilitated the modification of the contents of the digital videos. Therefore, it has become an essential concern for the legitimacy, trustworthiness, and authenticity of these digital videos. Digital video forgery detection aims to identify the manipulations in the video and to check its authenticity. These techniques can be divided into active and passive techniques. In this paper, a comprehensive survey on video forgery detection using passive techniques have been presented. The primary goal of this survey is to study and analyze the existing passive video forgery detection techniques. Firstly, the preliminary information required for understanding video forgery detection is presented. Later, a brief survey of existing passive video forgery detection techniques based on the features, forgery identified, datasets used, and performance parameters detail along with their limitations are reviewed. Then, anti-forensics strategy and deepfake detection in the video are discussed. After that, standard benchmark video forgery datasets and the generalized architecture for passive video forgery detection techniques are discussed. Finally, few open challenges in the field of passive video forgery detection are also described.
C1 [Shelke, Nitin Arvind; Kasana, Singara Singh] Thapar Inst Engn & Technol, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Shelke, NA (corresponding author), Thapar Inst Engn & Technol, Patiala, Punjab, India.
EM nshelke_phd17@thapar.edu; singara@thapar.edu
CR Afchar D, 2018, 2018 IEEE INT WORKSH, P1
   Aghamaleki JA, 2017, MULTIMED TOOLS APPL, V76, P20691, DOI 10.1007/s11042-016-4004-z
   Aghamaleki JA, 2016, SIGNAL PROCESS-IMAGE, V47, P289, DOI 10.1016/j.image.2016.07.001
   Al-Sanjary OI, 2016, FORENSIC SCI INT, V266, P565, DOI 10.1016/j.forsciint.2016.07.013
   Aloraini M, 2020, IEEE T CIRC SYST TEC
   Aloraini M., 2019, ELECT IMAGE, V5, P543
   Aparicio-Diaz E, 2019, J INTELL FUZZY SYST, V36, P5023, DOI 10.3233/JIFS-179048
   Ardizzone E, 2015, LECT NOTES COMPUT SC, V9280, P665, DOI 10.1007/978-3-319-23234-8_61
   Bagiwa MA, 2016, DIGIT INVEST, V19, P29, DOI 10.1016/j.diin.2016.09.001
   Bai SS, 2019, LECT NOTES COMPUT SC, V11903, P244, DOI 10.1007/978-3-030-34113-8_21
   Bakas J, 2019, MULTIMED TOOLS APPL, V78, P4905, DOI 10.1007/s11042-018-6570-8
   Bestagini P, 2013, IEEE INT WORKSH MULT, P488, DOI 10.1109/MMSP.2013.6659337
   Bidokhti A, 2015, 2015 INTERNATIONAL SYMPOSIUM ON ARTIFICIAL INTELLIGENCE AND SIGNAL PROCESSING (AISP), P13, DOI 10.1109/AISP.2015.7123529
   Bozkurt I, 2017, TURK J ELECTR ENG CO, V25, P4558, DOI 10.3906/elk-1703-125
   Caldelli R, 2019, P IEEE INT C COMP VI
   Chao J., 2012, INT WORKSH DIG WAT, P267, DOI DOI 10.1007/978-3-642-40099-5_22
   Chen CC, 2017, INF HIDING MULTIMED, V8, P86
   Chen R., 2012, INF TECHNOL J, V11, P1456
   Chen SD, 2016, IEEE T CIRC SYST VID, V26, P2138, DOI 10.1109/TCSVT.2015.2473436
   Chetty Girija, 2010, Proceedings of the 2010 Fourth International Conference on Network and System Security (NSS 2010), P606, DOI 10.1109/NSS.2010.8
   Chittapur GB, 2014, EMERGING RES ELECT C, P557
   Cho K., 2014, ARXIV14061078
   D'Amiano L, 2019, IEEE T CIRC SYST VID, V29, P669, DOI 10.1109/TCSVT.2018.2804768
   D'Avino D., 2017, ELECT IMAGE, V2017, P92
   Dong Q, 2012, DIGIT INVEST, V9, P151, DOI 10.1016/j.diin.2012.07.002
   Fadl SM, 2018, J FORENSIC SCI, V63, P1099, DOI 10.1111/1556-4029.13658
   Fan Y., 2016, J INFORM HIDING MULT, V7, P399
   Fayyaz MA, 2020, MULTIMED TOOLS APPL, V79, P5767, DOI 10.1007/s11042-019-08236-2
   Feng C, 2014, P 2 ACM WORKSH INF H, P171
   Gironi A., 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P6226, DOI 10.1109/ICASSP.2014.6854801
   GRIP, 2018, COP MOV DAT
   GRIP, 2017, SPLIC DAT
   Guan HY, 2019, IEEE WINT CONF APPL, P63, DOI 10.1109/WACVW.2019.00018
   Guera D, 2018, 2018 15TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P127
   Hong JH, 2019, DIGIT INVEST, V30, P23, DOI 10.1016/j.diin.2019.06.002
   Hongmei Liu, 2014, Information Security Practice and Experience. 10th International Conference, ISPEC 2014. Proceedings: LNCS 8434, P262, DOI 10.1007/978-3-319-06320-1_20
   Howard A. G., 2017, MOBILENETS EFFICIENT
   Hsu CC, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P170, DOI 10.1109/MMSP.2008.4665069
   Hu X, 2015, P IEEE SEMICOND THER, P280, DOI 10.1109/SEMI-THERM.2015.7100173
   Hu YJ, 2012, INT J DIGIT CRIME FO, V4, P20, DOI 10.4018/jdcf.2012070102
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Hyun D.K., 2013, ERA INTERACTIVE MEDI, P25
   Ioffe S, 2015, ARXIV150203167, P448
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Johnston P, 2020, NEURAL COMPUT APPL, V32, P12243, DOI 10.1007/s00521-019-04272-z
   Johnston P, 2019, DIGIT INVEST, V29, P67, DOI 10.1016/j.diin.2019.03.006
   Kancherla K, 2012, LECT NOTES ARTIF INT, V7198, P308, DOI 10.1007/978-3-642-28493-9_33
   Kang XG, 2016, MULTIMED TOOLS APPL, V75, P13833, DOI 10.1007/s11042-015-2762-7
   Karen, 2014, ARXIV14091556
   Kharat J, 2020, MULTIMED TOOLS APPL, V79, P8107, DOI 10.1007/s11042-019-08272-y
   Kingra S, 2017, MULTIMED TOOLS APPL, V76, P25767, DOI 10.1007/s11042-017-4762-2
   Kobayashi M, 2010, IEEE T INF FOREN SEC, V5, P883, DOI 10.1109/TIFS.2010.2074194
   Kobayashi M, 2009, LECT NOTES COMPUT SC, V5414, P306
   Kono K, 2018, P INT C SOFT COMP PA, P381
   Koopman M, 2018, P IR MACH VIS IM PRO, P133
   Labartino D, 2013, IEEE INT WORKSH MULT, P494, DOI 10.1109/MMSP.2013.6659338
   Li F., 2014, P 3 INT C MULT TECHN, P63
   Li L, 2012, INT WORKSH DIG FOR, P242
   Li L., 2013, J INF HIDING MULTIME, V4, P46
   LI Y, 2018, P IEEE INT WORKSH IN, P00001
   Li ZH, 2016, SECUR COMMUN NETW, V9, P4548, DOI 10.1002/sec.1648
   Liao SY, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P864, DOI 10.1109/CISP.2013.6745286
   Lin CS, 2014, DIGIT INVEST, V11, P120, DOI 10.1016/j.diin.2014.03.016
   Lin CS, 2013, 2 INT C CYB SEC CYB, P107
   Lin GS, 2012, INT J PATTERN RECOGN, V26, DOI 10.1142/S0218001412500176
   Liu YQ, 2018, MULTIMED TOOLS APPL, V77, P7405, DOI 10.1007/s11042-017-4652-7
   Liu YQ, 2017, MULTIMEDIA SYST, V23, P223, DOI [10.1007/s00530-015-0478-1, 10.1007/s00530-015-0461-x]
   Long CJ, 2017, IEEE COMPUT SOC CONF, P1898, DOI 10.1109/CVPRW.2017.237
   Lyu Siwei, 2019, IEEE C COMP VIS PATT
   Marcel Sebastien, 2018, ARXIV PREPRINT ARXIV
   Mathai M, 2016, IEEE SW SYMP IMAG, P149, DOI 10.1109/SSIAI.2016.7459197
   Mizher MA, 2017, INT J ELECTRON SECUR, V9, P191, DOI 10.1504/IJESDF.2017.10005634
   Mondaini N, 2007, PROC SPIE, V6505, DOI 10.1117/12.704924
   Nguyen HH, 2019, INT CONF ACOUST SPEE, P2307, DOI 10.1109/ICASSP.2019.8682602
   Nguyen T., 2019, DEEP LEARNING DEEPFA
   NTHU, FOR PROJ DAT
   NTHU, VID INP PROJ
   Oh S., 2011, CVPR 2011, P3153, DOI [10.1109/CVPR.2011.5995586, DOI 10.1109/CVPR.2011.5995586]
   Pandey Ramesh Chand, 2014, 2014 5th International Conference on Computer and Communication Technology (ICCCT), P301, DOI 10.1109/ICCCT.2014.7001509
   Pandey RC, 2016, DIGIT INVEST, V19, P1, DOI 10.1016/j.diin.2016.08.002
   Pu H, 2019, UK WORKSH COMP INT, P541
   Ravi H, 2014, IEEE IMAGE PROC, P5352, DOI 10.1109/ICIP.2014.7026083
   Rocha A, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1978802.1978805
   Rossler A, 2019, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2019.00009
   Rossler Andreas, 2018, ARXIV180309179
   Sabir Ekraam, 2019, INTERFACES GUI, P80
   Sabour S., 2017, ADV NEURAL INFORM PR, P3856
   Saddique M, 2019, ADV ELECTR COMPUT EN, V19, P97, DOI 10.4316/AECE.2019.03012
   Shanableh T, 2013, DIGIT INVEST, V10, P350, DOI 10.1016/j.diin.2013.10.004
   Shelke NA, 2013, IJCSET, V4
   Shelke NA, 2016, PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P1068, DOI 10.1109/WiSPNET.2016.7566301
   Shih TK, 2011, IEEE T SYST MAN CY C, V41, P720, DOI 10.1109/TSMCC.2010.2077674
   Singh G, 2019, MULTIMED TOOLS APPL, V78, P11527, DOI 10.1007/s11042-018-6585-1
   Singh RD, 2017, FORENSIC SCI INT, V281, P75, DOI 10.1016/j.forsciint.2017.10.028
   Singh RD, 2017, DIGIT INVEST, V21, P31, DOI 10.1016/j.diin.2017.01.001
   Singh RD, 2018, MULTIMEDIA SYST, V24, P211, DOI 10.1007/s00530-017-0538-9
   Singh RD, 2017, J CIRCUIT SYST COMP, V26, DOI 10.1142/S0218126617501079
   Singh VK, 2015, L N INST COMP SCI SO, V157, P29, DOI 10.1007/978-3-319-25512-5_3
   Sitara K, 2017, 2017 IEEE 13TH INTERNATIONAL COLLOQUIUM ON SIGNAL PROCESSING & ITS APPLICATIONS (CSPA), P73, DOI 10.1109/CSPA.2017.8064927
   Sitara K, 2016, DIGIT INVEST, V18, P8, DOI 10.1016/j.diin.2016.06.003
   Stamm MC, 2012, IEEE T INF FOREN SEC, V7, P1315, DOI 10.1109/TIFS.2012.2205568
   SU L, 2019, IEEE ACCESS, V0007, P10971
   Su LC, 2018, IEEE T MULTIMEDIA, V20, P825, DOI 10.1109/TMM.2017.2760098
   Su LC, 2018, MULTIDIM SYST SIGN P, V29, P1173, DOI 10.1007/s11045-017-0496-6
   Su LC, 2015, MULTIMED TOOLS APPL, V74, P6641, DOI 10.1007/s11042-014-1915-4
   Su PC, 2015, J VIS COMMUN IMAGE R, V29, P103, DOI 10.1016/j.jvcir.2015.02.006
   Su Y. G., 2009, 2009 INT C COMP INT, P1
   Subramanyam AV, 2013, INT CONF ACOUST SPEE, P3038, DOI 10.1109/ICASSP.2013.6638216
   Subramanyam AV, 2012, IEEE INT WORKSH MULT, P89, DOI 10.1109/MMSP.2012.6343421
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tan SQ, 2015, ASIAPAC SIGN INFO PR, P719, DOI 10.1109/APSIPA.2015.7415366
   Tralic D, 2014, 2014 X INT S TEL BIT, P1
   TREC, VID RETR EV TRECVID
   Ulutas G, 2018, MULTIMEDIA SYST, V24, P549, DOI 10.1007/s00530-017-0581-6
   Ulutas G, 2017, IET IMAGE PROCESS, V11, P333, DOI 10.1049/iet-ipr.2016.0321
   Wahab AWA, 2014, INT C INFORM ASSUR S, P29, DOI 10.1109/ISIAS.2014.7064616
   Wang Q, 2014, SENSORS TRANSDUCERS, V166, P229
   Wang Q., 2014, J COMPUT COMMUN, V2, P51, DOI DOI 10.4236/jcc.2014.24008
   Wang W., 2006, P 8 WORKSH MULT SEC, P37, DOI DOI 10.1145/1161366.1161375
   Wang W, 2013, IEEE INT CON DIS, P244, DOI 10.1109/ICDCSW.2013.69
   Wang W, 2007, IEEE T INF FOREN SEC, V2, P438, DOI 10.1109/TIFS.2007.902661
   Wang WH, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P39
   Wang WH, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P35
   Wang Yi, 2014, P IEEE C COMP VIS PA
   Wei W, 2019, MULTIMED TOOLS APPL, V78, P27109, DOI 10.1007/s11042-017-5083-1
   Xu J, 2018, INT J CIV ENG, V16, P335, DOI 10.1007/s40999-016-0132-0
   Yahaya, 2012, SURREY U LIB FORENSI, P1
   Yang JM, 2016, MULTIMED TOOLS APPL, V75, P1793, DOI 10.1007/s11042-014-2374-7
   Yang X, 2019, INT CONF ACOUST SPEE, P8261, DOI 10.1109/ICASSP.2019.8683164
   Yao HC, 2019, J REAL-TIME IMAGE PR, V16, P751, DOI 10.1007/s11554-019-00865-y
   Yao Y, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10010003
   Yin LG, 2014, INT CONF INFO SCI, P148, DOI 10.1109/ICIST.2014.6920352
   Yu LY, 2016, NEUROCOMPUTING, V205, P84, DOI 10.1016/j.neucom.2016.03.051
   Yuxing Wu, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P2674, DOI 10.1109/ICASSP.2014.6854085
   Zampoglou M, 2019, LECT NOTES COMPUT SC, V11295, P374, DOI 10.1007/978-3-030-05710-7_31
   Zhang J, 2009, PROCEEDINGS OF THE FIRST INTERNATIONAL WORKSHOP ON EDUCATION TECHNOLOGY AND COMPUTER SCIENCE, VOL II, P49, DOI 10.1109/ETCS.2009.273
   Zhang Z, 2019, INT C NAT COMP FUZZ, P415
   Zhang ZZ, 2015, SECUR COMMUN NETW, V8, P311, DOI 10.1002/sec.981
   Zhang ZH, 2015, INT CONF ASIAN LANG, P94, DOI 10.1109/IALP.2015.7451540
   Zhao DN, 2018, MULTIMEDIA TOOLS APP
   Zheng J, 2014, 2014 9TH INTERNATIONAL CONFERENCE ON COMMUNICATIONS AND NETWORKING IN CHINA (CHINACOM), P18, DOI 10.1109/CHINACOM.2014.7054251
NR 141
TC 4
Z9 4
U1 6
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 6247
EP 6310
DI 10.1007/s11042-020-09974-4
EA OCT 2020
PG 64
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000578275200002
DA 2022-02-06
ER

PT J
AU Zhang, KJ
   Liang, Y
   Zhang, JY
   Wang, ZQ
   Li, XX
AF Zhang, Kejun
   Liang, Yu
   Zhang, Jianyi
   Wang, Zhiqiang
   Li, Xinxin
TI No One Can Escape: A General Approach to Detect Tampered and Generated
   Image
SO IEEE ACCESS
LA English
DT Article
DE Digital image forensics; generative adversarial networks; deep learning;
   convolutional neural networks
ID MANIPULATION; STEGANALYSIS
AB Fake or tampered images pose a real problem in today's life. It is easy to unknowingly be drawn to an interesting image that is false. Recently, with the emergence of generative adversarial networks (GANs), it becomes much more easy to generate high-quality fake images in a very realistic way. However, the current digital image forensics algorithms mainly focus on the detection of traditional tampered images or need prior knowledge of the network structure of GANs. Hence, verifying the authenticity of an image is very challenging. In this paper, we propose a general method for simultaneously detecting tampered images, and GANs generated images. First, we use the Scharr operator to extract the edge information of the image. Then, we converted the edge image information matrix into the gray level co-occurrence matrix (GLCM) to scale the image without loss of image information. Finally, GLCM was fed into the deep neural network designed based on depthwise separable convolution for training. Compared with other methods, our model achieves a higher macro average of F1 score of 0.9865. Meanwhile, our method has better performance in detecting tampered images and has strong generalization ability for many GANs models.
C1 [Zhang, Kejun; Liang, Yu; Zhang, Jianyi; Wang, Zhiqiang; Li, Xinxin] Beijing Elect Sci & Technol Inst, Beijing 10070, Peoples R China.
   [Wang, Zhiqiang] Beijing Elect Sci & Technol Inst, Fac Comp Sci, Beijing 10070, Peoples R China.
   [Zhang, Kejun; Liang, Yu; Li, Xinxin] Xidian Univ, Xian 710071, Shaanxi, Peoples R China.
   [Wang, Zhiqiang] State Informat Ctr, Beijing 100045, Peoples R China.
C3 Beijing Electronic Science & Technology Institute; Beijing Electronic
   Science & Technology Institute; Xidian University
RP Zhang, JY; Wang, ZQ (corresponding author), Beijing Elect Sci & Technol Inst, Beijing 10070, Peoples R China.; Zhang, JY; Wang, ZQ (corresponding author), Beijing Elect Sci & Technol Inst, Fac Comp Sci, Beijing 10070, Peoples R China.; Wang, ZQ (corresponding author), State Informat Ctr, Beijing 100045, Peoples R China.
EM zjy@besti.edu.cn; wangzq@besti.edu.cn
RI Zhang, Jianyi/AAE-8396-2020
OI Zhang, Jianyi/0000-0001-8765-053X
FU National Key Research and Development Program of China [2018YFB1004100];
   Key Lab of Information Network Security; Ministry of Public Security
   [C18612]; Fundamental Research Funds for the Central
   UniversitiesFundamental Research Funds for the Central Universities
   [328201804, 328201908]
FX This work was supported in part by the National Key Research and
   Development Program of China under Grant 2018YFB1004100, in part by the
   Key Lab of Information Network Security, in part by the Ministry of
   Public Security under Grant C18612, and in part by the Fundamental
   Research Funds for the Central Universities under Grant 328201804 and
   Grant 328201908.
CR Agarwal S., 2019, P CVPR WORKSH LONG B, P38
   Agarwal S, 2018, ADV INTELL SYST, V518, P117, DOI 10.1007/978-981-10-3373-5_10
   Alahmadi AA, 2013, IEEE GLOB CONF SIG, P253, DOI 10.1109/GlobalSIP.2013.6736863
   Bayar B, 2018, IEEE T INF FOREN SEC, V13, P2691, DOI 10.1109/TIFS.2018.2825953
   Brock A., 2018, LARGE SCALE GAN TRAI, DOI DOI 10.1016/J.VETIMM.2015.04.007
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Cozzolino D, 2015, IEEE T INF FOREN SEC, V10, P2284, DOI 10.1109/TIFS.2015.2455334
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   He K., 2016, DEEP RESIDUAL LEARNI, DOI DOI 10.1109/CVPR.2016.90
   Howard A. G., 2017, ARXIV170404861
   Karras T., 2017, ARXIV171010196
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Li Haodong, 2018, ARXIV PREPRINT ARXIV
   [李艳歌 Li Yange], 2018, [高分子通报, Polymer Bulletin], P46
   Loffe S., 2015, ABS150203167 ARXIV, P448, DOI DOI 10.1109/CVPR.2016.90
   Marra F, 2018, IEEE 1ST CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2018), P384, DOI 10.1109/MIPR.2018.00084
   Mirsky Y, 2019, PROCEEDINGS OF THE 28TH USENIX SECURITY SYMPOSIUM, P461
   Miyato T., 2018, ICLR
   Mo HX, 2018, PROCEEDINGS OF THE 6TH ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY (IH&MMSEC'18), P43, DOI 10.1145/3206004.3206009
   Muhammad G, 2013, 2013 IEEE EUROCON, P1580
   Nataraj L, 2019, ELECT IMAGING, V2019, P532, DOI DOI 10.2352/ISSN.2470-1173.2019.5.MWSF-532
   Rao Y., 2016, P IEEE INT WORKSH IN, P1, DOI [10.1109/WIFS.2016.7823911, DOI 10.1109/WIFS.2016.7823911]
   Wang SY, 2019, IEEE I CONF COMP VIS, P10071, DOI 10.1109/ICCV.2019.01017
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Wang W, 2009, 2009 16TH IEEE INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOLS 1-6, P1257, DOI 10.1109/ICIP.2009.5413549
   Wang W, 2010, IEEE IMAGE PROC, P2101, DOI 10.1109/ICIP.2010.5652660
   Wen BH, 2016, IEEE IMAGE PROC, P161, DOI 10.1109/ICIP.2016.7532339
   Xu XK, 2013, IEEE IMAGE PROC, P4422, DOI 10.1109/ICIP.2013.6738911
   Yu F., 2015, ARXIV CONSTRUCTION LARGE S
   Yu F, 2017, PROC CVPR IEEE, P636, DOI 10.1109/CVPR.2017.75
   Zhang H., 2018, ARXIV PREPRINT ARXIV, P1, DOI [10.5194/acp-2018-720, DOI 10.5194/ACP-2018-720]
   Zhang H, 2019, IEEE T PATTERN ANAL, V41, P1947, DOI 10.1109/TPAMI.2018.2856256
   Zhang H, 2017, IEEE I CONF COMP VIS, P5908, DOI 10.1109/ICCV.2017.629
   Zhou P, 2018, PROC CVPR IEEE, P1053, DOI 10.1109/CVPR.2018.00116
NR 36
TC 3
Z9 3
U1 1
U2 7
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2019
VL 7
BP 129494
EP 129503
DI 10.1109/ACCESS.2019.2939812
PG 10
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA IZ7AA
UT WOS:000487235500019
OA gold
DA 2022-02-06
ER

PT J
AU Shao, HK
   Zhong, DX
AF Shao, Huikai
   Zhong, Dexing
TI Towards Cross-Dataset Palmprint Recognition Via Joint Pixel and Feature
   Alignment
SO IEEE TRANSACTIONS ON IMAGE PROCESSING
LA English
DT Article
DE Feature extraction; Palmprint recognition; Training; Databases;
   Adaptation models; Task analysis; Data models; Palmprint recognition;
   cross-dataset recognition; domain adaptation; deep hashing network
ID UNCONSTRAINED PALMPRINT; ADAPTATION; EXTRACTION; NETWORKS
AB Deep learning-based palmprint recognition algorithms have shown great potential. Most of them are mainly focused on identifying samples from the same dataset. However, they may be not suitable for a more convenient case that the images for training and test are from different datasets, such as collected by embedded terminals and smartphones. Therefore, we propose a novel Joint Pixel and Feature Alignment (JPFA) framework for such cross-dataset palmprint recognition scenarios. Two-stage alignment is applied to obtain adaptive features in source and target datasets. 1) Deep style transfer model is adopted to convert source images into fake images to reduce the dataset gaps and perform data augmentation on pixel level. 2) A new deep domain adaptation model is proposed to extract adaptive features by aligning the dataset-specific distributions of target-source and target-fake pairs on feature level. Adequate experiments are conducted on several benchmarks including constrained and unconstrained palmprint databases. The results demonstrate that our JPFA outperforms other models to achieve the state-of-the-arts. Compared with baseline, the accuracy of cross-dataset identification is improved by up to 28.10% and the Equal Error Rate (EER) of cross-dataset verification is reduced by up to 4.69%. To make our results reproducible, the codes are publicly available at http://gr.xjtu.edu.cn/web/bell/resource.
C1 [Shao, Huikai; Zhong, Dexing] Xi An Jiao Tong Univ, Sch Automat Sci & Engn, Xian 710049, Peoples R China.
   [Zhong, Dexing] Pazhou Lab, Guangzhou 510335, Peoples R China.
   [Zhong, Dexing] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210093, Peoples R China.
C3 Xi'an Jiaotong University; Nanjing University
RP Zhong, DX (corresponding author), Xi An Jiao Tong Univ, Sch Automat Sci & Engn, Xian 710049, Peoples R China.
EM shaohuikai@stu.xjtu.edu.cn; bell@xjtu.edu.cn
OI Zhong, Dexing/0000-0002-6806-6300
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61105021]; Natural Science Foundation of
   Zhejiang ProvinceNatural Science Foundation of Zhejiang Province
   [LGF19F030002]; Natural Science Foundation of Shaanxi ProvinceNatural
   Science Foundation of Shaanxi Province [2020JM-073]; Fundamental
   Research Funds for the Central UniversitiesFundamental Research Funds
   for the Central Universities [xzy022020051]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61105021, in part by the Natural Science
   Foundation of Zhejiang Province under Grant LGF19F030002, in part by the
   Natural Science Foundation of Shaanxi Province under Grant 2020JM-073,
   and in part by the Fundamental Research Funds for the Central
   Universities under Grant xzy022020051. The associate editor coordinating
   the review of this manuscript and approving it for publication was Dr.
   Soma Biswas.
CR [Anonymous], 2009, ADV NEURAL INFORM PR
   Ben-David S., 2006, NIPS, V19, P137
   Chen C, 2019, THIRTY-THIRD AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTY-FIRST INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / NINTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P3296
   Chen Chaoqi, 2020, P IEEE CVF C COMP VI, P8869, DOI DOI 10.1109/CVPR42600.2020.00889
   Chen C, 2018, LECT NOTES COMPUT SC, V11046, P143, DOI 10.1007/978-3-030-00919-9_17
   Chen YC, 2019, PROC CVPR IEEE, P1791, DOI 10.1109/CVPR.2019.00189
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deng WJ, 2018, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.2018.00110
   Ding CX, 2018, IEEE T PATTERN ANAL, V40, P1002, DOI 10.1109/TPAMI.2017.2700390
   Dou H, 2019, INT CONF ACOUST SPEE, P1757, DOI 10.1109/ICASSP.2019.8682600
   Du XF, 2021, IEEE T CIRC SYST VID, V31, P2372, DOI 10.1109/TCSVT.2020.3024593
   Fei LK, 2020, IEEE T INSTRUM MEAS, V69, P9743, DOI 10.1109/TIM.2020.3002463
   Fei LK, 2020, IEEE T CIRC SYST VID, V30, P468, DOI 10.1109/TCSVT.2019.2890835
   Fei LK, 2019, IEEE T IMAGE PROCESS, V28, P3808, DOI 10.1109/TIP.2019.2903307
   Fei LK, 2019, IEEE T SYST MAN CY-S, V49, P346, DOI 10.1109/TSMC.2018.2795609
   Fei LK, 2019, INFORM SCIENCES, V473, P59, DOI 10.1016/j.ins.2018.09.032
   Fei LK, 2016, IEEE T HUM-MACH SYST, V46, P787, DOI 10.1109/THMS.2016.2586474
   Ganin Y, 2016, J MACH LEARN RES, V17
   Genovese A, 2019, IEEE T INF FOREN SEC, V14, P3160, DOI 10.1109/TIFS.2019.2911165
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Gretton A, 2012, J MACH LEARN RES, V13, P723
   Guo ZH, 2009, PATTERN RECOGN LETT, V30, P1219, DOI 10.1016/j.patrec.2009.05.010
   Hoffman J, 2018, PR MACH LEARN RES, V80
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   Jia W, 2008, PATTERN RECOGN, V41, P1504, DOI 10.1016/j.patcog.2007.10.011
   Jia W, 2017, IEEE T IMAGE PROCESS, V26, P4483, DOI 10.1109/TIP.2017.2705424
   Jia W, 2012, SENSORS-BASEL, V12, P7938, DOI 10.3390/s120607938
   Kong A, 2009, PATTERN RECOGN, V42, P1408, DOI 10.1016/j.patcog.2009.01.018
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2015, PATTERN RECOGN, V48, P2290, DOI 10.1016/j.patcog.2015.01.021
   Leng L, 2010, INT J PHYS SCI, V5, P2543
   Li Y, 2019, IEEE GLOB CONF SIG, DOI 10.1080/15226514.2019.1671796
   Liu HM, 2016, PROC CVPR IEEE, P2064, DOI 10.1109/CVPR.2016.227
   Long MS, 2015, PR MACH LEARN RES, V37, P97
   Long MS, 2013, IEEE I CONF COMP VIS, P2200, DOI 10.1109/ICCV.2013.274
   Matkowski WM, 2020, IEEE T INF FOREN SEC, V15, P1601, DOI 10.1109/TIFS.2019.2945183
   Palma D, 2019, IEEE T SYST MAN CY-S, V49, P2676, DOI 10.1109/TSMC.2017.2771232
   Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Shao HK, 2021, NEUROCOMPUTING, V432, P288, DOI 10.1016/j.neucom.2020.12.072
   Shao HK, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3053991
   Shao HK, 2019, IEEE COMPUT SOC CONF, P714, DOI 10.1109/CVPRW.2019.00098
   Shao HK, 2020, J ELECTRON IMAGING, V29, DOI 10.1117/1.JEI.29.1.013018
   Shao HK, 2019, IEEE IMAGE PROC, P1153, DOI 10.1109/ICIP.2019.8803778
   Shao HK, 2019, IEEE INT CON MULTI, P1390, DOI 10.1109/ICME.2019.00241
   Simonyan K, 2015, ICLR 2015, DOI DOI 10.1109/CVPR.2015.7298594
   Sun BC, 2016, LECT NOTES COMPUT SC, V9915, P443, DOI 10.1007/978-3-319-49409-8_35
   Tang YZ, 2020, IEEE T IMAGE PROCESS, V29, P5641, DOI 10.1109/TIP.2020.2985545
   Tran L, 2019, PROC CVPR IEEE, P2667, DOI 10.1109/CVPR.2019.00278
   Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316
   Ungureanu AS, 2020, IEEE ACCESS, V8, P86130, DOI 10.1109/ACCESS.2020.2992219
   Ungureanu AS, 2017, IEEE T CONSUM ELECTR, V63, P334, DOI 10.1109/TCE.2017.014994
   Wang GA, 2019, IEEE I CONF COMP VIS, P3622, DOI 10.1109/ICCV.2019.00372
   Wang ZX, 2019, PROC CVPR IEEE, P618, DOI 10.1109/CVPR.2019.00071
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
   Wu XQ, 2006, IEEE T SYST MAN CY A, V36, P978, DOI 10.1109/TSMCA.2006.871797
   Xu Y, 2018, IEEE T SYST MAN CY-S, V48, P232, DOI 10.1109/TSMC.2016.2597291
   Yasarla R, 2020, PROC CVPR IEEE, P2723, DOI 10.1109/CVPR42600.2020.00280
   Yin XF, 2020, IEEE T INF FOREN SEC, V15, P28, DOI 10.1109/TIFS.2019.2918083
   Zhang D, 2010, IEEE T INSTRUM MEAS, V59, P480, DOI 10.1109/TIM.2009.2028772
   Zhang L, 2012, IEEE SIGNAL PROC LET, V19, P663, DOI 10.1109/LSP.2012.2211589
   Zhang Y., 2020, ARXIV200313266
   Zhong DX, 2019, IEEE T INF FOREN SEC, V14, P3140, DOI 10.1109/TIFS.2019.2912552
   Zhong DX, 2019, NEUROCOMPUTING, V328, P16, DOI 10.1016/j.neucom.2018.03.081
   Zhong Z, 2018, PROC CVPR IEEE, pCP99, DOI 10.1109/CVPR.2018.00541
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zuo WM, 2010, PROC CVPR IEEE, P2265, DOI 10.1109/CVPR.2010.5539909
NR 70
TC 3
Z9 3
U1 6
U2 11
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1057-7149
EI 1941-0042
J9 IEEE T IMAGE PROCESS
JI IEEE Trans. Image Process.
PY 2021
VL 30
BP 3764
EP 3777
DI 10.1109/TIP.2021.3065220
PG 14
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RD3OM
UT WOS:000633391800003
PM 33739923
DA 2022-02-06
ER

PT J
AU Ufarte-Ruiz, MJ
   Peralta-Garcia, L
   Murcia-Verdu, FJ
AF Ufarte-Ruiz, Maria-Jose
   Peralta-Garcia, Lidia
   Murcia-Verdu, Francisco-Jose
TI Fact checking: A new challenge in journalism
SO PROFESIONAL DE LA INFORMACION
LA Spanish
DT Article
DE Fact checking; Verification; Fake news; Credibility; Journalistic
   profiles; Cybermedia; Online newspapers; Information and Communication
   Technologies; ICT; Journalism
ID FAKE NEWS; STUDENTS; SKILLS
AB The present article analyses similarity and differences between academic and professional speech about "fact checking", understanding it from a double perspective, both, like a competence that current journalists have to acquire, and a work field that offers new opportunities. The research is based on a bibliographical review about the fact checkers' profiles. It also collects the opinion of seven university professors by means of a structured interview and has access to the student's point of view through a close-response test and a categorical test (n=316). It also analyses the content of the data verification departments that exists in Spain with the aim of knowing which the most demanded competences are. The results reflect that the discussion is still open and at the same time it shows a coincidence between both speeches about the necessity of a journalist' solid training that integrates new profiles.
C1 [Ufarte-Ruiz, Maria-Jose] Univ Castilla La Mancha, Campus Cuenca Polivalente,Campus Univ S-N, Cuenca 16071, Spain.
   [Peralta-Garcia, Lidia] Univ Castilla La Mancha, Fac Periodismo Cuenca, Campus Cuenca Polivalente,Campus Univ S-N, Cuenca 16071, Spain.
   [Murcia-Verdu, Francisco-Jose] Univ Basque Country, Fac Ciencias Sociales & Comunicac, B Sarriena S-N, Leioa 48940, Bizkaia, Spain.
C3 Universidad de Castilla-La Mancha; Universidad de Castilla-La Mancha;
   University of Basque Country
RP Ufarte-Ruiz, MJ (corresponding author), Univ Castilla La Mancha, Campus Cuenca Polivalente,Campus Univ S-N, Cuenca 16071, Spain.
EM mariajose.ufarte@uclm.es; lidia.peralta@uclm.es;
   franmurciaverdu@gmail.com
RI Garcia, Lidia Peralta/E-6602-2018; Verdu, Francisco Jose
   Murcia/W-4014-2019
OI Garcia, Lidia Peralta/0000-0003-2934-0108; Verdu, Francisco Jose
   Murcia/0000-0001-6020-1689
CR Alonso-Benito Luis-Enrique, 2009, DEBATE COMPETENCIAS
   Alvarez-Flores EP, 2018, PROF INFORM, V27, P136, DOI 10.3145/epi.2018.ene.13
   Alvarez-Gromaz L., 2016, SENSACIONALISMO AMAR, P215
   Amazeen MA, 2020, JOURNALISM, V21, P95, DOI 10.1177/1464884917730217
   [Anonymous], 2016, ELDIARIO        0914
   [Anonymous], 2017, EL OBJETIVO     1028
   APM, 2017, INF AN PROF PER
   Arias Oliva M, 2014, HIST COMUN SOC, V19, P355, DOI 10.5209/rev_HICS.2014.v19.44963
   Armendariz E, 2015, REV INT RELAC PUBLIC, V5, P153, DOI 10.5783/RIRP-9-2015-09-153-178
   Balmas M, 2014, COMMUN RES, V41, P430, DOI 10.1177/0093650212453600
   Besalu-Casademont R, 2017, REV LAT COMUN SOC, V72, P1536, DOI 10.4185/RLCS-2017-1233
   Bremer L., 2013, ENHANCING YOUTH EMPL
   Carey Benedict, 2018, NY TIMES, pA14
   Casero-Ripolles A., 2013, ESTUD MENSAJE PERIOD, V19, P681, DOI [10.5209/rev_ESMP.2013.v19.42151, DOI 10.5209/REV_ESMP.2013.V19.42151]
   Casero-Ripolles A, 2013, HIST COMUN SOC, V18, P53, DOI 10.5209/rev_HICS.2013.v18.44311
   Ciampaglia GL, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0128193
   Comision Europea, 2018, COMM ITS PRIOR
   Crucianelli Sandra, 2012, IJNET RED PERIODISTA
   DELPESO MM, 2013, REV EDUC, P244, DOI DOI 10.4438/1988-592X-RE-2011-360-110
   Elias-Perez Carlos., 2015, BIG DATA PERIODISMO
   Europa Press, 2017, EUROPA PRESS    1004
   Farias-Batlle Pedro, 2009, INFORME ANUAL PROFE
   Fole X., 2012, FRONTERAD 0926
   Fundeu, 2013, VER MEJ QUE FACT CHE
   Garcia I, 2012, ESTUDIOS MENSAJE PER, V18, P413, DOI DOI 10.5209/REV_ESMP.2012.V18.40996
   Munoz-Repiso AGV, 2016, REV LATINOAM TECNOL, V15, P155, DOI 10.17398/1695-288X.15.2.155
   Gomez-Mompart JL, 2015, COMUNICAR, V23, P143, DOI 10.3916/C45-2015-15
   Gonzalez S., 2012, ESTUDIOS MENSAJE PER, V18, P455, DOI DOI 10.5209/REV_ESMP.2012.V18.41000
   Graves L., 2016, DECIDING WHATS TRUE
   Greenberg D, 2017, J COMMUN, V67, pE1, DOI 10.1111/jcom.12329
   Haigh M, 2018, JOURNALISM STUD, V19, P2062, DOI 10.1080/1461670X.2017.1316681
   Hazard-Owen Laura, 2018, NIEMAN JOURNALISM LA
   Jankowski NW, 2018, JAVNOST-PUBLIC, V25, P248, DOI 10.1080/13183222.2018.1418964
   Khaldarova I, 2016, JOURNAL PRACT, V10, P891, DOI 10.1080/17512786.2016.1163237
   Kleis-Nielsen Rasmus, 2017, NEWS YOU DONT BELIEV
   Llaneras K., 2017, PAIS
   Lopez-Garcia X., 2012, REV COMUNICACION, V11, P178
   Lopez-Garcia X, 2017, COMUNICAR, V25, P81, DOI 10.3916/C53-2017-08
   Lopez-Garcia X, 2016, PROF INFORM, V25, P286, DOI 10.3145/epi.2016.mar.16
   Lopez-Garcia Xose, 2016, TELOS
   Humanes ML, 2014, COMUNICAR, V21, P181, DOI 10.3916/C42-2014-18
   Sanchez JLM, 2015, REV LAT COMUN SOC, V70, P69, DOI 10.4185/RLCS-2015-1035
   Manfredi-Sanchez Juan Luis, 2015, CUADERNOS ARTESANOS, V76
   Margolin DB, 2018, POLIT COMMUN, V35, P196, DOI 10.1080/10584609.2017.1334018
   Massot Josep, 2017, VANGUARDIA
   MEYER P, 1991, NEW PRECISION JOURNA
   Nelson JL, 2018, NEW MEDIA SOC, V20, P3720, DOI 10.1177/1461444818758715
   Palomo B, 2013, COMUN MEDIOS, P113, DOI 10.5354/0719-1529.2014.27403
   Alvarez-Flores EP, 2017, REV LAT COMUN SOC, V72, P540, DOI 10.4185/RLCS-2017-1178
   Perlado-Lamo-de-Espinosa Marta, 2015, CREATIVIDAD SOC, P6
   Redondo Myriam, 2017, BUENAS NOTICIAS FACT
   Reno L., 2014, NARRATIVAS TRANSMEDI
   Resenstiel, 2001, ELEMENTS JISM
   Sanchez-Gonzalez H., 2013, ESTUD MENSAJE PERIOD, V19, P981, DOI [10.5209/rev_ESMP.2013.v19.42183, DOI 10.5209/REV_ESMP.2013.V19.42183]
   Sanhermelando Juan, 2018, EL ESPANOL
   Tandoc EC, 2018, DIGIT JOURNAL, V6, P137, DOI 10.1080/21670811.2017.1360143
   Torres-Coronas T, 2015, REV EDUC-MADRID, P63, DOI 10.4438/1988-592X-RE-2015-367-283
   Uscinski JE, 2013, CRIT REV, V25, P162, DOI 10.1080/08913811.2013.843872
   Wilkinson John-William, 2017, VANGUARDIA
   Wintersieck AL, 2017, AM POLIT RES, V45, P304, DOI 10.1177/1532673X16686555
NR 60
TC 20
Z9 20
U1 5
U2 40
PU EPI
PI BARCELONA
PA APARTADO 32 280, BARCELONA, 08080, SPAIN
SN 1386-6710
J9 PROF INFORM
JI Prof. Inf.
PD JUL-AUG
PY 2018
VL 27
IS 4
BP 733
EP 741
DI 10.3145/epi.2018.jul.02
PG 9
WC Communication; Information Science & Library Science
WE Social Science Citation Index (SSCI)
SC Communication; Information Science & Library Science
GA GU7VR
UT WOS:000445536600002
OA Green Submitted, Bronze
DA 2022-02-06
ER

PT J
AU Guo, AJ
   Fang, LY
   Qi, M
   Li, ST
AF Guo, Anjing
   Fang, Leyuan
   Qi, Min
   Li, Shutao
TI Unsupervised Denoising of Optical Coherence Tomography Images With
   Nonlocal-Generative Adversarial Network
SO IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT
LA English
DT Article
DE Deep learning; generative adversarial networks (GANs); image denoising;
   optical coherence tomography (OCT)
ID SPECKLE REDUCTION; NOISE-REDUCTION; SD-OCT; SPARSE; SEGMENTATION; FILTER
AB Deep learning for image denoising has recently attracted considerable attentions due to its excellent performance. Since most of current deep learning-based denoising models require a large number of clean images for training, it is difficult to extend them to the denoising problems when the reference clean images are hard to acquire (e.g., optical coherence tomography (OCT) images). In this article, we propose a novel unsupervised deep learning model called as nonlocal-generative adversarial network (nonlocal-GAN) for OCT image denoising, where the deep model can be trained without reference clean images. Specifically, considering that the background areas of OCT images mainly contain pure real noise samples, we creatively train a discriminator to distinguish background real noise samples from the fake noise samples generated by the denoiser, that is the generator, and then the discriminator will guide the generator for denoising. To further enhance denoising performance, we introduce a nonlocal means layer into the generator of the nonlocal-GAN model. Furthermore, since nearby several OCT B-scans have strong correlations, we also propose a nonlocal-GAN-M model to utilize the high correlations within nearby B-scans. Extensive experimental results on clinical retinal OCT images demonstrate the effectiveness and efficiency of the proposed method.
C1 [Guo, Anjing; Fang, Leyuan; Li, Shutao] Hunan Univ, Coll Elect & Informat Engn, Changsha 410082, Peoples R China.
   [Guo, Anjing; Fang, Leyuan; Li, Shutao] Key Lab Visual Percept & Artificial Intelligence, Changsha 410082, Peoples R China.
   [Qi, Min] Cent South Univ, Dept Plast Surg, Xiangya Hosp, Changsha 410082, Peoples R China.
C3 Hunan University; Central South University
RP Li, ST (corresponding author), Hunan Univ, Coll Elect & Informat Engn, Changsha 410082, Peoples R China.
EM anjing_guo@hnu.edu.cn; fangleyuan@gmail.com; qimin05@csu.edu.cn;
   shutao_li@hnu.edu.cn
OI Fang, Leyuan/0000-0003-2351-4461; Li, Shutao/0000-0002-0585-9848
FU National Natural Science Fund of ChinaNational Natural Science
   Foundation of China (NSFC) [61890962, 61922029]; Science and Technology
   Plan Project Fund of Hunan Province [CX2018B171, 2017RS3024,
   2018TP1013]; Science and Technology Talents Program of Hunan Association
   for Science and Technology [2017TJ-Q09]; National Key Research and
   Development Program of China [2018YFB1305200]
FX This work was supported in part by the National Natural Science Fund of
   China under Grant 61890962 and Grant 61922029, in part by the Science
   and Technology Plan Project Fund of Hunan Province under Grant
   CX2018B171, Grant 2017RS3024, and Grant 2018TP1013; in part by the
   Science and Technology Talents Program of Hunan Association for Science
   and Technology under Grant 2017TJ-Q09, and in part by the National Key
   Research and Development Program of China under Grant 2018YFB1305200.
   The Associate Editor coordinating the review process was Dr. Sabrina
   Grassini.
CR Abadi M., 2016, ARXIV PREPRINT ARXIV, DOI 10.1038/s41598-021-85274-7
   Abbasi A, 2019, COMPUT BIOL MED, V108, P1, DOI 10.1016/j.compbiomed.2019.01.010
   Anwar S., 2019, ARXIV190407396
   Arjovsky M, 2017, ARXIV170107875
   Attivissimo F, 2010, IEEE T INSTRUM MEAS, V59, P1251, DOI 10.1109/TIM.2010.2040932
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Burger HC, 2012, PROC CVPR IEEE, P2392, DOI 10.1109/CVPR.2012.6247952
   Chen JW, 2018, PROC CVPR IEEE, P3155, DOI 10.1109/CVPR.2018.00333
   Cheng J, 2016, IEEE T MED IMAGING, V35, P2270, DOI 10.1109/TMI.2016.2556080
   Cheng J, 2014, IEEE ENG MED BIO, P186, DOI 10.1109/EMBC.2014.6943560
   Chitchian S., 2009, J BIOMEDICAL OPTICS, V14, P14
   Chiu SJ, 2012, INVEST OPHTH VIS SCI, V53, P53, DOI 10.1167/iovs.11-7640
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Fang LY, 2017, IEEE T MED IMAGING, V36, P407, DOI 10.1109/TMI.2016.2611503
   Fang LY, 2013, IEEE T MED IMAGING, V32, P2034, DOI 10.1109/TMI.2013.2271904
   Fang LY, 2012, BIOMED OPT EXPRESS, V3, P927, DOI 10.1364/BOE.3.000927
   Farsiu S, 2014, OPHTHALMOLOGY, V121, P162, DOI 10.1016/j.ophtha.2013.07.013
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Guo S, 2019, PROC CVPR IEEE, P1712, DOI 10.1109/CVPR.2019.00181
   Han JH, 2011, IEEE T INSTRUM MEAS, V60, P3958, DOI 10.1109/TIM.2011.2164822
   HUANG D, 1991, SCIENCE, V254, P1178, DOI 10.1126/science.1957169
   Jain V., 2009, NIPS, V21, P769
   Jian ZP, 2010, OPT EXPRESS, V18, P1024, DOI 10.1364/OE.18.001024
   Jiang GQ, 2017, IEEE T INSTRUM MEAS, V66, P2391, DOI 10.1109/TIM.2017.2698738
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Krizhevsky A., 2012, ADV NEURAL INF PROCE, P1097, DOI DOI 10.1145/3065386
   Lei J, 2018, IEEE T INSTRUM MEAS, V67, P2107, DOI 10.1109/TIM.2018.2811228
   Liu XA, 2010, OPT EXPRESS, V18, P22010, DOI 10.1364/OE.18.022010
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu SJ, 2010, IEEE T BIO-MED ENG, V57, P2605, DOI 10.1109/TBME.2010.2055057
   Maggioni M, 2013, IEEE T IMAGE PROCESS, V22, P119, DOI 10.1109/TIP.2012.2210725
   Mao YX, 2011, IEEE T INSTRUM MEAS, V60, P3376, DOI 10.1109/TIM.2011.2126950
   Ozcan A, 2007, J OPT SOC AM A, V24, P1901, DOI 10.1364/JOSAA.24.001901
   Pizurica A, 2008, CURR MED IMAGING REV, V4, P270, DOI 10.2174/157340508786404044
   Rabbani H, 2008, IEEE T BIO-MED ENG, V55, P2152, DOI 10.1109/TBME.2008.923140
   Rabbani H, 2009, IEEE T BIO-MED ENG, V56, P2826, DOI 10.1109/TBME.2009.2028876
   Simonyan K., 2015, P INT C LEARN REPR, P106
   Springenberg J. T., 2015, P INT C LEARN REPR, P200
   Sun W, 2010, STATISTIC APPLICATION IN SCIENTIFIC AND SOCIAL REFORMATION, P453
   Taji B, 2018, IEEE T INSTRUM MEAS, V67, P1124, DOI 10.1109/TIM.2017.2769198
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wilkins GR, 2012, IEEE T BIO-MED ENG, V59, P1109, DOI 10.1109/TBME.2012.2184759
   Wolterink JM, 2017, IEEE T MED IMAGING, V36, P2536, DOI 10.1109/TMI.2017.2708987
   Wu AB, 2013, IEEE T BIO-MED ENG, V60, P470, DOI 10.1109/TBME.2012.2199489
   Xu DG, 2012, OPT LETT, V37, P4209, DOI 10.1364/OL.37.004209
   Yang QS, 2018, IEEE T MED IMAGING, V37, P1348, DOI 10.1109/TMI.2018.2827462
   Zhang K, 2018, IEEE T IMAGE PROCESS, V27, P4608, DOI 10.1109/TIP.2018.2839891
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhao WD, 2017, IEEE T INSTRUM MEAS, V66, P2283, DOI 10.1109/TIM.2017.2700198
NR 51
TC 9
Z9 9
U1 18
U2 35
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0018-9456
EI 1557-9662
J9 IEEE T INSTRUM MEAS
JI IEEE Trans. Instrum. Meas.
PY 2021
VL 70
AR 5000712
DI 10.1109/TIM.2020.3017036
PG 12
WC Engineering, Electrical & Electronic; Instruments & Instrumentation
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Instruments & Instrumentation
GA OZ4PT
UT WOS:000594910700064
DA 2022-02-06
ER

PT J
AU Wang, Z
   Jing, JF
AF Wang, Zhen
   Jing, Junfeng
TI Pixel-Wise Fabric Defect Detection by CNNs Without Labeled Training Data
SO IEEE ACCESS
LA English
DT Article
DE Fabrics; Image segmentation; Feature extraction; Machine learning; Data
   models; Training; Convolution; Fabric defect; deep learning; image
   segmentation; defect detection; imbalanced dataset
AB Surface inspection is a necessary process of fabric quality control. However, it remains a challenging task owing to diverse types of defects, various patterns of fabric texture, and application requirements for detection speed. In this article, a lightweight deep learning model is therefore proposed to complete the segmentation of fabric defects. The input of the model is a fabric image, and the output is a binary image. Generally known, a deep learning model usually needs much data to update the parameters. Still, as an abnormal phenomenon, fabric defects are unpredictable, which makes it impossible to collect a large number of data. Distinct from other models, the proposed method is a supervised network but does not need manually labeled samples for training. A fake sample generator is designed to simulate the defect image, which only needs the defect-free fabric image. The proposed model is trained with fake samples and verified with real samples. The experimental results show that the model trained with false data is useful and achieves high segmentation accuracy on real fabric samples. Besides, a loss function is proposed to deal with the problem of imbalance between the number of background pixels and the number of defective pixels in the fabric image. Comprehensive experiments were performed on representative fabric samples to verify the segmentation accuracy and detection speed of this method.
C1 [Wang, Zhen; Jing, Junfeng] Xian Polytech Univ, Sch Elect & Informat, Xian 710048, Peoples R China.
C3 Xi'an Polytechnic University
RP Jing, JF (corresponding author), Xian Polytech Univ, Sch Elect & Informat, Xian 710048, Peoples R China.
EM jingjunfeng0718@sina.com
OI Wang, Zhen/0000-0002-3291-0768
FU Youth Innovation Team of Shaanxi Universities; Graduate Scientific
   Innovation Fund for Xi'an Polytechnic University [chx2020014]
FX This work was supported in part by the Youth Innovation Team of Shaanxi
   Universities, and in part by the Graduate Scientific Innovation Fund for
   Xi'an Polytechnic University under Grant chx2020014.
CR Ahn J, 2018, PROC CVPR IEEE, P4981, DOI 10.1109/CVPR.2018.00523
   Alguliyev RM, 2019, J IND INF INTEGR, V15, P1, DOI 10.1016/j.jii.2019.07.002
   Bousmalis K, 2017, PROC CVPR IEEE, P95, DOI 10.1109/CVPR.2017.18
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Herrero FJDLC, 2018, IEEE T IND APPL, V54, P4948, DOI 10.1109/TIA.2018.2832606
   Eldessouki M., 2018, APPL COMPUTER VISION, P61
   Gandelsman Y, 2019, PROC CVPR IEEE, P11018, DOI 10.1109/CVPR.2019.01128
   Hamdi Azhar A., 2017, 2017 Eighth International Conference on Intelligent Computing and Information Systems (ICICIS). Proceedings, P111, DOI 10.1109/INTELCIS.2017.8260041
   Hu GH, 2020, TEXT RES J, V90, P247, DOI 10.1177/0040517519862880
   Jing JF, 2019, COLOR TECHNOL, V135, P213, DOI 10.1111/cote.12394
   Jing JF, 2017, OPT ENG, V56, DOI 10.1117/1.OE.56.9.093104
   Johnson JM, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0192-5
   Li CL, 2018, IEEE ACCESS, V6, P27659, DOI 10.1109/ACCESS.2018.2841055
   Li J, 2019, IEEE T INTELL TRANSP, V20, P975, DOI 10.1109/TITS.2018.2843815
   Li M, 2019, COMPUT INTELL-US, V35, P517, DOI 10.1111/coin.12206
   Li YY, 2019, J TEXT I, V110, P487, DOI 10.1080/00405000.2018.1489951
   Li YD, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18093042
   Li YD, 2017, IEEE T AUTOM SCI ENG, V14, P1256, DOI 10.1109/TASE.2016.2520955
   Li YY, 2019, NEUROCOMPUTING, V329, P329, DOI 10.1016/j.neucom.2018.10.070
   Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI [10.1109/TPAMI.2018.2858826, 10.1109/ICCV.2017.324]
   Liu JH, 2020, IEEE T IMAGE PROCESS, V29, P3388, DOI 10.1109/TIP.2019.2959741
   Liu L, 2019, MULTIMED TOOLS APPL, V78, P12421, DOI 10.1007/s11042-018-6786-7
   Liu YH, 2019, NEUROCOMPUTING, V338, P139, DOI 10.1016/j.neucom.2019.01.036
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mei S, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18041064
   Ngan HYT, 2011, IMAGE VISION COMPUT, V29, P442, DOI 10.1016/j.imavis.2011.02.002
   Ouyang WB, 2019, IEEE ACCESS, V7, P70130, DOI 10.1109/ACCESS.2019.2913620
   Ren SQ, 2015, ADV NEUR IN, V28
   Tao X, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8091575
   Tsang CSC, 2016, PATTERN RECOGN, V51, P378, DOI 10.1016/j.patcog.2015.09.022
   Yapi D, 2018, IEEE T AUTOM SCI ENG, V15, P1014, DOI 10.1109/TASE.2017.2696748
   Zhang B, 2019, AUTEX RES J, V19, P257, DOI 10.1515/aut-2018-0040
   Zhang HH, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9173506
   Zhang KB, 2018, IEEE ACCESS, V6, P49170, DOI 10.1109/ACCESS.2018.2868059
NR 34
TC 3
Z9 3
U1 4
U2 13
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2020
VL 8
BP 161317
EP 161325
DI 10.1109/ACCESS.2020.3021189
PG 9
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA NP3LE
UT WOS:000570079800001
OA gold
DA 2022-02-06
ER

PT J
AU Shinohara, T
   Xiu, HY
   Matsuoka, M
AF Shinohara, Takayuki
   Xiu, Haoyi
   Matsuoka, Masashi
TI Point2Wave: 3-D Point Cloud to Waveform Translation Using a Conditional
   Generative Adversarial Network With Dual Discriminators
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE
   SENSING
LA English
DT Article
DE Three-dimensional displays; Laser radar; Atmospheric modeling;
   Superresolution; Deep learning; Generators; Feature extraction; Airborne
   LiDAR; conditional generative adversarial network; deep learning; full
   waveform LiDAR
ID LAND-COVER CLASSIFICATION; AIRBORNE LIDAR DATA; SUPERRESOLUTION;
   RECOGNITION
AB Since 2017, many deep learning methods for 3-D point clouds observed by airborne LiDAR (airborne 3-D point clouds) have been proposed. Moreover, not only a deep learning method for airborne 3-D point clouds but also a deep learning method for points and their waveforms observed by full-waveform LiDAR (airborne FW data) was proposed. We need to achieve highly accurate land cover classification by using airborne FW data, but open data often only have airborne 3-D point clouds available. Therefore, to improve the performance of land cover classification when using airborne 3-D point clouds published as open data, it is important to restore waveforms from airborne 3-D point clouds. In this article, we propose a deep learning model to translate an airborne 3-D point cloud to airborne FW data (called a point-to-waveform translation model, point2wave) using a conditional generative adversarial net (cGAN). Our point2wave is a cGAN pipeline consisting of a generator that translates the waveform corresponding to each point from the input airborne 3-D point cloud and discriminators that calculate the distance between the translated waveform and the ground truth waveform. Using a set of point clouds and waveforms dataset, we have experimented to translate points into the waveforms by point2wave. Experimental results showed that point2wave could translate waveforms from the airborne 3-D point cloud and the translated fake waveforms achieved nearly the same land cover classification performance as the real waveforms.
C1 [Shinohara, Takayuki] Tokyo Inst Technol, Dept Architecture & Bldg Engn, Yokohama, Kanagawa 2268502, Japan.
   [Xiu, Haoyi; Matsuoka, Masashi] Tokyo Inst Technol, Yokohama, Kanagawa 2268502, Japan.
C3 Tokyo Institute of Technology; Tokyo Institute of Technology
RP Shinohara, T (corresponding author), Tokyo Inst Technol, Dept Architecture & Bldg Engn, Yokohama, Kanagawa 2268502, Japan.
EM shinohara.t.af@m.titech.ac.jp; xiu.h.aa@m.titech.ac.jp;
   matsuoka.m.ab@m.titech.ac.jp
FU "Tokyo Metropolitan Resilience Project" of the Ministry of Education,
   Culture, Sports, Science and Technology (MEXT) of the Japanese
   Government; National Research Institute for Earth Science and Disaster
   Resilience (NIED)
FX This work was supported in part by "the Tokyo Metropolitan Resilience
   Project" of the Ministry of Education, Culture, Sports, Science and
   Technology (MEXT) of the Japanese Government and in part by the National
   Research Institute for Earth Science and Disaster Resilience (NIED).
CR Alexander C, 2010, ISPRS J PHOTOGRAMM, V65, P423, DOI 10.1016/j.isprsjprs.2010.05.002
   Nguyen A, 2013, PROCEEDINGS OF THE 2013 6TH IEEE CONFERENCE ON ROBOTICS, AUTOMATION AND MECHATRONICS (RAM), P225, DOI 10.1109/RAM.2013.6758588
   [Anonymous], 2020, Opentopography high-resolution topography data and tools
   [Anonymous], 2020, SHIZUOKA POINT CLOUD
   Anwar S, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3390462
   Awrangjeb M, 2014, IEEE J-STARS, V7, P4184, DOI 10.1109/JSTARS.2014.2318694
   Azadbakht M., 2015, P 9 INT S MOB MAPP T, P9
   Azadbakht M, 2018, INT J APPL EARTH OBS, V73, P277, DOI 10.1016/j.jag.2018.06.009
   Behley J, 2019, IEEE I CONF COMP VIS, P9296, DOI 10.1109/ICCV.2019.00939
   Bello SA, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12111729
   Chen D, 2012, INT J REMOTE SENS, V33, P6497, DOI 10.1080/01431161.2012.690083
   Chen YH, 2018, LECT NOTES COMPUT SC, V11070, P91, DOI 10.1007/978-3-030-00928-1_11
   Chen ZY, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17010150
   Chintala S, 2015, ARXIV151106434
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Dai A, 2017, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2017.261
   Demir I, 2018, IEEE COMPUT SOC CONF, P172, DOI 10.1109/CVPRW.2018.00031
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dinesh C, 2019, IEEE IMAGE PROC, P4390, DOI 10.1109/ICIP.2019.8803560
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Ducic V., 2006, P WORKSH 3D REM SENS, P211
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fieber KD, 2013, ISPRS J PHOTOGRAMM, V82, P63, DOI 10.1016/j.isprsjprs.2013.05.002
   FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251
   Garnett R., 2019, ADV NEURAL INFORM PR, P8024, DOI DOI 10.1038/S41591-021-01287-9
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Guo YL, 2021, IEEE T PATTERN ANAL, V43, P4338, DOI 10.1109/TPAMI.2020.3005434
   Hackel Timo, 2017, ARXIV170403847, DOI DOI 10.5194/ISPRS-ANNALS-IV-1-W1-91-2017
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Hofle B, 2012, ISPRS J PHOTOGRAMM, V67, P134, DOI 10.1016/j.isprsjprs.2011.12.003
   Ioffe S., 2015, ICML, P448
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jwa Y., 2009, INT ARCH PHOTOGRAMM, V38, P105
   Kim J, 2016, OCEANS 2016 MTS/IEEE MONTEREY, DOI 10.1109/OCEANS.2016.7761209
   Krizhevsky A., 2014, THE CIFAR 10 DATASET, V55
   Laefer D. F., 2017, 2015 AERIAL LASER PH
   Lai XD, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19143191
   LeCun Y, 1999, LECT NOTES COMPUT SC, V1681, P319, DOI 10.1007/3-540-46805-6_19
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Lei S, 2017, IEEE GEOSCI REMOTE S, V14, P1243, DOI 10.1109/LGRS.2017.2704122
   Li YH, 2019, IEEE ACCESS, V7, P25897, DOI 10.1109/ACCESS.2019.2900125
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu GP, 2019, PROC SPIE, V11187, DOI 10.1117/12.2536719
   Liu WP, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19194188
   Luo SZ, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8010003
   Ma L., 2017, ISPRS INT ARCH PHOTO, P263
   Mallet C, 2011, ISPRS J PHOTOGRAMM, V66, pS71, DOI 10.1016/j.isprsjprs.2011.09.008
   Mallet C, 2008, PHOTOGRAMM FERNERKUN, P337
   Nasrollahi K, 2014, MACH VISION APPL, V25, P1423, DOI 10.1007/s00138-014-0623-4
   Neuenschwander AL, 2009, J APPL REMOTE SENS, V3, DOI 10.1117/1.3229944
   Okyay U, 2019, EARTH-SCI REV, V198, DOI 10.1016/j.earscirev.2019.102929
   Osokin A, 2017, IEEE I CONF COMP VIS, P2252, DOI 10.1109/ICCV.2017.245
   Pan ZX, 2019, IEEE T GEOSCI REMOTE, V57, P7918, DOI 10.1109/TGRS.2019.2917427
   Perarnau Guim, 2016, ARXIV161106355
   Pereira MB, 2020, 2020 IEEE LATIN AMERICAN GRSS & ISPRS REMOTE SENSING CONFERENCE (LAGIRS), P6, DOI 10.1109/LAGIRS48042.2020.9165642
   Qi C.R., 2017, ADV NEURAL INFORM PR, P5099
   Rangnekar A., 2017, ARXIV171208690
   Reitberger J., 2009, P AM SOC PHOT REM SE, P1
   Shermeyer J, 2019, IEEE COMPUT SOC CONF, P1432, DOI 10.1109/CVPRW.2019.00184
   Shinohara Takayuki, 2020, SIGSPATIAL '20: Proceedings of the 28th International Conference on Advances in Geographic Information Systems, P640, DOI 10.1145/3397536.3422209
   Shinohara T, 2019, IEEE INT SYM MULTIM, P259, DOI 10.1109/ISM46123.2019.00060
   Takayuki S., 2020, SENSORS-BASEL, V20
   Tsagkatakis G, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19183929
   Viet Khanh Ha, 2018, Advances in Brain Inspired Cognitive Systems. 9th International Conference, BICS 2018. Proceedings: Lecture Notes in Artificial Intelligence (LNAI 10989), P106, DOI 10.1007/978-3-030-00563-4_11
   Vilaplana V, 2018, ARXIV PREPRINT ARXIV
   Wagner W, 2008, INT J REMOTE SENS, V29, P1433, DOI 10.1080/01431160701736398
   Wang CS, 2019, ISPRS J PHOTOGRAMM, V148, P75, DOI 10.1016/j.isprsjprs.2018.12.009
   Wang HZ, 2015, ISPRS J PHOTOGRAMM, V108, P1, DOI 10.1016/j.isprsjprs.2015.05.012
   Wang KP, 2019, FORESTS, V10, DOI 10.3390/f10010001
   Wang ZH, 2021, IEEE T PATTERN ANAL, V43, P3365, DOI 10.1109/TPAMI.2020.2982166
   Yan WY, 2015, REMOTE SENS ENVIRON, V158, P295, DOI 10.1016/j.rse.2014.11.001
   Yu LQ, 2018, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2018.00295
   Zhang DY, 2021, IEEE T GEOSCI REMOTE, V59, P5183, DOI 10.1109/TGRS.2020.3009918
   Zhang LP, 2016, IEEE GEOSC REM SEN M, V4, P22, DOI 10.1109/MGRS.2016.2540798
   Zhao LJ, 2019, PATTERN RECOGN, V88, P356, DOI 10.1016/j.patcog.2018.11.028
   Zhou M, 2016, INT ARCH PHOTOGRAMM, V41, P447, DOI 10.5194/isprsarchives-XLI-B3-447-2016
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
   Zorzi S, 2019, IEEE T GEOSCI REMOTE, V57, P8255, DOI 10.1109/TGRS.2019.2919472
NR 80
TC 0
Z9 0
U1 1
U2 1
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PY 2021
VL 14
BP 11630
EP 11642
DI 10.1109/JSTARS.2021.3124610
PG 13
WC Engineering, Electrical & Electronic; Geography, Physical; Remote
   Sensing; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Physical Geography; Remote Sensing; Imaging Science &
   Photographic Technology
GA XC4RN
UT WOS:000722001900010
OA gold
DA 2022-02-06
ER

PT J
AU Meel, P
   Vishwakarma, DK
AF Meel, Priyanka
   Vishwakarma, Dinesh Kumar
TI Fake news, rumor, information pollution in social media and web: A
   contemporary survey of state-of-the-arts, challenges and opportunities
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Review
DE Clickbait; Deep learning; Fraudulent Content; Information Pollution;
   Machine learning; Opinion Spam; Online Social Networks; Rumour
   Propagation
ID SPREADING MODEL; NETWORKS; PROPAGATION; FRAMEWORK; MECHANISM; INTERNET;
   GRAPH
AB Internet and social media have become a widespread, large scale and easy to use platform for real-time information dissemination. It has become an open stage for discussion, ideology expression, knowledge dissemination, emotions and sentiment sharing. This platform is gaining tremendous attraction and a huge user base from all sections and age groups of society. The matter of concern is that up to what extent the contents that are circulating among all these platforms every second changing the mindset, perceptions and lives of billions of people are verified, authenticated and up to the standards. This paper puts forward a holistic view of how the information is being weaponized to fulfil the malicious motives and forcefully making a biased user perception about a person, event or firm. Further, a taxonomy is provided for the classification of malicious information content at different stages and prevalent technologies to cope up with this issue form origin, propagation, detection and containment stages. We also put forward a research gap and possible future research directions so that the web information content could be more reliable and safer to use for decision making as well as for knowledge sharing. (C) 2019 Elsevier Ltd. All rights reserved.
C1 [Meel, Priyanka; Vishwakarma, Dinesh Kumar] Delhi Technol Univ, Dept Informat Technol, Biometr Res Lab, New Delhi 110042, India.
C3 Delhi Technological University
RP Vishwakarma, DK (corresponding author), Delhi Technol Univ, Dept Informat Technol, Biometr Res Lab, New Delhi 110042, India.
EM priyankameel86@gmail.com; dinesh@dtu.ac.in
RI Vishwakarma, Dinesh/L-3815-2018
OI Vishwakarma, Dinesh/0000-0002-1026-0047; MEEL,
   PRIYANKA/0000-0002-1195-1712
CR Adali S., 2017, 11 INT AAAI C WEB SO, P759
   Ahmed Hadeer, 2018, Security and Privacy, V1, DOI 10.1002/spy2.9
   Ajao Oluwaseun, 2018, P 9 INT C SOC MED SO, DOI 10.1145/3217804.3217917
   Alamri Atif, 2015, WEB APPL NETW WSWAN, P1, DOI DOI 10.1145/2816839.2816908.17
   Aldwairi M, 2018, PROCEDIA COMPUT SCI, V141, P215, DOI 10.1016/j.procs.2018.10.171
   Alexandrov A, 2012, PROC VLDB ENDOW, V5, P1890, DOI 10.14778/2367502.2367530
   Alrubaian M, 2018, IEEE T DEPEND SECURE, V15, P661, DOI 10.1109/TDSC.2016.2602338
   AlRubaian M, 2016, PROCEEDINGS OF THE 2016 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING ASONAM 2016, P1406, DOI 10.1109/ASONAM.2016.7752431
   AlRubaian M, 2015, PROCEEDINGS OF THE 2015 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2015), P1434, DOI 10.1145/2808797.2810065
   Ananth S., 2019, INT J INNOVATIVE RES, V7, P49, DOI [10.15680/IJIRCCE.2019, DOI 10.15680/IJIRCCE.2019]
   [Anonymous], 2019, DO PARACETAMOL TABLE
   [Anonymous], 2019, GLOBAL SOCIAL MEDIA
   [Anonymous], 2018, DID 600 MURDERS TAKE
   [Anonymous], 2019, D TRUMP ENDS SCH SHO
   [Anonymous], 2017, WAS H CLINTON PHOTOG
   [Anonymous], 2007, FACT CHECKING US POL
   [Anonymous], 2011, CHINESE SALT BUYING
   [Anonymous], 2019, TRUTH FICTION FACT C
   [Anonymous], 2018, WAS K NATH DRIVER R
   [Anonymous], 2015, SNAPLYTICS
   [Anonymous], 2005, GOOGLE ANAL
   Aphiwongsophon S, 2018, 2018 15TH INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING/ELECTRONICS, COMPUTER, TELECOMMUNICATIONS AND INFORMATION TECHNOLOGY (ECTI-CON), P528, DOI 10.1109/ECTICon.2018.8620051
   Bagan G, 2017, IEEE T KNOWL DATA EN, V29, P856, DOI 10.1109/TKDE.2016.2633993
   Belov YA, 2017, AUTOM CONTROL COMPUT, V51, P678, DOI 10.3103/S0146411617070264
   Bollen J, 2011, J COMPUT SCI-NETH, V2, P1, DOI 10.1016/j.jocs.2010.12.007
   Borges L, 2019, ACM J DATA INF QUAL, V11, DOI 10.1145/3287763
   Bovet A, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-018-07761-2
   Bronstein MV, 2019, J APPL RES MEM COGN, V8, P108, DOI 10.1016/j.jarmac.2018.09.005
   Buntain C, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON SMART CLOUD (SMARTCLOUD), P208, DOI 10.1109/SmartCloud.2017.40
   Cao N, 2012, IEEE T VIS COMPUT GR, V18, P2649, DOI 10.1109/TVCG.2012.291
   Castillo C., 2011, WWW, P675
   Cha S, 2016, INT CONF CONTR AUTO, P1, DOI 10.1109/ICCAIS.2016.7822425
   Chakrabarti D, 2004, SIAM PROC S, P442
   Chen Jianhong, 2017, [Journal of Systems Science and Information, 系统科学与信息学报], V5, P571
   Chen SM, 2017, COMPUT GRAPH FORUM, V36, P563, DOI 10.1111/cgf.13211
   Chen XQ, 2019, PROC INT CONF DATA, P770, DOI 10.1109/ICDE.2019.00074
   Chen Y., 2017, P 11 INT WORKSH SEM, P465
   Cheng JJ, 2013, EUR PHYS J B, V86, DOI 10.1140/epjb/e2012-30483-5
   Chi Y, 2009, IEEE T MULTIMEDIA, V11, P372, DOI 10.1109/TMM.2009.2012912
   Choi J., 2017, IEEE C COMP COMM INF, DOI [10.1109/INFOCOM.2017.8057194., DOI 10.1109/INFOCOM.2017.8057194]
   Chuan G., 2019, ARXIV190301728
   Conforti C., 2018, P 1 WORKSH FACT EXTR, P40
   Corchia L, 2019, 2019 IEEE INTERNATIONAL WORKSHOP ON METROLOGY FOR INDUSTRY 4.0 AND INTERNET OF THINGS (METROIND4.0&IOT), P1, DOI 10.1109/METROI4.2019.8792919
   Csanyi G, 2004, PHYS REV E, V69, DOI 10.1103/PhysRevE.69.036131
   Davis R, 2017, FRENCH J BRIT STUDIE, P1, DOI DOI 10.4000/RFCB.1364
   Del Vicario M, 2019, ACM T WEB, V13, DOI 10.1145/3316809
   Dhar J, 2016, SOC NETW ANAL MIN, V6, DOI 10.1007/s13278-016-0366-5
   Diakopoulos N, 2010, 2010 Proceedings of IEEE Symposium on Visual Analytics Science and Technology (VAST 2010), P115, DOI 10.1109/VAST.2010.5652922
   Dong M, 2019, PSYCHOL MED, V49, P1691, DOI [10.1017/S0033291718002301, 10.1016/j.patrec.2018.07.013]
   Dong S, 2017, COMMUN THEOR PHYS, V68, P545, DOI 10.1088/0253-6102/68/4/545
   Edunov S., 2016, ARXIV161000664
   Egele M, 2017, IEEE T DEPEND SECURE, V14, P447, DOI 10.1109/TDSC.2015.2479616
   Eimurrigi E, 2017, 2017 SEVENTH INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING TECHNOLOGY (INTECH 2017), P107, DOI 10.1109/INTECH.2017.8102442
   Elmurngi E., 2017, 6 INT C DAT AN, P65
   Elmurngi E., 2018, INT J ADV SYSTEMS ME, V11, P196
   Fairbanks J., 2018, MIS2
   Finn S., 2014, ARXIV14113550
   Fontanarava J, 2017, 2017 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE (WI 2017), P863, DOI 10.1145/3106426.3106464
   Garcia Lozano M., 2017, P 2017 INT WORKSH SE, P481
   Ghaisani A. P., 2017, 2017 IEEE 2 INT C IN, P1
   Gilda S, 2017, IEEE ST CONF RES DEV, P110, DOI 10.1109/SCORED.2017.8305411
   Girgis S, 2018, PROCEEDINGS OF 2018 13TH INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING AND SYSTEMS (ICCES), P93, DOI 10.1109/ICCES.2018.8639198
   Gravanis G, 2019, EXPERT SYST APPL, V128, P201, DOI 10.1016/j.eswa.2019.03.036
   Gu J, 2008, EUR PHYS J B, V62, P247, DOI 10.1140/epjb/e2008-00139-4
   Gupta A, 2014, LECT NOTES COMPUT SC, V8851, P228, DOI 10.1007/978-3-319-13734-6_16
   Hai Zhen, 2016, P 2016 C EMP METH NA, P1817
   Hamann M., 2018, J EXPT ALGORITHMICS, V23
   Hamidian S., 2015, P 5 INT C SOC MED TE, P71
   Han QY, 2017, 2017 17TH IEEE INTERNATIONAL CONFERENCE ON COMMUNICATION TECHNOLOGY (ICCT 2017), P1347, DOI 10.1109/ICCT.2017.8359853
   Han S, 2014, PHYSICA A, V394, P99, DOI 10.1016/j.physa.2013.10.003
   Hassan N, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1803, DOI 10.1145/3097983.3098131
   Indu V, 2019, J NETW COMPUT APPL, V125, P28, DOI 10.1016/j.jnca.2018.10.003
   Ishida Y, 2018, PROCEDIA COMPUT SCI, V126, P2228, DOI 10.1016/j.procs.2018.07.226
   Jin ZW, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P795, DOI 10.1145/3123266.3123454
   Jin ZW, 2017, IEEE T MULTIMEDIA, V19, P598, DOI 10.1109/TMM.2016.2617078
   Karimi H., 2018, P 27 INT C COMP LING, P1546
   Khattar D, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P2915, DOI 10.1145/3308558.3313552
   Kiran L., 2014, SAND201419132C SAND
   Kolda TG, 2014, SIAM J SCI COMPUT, V36, pC424, DOI 10.1137/130914218
   Korea North, 2018, N KOREA OPENING ITS
   Kumar KPK, 2014, HUM-CENT COMPUT INFO, V4, DOI 10.1186/s13673-014-0014-x
   Kumar S., 2018, ARXIV180408559
   Kwon S, 2013, IEEE DATA MINING, P1103, DOI 10.1109/ICDM.2013.61
   Lee C, 2016, INT C PATT RECOG, P745, DOI 10.1109/ICPR.2016.7899724
   Li T, 2015, INT C ELECTR MACH SY, P1752, DOI 10.1109/ICEMS.2015.7385324
   Li YY, 2015, IEEE INT CONF ADV LE, P405, DOI 10.1109/ICALT.2015.100
   Liu X., 2015, P 24 ACM INT C INF K, P1867, DOI DOI 10.1145/2806416.2806651
   Liu Y, 2018, THIRTY-SECOND AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTIETH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / EIGHTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P354
   Liu YX, 2016, IEEE C EVOL COMPUTAT, P508, DOI 10.1109/CEC.2016.7743836
   Lorek K, 2015, COMPUT SCI-AGH, V16, P157, DOI 10.7494/csci.2015.16.2.157
   Louni A, 2018, IEEE T COMPUT SOC SY, V5, P335, DOI 10.1109/TCSS.2018.2801310
   Lukasik M, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P393
   Luo WQ, 2013, IEEE T SIGNAL PROCES, V61, P2850, DOI 10.1109/TSP.2013.2256902
   Ma J., 2018, COMP WEB C 2018 WEB, P585, DOI DOI 10.1145/3184558.3188729
   Ma J, 2016, INT CONF ADV COMMUN, P822, DOI 10.1109/ICACT.2016.7423574
   Ma J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1980
   Ma J, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P708, DOI 10.18653/v1/P17-1066
   Martens D, 2019, EMPIR SOFTW ENG, V24, P3316, DOI 10.1007/s10664-019-09706-9
   Mason, 2013, ICONFERENCE 2014, DOI DOI 10.9776/14308
   Masood R., 2018, 10 INT JOINT C KNOWL, P128, DOI [10.5220/0006898801280135, DOI 10.5220/0006898801280135]
   Mendoza Marcelo, 2010, P 1 WORKSH SOC MED A, DOI DOI 10.1145/1964858.1964869
   Mexico, 2015, MEXICO TWITTER TERRO
   Mitra T., 2015, ICWSM, P258
   Miyabe M, 2014, INT J WEB INF SYST, V10, P394, DOI 10.1108/IJWIS-04-2014-0015
   Mohseni S., 2019, ARXIV190403016
   Mondal T, 2018, INFORM SYST FRONT, V20, P961, DOI 10.1007/s10796-018-9837-8
   Nekovee M, 2007, PHYSICA A, V374, P457, DOI 10.1016/j.physa.2006.07.017
   Nguyen NP, 2012, PROCEEDINGS OF THE 3RD ANNUAL ACM WEB SCIENCE CONFERENCE, 2012, P213
   Nielsen, 2019, REUTERS I DIGITAL NE, DOI [10.2139/ssrn.2619576, DOI 10.2139/SSRN.2619576]
   Nunes M., 2013, 2013 8 IB C INF SYST, P1
   O'Brien K, 2019, PROCEEDINGS OF THE 52ND ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES, P2235
   Pandian V. A., 2018, INT J PURE APPL MATH, V118, P3787
   Pe rez-Rosas V, 2017, ARXIV170807104
   Peng L., 2018, ANN BIOINSP C MANCH
   Poddar L, 2018, PROC INT C TOOLS ART, P65, DOI 10.1109/ICTAI.2018.00021
   Prat-Perez A., 2017, GRADES SIGMOD, P1, DOI DOI 10.1145/3078447.3078453
   Qian Feng, 2018, IJCAI, P3834
   RAKESH V, 2019, EMERGING RES CHALLEN, P438, DOI DOI 10.1145/3289600.3290963
   Rasool T, 2019, INT CONF COMPUT AUTO, P73, DOI 10.1145/3313991.3314008
   Rath B., 2017, P 2017 IEEE ACM INT, P179
   Reilly I, 2018, J AM CULTURE, V41, P139, DOI 10.1111/jacc.12834
   Resnick P., 2014, COMP JOURN C NEW YOR, P10121
   Roozenbeek J, 2019, J RISK RES, V22, P570, DOI 10.1080/13669877.2018.1443491
   Roy A., 2018, ARXIV181104670
   Ruchansky N, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P797, DOI 10.1145/3132847.3132877
   Sadiq S, 2019, 2019 2ND IEEE CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2019), P437, DOI 10.1109/MIPR.2019.00088
   Sahana VP, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTING AND NETWORK COMMUNICATIONS (COCONET), P607, DOI 10.1109/CoCoNet.2015.7411251
   SANTIA G., 2018, P 12 INT AAAI C WEB
   Shah D, 2011, IEEE T INFORM THEORY, V57, P5163, DOI 10.1109/TIT.2011.2158885
   Shao C, 2018, PLOS ONE, V13, P1, DOI DOI 10.1371/J0URNAL.P0NE.0196087
   Sharma K, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3305260
   Shelke Sushila, 2019, Online Social Networks and Media, V9, P30, DOI 10.1016/j.osnem.2018.12.001
   Shu K., 2019, 33 AAAI C ART INT HA
   Shu K, 2019, PROCEEDINGS OF THE TWELFTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'19), P312, DOI 10.1145/3289600.3290994
   Shu K, 2019, COMPUT MATH ORGAN TH, V25, P60, DOI 10.1007/s10588-018-09280-3
   Shu K, 2018, IEEE DATA MINING, P467, DOI 10.1109/ICDM.2018.00062
   Shu K, 2018, IEEE 1ST CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2018), P430, DOI 10.1109/MIPR.2018.00092
   Singhania S, 2017, LECT NOTES COMPUT SC, V10635, P572, DOI 10.1007/978-3-319-70096-0_59
   Starbird K, 2017, ICWSM, P230
   Tacchini E., 2017, ARXIV170407506, DOI DOI 10.1257/JEP.31.2.211
   Thota Aswini., 2018, SMU DATA SCI REV, V1, P10
   Tschiatschek S, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), P517, DOI 10.1145/3184558.3188722
   Turenne N, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0189080
   Vaghela D. B., 2018, INT J ADV ENG RES DE, V5, P924
   Varol O, 2017, EPJ DATA SCI, V6, DOI 10.1140/epjds/s13688-017-0111-y
   Vishwakarma DK, 2019, COGN SYST RES, V58, P217, DOI 10.1016/j.cogsys.2019.07.004
   Viviani M, 2017, WIRES DATA MIN KNOWL, V7, DOI 10.1002/widm.1209
   Vosoughi S, 2018, SCIENCE, V359, P1146, DOI 10.1126/science.aap9559
   Vosoughi S, 2017, ACM T KNOWL DISCOV D, V11, DOI 10.1145/3070644
   Wang, 2018, ARXIV180901286
   Wang Fang, 2006, Phys Rev E Stat Nonlin Soft Matter Phys, V73, P036123, DOI 10.1103/PhysRevE.73.036123
   Wang WY, 2017, ARXIV170500648
   Wen S, 2014, IEEE T PARALL DISTR, V25, P3306, DOI 10.1109/TPDS.2013.2297115
   Wu K, 2015, PROC INT CONF DATA, P651, DOI 10.1109/ICDE.2015.7113322
   Wu L, 2018, WSDM'18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P637, DOI 10.1145/3159652.3159677
   Wu YK, 2018, IEEE ACCESS, V6, P62612, DOI 10.1109/ACCESS.2018.2876394
   Xu A., 2019, ARXIV190400788
   Yang Y., 2018, ARXIV180600749
   Yang Z., 2016, NAACL HLT, P1480
   Yu, 2018, ARXIV180508751
   Zannettou S, 2018, ARXIV180403461
   Zhang Q, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P2333, DOI 10.1145/3308558.3313718
   Zhang XZ, 2016, PHYSICA A, V442, P100, DOI 10.1016/j.physa.2015.09.017
   Zhang ZL, 2015, HEALTH INFO LIBR J, V32, P195, DOI 10.1111/hir.12115
   Zhao J, 2014, IEEE T VIS COMPUT GR, V20, P1773, DOI 10.1109/TVCG.2014.2346922
   Zhao LJ, 2012, PHYSICA A, V391, P2444, DOI 10.1016/j.physa.2011.12.008
   Zhao LJ, 2011, PHYSICA A, V390, P2619, DOI 10.1016/j.physa.2011.03.010
   Zhou X., 2018, ARXIV181200315
   Zhou XY, 2019, PROCEEDINGS OF THE TWELFTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'19), P836, DOI 10.1145/3289600.3291382
   Zhu K, 2016, IEEE ACM T NETWORK, V24, P408, DOI 10.1109/TNET.2014.2364972
   Zubiaga A, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3161603
NR 171
TC 58
Z9 58
U1 22
U2 205
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD SEP 1
PY 2020
VL 153
AR 112986
DI 10.1016/j.eswa.2019.112986
PG 26
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic; Operations Research & Management Science
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Operations Research & Management Science
GA LO3FD
UT WOS:000533513600001
DA 2022-02-06
ER

PT J
AU Shah, N
AF Shah, Nishant
TI (Dis)information Blackouts: Politics and Practices of Internet Shutdowns
SO INTERNATIONAL JOURNAL OF COMMUNICATION
LA English
DT Article
DE disinformation; Internet blackouts; freedom of speech; Internet
   governance
AB Various emerging digital information societies like India exercise Internet shutdowns and information blackouts regularly as a way of dealing with different kinds of crises. These blackouts are justified as countering the misinformation cycles that amplify (dis)information that we have come to characterize as "fake news." An immersive ethnography during an Internet shutdowns in India revealed these blackouts are neither absolute nor foolproof because blackouts have multiple back doors that allow different kinds of information to flow through networked and social negotiations. I argue that Internet shutdowns need to be seen as specific exercises of geopolitical and sovereign power and read as performative because they are both inefficient and ineffective in achieving information blackouts. Making a distinction between misinformation and disinformation, I show how these Internet shutdowns do not stop the circulation of fake news but, as infrastructural tools, they enable state (dis)information and propaganda to spread without resistance and thus become potent tools in curbing protests and rightful critique of authoritarian practices.
C1 [Shah, Nishant] ArtEZ Univ Arts, Zwolle, Netherlands.
RP Shah, N (corresponding author), ArtEZ Univ Arts, Zwolle, Netherlands.
EM itsnishant@gmail.com
CR Abraham S., 2019, BUSINESS STANDARD
   [Anonymous], 2015, HINDU
   Bashir S., 2019, TIME
   Brown S., 2019, POLITICO
   Burgess M., 2018, FIGHT FAKE NEWS WHAT
   Chan A. S., 2014, NETWORKING PERIPHERI
   Chatterjee R., 2016, HUFFINGTON POST
   Choudhary M, 2019, DIGITAL INDIA IS OFF
   Chun WHK, 2016, UPDATING TO REMAIN THE SAME: HABITUAL NEW MEDIA, P1
   Express News Service, 2015, INDIAN EXPRESS
   Galloway A, 2004, PROTOCOL
   Ganai N, 2020, OUTLOOK INDIA
   Hafeez S, 2016, INDIAN EXPRESS
   Hoyng R, 2017, INT J COMMUN-US, V11, P4219
   HT Correspondent, 2020, HINDUSTAN TIMES
   Indo-Asian News Service, 2018, BUSINESS STANDARD
   International Telecommunications Union, 2002, CONST INT TEL UN
   Jalan T., 2020, HOOGHLY DISTRICT MAG
   Jaleel M., 2019, INDIAN EXPRESS
   Kanwal R, 2016, INDIA TODAY
   Keeling K, 2014, CINEMA J, V53, P152, DOI 10.1353/cj.2014.0004
   Lakshmanan R, 2019, HONG KONG PROTESTORS
   Langa M, 2015, HINDU
   Manzano M., 1996, EXTENSIONS 1 ORDER L
   Mozilla Foundation, 2019, INT HLTH REP 2019
   Netblocks, 2019, EV INT SHUTD ASS IND
   ONeil C., 2016, WEAPONS MATH DESTRUC
   Open Net Initiative, 2007, PULL PLUG TECHN REV
   Pariser, 2011, FILTER BUBBLE WHAT I
   Prasad R, 2018, MEDIA CULT SOC, V40, P415, DOI 10.1177/0163443717736117
   Press Trust of India, 2015, AHMEDABAD MIRROR
   Press Trust of India, 2019, FINANCIAL EXPRESS
   Rajadhyaksha A, 2011, LAST CULTURAL MILE I
   Reuters, 2018, HINDUSTAN TIMES
   Roth K, 2020, ANN REV HUMAN RIGHTS
   Schultz K., 2020, NEW YORK TIMES
   Shaikh S, 2015, TIMES INDIA
   Singh M, 2019, INDIA GETS MORE AGGR
   Sircar S., 2019, WHY LONG INTERNET SH
   Software Freedom Law Centre, 2019, INT SHUTD
   Sundaram R, 2009, ASIAS TRANSFORM, P1
   Thiagarajan K, 2020, NATL PUBLIC RADIO
   van Dijck J, 2013, MEDIA COMMUN, V1, P2, DOI 10.17645/mac.v1i1.70
   Watts D., 2016, SMALL IS WORLD REALL
NR 44
TC 0
Z9 0
U1 0
U2 0
PU USC ANNENBERG PRESS
PI LOS ANGELES
PA UNIV SOUTHERN CALIFORNIA, KERCKHOFF HALL, 734 W ADAMS BLVD, MC7725, LOS
   ANGELES, CA 90089 USA
SN 1932-8036
J9 INT J COMMUN-US
JI Int. J. Commun.
PY 2021
VL 15
BP 2693
EP 2709
PG 17
WC Communication
WE Social Science Citation Index (SSCI)
SC Communication
GA XO1HN
UT WOS:000729944300024
DA 2022-02-06
ER

PT J
AU Zhu, L
   Chen, YS
   Ghamisi, P
   Benediktsson, JA
AF Zhu, Lin
   Chen, Yushi
   Ghamisi, Pedram
   Benediktsson, Jon Atli
TI Generative Adversarial Networks for Hyperspectral Image Classification
SO IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING
LA English
DT Article
DE Convolutional neural network (CNN); deep learning; generative
   adversarial network (GAN); hyperspectral image (HSI) classification
ID SPECTRAL-SPATIAL CLASSIFICATION; BELIEF NETWORKS; NEURAL-NETWORKS; DEEP;
   REPRESENTATION
AB A generative adversarial network (GAN) usually contains a generative network and a discriminative network in competition with each other. The GAN has shown its capability in a variety of applications. In this paper, the usefulness and effectiveness of GAN for classification of hyperspectral images (HSIs) are explored for the first time. In the proposed GAN, a convolutional neural network (CNN) is designed to discriminate the inputs and another CNN is used to generate so-called fake inputs. The aforementioned CNNs are trained together: the generative CNN tries to generate fake inputs that are as real as possible, and the discriminative CNN tries to classify the real and fake inputs. This kind of adversarial training improves the generalization capability of the discriminative CNN, which is really important when the training samples are limited. Specifically, we propose two schemes: 1) a well-designed 1D-GAN as a spectral classifier and 2) a robust 3D-GAN as a spectral-spatial classifier. Furthermore, the generated adversarial samples are used with real training samples to fine-tune the discriminative CNN, which improves the final classification performance. The proposed classifiers are carried out on three widely used hyperspectral data sets: Salinas, Indiana Pines, and Kennedy Space Center. The obtained results reveal that the proposed models provide competitive results compared to the state-of-the-art methods. In addition, the proposed GANs open new opportunities in the remote sensing community for the challenging task of HSI classification and also reveal the huge potential of GAN-based methods for the analysis of such complex and inherently nonlinear data.
C1 [Zhu, Lin; Chen, Yushi] Harbin Inst Technol, Sch Elect & Informat Engn, Harbin 150001, Heilongjiang, Peoples R China.
   [Ghamisi, Pedram] German Aerosp Ctr DLR, Remote Sensing Technol Inst IMF, D-82234 Wessling, Germany.
   [Ghamisi, Pedram] Tech Univ Munich, Signal Proc Earth Observat, D-80333 Munich, Germany.
   [Benediktsson, Jon Atli] Univ Iceland, Fac Elect & Comp Engn, IS-107 Reykjavik, Iceland.
C3 Harbin Institute of Technology; Helmholtz Association; German Aerospace
   Centre (DLR); Technical University of Munich; University of Iceland
RP Chen, YS (corresponding author), Harbin Inst Technol, Sch Elect & Informat Engn, Harbin 150001, Heilongjiang, Peoples R China.
EM 17s105139@stu.hit.edu.cn; chenyushi@hit.edu.cn; p.ghamisi@gmail.com;
   benedikt@hi.is
RI Benediktsson, Jon Atli/F-2861-2010; Ghamisi, Pedram/ABD-5419-2021
OI Benediktsson, Jon Atli/0000-0003-0621-9647; Chen,
   Yushi/0000-0003-2421-0996
FU Natural Science Foundation of ChinaNational Natural Science Foundation
   of China (NSFC) [61771171]; National Natural Science Foundation of Key
   International Cooperation [61720106002]
FX This work was supported in part by the Natural Science Foundation of
   China under Grant 61771171 and in part by the National Natural Science
   Foundation of Key International Cooperation under Grant 61720106002.
CR Bartholomew D. J., 2011, STRUCT EQU MODELING, V18, P686
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Chang C.-I, 2003, HYPERSPECTRAL IMAGIN
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen Y., 2015, IEEE J-STARS, V8, P1, DOI DOI 10.4137/BCICI.S31353
   Chen YS, 2017, IEEE GEOSCI REMOTE S, V14, P2355, DOI 10.1109/LGRS.2017.2764915
   Chen YS, 2016, IEEE T GEOSCI REMOTE, V54, P6232, DOI 10.1109/TGRS.2016.2584107
   Chen YS, 2014, IEEE J-STARS, V7, P2094, DOI 10.1109/JSTARS.2014.2329330
   Chintala S., 2017, ARXIV170107875
   Creswell A, 2018, IEEE SIGNAL PROC MAG, V35, P53, DOI 10.1109/MSP.2017.2765202
   Fauvel M, 2013, P IEEE, V101, P652, DOI 10.1109/JPROC.2012.2197589
   Fauvel M, 2008, IEEE T GEOSCI REMOTE, V46, P3804, DOI 10.1109/TGRS.2008.922034
   Ghamisi P, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2016.2616418
   Ghamisi P, 2015, IEEE T GEOSCI REMOTE, V53, P2335, DOI 10.1109/TGRS.2014.2358934
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Gu YF, 2017, IEEE T GEOSCI REMOTE, V55, P6547, DOI 10.1109/TGRS.2017.2729882
   Gualtieri JA, 1999, P SOC PHOTO-OPT INS, V3584, P221, DOI 10.1117/12.339824
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Hu W, 2015, J SENSORS, V2015, DOI 10.1155/2015/258619
   HUGHES GF, 1968, IEEE T INFORM THEORY, V14, P55, DOI 10.1109/TIT.1968.1054102
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kruger N, 2013, IEEE T PATTERN ANAL, V35, P1847, DOI 10.1109/TPAMI.2012.272
   Le Roux N, 2010, NEURAL COMPUT, V22, P2192, DOI 10.1162/neco.2010.08-09-1081
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li W, 2017, IEEE T GEOSCI REMOTE, V55, P844, DOI 10.1109/TGRS.2016.2616355
   Li W, 2012, IEEE T GEOSCI REMOTE, V50, P1185, DOI 10.1109/TGRS.2011.2165957
   Li XW, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9030187
   LIANG H, 2016, NEURAL NETWORK FEATU, V0008, P00099
   Licciardi G, 2012, IEEE GEOSCI REMOTE S, V9, P447, DOI 10.1109/LGRS.2011.2172185
   Maas A. L., 2013, P ICML, V30, P1
   Melgani F, 2004, IEEE T GEOSCI REMOTE, V42, P1778, DOI 10.1109/TGRS.2004.831865
   Mirza M, 2014, ARXIV PREPRINT ARXIV
   Mou LC, 2017, IEEE T GEOSCI REMOTE, V55, P3639, DOI 10.1109/TGRS.2016.2636241
   Odena A., 2016, SEMISUPERVISED LEARN
   Odena A., 2016, CONDITIONAL IMAGE SY
   Pfau D., 2017, CONNECTING GENERATIV
   Radford A, 2016, PROC 4 INT C LEARN R
   Singhal V, 2017, IEEE T GEOSCI REMOTE, V55, P5274, DOI 10.1109/TGRS.2017.2704590
   Sutskever I, 2008, NEURAL COMPUT, V20, P2629, DOI 10.1162/neco.2008.12-07-661
   Tu TM, 2000, OPT ENG, V39, P897, DOI 10.1117/1.602461
   Wang Q, 2017, IEEE GEOSCI REMOTE S, V14, P2077, DOI 10.1109/LGRS.2017.2751559
   Weston J, 1998, CSDTR9804
   Yang HH, 2007, SPECTROSC SPECT ANAL, V27, P1955
   Yao KS, 2013, INTERSPEECH, P2523
   Yuan Y, 2016, IEEE T CYBERNETICS, V46, P2966, DOI 10.1109/TCYB.2015.2484324
   Yue J, 2015, REMOTE SENS LETT, V6, P468, DOI 10.1080/2150704X.2015.1047045
   Zhang LP, 2016, IEEE GEOSC REM SEN M, V4, P22, DOI 10.1109/MGRS.2016.2540798
   Zhao WZ, 2016, IEEE T GEOSCI REMOTE, V54, P4544, DOI 10.1109/TGRS.2016.2543748
   Zhong P, 2017, IEEE T GEOSCI REMOTE, V55, P3516, DOI 10.1109/TGRS.2017.2675902
   Zhu J., 2017, IEEE INT C COMP VIS, P2242
NR 51
TC 224
Z9 240
U1 60
U2 333
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0196-2892
EI 1558-0644
J9 IEEE T GEOSCI REMOTE
JI IEEE Trans. Geosci. Remote Sensing
PD SEP
PY 2018
VL 56
IS 9
BP 5046
EP 5063
DI 10.1109/TGRS.2018.2805286
PG 18
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA GS0BK
UT WOS:000443147600006
OA Green Accepted
DA 2022-02-06
ER

PT J
AU Meng, DL
   Wu, BY
   Wang, ZG
   Zhu, ZL
AF Meng, Delin
   Wu, Bangyu
   Wang, Zhiguo
   Zhu, Zhaolin
TI Seismic Impedance Inversion Using Conditional Generative Adversarial
   Network
SO IEEE GEOSCIENCE AND REMOTE SENSING LETTERS
LA English
DT Article
DE Impedance; Generators; Training; Data models; Generative adversarial
   networks; Linear programming; Convolution; Conditional generative
   adversarial network (cGAN); convolutional neural network (CNN); deep
   learning; seismic impedance inversion
AB Deep-learning methods, such as convolutional neural networks (CNNs), have been successfully applied to seismic impedance inversion in recent years. Compared with traditional geophysical inversion, deep-learning inversion can give inversion results with higher resolution. In this letter, we further improve the performance of deep-learning inversion and propose a seismic impedance inversion method based on conditional generative adversarial network (cGAN). In the proposed method, a generator learns to predict seismic impedance from seismic data, and a discriminator learns to distinguish between fake and real impedance. We mix the cGAN objective with mean square error (MSE) loss to bring in more information for model training. Besides, a CNN-based seismic forward model is trained to introduce the constraint of unlabeled data in the training of cGAN. Tests on Marmousi2 model and overthrust model show that the proposed method can obtain more accurate impedance and have better robustness against random noise than CNN method.
C1 [Meng, Delin] SINOPEC Petr Explorat & Prod Res Inst, State Key Lab Shale Oil & Gas Enrichment Mech & E, Beijing 100083, Peoples R China.
   [Meng, Delin] SINOPEC Petr Explorat & Prod Res Inst, Sinopec Key Lab Seism Elast Wave Technol, Beijing 100083, Peoples R China.
   [Meng, Delin; Wu, Bangyu; Wang, Zhiguo] Xi An Jiao Tong Univ, Sch Math & Stat, Xian 710049, Peoples R China.
   [Zhu, Zhaolin] Hainan Inst Zhejiang Univ, Sanya 572000, Hainan, Peoples R China.
C3 Sinopec; Sinopec; Xi'an Jiaotong University
RP Wu, BY (corresponding author), Xi An Jiao Tong Univ, Sch Math & Stat, Xian 710049, Peoples R China.
EM mengdelin@stu.xjtu.edu.cn; bangyuwu@xjtu.edu.cn; emailwzg@gmail.com;
   zhu.zhaolin@outlook.com
RI Wang, Zhiguo/B-3043-2012
OI Wang, Zhiguo/0000-0003-0343-7278
FU Natural Science Basic Research Program of Shaanxi under Program
   [2020JM-18]; National Natural Science Foundation of ChinaNational
   Natural Science Foundation of China (NSFC) [41974137, 41974122]
FX This work was supported in part by the Natural Science Basic Research
   Program of Shaanxi under Program 2020JM-18 and in part by the National
   Natural Science Foundation of China under Grant 41974137 and Grant
   41974122.
CR Alfarraj M, 2019, INTERPRETATION-J SUB, V7, pSE237, DOI 10.1190/INT-2018-0250.1
   AlRegib, 2020, P SEG TECH PROGR EXP, DOI DOI 10.1190/SEGAM2020-3428378.1
   AlRegib, 2020, P SEG TECH PROGR EXP, P1735, DOI DOI 10.1190/SEGAM2020-3428298.1
   Arjovsky M, 2017, ARXIV170107875
   Arjovsky M., 2017, ADV NEURAL INFORM PR, P5769
   Cai A., 2020, SEG TECHNICAL PROGRA, P1274
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Das V, 2019, GEOPHYSICS, V84, pR869, DOI 10.1190/GEO2018-0838.1
   Fang FM, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5279, DOI 10.1109/ICASSP.2018.8462342
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   HE KM, 2016, PROC CVPR IEEE, P770, DOI DOI 10.1109/CVPR.2016.90
   Isola P., 2017, P IEEE C COMPUTER VI, P5967, DOI DOI 10.1109/CVPR.2017.632
   King DB, 2015, ACS SYM SER, V1214, P1
   Li N., 2019, P SEG TECH PROGR EXP, P2338, DOI DOI 10.1190/SEGAM2019-3215750.1
   Loffe S., 2015, ABS150203167 ARXIV, P448, DOI DOI 10.1109/CVPR.2016.90
   Martin G.S., 2006, LEADING EDGE, V25, P156, DOI DOI 10.1190/1.2172306
   MENG D, 2020, PROC IGARSS IEEE INT, P1393
   Mirza M., 2014, ARXIV14111784, P1
   Mustafa A., 2019, 89 ANN INT M SEG, P2554, DOI [10.1190/segam2019-3216840.1, DOI 10.1190/SEGAM2019-3216840.1]
   Paoletti ME, 2021, IEEE GEOSCI REMOTE S, V18, P1288, DOI 10.1109/LGRS.2020.2997295
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Wu BY, 2020, IEEE GEOSCI REMOTE S, V17, P2140, DOI 10.1109/LGRS.2019.2963106
   Yan, 2019, P SEG TECH PROGR, P2498, DOI DOI 10.1190/SEGAM2019-3203757.1
   Yuji Kim, 2018, Leading Edge, V37, P894, DOI 10.1190/tle37120894.1
   Zhang YM, 2016, IEEE ACM T NETWORK, V24, P1632, DOI 10.1109/TNET.2015.2425146
   Zhu Jun-Yan, 2017, IEEE INT C COMP VIS, DOI [DOI 10.1109/ICCV.2017.244, DOI 10.1109/ICCV.2017.244:2242-2251]
NR 27
TC 0
Z9 0
U1 0
U2 0
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1545-598X
EI 1558-0571
J9 IEEE GEOSCI REMOTE S
JI IEEE Geosci. Remote Sens. Lett.
PY 2022
VL 19
DI 10.1109/LGRS.2021.3090108
EA JUL 2021
PG 5
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA XY1VP
UT WOS:000732222500001
DA 2022-02-06
ER

PT J
AU Makkar, A
   Kumar, N
   Zomaya, AY
   Dhiman, S
AF Makkar, Aaisha
   Kumar, Neeraj
   Zomaya, Albert Y.
   Dhiman, Shalini
TI SPAMI: A cognitive spam protector for advertisement malicious images
SO INFORMATION SCIENCES
LA English
DT Article
DE Deep learning; Spam image; Neural networks; Advertisement
ID ANOMALY DETECTION; CLASSIFICATION; MODEL
AB In modern era, the graphical information is presented in the form of web images. As the dependency of human beings on web information is increasing day-by-day, so the spammers are injecting spam by adopting new spamming techniques. Image spam is a spamming technique that integrates spam text contents into graphical images in order to bypass conventional text-based spam filters. The spam images are of various categories, such as redirection spam, advertisement spam, fake review, and content spam. In order to detect image spam efficiently, it is important to analyze the features of the image data. However, the existing image spam detection techniques in literature focused on textual or graphic features of the image. Moreover, to extract the relevant features from the images is also a challenging task. So, to fill these gaps, in this paper, we propose a Spam Protector for Advertisement of Malicious Images (SPAMI) framework using features extraction by browsing different websites and webpages. SPAMI is a cognitive spam protector which labels the spam advertisement images by using deep learning models. Three deep learning models are used for the same, i.e., CNN, RNN, and LSTM. The regress analysis of output from these models is done in the proposed SPAMI framework. Finally, we analysed the labels (Advertisement, Suspicious, Normal) for all the 600 images collected. The accuracy obtained from these models is 95% with real-time collected images, which improved up to 97% when tested with "Image Spam Hunter" dataset. (C) 2020 Elsevier Inc. All rights reserved.
C1 [Makkar, Aaisha; Dhiman, Shalini] Chandigarh Univ, Comp Sci Engn Dept, Chandigarh, India.
   [Kumar, Neeraj] Thapar Inst Engn & Technol, Dept Comp Sci & Engn, Patiala, Punjab, India.
   [Kumar, Neeraj] Asia Univ, Dept Comp Sci & Informat Engn, Taichung, Taiwan.
   [Kumar, Neeraj] King Abdulaziz Univ, Jeddah, Saudi Arabia.
   [Zomaya, Albert Y.] Univ Sydney, Sch Comp Sci, Sydney, NSW, Australia.
C3 Chandigarh University; Thapar Institute of Engineering & Technology;
   Asia University Taiwan; King Abdulaziz University; University of Sydney
RP Kumar, N (corresponding author), Asia Univ, Dept Comp Sci & Informat Engn, Taichung, Taiwan.; Kumar, N (corresponding author), King Abdulaziz Univ, Jeddah, Saudi Arabia.; Kumar, N (corresponding author), Thapar Inst Engn & Technol, Patiala, Punjab, India.
RI Zomaya, Albert Y./G-9697-2017; Makkar, Aaisha/AAN-4730-2020; Kumar,
   Neeraj/L-3500-2016
OI Zomaya, Albert Y./0000-0002-3090-1059; Makkar,
   Aaisha/0000-0001-7203-6553; Kumar, Neeraj/0000-0002-3020-3947
CR Abbasi A., 2012, ACM T INFORM SYST TO, V30
   Al-Duwairi Basheer, 2012, INT J INF SECUR, V2, P344
   Annadatha A, 2018, J COMPUT VIROL HACKI, V14, P39, DOI 10.1007/s11416-016-0287-x
   Aujla GSS, 2019, IEEE T SUST COMPUT, P1, DOI [10.1109/TSUSC.2019.2907110, DOI 10.1109/TSUSC.2019.2907110]
   Biggio B, 2007, 14TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P105, DOI 10.1109/ICIAP.2007.4362765
   Blanzieri E, 2008, ARTIF INTELL REV, V29, P63, DOI 10.1007/s10462-009-9109-6
   Byun B., 2007, CEAS
   Castillo Carlos, 2007, 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P423, DOI 10.1145/1277741.1277814
   Chao Wang, 2010, 2010 International Conference on Communications, Circuits and Systems (ICCCAS), P290, DOI 10.1109/ICCCAS.2010.5581998
   Chavda A., 2017, IMAGE SPAM DETECTION
   Congfu Xu, 2010, 2010 Proceedings of 22nd International Conference on Tools with Artificial Intelligence (ICTAI 2010), P171, DOI 10.1109/ICTAI.2010.31
   Duan MX, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3355542
   Duan MX, 2018, IEEE T INF FOREN SEC, V13, P758, DOI 10.1109/TIFS.2017.2766583
   Er-Xin Shang, 2016, 2016 International Conference on Machine Learning and Cybernetics (ICMLC). Proceedings, P398, DOI 10.1109/ICMLC.2016.7860934
   Ford S, 2009, 25TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE, P363, DOI 10.1109/ACSAC.2009.41
   Fumera G, 2006, J MACH LEARN RES, V7, P2699
   Gao Y, 2008, INT CONF ACOUST SPEE, P1765
   Gao Y, 2010, IEEE T INF FOREN SEC, V5, P826, DOI 10.1109/TIFS.2010.2080267
   Garg S, 2019, IEEE T NETW SERV MAN, V16, P924, DOI 10.1109/TNSM.2019.2927886
   Garg S, 2019, IEEE T MULTIMEDIA, V21, P566, DOI 10.1109/TMM.2019.2893549
   Gargiulo F., 2008, P 19 ICPR TAMP FL US, P1, DOI DOI 10.1109/ICPR.2008.4761828
   Gulati A., 2018, 2018 IEEE INT C COMM, P1
   Gyongyi Zoltan, 2005, 1 INT WORKSH ADV INF
   Hsia JH, 2009, IEEE INT CON MULTI, P1182, DOI 10.1109/ICME.2009.5202711
   Jain Gauri, 2019, International Journal of Information Technology, V11, P239, DOI 10.1007/s41870-018-0157-5
   Jindal T, 2018, SPRINGERBR ENV SCI, P1, DOI 10.1007/978-3-319-58415-7
   KASHYAP RL, 1981, IEEE T INFORM THEORY, V27, P627, DOI 10.1109/TIT.1981.1056390
   Krasser S, 2007, 2007 IEEE INFORMATION ASSURANCE WORKSHOP, P255, DOI 10.1109/IAW.2007.381941
   Kumar N., 2018, 2018 IEEE GLOB COMM, P1
   Leng AGK, 2012, CYBERNET SYST, V43, P459, DOI 10.1080/01969722.2012.707491
   Li K, 2013, IEEE T COMPUT, V64, P191
   Li KL, 2016, IEEE T PARALL DISTR, V27, P2795, DOI 10.1109/TPDS.2016.2516988
   Li Z., 2012, P 2012 ACM CCS, P674
   Lian J., 2019, IEEE T IND INF
   Makkar A., 2020, IEEE T IND INF
   Makkar A., 2020, FUTURE GENERATION CO
   Makkar A, 2019, 2019 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI 2019), P3132, DOI 10.1109/SSCI44817.2019.9002885
   Makkar A, 2018, SUSTAIN COMPUT-INFOR, V20, P174, DOI 10.1016/j.suscom.2018.02.003
   Makkar A, 2019, FUTURE GENER COMP SY, V90, P381, DOI 10.1016/j.future.2018.07.046
   Makkar A, 2017, ADV INTELL SYST, V547, P1, DOI 10.1007/978-981-10-3325-4_1
   Mehta B., 2008, P 17 INT C WORLD WID, P497, DOI DOI 10.1145/1367497.1367565
   Miglani A, 2019, VEH COMMUN, V20, DOI 10.1016/j.vehcom.2019.100184
   Qu ZY, 2009, ICICTA: 2009 SECOND INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTATION TECHNOLOGY AND AUTOMATION, VOL I, PROCEEDINGS, P600, DOI 10.1109/ICICTA.2009.151
   Soranamageswari M, 2010, Proceedings of the 2nd International Conference on Machine Learning and Computing (ICMLC 2010), P101, DOI 10.1109/ICMLC.2010.72
   Wang Z., 2007, CEAS
   Wu C.-T., 2005, IEEE INT C IM PROC 2, V3, pIII
   Zhang C., 2009, J MULTIMEDIA, V4
   [No title captured]
NR 48
TC 4
Z9 4
U1 0
U2 6
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 0020-0255
EI 1872-6291
J9 INFORM SCIENCES
JI Inf. Sci.
PD NOV
PY 2020
VL 540
BP 17
EP 37
DI 10.1016/j.ins.2020.05.113
PG 21
WC Computer Science, Information Systems
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NS2JR
UT WOS:000572092800001
DA 2022-02-06
ER

PT J
AU Yuan, SH
   Wu, XT
   Xiang, Y
AF Yuan, Shuhan
   Wu, Xintao
   Xiang, Yang
TI Task-specific word identification from short texts using a convolutional
   neural network
SO INTELLIGENT DATA ANALYSIS
LA English
DT Article
DE Task-specific word identification; convolutional neural network; deep
   learning
AB Task-specific word identification aims to choose the task-related words that best describe a short text. Existing approaches require well-defined seed words or lexical dictionaries (e.g., WordNet), which are often unavailable for many applications such as social discrimination detection and fake review detection. However, we often have a set of labeled short texts where each short text has a task-related class label, e.g., discriminatory or non-discriminatory, specified by users or learned by classification algorithms. In this paper, we focus on identifying task-specific words and phrases from short texts by exploiting their class labels rather than using seed words or lexical dictionaries. We consider the task-specific word and phrase identification as feature learning. We train a convolutional neural network over a set of labeled texts and use score vectors to localize the task-specific words and phrases. Experimental results on sentiment word identification show that our approach significantly outperforms existing methods. We further conduct two case studies to show the effectiveness of our approach. One case study on a crawled tweets dataset demonstrates that our approach can successfully capture the discrimination-related words/phrases. The other case study on fake review detection shows that our approach can identify the fake-review words/phrases.
C1 [Yuan, Shuhan; Xiang, Yang] Tongji Univ, Comp Sci & Technol Dept, Shanghai, Peoples R China.
   [Wu, Xintao] Univ Arkansas, Comp Sci & Comp Engn Dept, Fayetteville, AR 72701 USA.
C3 Tongji University; University of Arkansas System; University of Arkansas
   Fayetteville
RP Yuan, SH (corresponding author), Tongji Univ, Comp Sci & Technol Dept, Shanghai, Peoples R China.
EM 4e66@tongji.edu.cn
OI Wu, Xintao/0000-0002-2823-3063
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [71571136]; 973 Program of ChinaNational
   Basic Research Program of China [2014CB340404]; Research Projects of
   Science and Technology Commission of Shanghai Municipality [16JC1403000,
   14511108002]; National Science FoundationNational Science Foundation
   (NSF) [1646654, 1564250]; Division Of Computer and Network
   SystemsNational Science Foundation (NSF)NSF - Directorate for Computer &
   Information Science & Engineering (CISE) [1564250] Funding Source:
   National Science Foundation
FX The authors acknowledge the support from the National Natural Science
   Foundation of China (71571136), the 973 Program of China (2014CB340404),
   and the Research Projects of Science and Technology Commission of
   Shanghai Municipality (16JC1403000, 14511108002) to Shuhan Yuan and Yang
   Xiang, and from National Science Foundation (1646654, 1564250) to Xintao
   Wu.
CR Abdel-Hamid O., 2013, INTERSPEECH
   Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Bordes Antoine, 2014, P 2014 C EMP METH NA, DOI DOI 10.3115/V1/D14-1067
   Chen JZ, 2016, PROCEEDINGS OF 2016 12TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS), P551, DOI [10.1109/CIS.2016.133, 10.1109/CIS.2016.0134]
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Dasgupta A, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P230
   de Freitas N, 2014, ARXIV14063830
   Deng L, 2013, IEEE INT NEW CIRC
   Deng ZH, 2016, THIRTIETH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P115
   Graves A., 2013, ARXIV13080850
   Hancock, 2011, P 49 ANN M ASS COMP, P309, DOI DOI 10.1145/2567948.2577293
   Hassan A, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P395
   Hermann Karl Moritz, 2015, ADV NEURAL INFORM PR
   Hu M., 2004, P 10 ACM SIGKDD INT, P168
   Jijkoun V, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P585
   Kalchbrenner N, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P655, DOI 10.3115/v1/p14-1062
   Kanayama H, 2006, P 2006 C EMP METH NA, P355, DOI DOI 10.3115/1610075.1610125
   Kim Y., 2014, P EMNLP 2014, P1746, DOI 10.3115/v1/D14-1181
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li J., 2015, ARXIV150601066
   Li J., 2016, ARXIV160107996
   Li JW, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1566
   Liang J.G., 2014, CIKM, P1943, DOI DOI 10.1145/2661829.2662015
   Lu Y., 2011, P 20 INT C WORLD WID, P347, DOI DOI 10.1145/1963405.1963456
   Makrehchi M, 2017, INTELL DATA ANAL, V21, P39, DOI 10.3233/IDA-150390
   Manning CD etal, 2013, P 51 ANN M ASS COMP, Vvol1, P455
   Mikolov Tomas, 2013, P INT C LEARN REPR
   Mitchell J, 2010, COGNITIVE SCI, V34, P1388, DOI 10.1111/j.1551-6709.2010.01106.x
   Mukherjee A, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P632
   Oquab M, 2015, PROC CVPR IEEE, P685, DOI 10.1109/CVPR.2015.7298668
   Ott M, 2013, P NAACL HLT 2013, P497
   Pang B., 2005, P 43 ANN M ASS COMP, DOI DOI 10.3115/1219840.1219855
   Park S, 2015, PATTERN RECOGN LETT, V56, P38, DOI 10.1016/j.patrec.2015.01.004
   Pennington J, 2014, EMNLP, P1532, DOI 10.3115/v1/D14-1162
   Qiu GA, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P1199
   Simonyan K, 2013, ARXIV PREPRINT ARXIV
   Socher R., 2013, ADV NEURAL INFORM PR, P1
   Tai KS, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1556
   Tang J, 2014, PR MACH LEARN RES, V32
   Turney PD, 2003, ACM T INFORM SYST, V21, P315, DOI 10.1145/944012.944013
   Uysal AK, 2016, EXPERT SYST APPL, V43, P82, DOI 10.1016/j.eswa.2015.08.050
   Weston J., 2015, ARXIV150205698
   Wilson TS, 2005, PHIL EDUC, P347, DOI 10.3115/1220575.1220619
   Yang Y., 1997, ICML, V97, P412, DOI DOI 10.1093/BI0INF0RMATICS/BTH267
   Yin W., 2015, P 2015 C N AM CHAPT, P901, DOI DOI 10.3115/V1/N15-1091
   Yu H, 2013, ACL, P855
   Zeiler M.D., 2011, P 2011 INT C COMP VI
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zheng XL, 2014, KNOWL-BASED SYST, V61, P29, DOI 10.1016/j.knosys.2014.02.003
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
NR 53
TC 4
Z9 4
U1 1
U2 13
PU IOS PRESS
PI AMSTERDAM
PA NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS
SN 1088-467X
EI 1571-4128
J9 INTELL DATA ANAL
JI Intell. Data Anal.
PY 2018
VL 22
IS 3
BP 533
EP 550
DI 10.3233/IDA-173413
PG 18
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GF5MN
UT WOS:000432011700005
OA Green Submitted
DA 2022-02-06
ER

PT J
AU Vo, DM
   Le, TP
   Nguyen, DM
   Lee, SW
AF Vo, Duc My
   Le, Thao Phuong
   Duc Manh Nguyen
   Lee, Sang-Woong
TI BoostNet: A Boosted Convolutional Neural Network for Image Blind
   Denoising
SO IEEE ACCESS
LA English
DT Article
DE Generative adversarial networks; deep convolutional neural networks;
   image denoising; BoostNet; fluorescence microscopy images; blind
   denoising; Drosophila
ID FRAMEWORK
AB Deep convolutional neural networks and generative adversarial networks currently attracted the attention of researchers because it is more effective than conventional representation-based methods. However, they have been facing two serious problems in the trade-off between noise removal, artifacts, and preserving low-contrast features and high-frequency details. In particular, deep convolutional neural networks might fail to remove strong noise in regions with higher noise levels while completely erasing low-contrast features and high-frequency details. By contrast, compared with conventional deep convolutional neural networks, generative adversarial networks might be better in balancing between erasing different types of noise and recovering texture details. However, they often generate fake details and unexpected artifacts in the image owing to the instability of their discriminator during training. In this study, we explored an innovative strategy for handling the serious problems of image denoising. With this strategy, we propose a novel boosting generative adversarial network (BoostNet) that not only combines all advantages of a generative adversarial sub-network and a deep convolutional neural network, it also successfully avoids the serious problems caused by the corruption and instability of training. BoostNet is developed by integrating a stand-alone deep convolutional neural network and a robust generative adversarial network into an ensemble network, which can effectively boost the denoising performance. We conducted several experiments using challenging datasets of additive white Gaussian noise and real-world noisy images. The experimental results show that our proposed method is superior to other state-of-the-art denoisers in terms of quantitative metrics and visual quality. Our source codes and datasets for BoostNet are available at https://github.com/ZeroZero19/BoostNet.git.
C1 [Vo, Duc My; Lee, Sang-Woong] Gachon Univ, Pattern Recognit & Machine Learning Lab, Seongnam 13120, South Korea.
   [Le, Thao Phuong] Louisiana State Univ, Dept Biol Sci, Baton Rouge, LA 70803 USA.
   [Duc Manh Nguyen] Vietnam Acad Sci & Technol, Vietnam Natl Space Ctr, Hanoi 100000, Vietnam.
C3 Gachon University; Louisiana State University System; Louisiana State
   University; Vietnam Academy of Science & Technology (VAST)
RP Lee, SW (corresponding author), Gachon Univ, Pattern Recognit & Machine Learning Lab, Seongnam 13120, South Korea.
EM slee@gachon.ac.kr
RI Lee, Sang-Woong/ABF-6191-2020
FU Institute of Information & communications Technology Planning &
   Evaluation (IITP) - Korea government (MSIT)
FX This work was supported by Institute of Information & communications
   Technology Planning & Evaluation (IITP) grant funded by the Korea
   government (MSIT) (No.2020-0-01907, Development of Smart Signage
   Technology for Automatic Classification of Untact Examination and
   Patient Status Based on AI).
CR Anwar S, 2019, IEEE I CONF COMP VIS, P3155, DOI 10.1109/ICCV.2019.00325
   Arjovsky M., 2017, ADV NEURAL INFORM PR, P5769
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Arjovsky Martin, 2017, PRINCIPLED METHODS T, V1050, P17
   Burger HC, 2012, PROC CVPR IEEE, P2392, DOI 10.1109/CVPR.2012.6247952
   Chen JW, 2018, PROC CVPR IEEE, P3155, DOI 10.1109/CVPR.2018.00333
   Chen YJ, 2017, IEEE T PATTERN ANAL, V39, P1256, DOI 10.1109/TPAMI.2016.2596743
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Deng HY, 2020, INFORM SCIENCES, V528, P246, DOI 10.1016/j.ins.2020.04.028
   Franzen R., 1999, KODAK LOSSLESS TRUE
   Gu SH, 2014, PROC CVPR IEEE, P2862, DOI 10.1109/CVPR.2014.366
   Guo Q, 2021, INFORM SCIENCES, V556, P177, DOI 10.1016/j.ins.2020.12.066
   Guo S, 2019, PROC CVPR IEEE, P1712, DOI 10.1109/CVPR.2019.00181
   He J., 2019, P IEEE CVF C COMP VI, P11056
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Kingma DP, 2015, 3 INT C LEARN REPR I, DOI DOI 10.1145/1830483.1830503
   Lan XY, 2006, LECT NOTES COMPUT SC, V3952, P269
   Le TP, 2021, MOL BIOL CELL, V32, P1033, DOI 10.1091/mbc.E21-01-0021
   Le TP, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms11501
   Lebrun M, 2015, IMAGE PROCESS ON LIN, V5, P1, DOI 10.5201/ipol.2015.125
   LEHTINEN J, 2018, P ICML, P1
   Li HF, 2020, INFORM SCIENCES, V523, P14, DOI 10.1016/j.ins.2020.03.009
   Lin K, 2019, IEEE COMPUT SOC CONF, P1717, DOI 10.1109/CVPRW.2019.00221
   Liu JB, 2019, POULTRY SCI, V98, P4829, DOI 10.3382/ps/pez217
   Liu PJ, 2018, IEEE COMPUT SOC CONF, P886, DOI 10.1109/CVPRW.2018.00121
   Long Bao, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW). Proceedings, P1823, DOI 10.1109/CVPRW50498.2020.00232
   Ma KD, 2017, IEEE T IMAGE PROCESS, V26, P1004, DOI 10.1109/TIP.2016.2631888
   Mao XJ, 2016, ADV NEUR IN, V29
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Miyato T., 2018, ICLR
   MROUEH Y, 2017, ARXIV PREPRINT ARXIV
   Mroueh Youssef, 2017, NIPS, P2513
   Muller A, 1997, ADV APPL PROBAB, V29, P429, DOI 10.2307/1428011
   Paszke A., 2017, P NIPS WORKSH
   Roth S, 2005, PROC CVPR IEEE, P860
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Simonyan K, 2015, ICLR 2015, DOI DOI 10.1109/CVPR.2015.7298594
   Tai Y, 2017, IEEE I CONF COMP VIS, P4549, DOI 10.1109/ICCV.2017.486
   Vo DM, 2021, ENG APPL ARTIF INTEL, V97, DOI 10.1016/j.engappai.2020.104052
   Xiong RQ, 2017, IEEE T IMAGE PROCESS, V26, DOI 10.1109/TIP.2016.2621478
   Xu J, 2018, LECT NOTES COMPUT SC, V11212, P21, DOI 10.1007/978-3-030-01237-3_2
   Xue JZ, 2019, INFORM SCIENCES, V501, P406, DOI 10.1016/j.ins.2019.06.012
   Xue XQ, 2020, INFORM SCIENCES, V513, P190, DOI 10.1016/j.ins.2019.10.058
   Yang D, 2018, IEEE SIGNAL PROC LET, V25, P55, DOI 10.1109/LSP.2017.2768660
   Zhang K, 2018, IEEE T IMAGE PROCESS, V27, P4608, DOI 10.1109/TIP.2018.2839891
   [张黎明 ZHANG Liming], 2011, [生态环境学报, Ecology and Environmental Sciences], V20, P1
   Zhang Y., 2019, P IEEE CVF C COMP VI, DOI DOI 10.1109/CVPR.2019.01198
NR 48
TC 0
Z9 0
U1 3
U2 3
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2021
VL 9
BP 115145
EP 115164
DI 10.1109/ACCESS.2021.3081697
PG 20
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA UE9VO
UT WOS:000688230700001
OA gold
DA 2022-02-06
ER

PT J
AU Capilla, P
AF Capilla, Pablo
TI Post-Truth as a Mutation of Epistemology in Journalism
SO MEDIA AND COMMUNICATION
LA English
DT Article
DE epistemology; fake news; journalism; ontology; post-truth; reality;
   social media; truth
ID SOCIAL MEDIA; FAKE NEWS; NEOLIBERALISM; POLITICS; BELIEF
AB In recent years, many authors have observed that something is happening to the truth, pointing out that, particularly in politics and social communication, there are signs that the idea of truth is losing consideration in media discourse. This is no minor issue: Truth, understood as the criterion for the justification of knowledge, is the essential foundation of enlightened rationality. The aim of this article, based on prior research on social communication (especially as regards journalism), is to elucidate an explanation of this phenomenon, known as 'post-truth.' Because it is an epistemological question, the three main variables of the problem (reality, subject and truth) have been analysed by taking into account the manner in which digital social communication is transforming our perception of reality. By way of a conclusion, we propose that (a) the ontological complexity of reality as explained by the news media has accentuated the loss of confidence in journalism as a truth-teller, and that (b) truth is being replaced by sincerity, as an epistemological value, in people's understanding of the news. The result, using Foucault's concept of Regime of Truth, suggests a deep change in the global framework of political, economic, social and cultural relations, of which post-truth is a symptom.
C1 [Capilla, Pablo] Ramon Llull Univ, Blanquerna Inst Res Commun & Int Relat, Barcelona 08001, Spain.
C3 Universitat Ramon Llull
RP Capilla, P (corresponding author), Ramon Llull Univ, Blanquerna Inst Res Commun & Int Relat, Barcelona 08001, Spain.
EM pablocg@blanquerna.url.edu
OI Capilla, Pablo/0000-0001-9455-3746
FU Ministerio de Ciencia, Innovacion y Universidades (Spain)Spanish
   Government [RTI2018-095775-B-C44]
FX This work was supported by the Ministerio de Ciencia, Innovacion y
   Universidades (Spain) RTI2018-095775-B-C44.
CR Anderson CW., 2012, POSTINDUSTRIAL JOURN
   Austin John Langshaw, 1962, DO THINGS WORDS
   Baudrillard Jean, 1994, SIMULACRA SIMULATION
   Beck U., 1992, RISK SOC NEW MODERNI
   Beckett C, 2016, SOC MEDIA SOC, V2, DOI 10.1177/2056305116662395
   Berger P. L., 1967, SOCIAL CONSTRUCTION
   Berkowitz DA, 2009, INT COMMUN ASSOC HAN, P102
   Biesecker BA, 2018, PHILOS RHETORIC, V51, P329
   Boler M, 2018, EMOT SPACE SOC, V27, P75, DOI 10.1016/j.emospa.2018.03.002
   Boorstin Daniel J., 1987, IMAGE GUIDE PSEUDO E, V25th
   Brahms Y., 2020, PHILOS POSTTRUTH
   Broersma M, 2013, RETHINKING JOURNALISM: TRUST AND PARTICIPATION IN A TRANSFORMED NEWS LANDSCAPE, P28
   Brown W, 2015, NEAR FUTURES, P1
   Chadwick A., 2013, HYBRID MEDIA SYSTEM
   Chan MPS, 2017, PSYCHOL SCI, V28, P1531, DOI 10.1177/0956797617714579
   Clayton K, 2020, POLIT BEHAV, V42, P1073, DOI 10.1007/s11109-019-09533-0
   Cotoi C., 2011, INT REV SOCIAL RES, V1, P109
   D'Ancona M., 2017, POST TRUTH NEW WAR T
   [党鹏阳 Dang Pengyang], 2019, [火工品, Initiators & Pyrotechnics], P1
   Deuze M, 2018, JOURNALISM, V19, P165, DOI 10.1177/1464884916688550
   Diethelm P, 2009, EUR J PUBLIC HEALTH, V19, P2, DOI 10.1093/eurpub/ckn139
   Edelman, 2020, ED TRUST BAR
   Ferraris M., 2014, MANIFESTO NEW REALIS
   Finlayson L., 2019, NORDIC WITTGENSTEIN, P63, DOI [10.15845/nwr.v8i0.3502, DOI 10.15845/NWR.V8I0.3502]
   Fletcher R, 2018, NEW MEDIA SOC, V20, P2450, DOI 10.1177/1461444817724170
   Foucault M, 1977, RADICAL PHILOS, V17, P12
   Frankfurt H. G., 2007, ON TRUTH
   Fuller S., 2018, POST TRUTH KNOWLEDGE
   Gane N, 2014, SOCIOLOGY, V48, P1092, DOI 10.1177/0038038513512728
   Gjorgjioska MA, 2019, J SOC ISSUES, V75, P169, DOI 10.1111/josi.12315
   Goldstein Rebecca A., 2011, J INQUIRY ACTION ED, V4, P112
   Guess A., 2018, SELECTIVE EXPOSURE M
   Haack S, 2019, THEORIA-SWED J PHILO, V85, P258, DOI 10.1111/theo.12198
   Harsin J., 2018, POSTTRUTH CRITICAL C, DOI [10.1093/acrefore/9780190228613.001.0001/acrefore-9780190228613-e-757, DOI 10.1093/ACREFORE/9780190228613.001.0001/ACREFORE-9780190228613-E-757]
   Harsin J, 2015, COMMUN CULT CRIT, V8, P327, DOI 10.1111/cccr.12097
   Harvey D., 2005, BRIEF HIST NEOLIBERA
   Hearns-Branaman J. O., 2016, JOURNALISM PHILOS TR
   Jolly J., 2014, COLUMBIA JOURNALISM
   Jones JP, 2009, SHAP INQ CULT COMMUN, P127
   Botero JJ, 2017, IDEAS VALORES, V66, P11, DOI 10.15446/ideasyvalores.v66n3supl.65698
   Karidi M, 2018, JOURNALISM STUD, V19, P1237, DOI 10.1080/1461670X.2016.1266281
   Kovach B., 2007, ELEMENTS JOURNALISM
   Laybats C., 2016, BUS INF REV, V33, P204, DOI DOI 10.1177/0266382116680741
   Lewis SC, 2015, DIGIT JOURNAL, V3, P447, DOI 10.1080/21670811.2014.976418
   Leyva R., 2020, BRAINS MEDIA POLITIC
   Lorenzini D., 2016, FOUCAULT MAKING SUBJ, P63
   Luhmann N., 2000, REALITY MASS MEDIA
   Lule J, 2001, DAILY NEWS ETERNAL S
   Maddalena G., 2020, HIST THEORY POS TRUT
   Maras S., 2013, OBJECTIVITY JOURNALI
   Marmura S., 2018, WIKILEAKS PARADIGM P
   Masip P, 2020, INT J COMMUN-US, V14, P3355
   Matheson D, 2004, NEW MEDIA SOC, V6, P443, DOI 10.1177/146144804044329
   McCombs ME, 2014, MASS COMMUN SOC, V17, P781, DOI 10.1080/15205436.2014.964871
   McIntyre L, 2018, MIT PRESS ESSENT, P1
   Mejias UA, 2019, INTERNET POLICY REV, V8, DOI 10.14763/2019.4.1428
   MOLOTCH H, 1974, AM SOCIOL REV, V39, P101, DOI 10.2307/2094279
   Munoz-Torres JR, 2012, JOURNALISM STUD, V13, P566, DOI 10.1080/1461670X.2012.662401
   Nielsen R. K., 2017, AUDIENCE PERSPECTIVE
   Papacharissi Z., 2014, AFFECTIVE PUBLICS SE
   Pennycook G, 2020, J PERS, V88, P185, DOI 10.1111/jopy.12476
   Poerksen B., 2011, CREATION REALITY CON
   Prozorov S, 2019, CONSTELLATIONS, V26, P18, DOI 10.1111/1467-8675.12396
   Rabin N., 2006, COMMUNICATION 0125
   Rainie L, 2012, NETWORKED: THE NEW SOCIAL OPERATING SYSTEM, P1
   Read R., 2019, NORDIC WITTGENSTEIN, DOI [10.15845/nwr.v8i1.3508, DOI 10.15845/NWR.V8I1.3508]
   Rosenberg D, 2013, INFRASTRUCT SER, P15
   Ryfe D, 2019, JOURNALISM, V20, P206, DOI 10.1177/8756087918809246
   Schudson M., 2005, MEDIA ANTHR, P121
   Smith L., 2001, LOS ANGELES TIMES
   Sunstein CR, 2007, REPUBLIC.COM 2.0, P1
   Sunstein CR, 2018, REPUBLIC DIVIDED DEM
   Tandoc EC, 2018, DIGIT JOURNAL, V6, P137, DOI 10.1080/21670811.2017.1360143
   Tandoc EC, 2016, JOURNAL PRACT, V10, P950, DOI 10.1080/17512786.2015.1087811
   Thorson E, 2016, POLIT COMMUN, V33, P460, DOI 10.1080/10584609.2015.1102187
   Trilling D, 2015, DIGIT JOURNAL, V3, P140, DOI 10.1080/21670811.2014.899749
   Tuchman G., 1978, MAKING NEWS STUDY CO
   Uscinski JE, 2013, CRIT REV, V25, P162, DOI 10.1080/08913811.2013.843872
   Viner K., 2016, GUARDIAN 0712
   Wahl-Jorgensen K., 2016, SAGE HDB DIGITAL JOU, P128, DOI DOI 10.4135/9781473957909.N9
   Wardle C, 2017, INFORM DISORDER INTE
   Williams B., 2002, TRUTH TRUTHFULNESS
   Wolfsfeld G, 2013, INT J PRESS/POLIT, V18, P115, DOI 10.1177/1940161212471716
NR 83
TC 0
Z9 0
U1 3
U2 4
PU COGITATIO PRESS
PI LISBON
PA RUA FIALHO ALMEIDA 14, 2 ESQ, LISBON, 1070-129, PORTUGAL
SN 2183-2439
J9 MEDIA COMMUN-LISBON
JI Media Commun.
PY 2021
VL 9
IS 1
BP 313
EP 322
DI 10.17645/mac.v9i1.3529
PG 10
WC Communication
WE Social Science Citation Index (SSCI)
SC Communication
GA QR8IM
UT WOS:000625456900009
OA Green Published, gold
DA 2022-02-06
ER

PT J
AU Hu, ZH
   Turki, T
   Wang, JTL
AF Hu, Zhihang
   Turki, Turki
   Wang, Jason T. L.
TI Generative Adversarial Networks for Stochastic Video Prediction With
   Action Control
SO IEEE ACCESS
LA English
DT Article
DE Cycle consistency; deep learning; generative adversarial networks; video
   prediction
AB The ability of predicting future frames in video sequences, known as video prediction, is an appealing yet challenging task in computer vision. This task requires an in-depth representation of video sequences and a deep understanding of real-word causal rules. Existing approaches for tackling the video prediction problem can be classified into two categories: deterministic and stochastic methods. Deterministic methods lack the ability of generating possible future frames and often yield blurry predictions. On the other hand, although current stochastic approaches can predict possible future frames, their models lack the ability of action control in the sense that they cannot generate the desired future frames conditioned on a specific action. In this paper, we propose new generative adversarial networks (GANs) for stochastic video prediction. Our framework, called VPGAN, employs an adversarial inference model and a cycle-consistency loss function to empower the framework to obtain more accurate predictions. In addition, we incorporate a conformal mapping network structure into VPGAN to enable action control for generating desirable future frames. In this way, VPGAN is able to produce fake videos of an object moving along a specific direction. Experimental results show that the combination of VPGAN with a pre-trained image segmentation model outperforms existing stochastic video prediction methods.
C1 [Hu, Zhihang; Wang, Jason T. L.] New Jersey Inst Technol, Dept Comp Sci, Newark, NJ 07102 USA.
   [Turki, Turki] King Abdulaziz Univ, Dept Comp Sci, Jeddah 21589, Saudi Arabia.
C3 New Jersey Institute of Technology; King Abdulaziz University
RP Wang, JTL (corresponding author), New Jersey Inst Technol, Dept Comp Sci, Newark, NJ 07102 USA.; Turki, T (corresponding author), King Abdulaziz Univ, Dept Comp Sci, Jeddah 21589, Saudi Arabia.
EM tturki@kau.edu.sa; wangj@njit.edu
OI Hu, Zhihang/0000-0003-4947-2140; Turki, Turki/0000-0002-9491-2435
FU New Jersey Institute of Technology (NJIT); Deanship of Scientific
   Research (DSR) at King Abdulaziz University, Jeddah [KEP-8-611-38]
FX This work was supported by an New Jersey Institute of Technology (NJIT)
   seed grant, in part by the Deanship of Scientific Research (DSR) at King
   Abdulaziz University, Jeddah, under Grant KEP-8-611-38.
CR Ahlfors L. V., 1973, CONFORMAL INVARIANTS
   Babaeizadeh M., 2018, P INT C LEARN REPR, P1
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Beauchemin SS, 1995, ACM COMPUT SURV, V27, P433, DOI 10.1145/212094.212141
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Bahnsen AC, 2017, PROCEEDINGS OF THE 2017 APWG SYMPOSIUM ON ELECTRONIC CRIME RESEARCH (ECRIME), P1, DOI 10.1109/ECRIME.2017.7945048
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Denton E., 2018, P 35 INT C MACH LEAR, P1182
   Denton E.L., 2017, ARXIV170510915
   Donahue J., 2017, P 5 INT C LEARN REPR
   Dumoulin Vincent, 2017, INT C LEARN REPR
   Finn Chelsea, 2016, ADV NEURAL INFORM PR, P64, DOI DOI 10.5555/3157096.3157104
   Gonzalez R. C, 2008, DIGITAL IMAGE PROCES, V3rd
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Gulrajani I., 2017, ADV NEURAL INFORM PR, P5769, DOI DOI 10.5555/3295222.3295327
   Hou R., 2019, P 22 INT C ELECT MAC P 22 INT C ELECT MAC, P1
   Howell D.C., 2010, FUNDAMENTAL STAT BEH
   Hu ZH, 2018, IEEE ACCESS, V6, P43450, DOI 10.1109/ACCESS.2018.2861223
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Kingma D. P., 2013, ARXIV13060733
   Kingma DP, 2015, 3 INT C LEARN REPR I, DOI DOI 10.1145/1830483.1830503
   Lee Alex X, 2018, ARXIV180401523
   Li YJ, 2018, LECT NOTES COMPUT SC, V11213, P609, DOI 10.1007/978-3-030-01240-3_37
   Liu H, 2019, ASTROPHYS J, V877, DOI [10.5281/ZENODO.5651065, 10.5281/ZENODO.5652615, 10.3847/1538-4357/ab1b3c, 10.5281/ZENODO.5651064]
   Mathieu M., 2016, ICLR
   Mescheder L., 2018, ARXIV180104406
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045
   Nomizu K., 1994, AFFINE DIFFERENTIAL
   Oh J., 2015, ADV NEURAL INFORM PR, P2863
   Oliu M, 2018, LECT NOTES COMPUT SC, V11218, P745, DOI 10.1007/978-3-030-01264-9_44
   Pu Y., 2016, P NIPS, V29, P2352
   Ranzato MarcAurelio, 2014, ARXIV14126604
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Schuldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Simonyan K, 2015, ICLR 2015, DOI DOI 10.1109/CVPR.2015.7298594
   Soomro K., 2012, ABS12120402 ARXIV
   Srivastava N, 2015, PR MACH LEARN RES, V37, P843
   Tulyakov S, 2018, PROC CVPR IEEE, P1526, DOI 10.1109/CVPR.2018.00165
   Walker J, 2016, LECT NOTES COMPUT SC, V9911, P835, DOI 10.1007/978-3-319-46478-7_51
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Woo W.-C., 2015, ADV NEURAL INFORM PR
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 43
TC 4
Z9 4
U1 3
U2 7
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2020
VL 8
BP 63336
EP 63348
DI 10.1109/ACCESS.2020.2982750
PG 13
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA LK4LK
UT WOS:000530832200060
OA gold
DA 2022-02-06
ER

PT J
AU Downing, J
   Dron, R
AF Downing, Joseph
   Dron, Richard
TI Tweeting Grenfell: Discourse and networks in critical constructions of
   British Muslim social boundaries on social media
SO NEW MEDIA & SOCIETY
LA English
DT Article
DE Austerity; British Muslims; critical discourse analysis; Grenfell fire;
   social boundaries; social network analysis; twitter
ID BAD MUSLIM; CULTURE
AB The Grenfell fire has yet to be analysed to understand the event's implications in relation to construction of social boundaries for British Muslims. In this current research, two methodological approaches are applied to gain understandings of social boundary construction on twitter: thematic analysis of the content of tweets and social network analysis (SNA) of how messages are diffused and contested. Twitter is shown to be an important platform in spreading positive narratives about Muslims during the fire, enabling individuals to spontaneously contest fake news and hate narratives. Social media acts counter to established knowledge, demonstrating that it is not, per se, a conduit for fake news and hate speech. Furthermore, it demonstrates how twitter offers Muslims an international space to voice and articulate themselves where they can be influential in debates that effect Muslim diasporas in other national contexts.
C1 [Downing, Joseph] London Sch Econ & Polit Sci, European Inst, London WC2A 2AE, England.
   [Downing, Joseph] Univ Aix Marseille, CNRS, Marseille, France.
   Univ London, Sch Oriental & African Studies, London, England.
   [Dron, Richard] Univ Salford, Digital Business, Sch Business, Salford, Lancs, England.
C3 University of London; London School Economics & Political Science;
   Aix-Marseille Universite; Centre National de la Recherche Scientifique
   (CNRS); University of London; University of London School Oriental &
   African Studies (SOAS); University of Salford
RP Downing, J (corresponding author), London Sch Econ & Polit Sci, European Inst, London WC2A 2AE, England.
EM j.s.downing@lse.ac.uk
FU European UnionEuropean Commission [703613H2020, 703613]
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: This
   project has received funding from the European Union's Horizon 2020
   research and innova-tion programme under the Marie Sklodowska-Curie
   grant agreement No 703613H2020 Marie Sklodowska-Curie Actions [703613].
CR Abbas T., 2004, AM J ISLAMIC SOCIAL, V21, P26, DOI DOI 10.35632/AJISS.V21I3.506
   Adamson FB, 2011, J ETHN MIGR STUD, V37, P899, DOI 10.1080/1369183X.2011.576193
   Ahmed S, 2009, SEEN NOT HEARD VOICE
   Ahmed W, 2019, ONLINE INFORM REV, V43, P149, DOI 10.1108/OIR-03-2018-0093
   Alba R, 2005, ETHNIC RACIAL STUD, V28, P20, DOI 10.1080/0141987042000280003
   Allcott H, 2017, J ECON PERSPECT, V31, P211, DOI 10.1257/jep.31.2.211
   [Anonymous], 2017, INDEPENDENT
   [Anonymous], 2017, SUN
   [Anonymous], 2017, BBC NEWS
   [Anonymous], 2015, ARTS ED, V08, P246
   Barthelemy M., 2014, NOUVELLES ARCHEOLOGI, V135, P51, DOI DOI 10.4000/nda.2374
   Batagelj V., 2018, EXPLORATORY SOCIAL N
   Braun V., 2006, QUAL RES PSYCHOL, V3, P77, DOI DOI 10.1191/1478088706QP063OA
   Cesari J, 2013, WORLD REV
   Cesari J, 2009, CHANGING LANDSCAPE E
   Davies R., 2009, COMMUNICATION SOCIAL
   Demartini G., 2017, ADV RES ETHICS INTEG, DOI DOI 10.1108/S2398-601820180000002004
   Downing J, 2015, SECURITY THREAT POSE
   Downing J, 2019, FRENCH MUSLIMS PERSP
   Downing J, 2019, CRIT STUD TERROR, V12, P250, DOI 10.1080/17539153.2019.1573038
   Fairclough N., 1995, CRITICAL DISCOURSE A
   Fereday J., 2006, INT J QUAL METHODS, V5, P80, DOI DOI 10.1177/160940690600500107
   Gardy JL, 2011, NEW ENGL J MED, V364, P730, DOI 10.1056/NEJMoa1003176
   Gee J. P., 2004, SITUATED LANGUAGE LE
   Gentleman A, 2017, GUARDIAN, P16
   Graham-Harrison, 2017, OBSERVER
   Grandjean M, 2016, COGENT ARTS HUMANITE, V3, DOI 10.1080/23311983.2016.1171458
   Haas HD, 2011, EVOLUTION MOROCCAN M
   Haskins Ekaterina, 2007, RHETOR SOC Q, V37, P401, DOI [10.1080/02773940601086794, DOI 10.1080/02773940601086794]
   Herrman J, 2014, ITS WAKE UP CALL WE
   Hoque A, 2018, BRIT J SOCIOL EDUC, V39, P182, DOI 10.1080/01425692.2017.1406335
   Isa D, 2017, SOCIAL MEDIA SOC, P1, DOI [10.1177/2056305118760, DOI 10.1177/2056305118760]
   Islamic Relief, 2017, STAT FIR GRENF TOW
   Jarvis L, 2011, J AM STUD, V45, P793, DOI 10.1017/S002187581100096X
   Joseph Watson P, 2017, MUSLIMS CELEBRATE LO
   Kahani-Hopkins V, 2002, ETHNIC RACIAL STUD, V25, P288, DOI 10.1080/01419870120109494
   Kavakci E, 2017, MEDIA CULT SOC, V39, P850, DOI 10.1177/0163443716679031
   Maira S, 2009, FEMINIST STUD, V35, P631
   Mamdani M, 2002, AM ANTHROPOL, V104, P766, DOI 10.1525/aa.2002.104.3.766
   Mavelli L, 2013, MILLENNIUM-J INT ST, V41, P159, DOI 10.1177/0305829812463655
   Modood T, 2006, MULTICULTURALISM MUS, P37
   Mohammed J, 2011, GOOD MUSLIM BAD MUSL
   Moore K, 2008, WORKING PAPER
   Nussbaum E, 2017, JOKES WON ELECTION
   O'Reilly T, 2005, WHAT IS WEB 2 0
   Oppenheim M, 2017, MP GRENFELL DEATH TO
   Poole E., 2002, REPORTING ISLAM MEDI
   Qurashi F, 2018, PALGR COMMUN, V4, DOI 10.1057/s41599-017-0061-9
   Robertson MA, 2017, THESIS
   Rustin S, 2018, GUARDIAN
   Saeed A, 2007, SOCIOL COMPASS, V1, P443, DOI 10.1111/j.1751-9020.2007.00039.x
   Scott J., 1991, SOCIAL NETWORK ANAL
   Semati M, 2011, COMMUN STUD, V62, P113, DOI 10.1080/10510974.2011.540975
   Sian K, 2012, CTR ETHNICITY RACISM
   Sirin SR, 2007, APPL DEV SCI, V11, P151, DOI 10.1080/10888690701454658
   Smith M., 2014, MAPPING TWITTER TOPI
   Tandoc EC, 2018, DIGIT JOURNAL, V6, P137, DOI 10.1080/21670811.2017.1360143
   Tiffin H., 2006, POSTCOLONIAL STUDIES, P155
   Tilly C, 2004, PHILOS SOC SCI, V34, P211, DOI 10.1177/0048393103262551
   Vertovec S, 2007, ETHNIC RACIAL STUD, V30, P1024, DOI 10.1080/01419870701599465
   WHITE Harrison, 2008, IDENTITY CONTROL SOC
NR 61
TC 9
Z9 9
U1 3
U2 21
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 1461-4448
EI 1461-7315
J9 NEW MEDIA SOC
JI New Media Soc.
PD MAR
PY 2020
VL 22
IS 3
BP 449
EP 469
AR 1461444819864572
DI 10.1177/1461444819864572
EA JUL 2019
PG 21
WC Communication
WE Social Science Citation Index (SSCI)
SC Communication
GA KQ0PV
UT WOS:000478880500001
DA 2022-02-06
ER

PT J
AU Xing, JM
   Chu, L
   Hou, ZR
   Sun, W
   Zhang, YJ
AF Xing, Jiaming
   Chu, Liang
   Hou, Zhuoran
   Sun, Wen
   Zhang, Yuanjian
TI Energy Management Strategy Based on a Novel Speed Prediction Method
SO SENSORS
LA English
DT Article
DE speed prediction; deep learning; energy management strategy; model
   predictive control
ID NEURAL-NETWORK; MARKOV-CHAIN; MODEL; VELOCITY
AB Vehicle speed prediction can obtain the future driving status of a vehicle in advance, which helps to make better decisions for energy management strategies. We propose a novel deep learning neural network architecture for vehicle speed prediction, called VSNet, by combining convolutional neural network (CNN) and long-short term memory network (LSTM). VSNet adopts a fake image composed of 15 vehicle signals in the past 15 s as model input to predict the vehicle speed in the next 5 s. Different from the traditional series or parallel structure, VSNet is structured with CNN and LSTM in series and then in parallel with two other CNNs of different convolutional kernel sizes. The unique architecture allows for better fitting of highly nonlinear relationships. The prediction performance of VSNet is first examined. The prediction results show a RMSE range of 0.519-2.681 and a R2 range of 0.997-0.929 for the future 5 s. Finally, an energy management strategy combined with VSNet and model predictive control (MPC) is simulated. The equivalent fuel consumption of the simulation increases by only 4.74% compared with DP-based energy management strategy and decreased by 2.82% compared with the speed prediction method with low accuracy.
C1 [Xing, Jiaming; Chu, Liang; Hou, Zhuoran] Jilin Univ, State Key Lab Automot Dynam Simulat & Control, Changchun 130021, Peoples R China.
   [Sun, Wen] Changzhou Inst Technol, Coll Automot Engn, Changzhou 213032, Jiangsu, Peoples R China.
   [Zhang, Yuanjian] Queens Univ Belfast, Sch Mech & Aerosp Engn, Belfast BT9 5AG, Antrim, North Ireland.
C3 Jilin University; Changzhou Institute of Technology; Queens University
   Belfast
RP Zhang, YJ (corresponding author), Queens Univ Belfast, Sch Mech & Aerosp Engn, Belfast BT9 5AG, Antrim, North Ireland.
EM xingjm19@mails.jlu.edu.cn; chuliang@jlu.edu.cn;
   houzr20@mails.jlu.edu.cn; sunw@czu.cn; Y.Zhang@qub.ac.uk
OI Sun, Wen/0000-0003-1501-3771
FU Science and Technology Planning Project in Changzhou [CZ20210033]
FX FundingThis research was funded by the Science and Technology Planning
   Project in Changzhou (CZ20210033).
CR Andersson JAE, 2019, MATH PROGRAM COMPUT, V11, P1, DOI 10.1007/s12532-018-0139-4
   Loaiza FA, 2017, PROCEEDINGS OF THE 10TH INTERNATIONAL CONFERENCE ON COMPUTER MODELING AND SIMULATION (ICCMS 2018), P157, DOI 10.1145/3177457.3177464
   Borhan H, 2012, IEEE T CONTR SYST T, V20, P593, DOI 10.1109/TCST.2011.2134852
   Chi JT, 2021, LINEAR ALGEBRA APPL, V624, P87, DOI 10.1016/j.laa.2021.03.039
   de Moura J, 2021, J ENERG RESOUR-ASME, V143, DOI 10.1115/1.4049467
   Feng WL, 2019, CLUSTER COMPUT, V22, pS7401, DOI 10.1007/s10586-017-1576-y
   Gan L, 2021, FINANC RES LETT, V39, DOI 10.1016/j.frl.2020.101574
   Cuenca LG, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19102386
   Graves A., 2006, P 23 INT C MACHINE L, P369, DOI DOI 10.1145/1143844.1143891
   Graves A, 2013, 2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P273, DOI 10.1109/ASRU.2013.6707742
   Han SJ, 2019, IEEE INT C INTELL TR, P4055, DOI 10.1109/ITSC.2019.8917345
   Hemi H, 2015, ENERG CONVERS MANAGE, V91, P387, DOI 10.1016/j.enconman.2014.12.035
   Hill G, 2012, IEEE INT C INTELL TR, P1072, DOI 10.1109/ITSC.2012.6338818
   Nguyen H, 2018, IET INTELL TRANSP SY, V12, P998, DOI 10.1049/iet-its.2018.0064
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735
   Hosseini MK, 2019, TRANSPORT RES REC, V2673, P425, DOI 10.1177/0361198119841291
   Huang YJ, 2017, J POWER SOURCES, V341, P91, DOI 10.1016/j.jpowsour.2016.11.106
   Ibrahim A, 2021, TRANSPORT RES C-EMER, V124, DOI 10.1016/j.trc.2020.102905
   Guo JQ, 2021, ENERGY, V226, DOI 10.1016/j.energy.2021.120440
   Karbowski D, 2014, 2014 IEEE VEHICLE POWER AND PROPULSION CONFERENCE (VPPC)
   Karim SAA, 2018, AIP CONF PROC, V1974, DOI 10.1063/1.5041644
   Li L, 2019, IEEE T VEH TECHNOL, V68, P3279, DOI 10.1109/TVT.2019.2896260
   Li ML, 2020, J CLEAN PROD, V269, DOI 10.1016/j.jclepro.2020.122374
   Li YF, 2019, IET INTELL TRANSP SY, V13, P1281, DOI 10.1049/iet-its.2018.5593
   Li YF, 2018, SCI CHINA TECHNOL SC, V61, P782, DOI 10.1007/s11431-017-9213-0
   Ma DF, 2021, IEEE T INTELL TRANSP, V22, P2627, DOI 10.1109/TITS.2020.2973279
   Ma XL, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17040818
   Ma XL, 2015, TRANSPORT RES C-EMER, V54, P187, DOI 10.1016/j.trc.2015.03.014
   Ma ZY, 2016, VEHICLE SYST DYN, V54, P137, DOI 10.1080/00423114.2015.1122817
   Maji A, 2018, J TRANSP ENG A-SYST, V144, DOI 10.1061/JTEPBS.0000136
   Mirbaha B., 2017, IOP C SERIES MAT SCI
   Pei JZ, 2020, SCI CHINA TECHNOL SC, V63, P55, DOI 10.1007/s11431-018-9396-0
   Perez-Ortiz JA, 2003, NEURAL NETWORKS, V16, P241, DOI 10.1016/S0893-6080(02)00219-8
   Qi X., 2020, E3S WEB C
   Sah S, 2020, MACHINE LEARNING REV
   Shin J, 2019, IEEE T INTELL TRANSP, V20, P3201, DOI 10.1109/TITS.2018.2877785
   Shrestha A, 2019, IEEE ACCESS, V7, P53040, DOI 10.1109/ACCESS.2019.2912200
   Sokolov-Mladenovic S, 2016, COMPUT HUM BEHAV, V65, P43, DOI 10.1016/j.chb.2016.08.014
   Wang C., 2019, DATA DRIVEN MULTISTE
   Wang XC, 2020, APPL ENERG, V276, DOI 10.1016/j.apenergy.2020.115460
   Wang ZJ, 2021, IEEE T VIS COMPUT GR, V27, P1396, DOI 10.1109/TVCG.2020.3030418
   Yamashita H, 2012, MATH PROGRAM, V132, P1, DOI 10.1007/s10107-010-0354-x
   Yang C, 2020, IET INTELL TRANSP SY, V14, P702, DOI 10.1049/iet-its.2019.0606
   Yeon K, 2019, INT J AUTO TECH-KOR, V20, P713, DOI 10.1007/s12239-019-0067-y
NR 44
TC 0
Z9 0
U1 5
U2 5
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 1424-8220
J9 SENSORS-BASEL
JI Sensors
PD DEC
PY 2021
VL 21
IS 24
AR 8273
DI 10.3390/s21248273
PG 24
WC Chemistry, Analytical; Engineering, Electrical & Electronic; Instruments
   & Instrumentation
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Chemistry; Engineering; Instruments & Instrumentation
GA XZ1SN
UT WOS:000737440200001
PM 34960362
OA Green Published, gold
DA 2022-02-06
ER

PT J
AU Ashraf, MA
   Nawab, RMA
   Nie, FP
AF Ashraf, Muhammad Adnan
   Nawab, Rao Muhammad Adeel
   Nie, Feiping
TI Author profiling on bi-lingual tweets
SO JOURNAL OF INTELLIGENT & FUZZY SYSTEMS
LA English
DT Article
DE Twitter; author profiling; roman-urdu; deep learning; bi-lingual; gender
   identification
ID SENTIMENT ANALYSIS
AB The task of author profiling aims to distinguish the author's profile traits from a given content. It has got potential applications in marketing, forensic analysis, fake profile detection, etc. In recent years, the usage of bi-lingual text has raised due to the global reach of social media tools as people prefer to use language that expresses their true feelings during online conversations and assessments. It has likewise impacted the use of bi-lingual (English and Roman-Urdu) text in the sub-continent (Pakistan, India, and Bangladesh) over social media. To develop and evaluate methods for bi-lingual author profiling, benchmark corpora are needed. The majority of previous efforts have focused on developing mono-lingual author profiling corpora for English and other languages. To fulfill this gap, this study aims to explore the problem of author profiling on bi-lingual data and presents a benchmark corpus of bi-lingual (English and Roman-Urdu) tweets. Our proposed corpus contains 339 author profiles and each profile is annotated with six different traits including age, gender, education level, province, language, and political party. As a secondary contribution, a range of deep learning methods, CNN, LSTM, Bi-LSTM, and GRU, are applied and compared on the three different bi-lingual corpora for age and gender identification, including our proposed corpus. Our extensive experimentation showed that the best results for both gender identification task (Accuracy = 0.882, F1-Measure = 0.839) and age identification (Accuracy = 0.735, F1-Measure = 0.739) are obtained using Bi-LSTM deep learning method. Our proposed bi-lingual tweets corpus is free and publicly available for research purposes.
C1 [Ashraf, Muhammad Adnan; Nie, Feiping] Northwestern Polytech Univ, Xian 710072, Peoples R China.
   [Nawab, Rao Muhammad Adeel] COMSATS Univ Islamabad, Lahore Campus, Lahore, Pakistan.
C3 Northwestern Polytechnical University; COMSATS University Islamabad
   (CUI)
RP Ashraf, MA (corresponding author), Northwestern Polytech Univ, Xian 710072, Peoples R China.
EM adnan.ashraf@mail.nwpu.edu.cn
RI Ashraf, Muhammad Adnan/AAZ-8341-2020; Ashraf, Muhammad
   Adnan/ABC-1341-2020
OI Ashraf, Muhammad Adnan/0000-0003-3865-1258
CR Abbasi A, 2005, IEEE INTELL SYST, V20, P67, DOI 10.1109/MIS.2005.81
   Abid F, 2019, FUTURE GENER COMP SY, V95, P292, DOI 10.1016/j.future.2018.12.018
   Afzal H, 2016, INT CONF ADV COMMUN, P710, DOI 10.1109/ICACT.2016.7423530
   Al-Rowaily K, 2015, DIGIT INVEST, V14, P53, DOI 10.1016/j.diin.2015.07.006
   BenVerhoeven W.D., 2016, P 10 ANN C LANG RES
   Burger J. D., 2011, P C EMP METH NAT LAN, P1301
   Chung J., 2014, ARXIV14123555
   Estival D., 2007, P 10 C PAC ASS COMP, P263
   Fatima M, 2018, NAT LANG ENG, V24, P695, DOI 10.1017/S1351324918000244
   Fatima M, 2017, INFORM PROCESS MANAG, V53, P886, DOI 10.1016/j.ipm.2017.03.005
   Gaustad T., 2007, P AUSTR LANG TECHN W, P21
   Graves A, 2005, IEEE IJCNN, P2047
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735
   Javed Iqra, 2014, Natural Language Processing and Information Systems. 19th International Conference on Applications of Natural Language to Information Systems, NLDB 2014. Proceedings: LNCS 8455, P232
   Javed I, 2014, LECT NOTES ARTIF INT, V8556, P523, DOI 10.1007/978-3-319-08979-9_40
   Kim Y., 2014, P EMNLP 2014, P1746, DOI 10.3115/v1/D14-1181
   Koppel M., 2002, Literary & Linguistic Computing, V17, P401, DOI 10.1093/llc/17.4.401
   Layton R, 2010, Proceedings Second Cybercrime and Trustworthy Computing Workshop (CTC 2010), P1, DOI 10.1109/CTC.2010.17
   Maharjan S., 2014, CLEF WORKING NOTES, V1180, P1121
   Nguyen D, 2013, 7 INT AAAI C WEBL SO
   Pennington J, 2014, EMNLP, P1532, DOI 10.3115/v1/D14-1162
   RANGEL F, 2018, WORKING NOTES PAPERS
   Rangel F, 2015, CLEF
   Rangel F., 2014, CEUR WORKSHOP PROC, P1
   Rangel F., 2013, CLEF C MULT MULT INF, P1
   Rangel F., 2016, WORKING NOTES PAPERS
   Rangel F., 2017, WORKING NOTES CLEF 2
   Rao D., 2010, P 2 INT WORKSH SEARC, P37, DOI [DOI 10.1145/1871985.1871993, 10.1145/1871985.1871993]
   SolerCompany J., 2015, 37 ANN M COGN SCI SO
   Yan G., 2014, COMPUTER NETWORKS, V75, P12
NR 30
TC 3
Z9 3
U1 0
U2 3
PU IOS PRESS
PI AMSTERDAM
PA NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS
SN 1064-1246
EI 1875-8967
J9 J INTELL FUZZY SYST
JI J. Intell. Fuzzy Syst.
PY 2020
VL 39
IS 2
BP 2379
EP 2389
DI 10.3233/JIFS-179898
PG 11
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NN0TJ
UT WOS:000568501000033
DA 2022-02-06
ER

PT J
AU Zotova, E
   Agerri, R
   Rigau, G
AF Zotova, Elena
   Agerri, Rodrigo
   Rigau, German
TI Semi-automatic generation of multilingual datasets for stance detection
   in Twitter
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Stance detection; Multilingualism; Text categorization; Fake news; Deep
   learning
ID TWEET
AB Popular social media networks provide the perfect environment to study the opinions and attitudes expressed by users. While interactions in social media such as Twitter occur in many natural languages, research on stance detection (the position or attitude expressed with respect to a specific topic) within the Natural Language Processing field has largely been done for English. Although some efforts have recently been made to develop annotated data in other languages, there is a telling lack of resources to facilitate multilingual and crosslingual research on stance detection. This is partially due to the fact that manually annotating a corpus of social media texts is a difficult, slow and costly process. Furthermore, as stance is a highly domain-and topic-specific phenomenon, the need for annotated data is specially demanding. As a result, most of the manually labeled resources are hindered by their relatively small size and skewed class distribution. This paper presents a method to obtain multilingual datasets for stance detection in Twitter. Instead of manually annotating on a per tweet basis, we leverage user-based information to semi-automatically label large amounts of tweets. Empirical monolingual and cross-lingual experimentation and qualitative analysis show that our method helps to overcome the aforementioned difficulties to build large, balanced and multilingual labeled corpora. We believe that our method can be easily adapted to easily generate labeled social media data for other Natural Language Processing tasks and domains.
C1 [Zotova, Elena] Vicomtech Fdn, SNLT Grp, Basque Res & Technol Alliance BRTA, Mendaro, Spain.
   [Agerri, Rodrigo; Rigau, German] Univ Basque Country UPV EHU, HiTZ Ctr Ixa, Leioa, Spain.
C3 University of Basque Country
RP Agerri, R (corresponding author), Univ Basque Country UPV EHU, HiTZ Ctr Ixa, Leioa, Spain.
EM ezotova@vicomtech.org; Rodrigo.Agerri@chu.eus; German.Rigau@chu.eus
RI Agerri, Rodrigo/ABA-4096-2021; Rigau, German/H-7235-2015
OI Agerri, Rodrigo/0000-0002-7303-7598; Rigau, German/0000-0003-1119-0930
FU Spanish Ministry of Science, Innovation and Universities
   (MCIU/AEI/FEDER, UE)Spanish Government [RTI2018-096846-BC21]; Fundacion
   BBVA a Equipos de Investigacion Cientifica 2018 (BigKnowledge); Basque
   GovernmentBasque Government; DeepText [KK-2020/00088];  [RYC-2017-23647]
FX This work has been partially funded by the Spanish Ministry of Science,
   Innovation and Universities (DeepReading RTI2018-096846-BC21,
   MCIU/AEI/FEDER, UE), Ayudas Fundacion BBVA a Equipos de Investigacion
   Cientifica 2018 (BigKnowledge), and DeepText (KK-2020/00088), funded by
   the Basque Government. Rodrigo Agerri is also funded by the
   RYC-2017-23647 fellowship and acknowledges the donation of a Titan V GPU
   by the NVIDIA Corporation.
CR Agerri R, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P4781
   Aldayel Abeer, 2019, Proceedings of the ACM on Human-Computer Interaction, V3, DOI 10.1145/3359307
   AlDayel A., 2020, ARXIV PREPRINT ARXIV
   Augenstein I., 2016, ARXIV160605464, P876
   Barbera P, 2015, POLIT ANAL, V23, P76, DOI 10.1093/pan/mpu011
   Benton A., 2018, P 4 WORKSH NOIS US G, P184, DOI DOI 10.18653/V1/W18-6124
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Bohler H., 2016, P 10 INT WORKSH SEM, P445, DOI 10.18653/v1/S16-1072
   Boyd D, 2010, P ANN HICSS, P1657
   Conneau A., 2019, ARXIV PREPRINT ARXIV
   Conneau A., 2019, ARXIVABS191102116
   Cuquerella C.A., 2018, CEUR WORKSHOP PROC, P167
   Dai ZH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2978
   Devlin J, 2019, PROC C N AM CHAPTER, P4171, DOI DOI 10.18653/V1/N19-1423
   Du J., 2017, P 26 INT JOINT C ART, P3988
   Evrard M, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P6317
   Fraisier O, 2018, HT'18: PROCEEDINGS OF THE 29TH ACM CONFERENCE ON HYPERTEXT AND SOCIAL MEDIA, P220, DOI 10.1145/3209542.3209549
   Ghosh S, 2019, LECT NOTES COMPUT SC, V11696, P75, DOI 10.1007/978-3-030-28577-7_4
   Grave E, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P3483
   Hahn N., P 10 INT WORKSH SEM, P420
   Heinzerling B, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P273
   Himelboim I, 2013, J COMPUT-MEDIAT COMM, V18, P40, DOI 10.1111/jcc4.12001
   Igarashi Y., 2016, P 10 INT WORKSH SEM, P401, DOI DOI 10.18653/V1/S16-1065
   Joulin A, 2017, PROC 15 INT C EUR CH, V2, P427, DOI DOI 10.18653/V1/E17-2068
   Junczys-Dowmunt M, 2018, 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P116
   Karthikeyan K., 2020, INT C LEARN REPR ICL, P1
   Kenter T, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P941
   Kucuk D, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3369026
   Lai M., 2017, IBEREVAL SEPLN, P1
   Lai M, 2020, COMPUT SPEECH LANG, V63, DOI 10.1016/j.csl.2020.101075
   Liu Y, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5070
   M`arquez L., 2018, P 2018 C N AM CHAPT, V2, P21
   Marsh A., 2016, P 10 INT WORKSH SEM, P458, DOI DOI 10.18653/V1/S16-1074
   McCallum A. K., 2002, MALLET MACHINE LEARN
   Mikolov T., 2013, ARXIV PREPRINT ARXIV
   Mohammad S, 2016, P 10 INT WORKSH SEM, P31
   Mohammad SM, 2017, ACM T INTERNET TECHN, V17, DOI 10.1145/3003433
   Mohtarami M., 2019, P 2019 C EMP METH NA, P4441
   Otte E, 2002, J INF SCI, V28, P441, DOI 10.1177/016555102762202123
   Pires T, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4996
   Procter R., 2017, SEMEVAL 2017 TASK 8, P69
   Segura-Bedmar I., 2018, P 3 WORKSH EV HUM LA, P180
   Siddiqua U.A., 2019, NAACL, V1, P1868, DOI DOI 10.18653/V1/N19-1185
   SPARCKJONES K, 1972, J DOC, V28, P11, DOI 10.1108/eb026526
   Steinberger J., 2017, CEUR WORKSHOP PROC, P176
   Sun Q., 2018, P 27 INT C COMP LING, P2399
   Taule M., 2018, CEUR WS C 20 WORK NO, P149
   Taule M., 2017, P 2 WORKSH EV HUM LA, P158
   Thomas J. A, 2006, ELEMENTS INFORM THEO
   Tiedemann J, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2214
   Uria B, 2016, J MACH LEARN RES, V17
   Vaswani A, 2017, ADV NEUR IN, V30
   Vychegzhanin SV, 2019, PROGRAM COMPUT SOFT+, V45, P228, DOI 10.1134/S0361768819050074
   Wang R, 2019, IEEE ACCESS, V7, P41101, DOI 10.1109/ACCESS.2019.2906754
   Wei P., 2018, INT JOINT C NEUR NET, P1
   Wei W., 2016, P 10 INT WORKSH SEM, P384, DOI DOI 10.18653/V1/S16-1062
   Wolf T., 2019, ARXIVABS191003771
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Zotova E, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P1368
   Zubiaga A, 2019, IEEE INTELL SYST, V34, P34, DOI 10.1109/MIS.2019.2958393
NR 60
TC 4
Z9 4
U1 4
U2 21
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD MAY 15
PY 2021
VL 170
AR 114547
DI 10.1016/j.eswa.2020.114547
PG 13
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic; Operations Research & Management Science
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Operations Research & Management Science
GA QT2IC
UT WOS:000626414500003
OA Green Submitted
DA 2022-02-06
ER

PT J
AU Giachanou, A
   Ghanem, B
   Rosso, P
AF Giachanou, Anastasia
   Ghanem, Bilal
   Rosso, Paolo
TI Detection of conspiracy propagators using psycho-linguistic
   characteristics
SO JOURNAL OF INFORMATION SCIENCE
LA English
DT Article; Early Access
DE Conspiracy propagators; linguistic analysis; social media analysis
ID IMPACT
AB The rise of social media has offered a fast and easy way for the propagation of conspiracy theories and other types of disinformation. Despite the research attention that has received, fake news detection remains an open problem and users keep sharing articles that contain false statements but which they consider real. In this article, we focus on the role of users in the propagation of conspiracy theories that is a specific type of disinformation. First, we compare profile and psycho-linguistic patterns of online users that tend to propagate posts that support conspiracy theories and of those who propagate posts that refute them. To this end, we perform a comparative analysis over various profile, psychological and linguistic characteristics using social media texts of users that share posts about conspiracy theories. Then, we compare the effectiveness of those characteristics for predicting whether a user is a conspiracy propagator or not. In addition, we propose ConspiDetector, a model that is based on a convolutional neural network (CNN) and which combines word embeddings with psycho-linguistic characteristics extracted from the tweets of users to detect conspiracy propagators. The results show that ConspiDetector can improve the performance in detecting conspiracy propagators by 8.82% compared with the CNN baseline with regard to F1-metric.
C1 [Giachanou, Anastasia; Ghanem, Bilal; Rosso, Paolo] Univ Politecn Valencia, Valencia, Spain.
   [Giachanou, Anastasia] Univ Utrecht, Utrecht, Netherlands.
   [Ghanem, Bilal] Symanto Res, Nurnberg, Germany.
C3 Universitat Politecnica de Valencia; Utrecht University
RP Giachanou, A (corresponding author), Univ Utrecht, Methodol & Stat, Padualaan 14, Utrecht, Netherlands.
EM a.giachanou@uu.nl
OI Giachanou, Anastasia/0000-0002-7601-8667
FU SNSF Early Postdoc Mobility grant under the project Early Fake News
   Detection on Social Media, Switzerland [P2TIP2_181441]; Spanish
   MICINNSpanish Government [PGC2018096212-B-C31]; European Cooperation in
   Science and Technology under the COST Action [17124]
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship and/or publication of this article: The work of
   the first author was supported by the SNSF Early Postdoc Mobility grant
   P2TIP2_181441 under the project Early Fake News Detection on Social
   Media, Switzerland. The work of the third author was partially funded by
   the Spanish MICINN under the research project MISMIS-FAKEnHATE on
   Misinformation and Miscommunication in Social Media: Fake News and Hate
   Speech (PGC2018096212-B-C31) and by the European Cooperation in Science
   and Technology under the COST Action 17124 DigForAsp.
CR Addawood Aseel, 2019, P INT AAAI C WEB SOC, V13, P15
   An A., 2017, P 2017 EUR C INF RET
   Bensley DA, 2020, APPL COGNITIVE PSYCH, V34, P16, DOI 10.1002/acp.3581
   Borge-Holthoefer J, 2013, J STAT PHYS, V151, P383, DOI 10.1007/s10955-012-0595-6
   Callaghan T, 2019, SOC SCI MED, V238, DOI 10.1016/j.socscimed.2019.112407
   Castillo C., 2011, WWW, P675
   Cer D, 2018, ARXIV180311175, DOI DOI 10.18653/V1/D18-2029
   Devlin J, 2019, PROC C N AM CHAPTER, P4171, DOI DOI 10.18653/V1/N19-1423
   DIGMAN JM, 1990, ANNU REV PSYCHOL, V41, P417, DOI 10.1146/annurev.psych.41.1.417
   Douglas KM, 2008, J SOC PSYCHOL, V148, P210, DOI 10.3200/SOCP.148.2.210-222
   Douglas KM, 2017, CURR DIR PSYCHOL SCI, V26, P538, DOI 10.1177/0963721417718261
   El Azab A., 2015, WORLD ACAD SCI ENG T, V10, P13
   Ghanem B, 2020, ACM T INTERNET TECHN, V20, DOI 10.1145/3381750
   Ghosh R., 2010, P KDD WORKSH SOC NET
   Giachanou Anastasia, 2020, Natural Language Processing and Information Systems. 25th International Conference on Applications of Natural Language to Information Systems, NLDB 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12089), P181, DOI 10.1007/978-3-030-51310-8_17
   Giachanou A, 2020, PR INT CONF DATA SC, P647, DOI 10.1109/DSAA49011.2020.00091
   Giachanou A, 2020, LECT NOTES ARTIF INT, V12284, P30, DOI 10.1007/978-3-030-58323-1_3
   Giachanou A, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P877, DOI 10.1145/3331184.3331285
   GOERTZEL T, 1994, POLIT PSYCHOL, V15, P731, DOI 10.2307/3791630
   Jolley D, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0089177
   Kang C., 2016, NY TIMES
   Kitsak M, 2010, NAT PHYS, V6, P888, DOI [10.1038/NPHYS1746, 10.1038/nphys1746]
   Klein C, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0225098
   Lantian A, 2017, SOC PSYCHOL-GERMANY, V48, P160, DOI 10.1027/1864-9335/a000306
   Lazer DMJ, 2018, SCIENCE, V359, P1094, DOI 10.1126/science.aao2998
   Lutzke L, 2019, GLOBAL ENVIRON CHANG, V58, DOI 10.1016/j.gloenvcha.2019.101964
   Ma J., 2015, P 24 ACM INT C INF K, V19-23, P1751, DOI DOI 10.1145/2806416.2806607
   MANN HB, 1947, ANN MATH STAT, V18, P50, DOI 10.1214/aoms/1177730491
   McCaffrey P., 2012, REFERENCE SHELF CONS
   Vo N, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P335, DOI 10.1145/3331184.3331248
   Pennebaker J.W., 2015, DEV PSYCHOMETRIC PRO
   Pennebaker JW, 1997, J PERS SOC PSYCHOL, V72, P863, DOI 10.1037/0022-3514.72.4.863
   Pennebaker JW, 1999, J PERS SOC PSYCHOL, V77, P1296, DOI 10.1037/0022-3514.77.6.1296
   Pennington J., 2014, EMNLP, P1532, DOI [10.3115/v1/D14-1162, DOI 10.3115/V1/D14-1162]
   PLUTCHIK R, 1982, SOC SCI INFORM, V21, P529, DOI 10.1177/053901882021004003
   Procter R., 2017, SEMEVAL 2017 TASK 8, P69
   Rangel F., 2020, CLEF 2020 LABS WORKS, V2696, P1
   Rangel F, 2016, INFORM PROCESS MANAG, V52, P73, DOI 10.1016/j.ipm.2015.06.003
   Rangel Francisco., 2019, P IEEE ACM 23 INT S, DOI DOI 10.1109/DS-RT47707.2019.8958692
   Rashkin Hannah, 2017, P 2017 C EMPIRICAL M, P2931
   Ruchansky N, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P797, DOI 10.1145/3132847.3132877
   Shu K, 2018, FAKENEWSNET DATA REP
   Shu K, 2018, IEEE 1ST CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2018), P430, DOI 10.1109/MIPR.2018.00092
   Singhal S, 2019, 2019 IEEE FIFTH INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2019), P39, DOI [10.1109/BigMM.2019.00018, 10.1109/BigMM.2019.00-44]
   Tambuscio M, 2019, APPL NETW SCI, V4, DOI 10.1007/s41109-019-0233-1
   Tausczik YR, 2010, J LANG SOC PSYCHOL, V29, P24, DOI 10.1177/0261927X09351676
   Turney P., 2010, P NAACL HLT 2010 WOR, P26
   Vlachos A, 2014, ACL, P18, DOI DOI 10.3115/V1/W14-2508
   Vosoughi S, 2018, SCIENCE, V359, P1146, DOI 10.1126/science.aap9559
   Wang WY, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P422, DOI 10.18653/v1/P17-2067
   Wardle C, 2017, INFORM DISORDER INTE
NR 51
TC 1
Z9 1
U1 1
U2 4
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 0165-5515
EI 1741-6485
J9 J INF SCI
JI J. Inf. Sci.
AR 0165551520985486
DI 10.1177/0165551520985486
EA JAN 2021
PG 15
WC Computer Science, Information Systems; Information Science & Library
   Science
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Information Science & Library Science
GA QZ6CK
UT WOS:000630811500001
DA 2022-02-06
ER

PT J
AU Dang, LM
   Hassan, SI
   Im, S
   Moon, H
AF Dang, L. Minh
   Hassan, Syed Ibrahim
   Im, Suhyeon
   Moon, Hyeonjoon
TI Face image manipulation detection based on a convolutional neural
   network
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Image manipulation; Deep learning; AdaBoost; XGBoost; Imbalanced
   dataset; Boosting
ID FORGERY DETECTION; LOCALIZATION; ENSEMBLE
AB Facial image manipulation is a particular instance of digital image tampering, which is done by corn positing a region from one facial image into another facial image. Fake images generated by facial image manipulation now spread like wildfire on news websites and social networks, and are considered the greatest threat to press freedom. Previous research relied heavily on handcrafted features to analyze tampered regions which were inefficient and time-consuming. This paper introduces a framework that accurately detects manipulated face image using deep learning approach. The original contributions of this paper include (1) a customized convolutional neural network model for Manipulated Face (MANFA) identification; it contains several convolutional layers that effectively extract features of multi-levels of abstraction from a tampered region. (2) A hybrid framework (HF-MANFA) that uses Adaptive Boosting (AdaBoost) and eXtreme Gradient Boosting (XGBoost) to deal with the imbalanced dataset challenge. (3) A large manipulated face dataset that is manually collected and validated. The results from various experiments proved that proposed models outperformed existing expert and intelligent systems which were usually used for the manipulated face image detection task in terms of area under the curve (AUC), computational complexity, and robustness against imbalanced datasets. As a result, the presented framework will motivate the finding of a more powerful altered face images detection method and encourages the integration of the proposed model in applications that have to deal with manipulated images regularly. (C) 2019 Elsevier Ltd. All rights reserved.
C1 [Dang, L. Minh; Hassan, Syed Ibrahim; Im, Suhyeon; Moon, Hyeonjoon] Sejong Univ, Dept Comp Sci & Engn, Seoul, South Korea.
C3 Sejong University
RP Moon, H (corresponding author), Sejong Univ, Dept Comp Sci & Engn, Seoul, South Korea.
EM hmoon@sejong.ac.kr
RI Dang, L. Minh/AAQ-4791-2020; Dang, L. Minh/T-8007-2019; Dang, L.
   Minh/O-9085-2018
OI Dang, L. Minh/0000-0001-7691-3453; 
FU Korea Institute of Planning and Evaluation for Technology in Food,
   Agriculture, Forestry and Fisheries (IPET) through Agri-Bio Industry
   Technology Development Program - Ministry of Agriculture, Food and Rural
   Affairs (MAFRA) [316033-04-2-338 SB030]
FX This work was supported by Korea Institute of Planning and Evaluation
   for Technology in Food, Agriculture, Forestry and Fisheries (IPET)
   through Agri-Bio Industry Technology Development Program, funded by
   Ministry of Agriculture, Food and Rural Affairs (MAFRA) (316033-04-2-338
   SB030).
CR Amerini I., 2017, P IEEE CVPR WORKSH M
   Andreassen CS, 2014, J COMPUT-MEDIAT COMM, V19, P906, DOI 10.1111/jcc4.12085
   Asghar K, 2017, AUST J FORENSIC SCI, V49, P281, DOI 10.1080/00450618.2016.1153711
   Bappy J. H, 2017, P IEEE INT C COMP VI
   Barni M, 2017, J VIS COMMUN IMAGE R, V49, P153, DOI 10.1016/j.jvcir.2017.09.003
   Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2
   Chen JK, 2017, MACH VISION APPL, V28, P173, DOI 10.1007/s00138-016-0817-z
   Chen T., P 22 ACM SIGKDD INT
   Chollet, 2015, KERAS DEEP LEARNING
   Cristin R, 2018, IET IMAGE PROCESS, V12, P1439, DOI 10.1049/iet-ipr.2017.1120
   Dang L.M., 2018, SUSTAINABLE COMPUTIN
   de Carvalho TJ, 2013, IEEE T INF FOREN SEC, V8, P1182, DOI 10.1109/TIFS.2013.2265677
   Dong J, 2013, SIGN INF PROC CHINAS
   Farooq S, 2017, COMPUT ELECTR ENG, V62, P459, DOI 10.1016/j.compeleceng.2017.05.008
   Fernandez A., 2018, COST SENSITIVE LEARN, P63
   Ferrara P, 2012, IEEE T INF FOREN SEC, V7, P1566, DOI 10.1109/TIFS.2012.2202227
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Friedman JH, 2002, COMPUT STAT DATA AN, V38, P367, DOI 10.1016/S0167-9473(01)00065-2
   Glorot X., 2011, P 14 INT C ART INT S
   Gu L, 2017, PDFL TREND MICRO, V81
   Guo JM, 2013, EXPERT SYST APPL, V40, P707, DOI 10.1016/j.eswa.2012.08.002
   He HB, 2009, IEEE T KNOWL DATA EN, V21, P1263, DOI 10.1109/TKDE.2008.239
   Holub V, 2015, IEEE T INF FOREN SEC, V10, P219, DOI 10.1109/TIFS.2014.2364918
   Hu Y., 2014, ICWSM
   Kazemi V., 2014, P IEEE C COMP VIS PA
   Khan SH, 2018, IEEE T NEUR NET LEAR, V29, P3573, DOI 10.1109/TNNLS.2017.2732482
   Khoshgoftaar T. M., 2015, TOOLS ART INT ICTAI
   Kingma DP, 2015, 3 INT C LEARN REPR I, DOI DOI 10.1145/1830483.1830503
   Lee S, 2016, EXPERT SYST APPL, V62, P347, DOI 10.1016/j.eswa.2016.06.039
   Lu C., 2017, MEMET COMPUT, V1, P1
   Moon H, 2001, PERCEPTION, V30, P303, DOI 10.1068/p2896
   Ng TT, 2009, COLUMBIA IMAGE SPLIC
   Nguyen TN, 2018, COMPOS STRUCT, V193, P268, DOI 10.1016/j.compstruct.2018.03.036
   Parkhi Omkar M, 2015, BMVC
   Peng B, 2017, IEEE T INF FOREN SEC, V12, P479, DOI 10.1109/TIFS.2016.2623589
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Ren SQ, 2018, NEUROCOMPUTING, V286, P150, DOI 10.1016/j.neucom.2018.01.063
   Wu F, 2017, AAAI
   Yao H, 2017, MULTIMED TOOLS APPL, V76, P12457, DOI 10.1007/s11042-016-3660-3
   Yu LA, 2018, APPL SOFT COMPUT, V69, P192, DOI 10.1016/j.asoc.2018.04.049
   Zeng H, 2017, MULTIMED TOOLS APPL, V76, P4783, DOI 10.1007/s11042-016-3712-8
   Zhou P, 2017, 2017 IEEE C COMP VIS
NR 42
TC 33
Z9 35
U1 1
U2 56
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD SEP 1
PY 2019
VL 129
BP 156
EP 168
DI 10.1016/j.eswa.2019.04.005
PG 13
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic; Operations Research & Management Science
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Operations Research & Management Science
GA HZ9DT
UT WOS:000469156700011
DA 2022-02-06
ER

PT J
AU Geng, Z
   Wang, BN
   Yan, H
   Zhang, JD
   Zhu, DY
AF Geng, Zhe
   Wang, Beining
   Yan, He
   Zhang, Jindong
   Zhu, Daiyin
TI Moving target detection and tracking with multiplatform radar network
   (MRN)
SO IET RADAR SONAR AND NAVIGATION
LA English
DT Article; Early Access
DE adaptive radar countermeasures; cognitive radar; deep neural network;
   internet of battlefield things (IoBT); MIMO radar; radar network
ID WAVE-FORM RECOGNITION; MIMO RADAR; COGNITIVE RADAR; PHASED-ARRAY;
   HYBRID-MIMO; DESIGN
AB A multiplatform radar network (MRN) composed of multiple transmitting and receiving facilities is advantageous over monostatic radar in moving target detection (MTD) and tracking due to the diversity gain. Within the framework of the Internet of Battlefield Things (IoBT), the authors propose that the airborne platforms equipped with the cognitive multimodal radar (CMR), the subarray-based MIMO radar (SMR), the active electronically scanned array (AESA) radar, and the adaptive radar countermeasures (ARC) should team up in target detection and tracking. To obtain better target detection and tracking performance, the probing signals from the CMR, the SMR, and the AESA radar are adaptively optimised based on the scenario under consideration. The ARC consists of two parts: 1) RF signal sensing and recognition with deep neural network (DNN), that is, to detect, identify, and localise multiple radio frequency emitters; 2) intelligent fake return creation and jamming to confuse the enemy radars in real time in the field. This work aims to serve as a good reference for future researchers interested in developing MRN with diverse nodes and the general teaming of radars on the battlefield.
C1 [Geng, Zhe; Wang, Beining; Yan, He; Zhang, Jindong; Zhu, Daiyin] Nanjing Univ Aeronaut & Astronaut, Coll Elect & Informat Engn, Off 138, Nanjing 210016, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics
RP Geng, Z (corresponding author), Nanjing Univ Aeronaut & Astronaut, Coll Elect & Informat Engn, Off 138, Nanjing 210016, Peoples R China.
EM zhe.geng@ieee.org
FU Research Funds for New Faculty of NUAA [1004-YAH19111]; Fundamental
   Research Funds for the Central UniversitiesFundamental Research Funds
   for the Central Universities [1004-XZA20014]; Natural Science Foundation
   from Jiangsu ProvinceNatural Science Foundation of Jiangsu Province
   [BK20200420]
FX Research Funds for New Faculty of NUAA, Grant/Award Number:
   1004-YAH19111; Fundamental Research Funds for the Central Universities,
   Grant/Award Number: 1004-XZA20014; Natural Science Foundation from
   Jiangsu Province, Grant/Award Number: BK20200420
CR Abuzainab N, 2018, IEEE INTERNET THINGS, V5, P378, DOI 10.1109/JIOT.2017.2786546
   Airbus, 2020, AIRB NEWSR
   Bell KL, 2015, IEEE J-STSP, V9, P1427, DOI 10.1109/JSTSP.2015.2465304
   Chernyak V, 2014, IEEE AERO EL SYS MAG, V29, P28, DOI 10.1109/MAES.2014.7015713
   Deng H., 2020, RADAR NETWORKS
   Feraidooni MM, 2020, IEEE COMMUN LETT, V24, P1115, DOI 10.1109/LCOMM.2020.2971210
   Feraidooni MM, 2020, SIGNAL PROCESS, V174, DOI 10.1016/j.sigpro.2020.107620
   Feraidooni MM, 2019, SIGNAL IMAGE VIDEO P, V13, P1275, DOI 10.1007/s11760-019-01475-8
   Freitas J, 2020, IEEE SIG PROC MED, DOI 10.1109/SPMB50085.2020.9353617
   Fuhrmann DR, 2010, IEEE J-STSP, V4, P66, DOI 10.1109/JSTSP.2009.2038968
   Geng Z., 2017, 2017 INT C RAD SYST, P1
   Geng Z, 2021, IEEE ACCESS, V9, P141800, DOI 10.1109/ACCESS.2021.3119561
   Geng Z, 2020, IEEE ACCESS, V8, P124961, DOI 10.1109/ACCESS.2020.3007774
   Ghadimi G, 2020, J COMMUN TECHNOL EL+, V65, P1179, DOI 10.1134/S1064226920100034
   Godrich H, 2010, IEEE T INFORM THEORY, V56, P2783, DOI 10.1109/TIT.2010.2046246
   Haimovich AM, 2008, IEEE SIGNAL PROC MAG, V25, P116, DOI 10.1109/MSP.2008.4408448
   Hassanien A, 2010, IEEE T SIGNAL PROCES, V58, P3137, DOI 10.1109/TSP.2010.2043976
   Haykin I, 2006, IEEE SIGNAL PROC MAG, V23, P30, DOI 10.1109/MSP.2006.1593335
   He QA, 2010, IEEE T AERO ELEC SYS, V46, P1290, DOI 10.1109/TAES.2010.5545189
   Hoehn J.R, 2021, JOINT ALL DOMAIN COM
   Huang L, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21113887
   Huleihel W, 2013, IEEE T SIGNAL PROCES, V61, P5075, DOI 10.1109/TSP.2013.2269045
   Iandola F.N., 2016, ARXIV160207360
   Kong SH, 2018, IEEE ACCESS, V6, P4207, DOI 10.1109/ACCESS.2017.2788942
   Kott A, 2016, COMPUTER, V49, P70, DOI 10.1109/MC.2016.355
   La Manna M.L., 2016, 2016 IEEE RAD C RADA, P1
   La Manna M, 2017, IEEE J-STSP, V11, P404, DOI 10.1109/JSTSP.2016.2627187
   Lee GH, 2020, SECUR COMMUN NETW, V2020, DOI 10.1155/2020/2151570
   Li HB, 2015, IEEE J-STSP, V9, P1524, DOI 10.1109/JSTSP.2015.2467355
   Li J, 2020, IEEE SIGNAL PROC LET, V27, P1969, DOI 10.1109/LSP.2020.3022239
   Li J, 2018, IEEE RAD CONF, P1439, DOI 10.1109/RADAR.2018.8378776
   Ni X, 2021, IEEE ACCESS, V9, P26138, DOI 10.1109/ACCESS.2021.3058305
   Office of the Secretary of Defense, 2020, DEP DEF FISC YEAR FY
   Orduyilmaz A, 2021, SIGNAL IMAGE VIDEO P, V15, P1653, DOI 10.1007/s11760-021-01901-w
   Pan ZS, 2020, IEEE SIGNAL PROC LET, V27, P1275, DOI 10.1109/LSP.2020.3009195
   Romero RA, 2013, IEEE T AERO ELEC SYS, V49, P915, DOI 10.1109/TAES.2013.6494389
   Sandler M., 2018, INVERTED RESIDUALS L
   Seok-Jun Hong, 2018, 2018 Tenth International Conference on Ubiquitous and Future Networks (ICUFN), P894, DOI 10.1109/ICUFN.2018.8436647
   Sharaga N, 2015, IEEE J-STSP, V9, P1440, DOI 10.1109/JSTSP.2015.2467354
   The MathWorks Inc, RAD COMM WAV CLASS U
   Wan J, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11050725
   Wang WQ, 2013, IEEE SENS J, V13, DOI 10.1109/JSEN.2012.2232909
   Wei SJ, 2020, SIGNAL IMAGE VIDEO P, V14, P1133, DOI 10.1007/s11760-020-01652-0
   Xu JW, 2017, IEEE J-STSP, V11, P309, DOI 10.1109/JSTSP.2016.2615269
   Xu JW, 2015, IEEE T SIGNAL PROCES, V63, P3396, DOI 10.1109/TSP.2015.2422680
   Zhang G., 2016, WEATHER RADAR POLARI
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhou QS, 2020, DIGIT SIGNAL PROCESS, V101, DOI 10.1016/j.dsp.2020.102709
NR 48
TC 0
Z9 0
U1 3
U2 3
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 1751-8784
EI 1751-8792
J9 IET RADAR SONAR NAV
JI IET Radar Sonar Navig.
DI 10.1049/rsn2.12222
EA DEC 2021
PG 10
WC Engineering, Electrical & Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Telecommunications
GA XU6VZ
UT WOS:000734401100001
OA gold
DA 2022-02-06
ER

PT J
AU Yang, JC
   Li, AY
   Xiao, S
   Lu, W
   Gao, XB
AF Yang, Jiachen
   Li, Aiyun
   Xiao, Shuai
   Lu, Wen
   Gao, Xinbo
TI MTD-Net: Learning to Detect Deepfakes Images by Multi-Scale Texture
   Difference
SO IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY
LA English
DT Article
DE Faces; Forgery; Videos; Feature extraction; Databases; Information
   integrity; Deep learning; Face forgery detection; multi-scale; texture
   difference
ID MANIPULATION; MODELS
AB With the rapid development of face manipulation technology, it is difficult for human eyes to distinguish fake face images. On the contrary, Convolutional Neural Network (CNN) discriminators can quickly reach high accuracy in identifying fake/real face images. In this study, we explore the behavior of CNN models in distinguish fake/real faces. We find multi-scale texture difference information plays an important role in face forgery detection. Motivated by the above observation, we propose a new Multi-scale Texture Difference model coined as MTD-Net for robust face forgery detection, which leverages central difference convolution (CDC) and atrous spatial pyramid pooling (ASPP). CDC combines the pixel intensity information and the pixel gradient information to give a stationary description of texture difference information. Simultaneously, based on the ASPP, multi-scale information fusion can keep the texture features from being destroyed. Experimental results on several databases, Faceforensics++, DeeperForensics-1.0, Celeb-DF and DFDC prove that our MTD-Net outperforms existing approaches. The MTD-Net is more robust to image distortion, e.g., JPEG compression and blur, which is urgently needed in the wild world.
C1 [Yang, Jiachen; Li, Aiyun; Xiao, Shuai] Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
   [Lu, Wen] Xidian Univ, Sch Elect Engn, Xian 710071, Peoples R China.
   [Gao, Xinbo] Chongqing Univ Posts & Telecommun, Chongqing Key Lab Image Cognit, Chongqing 400065, Peoples R China.
C3 Tianjin University; Xidian University; Chongqing University of Posts &
   Telecommunications
RP Xiao, S (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
EM yangjiachen@tju.edu.cn; liaiyun@tju.edu.cn; xs611@tju.edu.cn;
   luwen@mail.xidian.edu.cn; gaoxb@cqupt.edu.cn
OI Xiao, Shuai/0000-0003-4058-8120; Yang, Jiachen/0000-0003-2558-552X
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61871283]; Foundation of Pre-Research on
   Equipment of China [61400010304]; Major Civil-Military Integration
   Project in Tianjin, China [18ZXJMTG00170]
FX Manuscript received May 18, 2021; revised July 15, 2021; accepted July
   16, 2021. Date of publication August 3, 2021; date of current version
   August 30, 2021. This work was supported in part by the National Natural
   Science Foundation of China under Grant 61871283, in part by the
   Foundation of Pre-Research on Equipment of China under Grant
   61400010304, and in part by the Major Civil-Military Integration Project
   in Tianjin, China under Grant 18ZXJMTG00170. The associate editor
   coordinating the review of this manuscript and approving it for
   publication was Dr. Alessandro Piva. (Corresponding author: Shuai Xiao.)
CR Afchar D, 2018, IEEE INT WORKS INFOR
   Amerini I, 2019, IEEE INT CONF COMP V, P1205, DOI 10.1109/ICCVW.2019.00152
   [Anonymous], 2017, RETHINKING ATROUS CO
   Bahrami K, 2015, IEEE T INF FOREN SEC, V10, P999, DOI 10.1109/TIFS.2015.2394231
   Bayar B, 2018, IEEE T INF FOREN SEC, V13, P2691, DOI 10.1109/TIFS.2018.2825953
   Bianchi T, 2013, IEEE INT WORKS INFOR, P168, DOI 10.1109/WIFS.2013.6707813
   Bondi L, 2020, IEEE INT WORKS INFOR, DOI 10.1109/WIFS49906.2020.9360901
   Bonettini N., 2020, ARXIV200407676
   Ciftci Umur Aybars, 2020, IEEE Trans Pattern Anal Mach Intell, VPP, DOI 10.1109/TPAMI.2020.3009287
   Cozza D., 2015, 2015 IEEE 42nd Photovoltaic Specialist Conference (PVSC). Proceedings, P1, DOI 10.1109/PVSC.2015.7355795
   Cozzolino Davide, 2017, P 5 ACM WORKSH INF H, P159, DOI DOI 10.1145/3082031.3083247
   de Carvalho TJ, 2013, IEEE T INF FOREN SEC, V8, P1182, DOI 10.1109/TIFS.2013.2265677
   Dolhansky B., 2020, DEEPFAKE DETECTION C
   Dumoulin V., 2016, ARXIV160307285
   Durall Ricard, 2019, ARXIV191100686
   Ferrara P, 2012, IEEE T INF FOREN SEC, V7, P1566, DOI 10.1109/TIFS.2012.2202227
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hernandez-Ortega J., 2020, ARXIV201000400
   Huh M, 2018, LECT NOTES COMPUT SC, V11215, P106, DOI 10.1007/978-3-030-01252-6_7
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jiang LM, 2020, PROC CVPR IEEE, P2886, DOI 10.1109/CVPR42600.2020.00296
   Kingma D., 2013, ARXIV13126114
   Kingma DP, 2015, 3 INT C LEARN REPR I, DOI DOI 10.1145/1830483.1830503
   Kirchner M, 2010, MM&SEC 2010: 2010 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, PROCEEDINGS, P13
   Koltun V, 2016, INT C LEARN REPR
   Kumar A, 2020, PSYCHON B REV, P1, DOI DOI 10.3758/s13423-020-01792-x
   Li LZ, 2020, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR42600.2020.00505
   Li YZ, 2018, IEEE INT WORKS INFOR
   Li Yuezun, 2019, IEEE C COMP VIS PATT
   Lin KY, 2018, PROC CVPR IEEE, P732, DOI 10.1109/CVPR.2018.00083
   Liu Zhengzhe, 2020, P IEEE CVF C COMP VI, P8060, DOI DOI 10.1109/CVPR42600.2020.00808
   Loshchilov Ilya, 2017, ICLR
   Lukas J, 2006, IEEE T INF FOREN SEC, V1, P205, DOI 10.1109/TIFS.2006.873602
   Matern F, 2020, IEEE T INF FOREN SEC, V15, P1303, DOI 10.1109/TIFS.2019.2935913
   Matern F, 2019, IEEE WINT CONF APPL, P83, DOI 10.1109/WACVW.2019.00020
   Mayer O, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2012, DOI 10.1109/ICASSP.2018.8462585
   Qian Yuyang, 2020, ECCV
   Rahman N., 2018, P INT ANN C AM SOC E, P1
   Redi JA, 2011, MULTIMED TOOLS APPL, V51, P133, DOI 10.1007/s11042-010-0620-1
   Rossler A, 2019, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2019.00009
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Thai TH, 2017, IEEE T INF FOREN SEC, V12, P123, DOI 10.1109/TIFS.2016.2604208
   Thies J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323035
   Thies J, 2019, COMMUN ACM, V62, P96, DOI 10.1145/3292039
   Tolosana R., 2020, ARXIV PREPRINT ARXIV
   Wang R., 2020, P INT JOINT C ART IN, P3444
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Wen JB, 2021, IEEE T FUZZY SYST, V29, P4, DOI 10.1109/TFUZZ.2020.3012393
   Yang J., 2020, IEEE T INTELL TRANSP, V94, P91, DOI [10.1016/j.ijid.2020.03.017, DOI 10.1109/TITS.2020.3023788]
   Yang JC, 2021, FUTURE GENER COMP SY, V125, P127, DOI 10.1016/j.future.2021.06.043
   Yu ZT, 2020, PROC CVPR IEEE, P5294, DOI 10.1109/CVPR42600.2020.00534
   Yuezun Li, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P3204, DOI 10.1109/CVPR42600.2020.00327
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
   Zhou P, 2018, PROC CVPR IEEE, P1053, DOI 10.1109/CVPR.2018.00116
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 58
TC 0
Z9 0
U1 6
U2 6
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1556-6013
EI 1556-6021
J9 IEEE T INF FOREN SEC
JI IEEE Trans. Inf. Forensic Secur.
PY 2021
VL 16
BP 4234
EP 4245
DI 10.1109/TIFS.2021.3102487
PG 12
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UK8IE
UT WOS:000692207600007
DA 2022-02-06
ER

PT J
AU Damiano, R
   Patti, V
   Clavel, C
   Rosso, P
AF Damiano, Rossana
   Patti, Viviana
   Clavel, Chloe
   Rosso, Paolo
TI Introduction to the Special Section on Computational Modeling and
   Understanding of Emotions in Conflictual Social Interactions
SO ACM TRANSACTIONS ON INTERNET TECHNOLOGY
LA English
DT Article
DE Affective computing; socio-affective behavior; social interactions; hate
   speech detection
C1 [Damiano, Rossana; Patti, Viviana] Univ Turin, Dipartimento Informat, Corso Svizzera 185, I-10149 Turin, Italy.
   [Clavel, Chloe] Inst Polytech Paris, Telecom Paris, LTCI, F-75013 Paris, France.
   [Rosso, Paolo] Univ Politecn Valencia, Camino Vera S-N, E-46022 Valencia, Spain.
C3 University of Turin; IMT - Institut Mines-Telecom; Institut
   Polytechnique de Paris; Universitat Politecnica de Valencia
RP Damiano, R (corresponding author), Univ Turin, Dipartimento Informat, Corso Svizzera 185, I-10149 Turin, Italy.
EM rossana.damiano@unito.it; patti@di.unito.it;
   chloe.clavel@telecom-paristech.fr
FU French National Research AgencyFrench National Research Agency (ANR)
   [ANR17-MAOI]; European project H2020 ANIMATAS [MSCA-ITN-ETN 7659552];
   Progetto di Ateneo/CSP 2016 (Immigrants, Hate and Prejudice in Social
   Media) [S1618_L2_BOSC_01]; Spanish MICINN under the research project
   MISMIS-FAKEnHATE on MISinformation and MIScommunication in social media:
   FAKE news and HATE speech [PGC2018-096212-B-C31]
FX The editorial work of C. Clavel for this special issue was partially
   supported by a grant overseen by the French National Research Agency
   (ANR17-MAOI) and by the European project H2020 ANIMATAS (MSCA-ITN-ETN
   7659552). The editorial work of V. Patti was partially funded by
   Progetto di Ateneo/CSP 2016 (Immigrants, Hate and Prejudice in Social
   Media, S1618_L2_BOSC_01). P. Rosso was partially funded by Spanish
   MICINN under the research project MISMIS-FAKEnHATE on MISinformation and
   MIScommunication in social media: FAKE news and HATE speech
   (PGC2018-096212-B-C31).
CR Basile V., 2019, SEMEVAL NAACL HLT, DOI DOI 10.18653/V1/S19-2007
   Bassignana Elisa, 2018, P 5 IT C COMP LING C, P6
   Bosco Cristina, 2018, P 6 EV CAMP NAT LANG
   Brady WJ, 2017, P NATL ACAD SCI USA, V114, P7313, DOI 10.1073/pnas.1618923114
   Corazza M, 2020, ACM T INTERNET TECHN, V20, DOI 10.1145/3377323
   Davidson T., 2017, P 11 INT C WEB SOC M, P512
   deAlbornoz, 2018, CEUR WORKSHOP P, V2150, P214
   EU Commission, 2016, EU COD COND COUNT IL
   Fortuna P, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3232676
   Gupta K, 2020, ACM T INTERNET TECHN, V20, DOI 10.1145/3372045
   Haidt J, 2003, SER AFFECTIVE SCI, P852
   Pamungkas EW, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019:): STUDENT RESEARCH WORKSHOP, P363
   Paschalides D, 2020, ACM T INTERNET TECHN, V20, DOI 10.1145/3371276
   Plaza-Del-Arco FM, 2020, ACM T INTERNET TECHN, V20, DOI 10.1145/3369869
   Plutchik R, 2001, AM SCI, V89, P344, DOI 10.1511/2001.4.344
   Ruppenhofer J, P GERMEVAL 2018 WORK, P1
   Sanguinetti Manuela, 2018, P 11 INT C LANG RES, P8
   Schmidt A., 2017, P 5 INT WORKSHOP NAT, P1, DOI [10.18653/v1/W17-1101, DOI 10.18653/V1/W17-1101]
   Wang Shuo, 2020, ACM T INTERNET TECHN, V20, P1
   Wilmot W., 2013, INTERPERSONAL CONFLI
NR 20
TC 0
Z9 0
U1 1
U2 4
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1533-5399
EI 1557-6051
J9 ACM T INTERNET TECHN
JI ACM Trans. Internet. Technol.
PD MAY
PY 2020
VL 20
IS 2
AR 8
DI 10.1145/3392334
PG 5
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OJ1BU
UT WOS:000583703300001
OA Bronze, Green Published
DA 2022-02-06
ER

PT J
AU Uchiyama, K
   Kawamoto, K
AF Uchiyama, Kodai
   Kawamoto, Kazuhiko
TI Audio-Visual Model for Generating Eating Sounds Using Food ASMR Videos
SO IEEE ACCESS
LA English
DT Article
DE Videos; Spectrogram; Faces; Visualization; Feature extraction;
   Predictive models; Face recognition; Multi-modal deep neural network;
   autonomous sensory meridian response; eating sound generation
AB We present an audio-visual model for generating food texture sounds from silent eating videos. We designed a deep network-based model that takes the visual features of the detected faces as input and outputs a magnitude spectrogram that aligns with the visual streams. Generating raw waveform samples directly from a given input visual stream is challenging; in this study, we used the Griffin-Lim algorithm for phase recovery from the predicted magnitude to generate raw waveform samples using inverse short-time Fourier transform. Additionally, we produced waveforms from these magnitude spectrograms using an example-based synthesis procedure. To train the model, we created a dataset containing several food autonomous sensory meridian response videos. We evaluated our model on this dataset and found that the predicted sound features exhibit appropriate temporal synchronization with the visual inputs. Our subjective evaluation experiments demonstrated that the predicted sounds are considerably realistic to fool participants in a "real" or "fake" psychophysical experiment.
C1 [Uchiyama, Kodai] Chiba Univ, Grad Sch Sci & Engn, Chiba 2638522, Japan.
   [Kawamoto, Kazuhiko] Chiba Univ, Grad Sch Engn, Chiba 2638522, Japan.
C3 Chiba University; Chiba University
RP Kawamoto, K (corresponding author), Chiba Univ, Grad Sch Engn, Chiba 2638522, Japan.
EM kawa@faculty.chiba-u.jp
RI Kawamoto, Kazuhiko/AAL-7618-2021
OI Kawamoto, Kazuhiko/0000-0003-3701-1961
FU Japan Society for the Promotion of Science (JSPS) KAKENHIMinistry of
   Education, Culture, Sports, Science and Technology, Japan (MEXT)Japan
   Society for the Promotion of ScienceGrants-in-Aid for Scientific
   Research (KAKENHI) [JP19K12039]
FX This work was supported by Japan Society for the Promotion of Science
   (JSPS) KAKENHI under Grant JP19K12039.
CR Afouras T, 2018, INTERSPEECH, P3244
   Akbari H, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2516, DOI 10.1109/ICASSP.2018.8461856
   Chen K., 2019, LECT NOTES COMPUTER, V11134
   Chen LL, 2017, PROCEEDINGS OF THE THEMATIC WORKSHOPS OF ACM MULTIMEDIA 2017 (THEMATIC WORKSHOPS'17), P349, DOI 10.1145/3126686.3126723
   Chen PH, 2020, IEEE T IMAGE PROCESS, V29, P8292, DOI 10.1109/TIP.2020.3009820
   Chuang Gan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10475, DOI 10.1109/CVPR42600.2020.01049
   Cole F, 2017, PROC CVPR IEEE, P3386, DOI 10.1109/CVPR.2017.361
   Elder RS, 2016, FOOD QUAL PREFER, V51, P39, DOI 10.1016/j.foodqual.2016.02.015
   Ephrat A, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201357
   Gao RH, 2019, IEEE I CONF COMP VIS, P3878, DOI 10.1109/ICCV.2019.00398
   GRIFFIN DW, 1984, IEEE T ACOUST SPEECH, V32, P236, DOI 10.1109/TASSP.1984.1164317
   Owens A, 2016, PROC CVPR IEEE, P2405, DOI 10.1109/CVPR.2016.264
   Rasukaru Ogui, 2019, ASMR CHEESE CORN DOG
   Rix AW, 2001, INT CONF ACOUST SPEE, P749, DOI 10.1109/ICASSP.2001.941023
   Rudd EM, 2016, LECT NOTES COMPUT SC, V9909, P19, DOI 10.1007/978-3-319-46454-1_2
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Vanden Oord A., 2016, WAVENET GENERATIVE M, P1
   Zhang KP, 2016, IEEE SIGNAL PROC LET, V23, P1499, DOI 10.1109/LSP.2016.2603342
   Zhou YP, 2018, PROC CVPR IEEE, P3550, DOI 10.1109/CVPR.2018.00374
NR 20
TC 0
Z9 0
U1 2
U2 3
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2021
VL 9
BP 50106
EP 50111
DI 10.1109/ACCESS.2021.3069267
PG 6
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA RJ3RS
UT WOS:000637515900001
OA gold
DA 2022-02-06
ER

PT J
AU Mutlu, U
   Alpaydin, E
AF Mutlu, Uras
   Alpaydin, Ethem
TI Training bidirectional generative adversarial networks with hints
SO PATTERN RECOGNITION
LA English
DT Article
DE Generative Modeling; Generative Adversarial Networks; Unsupervised
   Learning; Autoencoders; Neural Networks; Deep Learning
AB The generative adversarial network (GAN) is composed of a generator and a discriminator where the generator is trained to transform random latent vectors to valid samples from a distribution and the discriminator is trained to separate such "fake" examples from true examples of the distribution, which in turn forces the generator to generate better fakes. The bidirectional GAN (BiGAN) also has an encoder working in the inverse direction of the generator to produce the latent space vector for a given example. This added encoder allows defining auxiliary reconstruction losses as hints for a better generator. On five widely-used data sets, we showed that BiGANs trained with the Wasserstein loss and augmented with hints learn better generators in terms of image generation quality and diversity, as measured numerically by the 1-nearest neighbor test, Frechet inception distance, and reconstruction error, and qualitatively by visually analyzing the generated samples. (C) 2020 Elsevier Ltd. All rights reserved.
C1 [Mutlu, Uras; Alpaydin, Ethem] Bogazici Univ, Dept Comp Engn, TR-34342 Istanbul, Turkey.
C3 Bogazici University
RP Mutlu, U (corresponding author), Bogazici Univ, Dept Comp Engn, TR-34342 Istanbul, Turkey.
EM uras.mutlu@boun.edu.tr; alpaydin@boun.edu.tr
OI Mutlu, Uras/0000-0002-6844-3153
FU Bogazici University Research FundsBogazici University [18A01P7]
FX This work is partially supported by Bogazici University Research Funds
   with Grant Number 18A01P7. We also thank TETAM for the computing
   facilities provided.
CR Arjovsky M, 2017, ARXIV170107875
   Arjovsky M., 2017, INT C LEARN REPR
   Atapour-Abarghouei A, 2019, PATTERN RECOGN, V91, P232, DOI 10.1016/j.patcog.2019.02.010
   Bang D., 2018, ARXIV180510717
   Berthelot David, 2017, ARXIV170310717
   Brock A., 2016, ARXIV160907093
   Donahue J., 2016, ARXIV160509782
   Dumoulin V., 2016, ARXIV160600704
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Gulrajani I, 2017, ADV NEURAL INFORM PR, P5767
   Heusel M., 2017, ADV NEURAL INFORM PR, V30, P6626
   Hong Y., 2019, ARXIV171105914
   Intrator Y., 2018, ARXIV181005221
   Jaitly N., 2015, ARXIV PREPRINT ARXIV
   Karras T, 2018, PROGRESSIVE GROWING
   Kim T., 2017, ARXIV170305192
   Kingma D. P., 2014, ARXIV13126114, DOI DOI 10.1007/S11042-018-6187-Y
   Larsen A. B. L., 2015, ARXIV151209300
   LeCun Yann, 2016, ARXIV 1609 03126
   Li C., 2017, ADV NEURAL INFORM PR, V2017, P5495
   Lopez-Paz D., 2016, ARXIV161006545
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Mescheder L., 2017, ARXIV170104722
   Qi G. J., 2017, ARXIV170106264
   Radford A., 2015, ARXIV151106434
   Rosca Mihaela, 2017, ARXIV170604987
   Srivastava A., 2017, NIPS, P3308
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Xu Q, 2018, ARXIV PREPRINT ARXIV
   Xu WJ, 2019, PATTERN RECOGN, V93, P570, DOI 10.1016/j.patcog.2019.05.017
   Yi ZL, 2017, IEEE I CONF COMP VIS, P2868, DOI 10.1109/ICCV.2017.310
   Zhu J.-Y., 2017, ARXIV170310593
NR 32
TC 7
Z9 7
U1 3
U2 14
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 0031-3203
EI 1873-5142
J9 PATTERN RECOGN
JI Pattern Recognit.
PD JUL
PY 2020
VL 103
AR 107320
DI 10.1016/j.patcog.2020.107320
PG 10
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LK4PB
UT WOS:000530845000047
DA 2022-02-06
ER

PT J
AU Narayanan, A
   Verma, S
   Ramadan, E
   Babaie, P
   Zhang, ZL
AF Narayanan, Arvind
   Verma, Saurabh
   Ramadan, Eman
   Babaie, Pariya
   Zhang, Zhi-Li
TI Making Content Caching Policies 'Smart' using the DEEPCACHE Framework
SO ACM SIGCOMM COMPUTER COMMUNICATION REVIEW
LA English
DT Article; Proceedings Paper
CT ACM SIGCOMM Workshop on Network Meets AI and ML (NetAI)
CY AUG 20-24, 2018
CL Budapest, HUNGARY
DE DeepCache; deep learning; machine learning; caching; 1stm; seq2seq;
   smart caching policies; cache hit; video object caches; prefetching;
   proactive caching; popularity prediction; fake requests
AB In this paper, we present DEEPCACHE a novel Framework for content caching, which can significantly boost cache performance. Our Framework is based on powerful deep recurrent neural network models. It comprises of two main components: i) Object Characteristics Predictor, which builds upon deep LSTM Encoder-Decoder model to predict the future characteristics of an object (such as object popularity) - to the best of our knowledge, we are the first to propose LSTM Encoder-Decoder model for content caching; ii) a caching policy component, which accounts for predicted information of objects to make smart caching decisions. In our thorough experiments, we show that applying DEEPCACHE Framework to existing cache policies, such as LRU and k-LRU, significantly boosts the number of cache hits.
C1 [Narayanan, Arvind; Verma, Saurabh; Ramadan, Eman; Babaie, Pariya; Zhang, Zhi-Li] Univ Minnesota, Minneapolis, MN 55455 USA.
C3 University of Minnesota System; University of Minnesota Twin Cities
RP Narayanan, A (corresponding author), Univ Minnesota, Minneapolis, MN 55455 USA.
EM arvind@cs.umn.edu; verma@cs.umn.edu; eman@cs.umn.edu;
   babai008@cs.umn.edu; zhzhang@cs.umn.edu
OI Ramadan, Eman/0000-0002-8931-0691
FU US NSFNational Science Foundation (NSF) [CNS-1411636, CNS-1618339,
   CNS-1617729]; DTRAUnited States Department of DefenseDefense Threat
   Reduction Agency [HDTRA1-14-1-0040]; Huawei gift
FX This research was supported in part by US NSF grant CNS-1411636,
   CNS-1618339 and CNS-1617729, DTRA grant HDTRA1-14-1-0040, and a Huawei
   gift.
CR [Anonymous], 2017, CISCO VISUAL NETWORK, P2016
   Bahdanau D., 2014, ARXIV PREPRINT ARXIV
   BASU S., ADAPTIVE TTL BASED C, V45, P45
   Che H, 2001, IEEE INFOCOM SER, P1416, DOI 10.1109/INFCOM.2001.916637
   Chung J., 2014, ARXIV
   FERRAGUT A., OPTIMIZING TTL CACHE, V44, P101
   Graves A, 2014, PR MACH LEARN RES, V32, P1764
   Gregor K., 2015, ARXIV150204623
   Hashemi M., 2018, ARXIV180302329
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735
   Jacobson V., 2009, P 5 INT C EM NETW EX, P1, DOI DOI 10.1145/1658939.1658941
   Koponen T, 2007, ACM SIGCOMM COMP COM, V37, P181, DOI 10.1145/1282427.1282402
   Mao H., 2017, P C ACM SPEC INT GRO
   Martina V, 2014, IEEE INFOCOM SER, P2040, DOI 10.1109/INFOCOM.2014.6848145
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045
   Ramadan E., 2015, 2015 IEEE ICMEW, P1, DOI [10.1109/ICMEW.2015.7169811, DOI 10.1109/ICMEW.2015.7169811]
   Sadeghi A, 2018, IEEE J-STSP, V12, P180, DOI 10.1109/JSTSP.2017.2787979
   SHAFIO M. Z., REVISITING CACHING C, V42, P567
   SUTSKEVER I., NIPS 14
   TANG W., 2003, NOSSDAV
NR 20
TC 3
Z9 3
U1 1
U2 7
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 0146-4833
EI 1943-5819
J9 ACM SIGCOMM COMP COM
JI ACM SIGCOMM Comp. Commun. Rev.
PD OCT
PY 2018
VL 48
IS 5
BP 64
EP 69
DI 10.1145/3310165.3310174
PG 6
WC Computer Science, Information Systems
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA HJ4RL
UT WOS:000457161300008
DA 2022-02-06
ER

PT J
AU Ren, YP
   Ren, HP
   Shi, CH
   Zhang, X
   Wu, X
   Li, XJ
   Lv, JC
   Zhou, JL
   Mumtaz, I
AF Ren, Yongpeng
   Ren, Hongping
   Shi, Canghong
   Zhang, Xian
   Wu, Xi
   Li, Xiaojie
   Lv, Jiancheng
   Zhou, Jiliu
   Mumtaz, Imran
TI Multistage semantic-aware image inpainting with stacked generator
   networks
SO INTERNATIONAL JOURNAL OF INTELLIGENT SYSTEMS
LA English
DT Article
DE coarse-to-fine hierarchical representation; deep learning; image
   inpainting; semantic information; stacked generator networks
AB Deep learning has been widely applied into image inpainting. However, traditional image processing methods (i.e., patch-based and diffusion-based methods) generally fail to produce visually natural contents and semantically reasonable structures due to ineffectively processing the high-level semantic information of images. To solve the problem, we propose a stacked generator networks assisted by patch discriminator for image inpainting by multistage. In the proposed method, our generator network mainly consists of three-layer stacked encoder-decoder architecture, which could fuse different level feature information and achieve image inpainting via a coarse-to-fine hierarchical representation. Meanwhile, we split the masked image into different patches in each layer, which could effectively enlarge the receptive field and extract more useful features of images. Moreover, the patch discriminator is introduced to judge the patches of inpainting image are real or fake. In this way, our network can effectively utilize the semantic information to complete a fine result. Furthermore, both perceptual loss and style loss are used to improve the inpainting results in verse. Experimental results on Places2 and Paris StreetView illustrate that our approach could generate high-quality inpainting results, and our method is more effective than the existing image inpainting methods.
C1 [Ren, Yongpeng; Ren, Hongping; Zhang, Xian; Wu, Xi; Li, Xiaojie; Zhou, Jiliu] Chengdu Univ Informat Technol, Coll Comp Sci, Chengdu 610225, Peoples R China.
   [Shi, Canghong] Xihua Univ, Coll Comp Sci, Chengdu, Peoples R China.
   [Lv, Jiancheng] Sichuan Univ, Coll Comp Sci, Chengdu, Peoples R China.
   [Mumtaz, Imran] Univ Agr Faisalabad, Faisalabad, Pakistan.
C3 Chengdu University of Information Technology; Xihua University; Sichuan
   University; University of Agriculture Faisalabad
RP Li, XJ (corresponding author), Chengdu Univ Informat Technol, Coll Comp Sci, Chengdu 610225, Peoples R China.
EM lixj@cuit.edu.cn
OI Mumtaz, Imran/0000-0003-4294-2971; Xiaojie, Li/0000-0003-3341-4034
FU Sichuan Science and Technology program [2019JDJQ0002, 2019ZDZX0005,
   2018GZ0184]
FX This study was supported by the Sichuan Science and Technology program
   (2019JDJQ0002, 2019ZDZX0005, 2018GZ0184).
CR Ballester C, 2001, IEEE T IMAGE PROCESS, V10, P1200, DOI 10.1109/83.935036
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Bethge, 2016, ARXIV150806576, V16, P326, DOI DOI 10.1167/16.12.326
   Brock A., 2018, LARGE SCALE GAN TRAI, DOI DOI 10.1016/J.VETIMM.2015.04.007
   Darabi S, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185578
   Doersch C, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185597
   Efros AA, 2001, COMP GRAPH, P341
   Esedoglu S, 2002, EUR J APPL MATH, V13, P353, DOI 10.1017/S0956792501004904
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Guillemot C, 2014, IEEE SIGNAL PROC MAG, V31, P127, DOI 10.1109/MSP.2013.2273004
   Guo F, 2020, SOFT COMPUT, V24, P12671, DOI 10.1007/s00500-020-04708-y
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang J, 2014, ACM T GRAPHIC, V33, DOI [10.1145/2601097.2601205, 10.1145/2602141]
   Huang YF, 2021, INT J INTELL SYST, V36, P2465, DOI 10.1002/int.22387
   Iizuka S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073659
   Isola P., 2017, P IEEE C COMPUTER VI, P5967, DOI DOI 10.1109/CVPR.2017.632
   Jingyuan Li, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7757, DOI 10.1109/CVPR42600.2020.00778
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Karras T., 2017, ARXIV171010196
   Lee CY, 2021, INT J INTELL SYST, V36, P2491, DOI 10.1002/int.22389
   Li XJ, 2020, IEEE T CYBERNETICS, V50, P2302, DOI 10.1109/TCYB.2018.2876615
   Li XJ, 2018, IEEE T NEUR NET LEAR, V29, P51, DOI 10.1109/TNNLS.2016.2614896
   Li XH, 2014, IEEE T GEOSCI REMOTE, V52, P7086, DOI 10.1109/TGRS.2014.2307354
   Lim TY., 2016, P 2017 IEEE C COMP V
   Liu D, 2007, IEEE T CIRC SYST VID, V17, P1273, DOI 10.1109/TCSVT.2007.903663
   Liu GL, 2018, LECT NOTES COMPUT SC, V11215, P89, DOI 10.1007/978-3-030-01252-6_6
   Liu HY, 2019, IEEE I CONF COMP VIS, P4169, DOI 10.1109/ICCV.2019.00427
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Nazeri Kamyar, 2019, ARXIV190100212
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Simonyan K, 2015, ICLR 2015, DOI DOI 10.1109/CVPR.2015.7298594
   Wilczkowiak M., 2005, P BRIT MACH VIS C WF
   Yan ZY, 2018, LECT NOTES COMPUT SC, V11218, P3, DOI 10.1007/978-3-030-01264-9_1
   Yang, 2018, P IEEE C COMP VIS PA, P5505
   Yang C, 2017, PROC CVPR IEEE, P4076, DOI 10.1109/CVPR.2017.434
   Yu JH, 2019, IEEE I CONF COMP VIS, P4470, DOI 10.1109/ICCV.2019.00457
   Yu JH, 2018, PROC CVPR IEEE, P5505, DOI 10.1109/CVPR.2018.00577
   Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 40
TC 0
Z9 0
U1 9
U2 9
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0884-8173
EI 1098-111X
J9 INT J INTELL SYST
JI Int. J. Intell. Syst.
PD FEB
PY 2022
VL 37
IS 2
BP 1599
EP 1617
DI 10.1002/int.22687
EA SEP 2021
PG 19
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XV5MK
UT WOS:000698584000001
DA 2022-02-06
ER

PT J
AU Yadav, A
   Vishwakarma, DK
AF Yadav, Ashima
   Vishwakarma, Dinesh Kumar
TI A Language-independent Network to Analyze the Impact of COVID-19 on the
   World via Sentiment Analysis
SO ACM TRANSACTIONS ON INTERNET TECHNOLOGY
LA English
DT Article
DE Attention; coronavirus; deep learning; pandemic; sentiment analysis;
   social media
ID CLASSIFICATION; TWITTER; LSTM
AB Towards the end of 2019, Wuhan experienced an outbreak of novel coronavirus, which soon spread worldwide, resulting in a deadly pandemic that infected millions of people around the globe. The public health agencies followed many strategies to counter the fatal virus. However, the virus severely affected the lives of the people. In this paper, we study the sentiments of people from the top five worst affected countries by the virus, namely the USA, Brazil, India, Russia, and South Africa. We propose a deep language-independent Multilevel Attention-based Conv-BiGRU network (MACBiG-Net), which includes embedding layer, word-level encoded attention, and sentence-level encoded attention mechanisms to extract the positive, negative, and neutral sentiments. The network captures the subtle cues in a document by focusing on the local characteristics of text along with the past and future context information for the sentiment classification. We further develop a COVID-19 Sentiment Dataset by crawling the tweets from Twitter and applying topic modeling to extract the hidden thematic structure of the document. The classification results demonstrate that the proposed model achieves an accuracy of 85%, which is higher than other well-known algorithms for sentiment classification. The findings show that the topics which evoked positive sentiments were related to frontline workers, entertainment, motivation, and spending quality time with family. The negative sentiments were related to socio-economic factors like racial injustice, unemployment rates, fake news, and deaths. Finally, this study provides feedback to the government and health professionals to handle future outbreaks and highlight future research directions for scientists and researchers.
C1 [Yadav, Ashima; Vishwakarma, Dinesh Kumar] Delhi Technol Univ, Dept Informat Technol, Biometr Res Lab, Delhi, India.
C3 Delhi Technological University
RP Yadav, A (corresponding author), Delhi Technol Univ, Dept Informat Technol, Biometr Res Lab, Delhi, India.
EM ashimayadavdtu@gmail.com; dvishwakarma@gmail.com
RI Vishwakarma, Dinesh/L-3815-2018
OI Vishwakarma, Dinesh/0000-0002-1026-0047
CR Agarwal Ayush, 2019, 2019 4th International Conference on Big Data, Cloud Computing, Data Science & Engineering (BCD), P19, DOI 10.1109/BCD.2019.8885108
   Alamoodi AH, 2021, EXPERT SYST APPL, V167, DOI 10.1016/j.eswa.2020.114155
   Anderson RM, 2020, LANCET, V395, P931, DOI 10.1016/S0140-6736(20)30567-5
   [Anonymous], MUMBAI ACCOUNTS 62 C
   [Anonymous], Sonu Sood, the 'messiah' ofmigrant workers, bags UN honour
   [Anonymous], India to observe 'Janata curfew' on Sunday amid spurt in Coronavirus cases
   [Anonymous], EXCLUSIVE RUSSIA ROL
   [Anonymous], INDIA CLIMBS 7 9 SPO
   [Anonymous], 30 Per Cent Of Coronavirus Cases Linked To Delhi Mosque Event: Government
   [Anonymous], 1 2 CASES CORONAVIRU
   [Anonymous], Moscow mayor orders all residents to stay at home
   [Anonymous], IPL postponed, India ODIs called off: How coronavirus has rocked cricketing world
   Araujo M, 2020, INFORM SCIENCES, V512, P1078, DOI 10.1016/j.ins.2019.10.031
   Baccianella S, 2010, LREC 2010 - SEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION
   Bojanowski P., 2017, TACL, V5, P135, DOI [DOI 10.1162/TACL_A_00051, 10.1162/tacl_a_00051]
   Cambria Erik, 2020, CIKM '20: Proceedings of the 29th International Conference on Information & Knowledge Management, P105, DOI 10.1145/3340531.3412003
   Cambria E, 2017, IEEE INTELL SYST, V32, P74, DOI 10.1109/MIS.2017.4531228
   Cambria E, 2017, IEEE T AFFECT COMPUT, V8, P426, DOI 10.1109/TAFFC.2017.2763218
   Cambria E, 2016, IEEE INTELL SYST, V31, P102, DOI 10.1109/MIS.2016.31
   Dashtipour K, 2016, COGN COMPUT, V8, P757, DOI 10.1007/s12559-016-9415-7
   Denecke K, 2015, ARTIF INTELL MED, V64, P17, DOI 10.1016/j.artmed.2015.03.006
   Devlin J, 2019, PROC C N AM CHAPTER, P4171, DOI DOI 10.18653/V1/N19-1423
   Fu KW, 2016, AM J INFECT CONTROL, V44, P1700, DOI 10.1016/j.ajic.2016.04.253
   Garcia K, 2021, APPL SOFT COMPUT, V101, DOI 10.1016/j.asoc.2020.107057
   Ghosh S, 2016, CIKM'16: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1129, DOI 10.1145/2983323.298336
   Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042
   Grisstte H, 2019, PROCEEDINGS OF THE 2019 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2019), P921, DOI 10.1145/3341161.3343854
   Farias DIH, 2016, ACM T INTERNET TECHN, V16, DOI 10.1145/2930663
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735
   Huang CL, 2020, ACM T INTERNET TECHN, V20, DOI 10.1145/3414841
   Imran AS, 2020, IEEE ACCESS, V8, P181074, DOI 10.1109/ACCESS.2020.3027350
   Jelodar H, 2020, IEEE J BIOMED HEALTH, V24, P2733, DOI 10.1109/JBHI.2020.3001216
   Kenneth ALachlan, 2019, J STRATEGIC INNOVATI, V14, P16, DOI [10.33423/jsis.v14i1.984, DOI 10.33423/JSIS.V14I1.984]
   Khatua A, 2019, INFORM PROCESS MANAG, V56, P247, DOI 10.1016/j.ipm.2018.10.010
   Kim Y., 2014, P EMNLP 2014, P1746, DOI 10.3115/v1/D14-1181
   Korkontzelos I, 2016, J BIOMED INFORM, V62, P148, DOI 10.1016/j.jbi.2016.06.007
   Kowsari K, 2019, INFORMATION, V10, DOI 10.3390/info10040150
   Lai SW, 2015, PROCEEDINGS OF THE TWENTY-NINTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2267
   Lampos V, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P695, DOI 10.1145/3038912.3052622
   Le Q., 2014, P 31 INT C INT C MAC
   Liang H, 2019, BMC PUBLIC HEALTH, V19, DOI 10.1186/s12889-019-6747-8
   Limsopatham N, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1014
   Lin Z., 2017, INT C LEARN REPR ICL, P1
   Lo SL, 2017, ARTIF INTELL REV, V48, P499, DOI 10.1007/s10462-016-9508-4
   Jimenez-Zafra SM, 2019, ARTIF INTELL MED, V93, P50, DOI 10.1016/j.artmed.2018.03.007
   Medford RJ, 2020, OPEN FORUM INFECT DI, V7, DOI 10.1093/ofid/ofaa258
   Meng Xinfan, 2012, P 50 ANN M ASS COMP, P572
   Mikolov T., 2013, NIPS, V26, P3111
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Moh M, 2017, NETW MODEL ANAL HLTH, V6, DOI 10.1007/s13721-017-0159-4
   Nankani H, 2020, ALGO INTELL SY, P193, DOI 10.1007/978-981-15-1216-2_8
   Pennington J., 2014, EMNLP, P1532, DOI [10.3115/v1/D14-1162, DOI 10.3115/V1/D14-1162]
   Poria S., 2020, ARXIV PREPRINT ARXIV, DOI [10.1109/TAFFC.2020.3038167, DOI 10.1109/TAFFC.2020.3038167]
   Rahman MM, 2021, HELIYON, V7, DOI 10.1016/j.heliyon.2021.e06200
   Sabra S, 2018, COMPUT BIOL MED, V94, P1, DOI 10.1016/j.compbiomed.2017.12.026
   Samuel J, 2020, IEEE ACCESS, V8, P142173, DOI 10.1109/ACCESS.2020.3013933
   Sciandra A, 2020, IEEE SYMP COMP COMMU, P1004
   She DY, 2020, IEEE T MULTIMEDIA, V22, P1358, DOI 10.1109/TMM.2019.2939744
   Sievert C., 2014, P WORKSH INT LANG LE, P63
   Stevens K., 2012, P 2012 JOINT C EMP M, V2012, P952, DOI DOI 10.1094/PDIS-11-11-0999-PDN
   Strapparava C., 2004, P 4 INT C LANGUAGE R, V4, P1083
   Sukhbaatar S, 2015, ADV NEUR IN, V28
   Susanto Y, 2020, IEEE INTELL SYST, V35, P96, DOI 10.1109/MIS.2020.2992799
   Talpada H, 2019, INT CONF KNOWL SYS, P37
   Vilares D, 2018, 2018 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI), P1292, DOI 10.1109/SSCI.2018.8628718
   Wan Xiaojun, 2008, P C EMP METH NAT LAN, P553, DOI DOI 10.3115/1613715.1613783
   Wang C.-K., 2017, P INT WORKSH DIG DIS
   Wang YQ, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P1165, DOI 10.1145/3178876.3186015
   Wilson T., 2005, P HLT EMNLP 2005 INT, P34, DOI DOI 10.3115/1225733.1225751
   Yadav A., 2020, 11 INT C COMP COMM N, P1
   Yadav A, 2020, APPL SOFT COMPUT, V96, DOI 10.1016/j.asoc.2020.106624
   Yadav A, 2020, 2020 IEEE SIXTH INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2020), P326, DOI 10.1109/BigMM50055.2020.00057
   Yadav A, 2020, MULTIMEDIA SYST, V26, P431, DOI 10.1007/s00530-020-00656-7
   Yadav A, 2020, CLUSTER COMPUT, V23, P2969, DOI 10.1007/s10586-020-03062-w
   Yadav A, 2019, 2019 IEEE FIFTH INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2019), P219, DOI [10.1109/BigMM.2019.00-22, 10.1109/BigMM.2019.00040]
   Yadav A, 2020, ARTIF INTELL REV, V53, P4335, DOI 10.1007/s10462-019-09794-5
   Yang F.-C., 2016, J MED SYST, V40, P1
   Yang Z., 2016, NAACL HLT, P1480
NR 78
TC 0
Z9 0
U1 10
U2 10
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
SN 1533-5399
EI 1557-6051
J9 ACM T INTERNET TECHN
JI ACM Trans. Internet. Technol.
PD FEB
PY 2022
VL 22
IS 1
AR 28
DI 10.1145/3475867
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WV7FV
UT WOS:000717399100027
DA 2022-02-06
ER

PT J
AU Toshpulatov, M
   Lee, W
   Lee, S
AF Toshpulatov, Mukhiddin
   Lee, Wookey
   Lee, Suan
TI Generative adversarial networks and their application to 3D face
   generation: A survey
SO IMAGE AND VISION COMPUTING
LA English
DT Review
DE Generative adversarial networks; Generator; Discriminator; Deep neural
   network; Deep learning
ID MORPHABLE MODEL
AB Generative adversarial networks (GANs) have been extensively studied in recent years and have been used to address several problems in the fields of image generation and computer vision. Despite significant advancements in computer vision, applying GANs to real-world problems such as 3D face generation remains a challenge. Owing to the proliferation of fake images generated by GANs, it is important to analyze and build a taxonomy for providing an overall view of GANs. This, in turn, would facilitate many interesting applications, including virtual reality, augmented reality, computer games, teleconferencing, virtual try-on, special effects in movies, and 3D avatars. This paper reviews and discusses GANs and their application to 3D face generation. We aim to compare existing GANs methods in terms of their application to 3D face generation, investigate the related theoretical issues, and highlight the open research problems. Authors provided both qualitative and quantitative evaluations of the proposed approach. They claimed their results show the higher quality of the synthesized data compared to state-ofthe-art ones. ? 2021 Elsevier B.V. All rights reserved.
C1 [Toshpulatov, Mukhiddin; Lee, Wookey] Inho Univ, Biomed Sci & Engn, 100 Inha Ro, Incheon 22212, South Korea.
   [Lee, Suan] Semyung Univ, Sch Comp Sci, Jecheon 27136, South Korea.
C3 Semyung University
RP Lee, W (corresponding author), Inho Univ, Biomed Sci & Engn, 100 Inha Ro, Incheon 22212, South Korea.; Lee, S (corresponding author), Semyung Univ, Sch Comp Sci, Jecheon 27136, South Korea.
EM mukhiddin1979@inha.edu; trinity@inha.ac.kr; suanlee@semyung.ac.kr
FU Ministry of Education of the Republic of Korea; National Research
   Foundation of KoreaNational Research Foundation of Korea [NRF
   019S1A5C2A03081234]
FX This work was supported by the Ministry of Education of the Republic of
   Korea and the National Research Foundation of Korea (NRF
   019S1A5C2A03081234) .
CR Abrevaya VF, 2019, IEEE I CONF COMP VIS, P9418, DOI 10.1109/ICCV.2019.00951
   Adler J., 2018, ARXIV180606621, P6754
   Ak KE, 2019, IEEE I CONF COMP VIS, P10540, DOI 10.1109/ICCV.2019.01064
   Alberry Hesham A., 2018, Future Computing and Informatics Journal, V3, P159, DOI 10.1016/j.fcij.2018.03.001
   Algadhy R, 2019, INT CONF ACOUST SPEE, P2367, DOI 10.1109/ICASSP.2019.8682455
   Almalioglu Y, 2019, IEEE INT CONF ROBOT, P5474, DOI 10.1109/ICRA.2019.8793512
   Anoosheh A., 2018, P IEEE C COMP VIS PA, P783
   Antipov G, 2017, IEEE IMAGE PROC, P2089, DOI 10.1109/ICIP.2017.8296650
   Arbel M., 2018, ADV NEURAL INFORM PR, P6700
   Arjovsky M., 2017, ARXIV E PRINTS ART A
   Bardsley JM, 2008, INVERSE PROBL IMAG, V2, P167
   Barlow HB, 1989, NEURAL COMPUT, V1, P295, DOI 10.1162/neco.1989.1.3.295
   Barsoum E, 2018, IEEE COMPUT SOC CONF, P1499, DOI 10.1109/CVPRW.2018.00191
   Berthelot D., 2017, ARXIV PREPRINT ARXIV, P10717
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Boiman O, 2008, PROC CVPR IEEE, P1992, DOI 10.1109/CVPR.2008.4587598
   Bolton RN, 2003, J RETAILING, V79, P213, DOI 10.1016/j.jretai.2003.09.005
   Booth J, 2018, INT J COMPUT VISION, V126, P233, DOI 10.1007/s11263-017-1009-7
   Booth J, 2017, PROC CVPR IEEE, P5464, DOI 10.1109/CVPR.2017.580
   Booth J, 2016, PROC CVPR IEEE, P5543, DOI 10.1109/CVPR.2016.598
   Booth J, 2014, IEEE IMAGE PROC, P4672, DOI 10.1109/ICIP.2014.7025947
   Borji A, 2019, COMPUT VIS IMAGE UND, V179, P41, DOI 10.1016/j.cviu.2018.10.009
   Brownlee J., 2019, GENERATIVE ADVERSARI GENERATIVE ADVERSARI
   Cao C, 2014, IEEE T VIS COMPUT GR, V20, P413, DOI 10.1109/TVCG.2013.249
   CAO J, 2019, ADV NEURAL INFORM PR, P1776
   Cao YJ, 2019, IEEE ACCESS, V7, P14985, DOI 10.1109/ACCESS.2018.2886814
   Cao Y, 2018, PROC CVPR IEEE, P1287, DOI 10.1109/CVPR.2018.00140
   Che T., 2016, ARXIV PREPRINT ARXIV
   Chen X., 2016, Adv. Neural Inf. Process. Syst., V29, P2172
   Chen YZ, 2018, IEEE T POWER SYST, V33, P3265, DOI 10.1109/TPWRS.2018.2794541
   Cheng SY, 2018, PROC CVPR IEEE, P5117, DOI 10.1109/CVPR.2018.00537
   Chetverikov D, 2005, IMAGE VISION COMPUT, V23, P299, DOI 10.1016/j.imavis.2004.05.007
   Cheung N.-M., 2018, P EUR C COMP VIS, P370
   Chintala S., 2017, ARXIV170107875
   Choi J, 2019, IEEE I CONF COMP VIS, P6829, DOI 10.1109/ICCV.2019.00693
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Dai GX, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P672, DOI 10.1145/3123266.3123334
   Dai H, 2020, INT J COMPUT VISION, V128, P547, DOI 10.1007/s11263-019-01260-7
   Danelakis A, 2016, PATTERN RECOGN, V52, P174, DOI 10.1016/j.patcog.2015.10.012
   De Cao N., 2018, ARXIV PREPRINT ARXIV, P11973
   Degottex G, 2018, IEEE W SP LANG TECH, P603, DOI 10.1109/SLT.2018.8639609
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Deng Jiankang, 2018, P IEEE C COMP VIS PA
   Deng Y., P IEEE C COMP VIS PA
   Dhall A, 2017, P 19 ACM INT C MULT, P524, DOI DOI 10.1145/3136755.3143004
   DHANWADA KR, 1995, ONCOGENE, V11, P1947
   Di Mattia F., 2019, ARXIV PREPRINT ARXIV, P11632
   Di X, 2018, INT C PATT RECOG, P1079, DOI 10.1109/ICPR.2018.8545081
   Dimitrakopoulos P, 2020, INT CONF ACOUST SPEE, P3182, DOI 10.1109/ICASSP40776.2020.9053325
   Ding L, 2020, J IMAGING SCI TECHN, V64, DOI 10.2352/J.ImagingSci.Technol.2020.64.3.030505
   Dinh L., ARXIV PREPRINT ARXIV
   Doersch C., ARXIV PREPRINT ARXIV
   Du SY, 2010, PATTERN RECOGN LETT, V31, P791, DOI 10.1016/j.patrec.2010.01.020
   Duncan C., 2017, P IEEE INT C COMP VI, P3085
   Egger B., 2019, ARXIV PREPRINT ARXIV
   Esteban C., 2017, ARXIV PREPRINT ARXIV
   Fedus W., 2017, ARXIV PREPRINT ARXIV
   Ferrari Claudio, 2018, Smart Multimedia. First International Conference, ICSM 2018. Revised Selected Papers: Lecture Notes in Computer Science (LNCS 11010), P320, DOI 10.1007/978-3-030-04375-9_27
   Ferrari C, 2017, IEEE T MULTIMEDIA, V19, P2666, DOI 10.1109/TMM.2017.2707341
   Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138
   Foody GM, 2006, REMOTE SENS ENVIRON, V104, P1, DOI 10.1016/j.rse.2006.03.004
   Gao W, 2008, IEEE T SYST MAN CY A, V38, P149, DOI 10.1109/TSMCA.2007.909557
   Gatys LA, 2016, PROC CVPR IEEE, P2414, DOI 10.1109/CVPR.2016.265
   Gauthier J., 2014, CLASS PROJECT STANFO, V2014
   Gecer B, 2019, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2019.00125
   Genova K, 2018, PROC CVPR IEEE, P8377, DOI 10.1109/CVPR.2018.00874
   Ghafoorian M., 2018, P EUR C COMP VIS ECC
   Ghahramani Z, 2004, LECT NOTES ARTIF INT, V3176, P72
   Ghazi M. M., 2016, P IEEE C COMP VIS PA, P34
   Goldberg Y, 2017, SYNTHESIS LECT HUMAN, V10, P1, DOI [10.2200/S00762ED1V01Y201703HLT037, DOI 10.2200/S00762ED1V01Y201703HLT037]
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002
   Gulrajani I, 2017, ADV NEURAL INFORM PR, P5767
   Guo YD, 2016, LECT NOTES COMPUT SC, V9907, P87, DOI 10.1007/978-3-319-46487-9_6
   Gupta A, 2018, PROC CVPR IEEE, P2255, DOI 10.1109/CVPR.2018.00240
   Han X., 2019, IEEE T PATTERN ANAL
   Han ZY, 2018, MED IMAGE ANAL, V50, P23, DOI 10.1016/j.media.2018.08.005
   Handrich S, 2020, PROCEDIA COMPUT SCI, V170, P634, DOI 10.1016/j.procs.2020.03.134
   Heusel M., 2017, NIPS, V30, P6629
   Ho Jonathan, 2019, AXIAL ATTENTION MULT
   Hsieh Y.P., 2018, INT C MACH LEARN 201, P2810
   Hu G., BMVC 2012, P1
   Hu GS, 2016, LECT NOTES COMPUT SC, V9912, P73, DOI 10.1007/978-3-319-46484-8_5
   Hu  Y., 2008, P ICPR, P1
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   Huh M, 2019, PROC CVPR IEEE, P1476, DOI 10.1109/CVPR.2019.00157
   Huynh L, 2018, PROC CVPR IEEE, P8407, DOI 10.1109/CVPR.2018.00877
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Izutov E., 2018, CORR
   Jaakkola TS, 1999, ADV NEUR IN, V11, P487
   Jahn RG, 2007, EXPLORE-NY, V3, P244, DOI 10.1016/j.explore.2007.03.009
   Jeni Laszlo A., 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163142
   Jiankang Deng, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P741, DOI 10.1007/978-3-030-58621-8_43
   Jo Y, 2019, IEEE I CONF COMP VIS, P1745, DOI 10.1109/ICCV.2019.00183
   Jolicoeur-Martineau A., ARXIV PREPRINT ARXIV
   Juefei-Xu F., 2018, P AS C COMP VIS PERT, P3
   Kaneko T, 2017, PROC CVPR IEEE, P7006, DOI 10.1109/CVPR.2017.741
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Karras T, 2018, PROGRESSIVE GROWING
   Karras T., 2020, P IEEE CVF C COMP VI, P8110
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Kaya H, 2017, IMAGE VISION COMPUT, V65, P66, DOI 10.1016/j.imavis.2017.01.012
   Kim T, 2017, PR MACH LEARN RES, V70
   Kim V, 2019, P NEURIPS, P7433
   Kim Y., 2014, P EMNLP 2014, P1746, DOI 10.3115/v1/D14-1181
   Kingma D., 2014, ADV NEURAL INFORM PR, V27, P3581
   Kneyber MCJ, 2017, INTENS CARE MED, V43, P1764, DOI 10.1007/s00134-017-4920-z
   Knyaz V.A., 2018, P EUR C COMP VIS ECC
   Koizumi T., 2020, EUR C COMP VIS SPRIN, P690
   Kolesnikov A, 2017, PR MACH LEARN RES, V70
   Kollias D., 2018, PROC EUR C COMP VIS
   Kollias D, 2020, INT J COMPUT VISION, V128, P1455, DOI 10.1007/s11263-020-01304-3
   Kollias D, 2019, INT J COMPUT VISION, V127, P907, DOI 10.1007/s11263-019-01158-4
   Kollias Dimitrios, 2020, IEEE T AFFECT COMPUT
   Komkov S., 2019, ARXIV PREPRINT ARXIV
   Koppen P, 2018, PATTERN RECOGN, V74, P617, DOI 10.1016/j.patcog.2017.09.006
   Kossaifi J, 2017, IMAGE VISION COMPUT, V65, P23, DOI 10.1016/j.imavis.2017.02.001
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kurach K., 2018, GAN LANDSCAPE LOSSES
   Kusner M.J., 2016, ARXIV PREPRINT ARXIV
   Lahiri A, 2017, IEEE COMPUT SOC CONF, P794, DOI 10.1109/CVPRW.2017.110
   Lattas A., ARXIV PREPRINT ARXIV
   Lempitsky V.S., 2016, ICML, V1, P4
   Li F, 2017, COMPUT PHYS COMMUN, V214, P6, DOI 10.1016/j.cpc.2017.01.001
   Li PP, 2018, INT C PATT RECOG, P1073, DOI 10.1109/ICPR.2018.8545119
   Li RH, 2019, IEEE I CONF COMP VIS, P7202, DOI 10.1109/ICCV.2019.00730
   Li S, 2017, PROC CVPR IEEE, P2584, DOI 10.1109/CVPR.2017.277
   Li XY, 2017, GEOL J, V52, P286, DOI 10.1002/gj.3054
   Li X, 2021, IMAGE VISION COMPUT, V105, DOI 10.1016/j.imavis.2020.104077
   Liao JJZ, 2000, PDA J PHARM SCI TECH, V54, P23
   Lin CH, 2018, PROC CVPR IEEE, P9455, DOI 10.1109/CVPR.2018.00985
   LIN LI, 1989, BIOMETRICS, V45, P255, DOI 10.2307/2532051
   LIN LIK, 1992, BIOMETRICS, V48, P599, DOI 10.2307/2532314
   Lin T., 2017, P IEEE INT C COMP VI
   Lin T.-Y., 2017, P IEEE C COMP VIS PA
   Liu H, 2019, IET IMAGE PROCESS, V13, P2662, DOI 10.1049/iet-ipr.2018.6545
   Liu KL, 2020, IMAGE VISION COMPUT, V104, DOI 10.1016/j.imavis.2020.104005
   Liu M. Y., 2016, P ADV NEUR PROC SYST, P469
   Liu N., 2020, ARXIV PREPRINT ARXIV, P11488
   Liu Y., 2019, IEEE C COMP VIS PATT, p11 877
   Liu Y, 2021, IMAGE VISION COMPUT, V105, DOI 10.1016/j.imavis.2020.104087
   Liu Z., 2018, LARGE SCALE CELEBFAC
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Lourakis M., 2007, P EVA, P11
   Lu D, 2007, INT J REMOTE SENS, V28, P823, DOI 10.1080/01431160600746456
   Lu Y., 2018, P EUR C COMP VIS, P282
   Tran L, 2018, PROC CVPR IEEE, P7346, DOI 10.1109/CVPR.2018.00767
   Lucic M., 2018, NEURIPS, P700
   Luxburg U. V., 2016, P NEURIPS, V29, P4790
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Marafioti A, 2019, PR MACH LEARN RES, V97
   Matuszewski BJ, 2012, IMAGE VISION COMPUT, V30, P713, DOI 10.1016/j.imavis.2012.02.002
   Memmi G, 2019, ARXIV190408270
   Mescheder L, 2018, PR MACH LEARN RES, V80
   Minnen David, 2018, ADV NEURAL INFORM PR, P10771
   Mirza M, 2014, ARXIV PREPRINT ARXIV
   Mittal P, 2020, IMAGE VISION COMPUT, V104, DOI 10.1016/j.imavis.2020.104046
   Mohamed S., ARXIV PREPRINT ARXIV
   Mollahosseini A, 2019, IEEE T AFFECT COMPUT, V10, P18, DOI 10.1109/TAFFC.2017.2740923
   Moschoglou S., 2019, ARXIV PREPRINT ARXIV
   Moubayed S.A., 2008, 9 ANN C INT SPEECH C
   Mukhiddin T, 2020, INT CONF BIG DATA, P487, DOI 10.1109/BigComp48618.2020.00-19
   Nickerson CAE, 1997, BIOMETRICS, V53, P1503, DOI 10.2307/2533516
   Nomani H, 2018, 2018 INTERNATIONAL CONFERENCE ON ADVANCES IN COMMUNICATION AND COMPUTING TECHNOLOGY (ICACCT), P426, DOI 10.1109/ICACCT.2018.8529358
   Odena A., INT C MACH LEARN PML, P2642
   Papamakarios G., 2017, ADV NEURAL INFORM PR, P2338
   Pardo-Castellote G, 2003, 23RD INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING SYSTEMS WORKSHOPS, P200
   Park SW, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9040688
   Ploumpis S, 2019, PROC CVPR IEEE, P10926, DOI 10.1109/CVPR.2019.01119
   Prabhu V.U., 2019, ARXIV190712917
   Prajwal KR, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1428, DOI 10.1145/3343031.3351066
   Prenger R, 2019, INT CONF ACOUST SPEE, P3617, DOI 10.1109/ICASSP.2019.8683143
   Pumarola A, 2018, LECT NOTES COMPUT SC, V11214, P835, DOI 10.1007/978-3-030-01249-6_50
   Qian Y., 2019, P IEEE C COMP VIS PA, P9851
   Qin Y., 2018, ARXIV PREPRINT ARXIV
   Radford A., 2015, ARXIV151106434
   Rasheed A., ARXIV PREPRINT ARXIV
   Razavi Ali, 2019, ADV NEURAL INFORM PR, P14866
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Reed S., 2017, ARXIV PREPRINT ARXIV
   Reed S., 2016, ARXIV PREPRINT ARXIV
   Reimann C, 2000, ENVIRON GEOL, V39, P1001, DOI 10.1007/s002549900081
   Riaz S, 2020, IMAGE VISION COMPUT, V104, DOI 10.1016/j.imavis.2020.104020
   Ringeval F., 2013, AUT FAC GEST REC FG, P1, DOI [10.1109/FG.2013.6553805, DOI 10.1109/FG.2013.6553805]
   Roldan V, 2015, AM J MED, V128, P1237, DOI 10.1016/j.amjmed.2015.05.036
   Rosca M., 2017, ARXIV PREPRINT ARXIV
   Roth K., 2017, ADV NEURAL INFORM PR, P2018
   Salimans T., 2016, ADV NEURAL INFORM PR, P2234
   Salimans T., 2017, INT C LEARN REPR
   Savran A, 2008, LECT NOTES COMPUT SC, V5372, P47, DOI 10.1007/978-3-540-89991-4_6
   Shalev-Shwartz S., 2008, P 25 INT C MACH LEAR, P928, DOI DOI 10.1145/1390156.1390273
   Shamai G, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3337067
   Shen Y., 2020, P IEEE CVF C COMP VI, P9243
   Singh, 2019, ADV NEURAL INFORM PR, P5266
   Smith, 2020, ARXIV PREPRINT ARXIV
   Soyel H, 2007, LECT NOTES COMPUT SC, V4633, P831
   Speth J., 2019, CVPR WORKSH
   Stahl A, 2017, COMPUT PHYS COMMUN, V212, P269, DOI 10.1016/j.cpc.2016.10.024
   STANISWALIS JG, 1989, J AM STAT ASSOC, V84, P276, DOI 10.2307/2289874
   Stone Z, 2010, P IEEE, V98, P1408, DOI 10.1109/JPROC.2010.2044551
   Szabo A., ARXIV PREPRINT ARXIV
   Szummer M, 1998, 1998 IEEE INTERNATIONAL WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO DATABASE, PROCEEDINGS, P42, DOI 10.1109/CAIVD.1998.646032
   Tanchenko A, 2014, J VIS COMMUN IMAGE R, V25, P874, DOI 10.1016/j.jvcir.2014.01.008
   Tang Hao, 2018, ACCV
   Tao D., ARXIV PREPRINT ARXIV
   Tellamekala M.K., 2019, 2019 8 INT C AFF COM, P1
   Theis L., P IEEE C COMP VIS PA, P4681
   Thomaz C.E., 2010, TECHNOLOGICAL REPORT, P1
   Thomaz CE, 2010, IMAGE VISION COMPUT, V28, P902, DOI 10.1016/j.imavis.2009.11.005
   Tran AT, 2017, PROC CVPR IEEE, P1493, DOI 10.1109/CVPR.2017.163
   Tran Luan, 2019, IEEE T PATTERN ANAL
   Truong K.T., 2018, VIDEO BASED FACE REC
   Turaga DS, 2004, SIGNAL PROCESS-IMAGE, V19, P173, DOI 10.1016/j.image.2003.09.001
   Ulyanov D., 2016, ARXIV PREPRINT ARXIV
   Usman B, 2019, IEEE I CONF COMP VIS, P9449, DOI 10.1109/ICCV.2019.00954
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Venkatesh YV, 2012, PATTERN RECOGN LETT, V33, P1785, DOI 10.1016/j.patrec.2012.05.015
   WALLACH D, 1989, ECOL MODEL, V44, P299, DOI 10.1016/0304-3800(89)90035-5
   Wang H, ARXIV PREPRINT ARXIV
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Wang JR, 2019, IEEE ACCESS, V7, P111168, DOI 10.1109/ACCESS.2019.2924003
   Wang R., ARXIV PREPRINT ARXIV
   Wang S.-Y., 2020, P IEEE C COMP VIS PA
   Wang WS, 2019, IEEE T VEH TECHNOL, V68, P11679, DOI 10.1109/TVT.2019.2948911
   Wang Z., 2019, ARXIV190601529
   Wang ZW, 2018, PROC CVPR IEEE, P7939, DOI 10.1109/CVPR.2018.00828
   Weng L., FLOW BASED DEEP GENE
   Wiatrak M., 2019, ARXIV PREPRINT ARXIV
   Wierstra D., 2014, ARXIV PREPRINT ARXIV
   Williams Jr B.L., 1989, US Patent, Patent No. [4,868,866, 4868866]
   Wu FZ, 2019, PROC CVPR IEEE, P959, DOI 10.1109/CVPR.2019.00105
   Wu FZ, 2019, PATTERN RECOGN LETT, V125, P766, DOI 10.1016/j.patrec.2019.07.017
   Wu G, 2005, IEEE T KNOWL DATA EN, V17, P786, DOI 10.1109/TKDE.2005.95
   Wu Zheng, 2019, Advanced Technology of Electrical Engineering and Energy, V38, P1, DOI 10.12067/ATEEE1808029
   Xu Z., 2017, P 2017 C EMP METH NA, DOI DOI 10.18653/V1/D17-1065
   Xuan-Phung Huynh, 2016, International Conference on Information Science and Applications (ICISA) 2016. LNEE 376, P441, DOI 10.1007/978-981-10-0557-2_44
   Yamaguchi S, 2018, ACM T GRAPH TOG, V37, P1
   Yang C., BMVC 2018, P110
   Yang C, 2019, IEEE T IMAGE PROCESS, V28, P4845, DOI 10.1109/TIP.2019.2914583
   YANG Z, 2018, ADV NEURAL INFORM PR, P7287
   Yanga Y., ARXIV PREPRINT ARXIV
   Yeh RA, 2017, PROC CVPR IEEE, P6882, DOI 10.1109/CVPR.2017.728
   Yin X., 2017, P IEEE INT C COMP VI, P3990
   Young T, 2018, IEEE COMPUT INTELL M, V13, P55, DOI 10.1109/MCI.2018.2840738
   Yu SQ, 2017, IEEE COMPUT SOC CONF, P532, DOI 10.1109/CVPRW.2017.80
   Yuan XW, 2019, IEEE I CONF COMP VIS, P10061, DOI 10.1109/ICCV.2019.01016
   Zafeiriou Stefanos, 2017, P IEEE C COMP VIS PA, P34
   Zhang G., 2018, ECCV, P417
   Zhang H, 2019, PR MACH LEARN RES, V97
   Zhang H, 2019, IEEE T PATTERN ANAL, V41, P1947, DOI 10.1109/TPAMI.2018.2856256
   Zhang X, 2014, IMAGE VISION COMPUT, V32, P692, DOI 10.1016/j.imavis.2014.06.002
   Zhang Y, ARXIV PREPRINT ARXIV
   Zhao Y, 2018, IEEE ACCESS, V6, P60478, DOI 10.1109/ACCESS.2018.2872060
   Zhou J., 2020, HEART SOUND SEGMENTA
   Zhou TH, 2017, PROC CVPR IEEE, P6612, DOI 10.1109/CVPR.2017.700
   Zhou YQ, 2017, INT CONF AFFECT, P370, DOI 10.1109/ACII.2017.8273626
   Zhu D., 2018, ARXIV PREPRINT ARXIV
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu X., 2017, 2017 14 IEEE INT C A, P1
   Zhu Y., IMAGE VISION COMPUT, V104, DOI [10.1016/j. imavis.2020.104023, 2020, DOI 10.1016/J.IMAVIS.2020.104023,2020]
NR 260
TC 2
Z9 2
U1 9
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2021
VL 108
AR 104119
DI 10.1016/j.imavis.2021.104119
PG 18
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA RM7QN
UT WOS:000639853600007
DA 2022-02-06
ER

PT J
AU Liu, Q
   Huang, ZZ
AF Liu, Qi
   Huang, Zhenzhen
TI Research on intelligent prevention and control of COVID-19 in China's
   urban rail transit based on artificial intelligence and big data
SO JOURNAL OF INTELLIGENT & FUZZY SYSTEMS
LA English
DT Article
DE COVID-19; epidemic prevention and control; urban rail transit;
   intelligent police; big data; deep learning
AB Since December 2019, the outbreak of novel coronavirus pneumonia has brought great challenges to global public health, which is the most serious epidemic over the past hundred years. The urban rail transit is an important part of public transport in large cities with characteristic of intensive passengers and confined space, which is easy to become viral infection intermediary. In order to prevent and control the situation of the epidemic, the police's public security department for urban rail transit and the urban rail transit operation company have established a three-layer filter network, which is composed of safety inspection, patrol and temporary interrogation, and intelligent police service, and this network implements the deep learning technology to identify key persons, prohibited luggage, and the body temperature of passengers. For the problem of uncertainty in total passenger flow and its density, this paper proposes a method for re-establishing the passenger flow model to focus on data monitoring, and resetting the threshold value of alarm to control the passenger density. In view of the difficulty of passenger identification caused by mask during the epidemic, this paper proposes a systematic schema of timely adjusting face recognition algorithm, modifying the alarm threshold, using iris recognition system, carrying out information collision comparison, deep mining and intelligent judging, which discover the high-risk groups of epidemic prevention and control in time. China's police's public security department for urban rail transit aims at prevention of virus input, infection, riot, fake new, scientific prevention and control, and has made precise policy implementation to hold urban rail transit's covid-19 intelligent prevention and control work, finally won the battle and effectively guaranteed the people's life safety and health.
C1 [Liu, Qi] Railway Police Coll, Urban Rail Transit Secur Dept, Zhengzhou 450053, Henan, Peoples R China.
   [Huang, Zhenzhen] Railway Police Coll, Railway Police Dept, Zhengzhou, Henan, Peoples R China.
   [Huang, Zhenzhen] Railway Police Coll, Police Sports Dept, Zhengzhou, Henan, Peoples R China.
RP Liu, Q (corresponding author), Railway Police Coll, Urban Rail Transit Secur Dept, Zhengzhou 450053, Henan, Peoples R China.
EM liuqi@rpc.edu.cn
FU Henan Provincial Research Foundation for Science and Technological
   Breakthroughs, China [182102210119]; Railway Police College Teaching
   Reform Research Projects [JY2019004]
FX This paper is supported by Henan Provincial Research Foundation for
   Science and Technological Breakthroughs, China (Grant No. 182102210119)
   and Railway Police College Teaching Reform Research Projects (Grant No.
   JY2019004).
CR Asadi S, 2019, NATURE, V9, P1, DOI [10.1038/s41598-018-37186-2, DOI 10.HTTPS://D0I.0RG/10.1038/S41598-019-38808-Z]
   Cuevas AG, 2016, HEALTH PSYCHOL, V35, P987, DOI 10.1037/hea0000368
   Ding XB, 2019, J INTELL FUZZY SYST, V37, P4511, DOI 10.3233/JIFS-179284
   Ekker K, 2016, J INTELL FUZZY SYST, V31, P939, DOI 10.3233/JIFS-169023
   Emanuel EJ, 2020, NEW ENGL J MED, V382, P2049, DOI 10.1056/NEJMsb2005114
   Goldbaum C, 2020, NY TIMES
   Hong KH, 2020, ANN LAB MED, V40, P351, DOI 10.3343/alm.2020.40.5.351
   Kirby T, 2020, LANCET RESP MED, V8, P451, DOI 10.1016/S2213-2600(20)30164-8
   Liu Q, 2018, J ENVIRON PROT ECOL, V19, P1704
   Liu Q, 2018, J ENVIRON PROT ECOL, V19, P1065
   McEnery T, 2020, LANCET RESP MED, V8, P538, DOI 10.1016/S2213-2600(20)30176-4
   Mohamed A.E. Tarek, 2020, INFECT GENETICS EVOL, V83
   van Doremalen N, 2020, NEW ENGL J MED, V382, P1564, DOI [10.1056/NEJMc2004973, 10.1101/2020.03.09.20033217]
   Wasdani KP, 2020, LOCAL ENVIRON, V25, P414, DOI 10.1080/13549839.2020.1754375
   Yu F., 2020, J AEROSOL SCI, V147, P1
NR 15
TC 3
Z9 3
U1 18
U2 24
PU IOS PRESS
PI AMSTERDAM
PA NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS
SN 1064-1246
EI 1875-8967
J9 J INTELL FUZZY SYST
JI J. Intell. Fuzzy Syst.
PY 2020
VL 39
IS 6
BP 9085
EP 9090
DI 10.3233/JIFS-189307
PG 6
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA PF7MC
UT WOS:000599232800097
OA Bronze
DA 2022-02-06
ER

PT J
AU Mitchelstein, E
   Matassi, M
   Boczkowski, PJ
AF Mitchelstein, Eugenia
   Matassi, Mora
   Boczkowski, Pablo J.
TI Minimal Effects, Maximum Panic: Social Media and Democracy in Latin
   America
SO SOCIAL MEDIA + SOCIETY
LA English
DT Article
DE social media; Latin America; minimal effects; fake news; political
   communication
AB In face of public discourses about the negative effects that social media might have on democracy in Latin America, this article provides a qualitative assessment of existing scholarship about the uses, actors, and effects of platforms for democratic life. Our findings suggest that, first, campaigning, collective action, and electronic government are the main political uses of platforms. Second, politicians and office holders, social movements, news producers, and citizens are the main actors who utilize them for political purposes. Third, there are two main positive effects of these platforms for the democratic process-enabling social engagement and information diffusion-and two main negative ones-the presence of disinformation, and the spread of extremism and hate speech. A common denominator across positive and negative effects is that platforms appear to have minimal effects that amplify pre-existing patterns rather than create them de novo.
C1 [Mitchelstein, Eugenia] Univ San Andres, Dept Social Sci, Victoria, Buenos Aires, Argentina.
   [Matassi, Mora] Northwestern Univ, Media Technol & Soc, Evanston, IL 60208 USA.
   [Boczkowski, Pablo J.] Northwestern Univ, Dept Commun Studies, Evanston, IL 60208 USA.
C3 Northwestern University; Northwestern University
RP Mitchelstein, E (corresponding author), Univ San Andres, Vito Dumas 284, RA-1644 Victoria, Buenos Aires, Argentina.
EM emitchelstein@udesa.edu.ar
OI Mitchelstein, Eugenia/0000-0001-7355-8740
FU Kofi Annan foundation
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: Research
   for this article was funded by a grant from the Kofi Annan foundation.
CR Aguirre Sala Jorge Francisco, 2014, Comun. soc, P211
   Alava S., 2017, YOUTH VIOLENT EXTREM
   Alianza Regional por la Libre ExpresiuEn e InformaciuEn [Alliance for free expression and information], 2016, ART CULO 13 INFORME
   Allen, 2007, SAGE ENCY COMMUNICAT, P1075
   Anderson CW, 2021, COMMUN THEOR, V31, P42, DOI 10.1093/ct/qtaa008
   Arias, 2019, THESIS U MIAMI
   Aruguete N, 2018, J COMMUN, V68, P480, DOI 10.1093/joc/jqy007
   BANK WORLD, 2017, WORLD DEV REP 2017 G, p[2, 7, 25, 41]
   Batista D., 2017, INSIGHTS SOCIAL MEDI
   Baumeister R.F., 1997, REV GEN PSYCHOL, V1, P311, DOI [DOI 10.1037/1089-2680.1.3.311, 10.1037/1089-2680.1.3.311]
   Bejar S, 2020, J ELECT PUBLIC OPIN, V30, P1, DOI 10.1080/17457289.2018.1545775
   Bennett WL, 2008, J COMMUN, V58, P707, DOI 10.1111/j.1460-2466.2008.00410.x
   Birnbaum L., 2019, 2019 INT C ADV SOC N
   Boczkowski, 2017, HEADLINES HASHTAGS V, P35
   Boczkowski PJ, 2018, J COMPUT-MEDIAT COMM, V23, P245, DOI 10.1093/jcmc/zmy012
   Boczkowski PJ, 2018, NEW MEDIA SOC, V20, P3523, DOI 10.1177/1461444817750396
   Boczkowski PJ, 2013, NEWS GAP: WHEN THE INFORMATION PREFERENCES OF THE MEDIA AND THE PUBLIC DIVERGE, P1
   BRADY HE, 1995, AM POLIT SCI REV, V89, P271, DOI 10.2307/2082425
   Bruckman, 2016, EARLY ADOPTERS INTER, DOI [10.1145/2818048.2819947, DOI 10.1145/2818048.2819947]
   Bugs R., 2017, REV LATINA COMUNICAC, V72, P1278, DOI 10.4185/RLCS-2017-1219en
   CALvO Ernesto, 2020, FAKE NEWS TROLLS OTR
   Cardoso G, 2016, INT J COMMUN-US, V10, P3909
   Corrales Mejuias, 2015, IMPACTO REDES SOCIAL
   Council on Hemispheric Affairs, 2010, WASH REP HEM
   CUSTODIO L, 2017, FAVELA MEDIA ACTIVIS
   Dahl RobertAlan., 1989, DEMOCRACY ITS CRITIC
   Galvez-Rodriguez MD, 2018, PUBLIC RELAT REV, V44, P265, DOI 10.1016/j.pubrev.2018.03.003
   Dubois E, 2018, INFORM COMMUN SOC, V21, P729, DOI 10.1080/1369118X.2018.1428656
   Filer T, 2017, INT J POLITICS CULT, V30, P259, DOI 10.1007/s10767-016-9233-7
   Fisher Max, 2019, NEW YORK TIMES
   Friedman EJ, 2017, INTERPRETING THE INTERNET: FEMINIST AND QUEER COUNTERPUBLICS IN LATIN AMERICA, P1
   Gainous J, 2016, ONLINE INFORM REV, V40, P712, DOI 10.1108/OIR-11-2015-0351
   Garcuia Santamaruia, 2018, DIGITAL MEDIA PROMOT
   Luque SG, 2017, COMMUN SOC-SPAIN, V30, P77, DOI 10.15581/003.30.3.77-97
   Gray TJ, 2017, SOC SCI QUART, V98, P326, DOI 10.1111/ssqu.12270
   Halpern D, 2017, J COMPUT-MEDIAT COMM, V22, P320, DOI 10.1111/jcc4.12198
   Harlow S., 2017, LIBERATION TECHNOLOG
   Harlow S, 2012, NEW MEDIA SOC, V14, P225, DOI 10.1177/1461444811410408
   Harlow S, 2012, INFORM COMMUN SOC, V15, P196, DOI 10.1080/1369118X.2011.591411
   Harp D, 2012, INT J COMMUN-US, V6, P298
   Hausmann R, 2018, 342 CID HARV U
   Haynes Nell, 2016, SOCIAL MEDIA NO CHIL
   Hoskins G., 2013, INT J TECHNOLOGY KNO, V9, P25
   Hughes S., 2017, ASSAULT JOURNALISM B, P303
   Criado JI, 2013, GOV INFORM Q, V30, P319, DOI 10.1016/j.giq.2013.10.003
   Kofi Annan Foundation, 2017, EL INT LAT AM
   Labaqui, 2015, ESTUDIO COMPARADO DE
   Lee C, 2018, TELEMAT INFORM, V35, P245, DOI 10.1016/j.tele.2017.11.005
   Levitsky S, 2018, J DEMOCR, V29, P102, DOI 10.1353/jod.2018.0066
   Long M., 2018, ONLINE ACTIVISM LATI, P252
   Lupu N, 2020, J DEMOCR, V31, P160, DOI 10.1353/jod.2020.0038
   Machado C., 2018, NEWS POLITICAL INFOR
   Masias VH, 2018, TELEMAT INFORM, V35, P1809, DOI 10.1016/j.tele.2018.05.010
   Mastrini G., 2017, MEDIOS GUERRA BALANC
   Matos C, 2017, INT SOCIOL, V32, P417, DOI 10.1177/0268580917694971
   Mitchelstein E, 2018, CIC-CUAD INF COMUN, V23, P157, DOI 10.5209/CIYC.60913
   Morgans C, 2018, LAT AM PERSPECT, V45, P250, DOI 10.1177/0094582X18760520
   Mourao, 2016, THESIS U TEXAS AUSTI
   Navia P, 2017, CUAD INFO-SANTIAGO, P71, DOI 10.7764/cdi.40.1049
   Nemer D, 2016, INFORM TECHNOL DEV, V22, P364, DOI 10.1080/02681102.2015.1011598
   Orben A, 2020, PERSPECT PSYCHOL SCI, V15, P1143, DOI 10.1177/1745691620919372
   PAYNE Michael, 2006, POLITICA IMPORTA DEM
   Picazo-Vela S, 2016, GOV INFORM Q, V33, P693, DOI 10.1016/j.giq.2016.08.004
   Purez Arguaello M., 2019, DISINFORMATION DEMOC, P20
   Recuero R, 2015, SOC MEDIA SOC, V1, DOI 10.1177/2056305115580332
   Rincon Omar, 2011, NUEVA SOC, V235, P74
   Riorda M, 2017, AUSTRAL COMUN, V6, P5
   Rodruiguez-Virgili J., 2018, REV INTERDISCIPLINAR, V27, P19
   Rosenstone SJ., 1993, MOBILIZATION PARTICI
   Saldana M, 2017, JOURNAL PRACT, V11, P396, DOI 10.1080/17512786.2016.1151818
   Santana B., 2013, NUEVA SOC, V247, P4
   Santana LE, 2019, CUAD INFO-SANTIAGO, P61, DOI 10.7764/cdi.44.1629
   Segado-Boj F, 2015, REV LAT COMUN SOC, V70, P156, DOI 10.4185/RLCS-2015-1040
   Semenova E., 2017, C E DEM OP GOV KREMS
   Senmartin D., 2014, DIGITAL TECHNOLOGIES, P183
   Sponholz L, 2019, GLOB MEDIA COMMUN, V15, P67, DOI 10.1177/1742766518818870
   Spyer J., 2017, SOCIAL MEDIA EMERGEN
   Terrasa, 2019, EL MUNDO
   Transparencia Electoral en Amurica Latina, 2018, MIS EL PAR
   United Nations Educational Scientific and Cultural Organization, 2018, WORLD TRENDS FREED E
   Valenzuela S, 2021, DIGIT JOURNAL, V9, P155, DOI 10.1080/21670811.2019.1693904
   Valenzuela S, 2018, POLIT COMMUN, V35, P117, DOI 10.1080/10584609.2017.1334726
   Valenzuela S, 2016, ONLINE INFORM REV, V40, P695, DOI 10.1108/OIR-11-2015-0347
   Valenzuela S, 2012, J COMMUN, V62, P299, DOI 10.1111/j.1460-2466.2012.01635.x
   van Dijck J, 2013, MEDIA COMMUN, V1, P2, DOI 10.17645/mac.v1i1.70
   Waisbord S, 2017, INFORM COMMUN SOC, V20, P1330, DOI 10.1080/1369118X.2017.1328521
   We Are Social & Hootsuite, 2020, DIG 2020 GLOB DIG OV
   Weeks BE, 2021, AM BEHAV SCI, V65, P277, DOI 10.1177/0002764219878236
   Weiss AS, 2015, INT COMMUN GAZ, V77, P74, DOI 10.1177/1748048514556985
   Welp Y, 2017, CROSS BOUND GEND, P131, DOI 10.1057/978-1-349-95009-6_8
   Zulianello M, 2018, INT J PRESS/POLIT, V23, P439, DOI 10.1177/1940161218783836
   Zuluaga J., 2012, MAPPING DIGITAL MEDI
NR 92
TC 0
Z9 0
U1 6
U2 15
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 2056-3051
J9 SOC MEDIA SOC
JI Soc. Med. Soc.
PD OCT
PY 2020
VL 6
IS 4
AR 2056305120984452
DI 10.1177/2056305120984452
PG 11
WC Communication
WE Social Science Citation Index (SSCI)
SC Communication
GA PO7IV
UT WOS:000605343200001
OA gold
DA 2022-02-06
ER

PT J
AU Allison, T
AF Allison, Tanine
TI Race and the digital face: Facial (mis)recognition in Gemini Man
SO CONVERGENCE-THE INTERNATIONAL JOURNAL OF RESEARCH INTO NEW MEDIA
   TECHNOLOGIES
LA English
DT Article
DE digital visual effects; racial justice; deepfakes; facial recognition;
   computer-generated imagery; digital humans
AB Ang Lee's 2019 film Gemini Man features the most realistic digital human to grace the cinematic screen, specifically a computer-generated version of young Will Smith who battles his more aged self throughout the film. And for the first time in film history, this photorealistic digital human is Black. This essay explores why this groundbreaking achievement has not been acknowledged or celebrated by the film's production or publicity teams. I argue that Will Smith's particular "post-racial" identity mediates contemporary concerns related to the racialized implications of facial recognition and other digital imaging technologies, as well as to the future of the film industry in the digital age. In the second half of the essay, I examine how the appearance of Will Smith in deepfake parody videos illustrates how race circulates on screens of various media formats. I conclude with a call to use digital visual effects, deepfake tools, and other advanced technologies to further racial justice instead of repeating the problematic usage of the past.
C1 [Allison, Tanine] Emory Univ, Film & Media, Decatur, GA 30033 USA.
C3 Emory University
RP Allison, T (corresponding author), Emory Univ, Dept Film & Media, 109 Rich Bldg,1602 Fishburne Dr, Decatur, GA 30033 USA.
EM talliso@emory.edu
OI Allison, Tanine/0000-0002-5056-3077
CR Allison T, 2015, SPECIAL EFFECTS: NEW HISTORIES/THEORIES/CONTEXTS, P114
   Andreeva N, 2020, BEL AIR PEACOCK GIVE
   Buolamwini J., 2018, NEW YORK TIMES
   BuzzFeedVideo, 2018, YOU WONT BELE WHAT O
   CosmicMatt, 2020, DEEPF CGI WILL SMITH
   Duncan J, 2019, CINEFEX, V167, P58
   Eubanks V., 2017, AUTOMATING INEQUALIT
   Failes I, 2019, PROCEDURAL PORES MOD
   Fletcher J, 2018, THEATRE J, V70, P455, DOI 10.1353/tj.2018.0097
   George N, 2005, HIP HOP AM
   Grush Loren, 2015, GOOGLE ENG APOLOGIZE
   Guerrasio J, 2019, GEMINI MAN STARRING
   Hill, 2020, NEW YORK TIMES
   Idelson K, 2019, VARIETY
   Jipguep-Akhtar M, 2020, SOC FORCES, V98, DOI 10.1093/sf/soz162
   Ketchum K. E., 2009, WOMENS STUD Q TECHN, V37, P183
   King CS, 2017, COMMUN CRIT-CULT STU, V14, P83, DOI 10.1080/14791420.2016.1202422
   King D, 2019, WIRED
   Larson J., 2016, PROPUBLICA
   Leonard D., 2004, INTELLIGENT AGENT, P1
   Maurice, 2013, CINEMA ITS SHADOW RA
   McDonald P, 2012, HOLLYWOOD STARDOM
   Meskimen J, 2019, DEEPER LOOK LIFE IMP
   Mukherjee R, 2014, COLORBLIND SCREEN TE, P39
   Myster Giraffe, 2019, C SMITH
   Nakamura L., 2002, CYBERTYPES RACE ETHN
   Noble SU., 2018, ALGORITHMS OPPRESSIO
   ONeil C., 2016, WEAPONS MATH DESTRUC
   Portanova S, 2017, COMPUTATIONAL CULTUR
   Power E, 2019, TELEGRAPH
   Quinn Eithne., 2019, PIECE ACTION RACE LA
   Reds Only, 2019, WILL SMITH HE STARR
   Reed A, 2013, DIGIT CREAT, V24, P130, DOI 10.1080/14626268.2013.808965
   Robertson, 2019, COMPUT GRAPH WORLD
   Roettgers J, 2016, VARIETY 0420
   Russworm TM, 2018, BLACK CAMERA, V10, P193, DOI 10.2979/blackcamera.10.1.12
   Sammond Nicholas, 2015, BIRTH IND BLACKFACE
   Shamook, 2019, WILL SMITH NEO MATR
   Simonite T, 2018, WIRED 0111
   Singer N., 2019, NEW YORK TIMES
   Smith W, 2020, CONVERSATION BEING B
   Smith W, 2009, USA TODAY
   Smith W, 2019, GEMINI MAN OFFICIAL
   Sperling, 2021, NEW YORK TIMES
   The Fake Report, 2020, WILL SMITH IS WITCH
   VFXChris Ume, 2019, WILL SMITHS ENT DRAG
   Warren-Chow H., 2017, SCREEN BODIES, V2, P22
   Watson, 2009, PIMPS WIMPS STUDS TH, P126
   Williams L., 1990, Computer Graphics, V24, P235
NR 49
TC 0
Z9 0
U1 2
U2 2
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 1354-8565
EI 1748-7382
J9 CONVERGENCE-US
JI Convergence
PD AUG
PY 2021
VL 27
IS 4
SI SI
BP 999
EP 1017
AR 13548565211031041
DI 10.1177/13548565211031041
EA JUL 2021
PG 19
WC Communication
WE Social Science Citation Index (SSCI)
SC Communication
GA UK7UP
UT WOS:000679510800001
DA 2022-02-06
ER

PT J
AU Chen, YT
   Tao, JJ
   Wang, J
   Chen, X
   Xie, JB
   Xiong, J
   Yang, K
AF Chen, Yuantao
   Tao, Jiajun
   Wang, Jin
   Chen, Xi
   Xie, Jingbo
   Xiong, Jie
   Yang, Kai
TI The Novel Sensor Network Structure for Classification Processing Based
   on the Machine Learning Method of the ACGAN
SO SENSORS
LA English
DT Article
DE generative adversarial networks (GAN); auxiliary classifier generative
   adversarial networks (ACGAN); feature matching; image classification;
   CP-ACGAN
AB To address the problem of unstable training and poor accuracy in image classification algorithms based on generative adversarial networks (GAN), a novel sensor network structure for classification processing using auxiliary classifier generative adversarial networks (ACGAN) is proposed in this paper. Firstly, the real/fake discrimination of sensor samples in the network has been canceled at the output layer of the discriminative network and only the posterior probability estimation of the sample tag is outputted. Secondly, by regarding the real sensor samples as supervised data and the generative sensor samples as labeled fake data, we have reconstructed the loss function of the generator and discriminator by using the real/fake attributes of sensor samples and the cross-entropy loss function of the label. Thirdly, the pooling and caching method has been introduced into the discriminator to enable more effective extraction of the classification features. Finally, feature matching has been added to the discriminative network to ensure the diversity of the generative sensor samples. Experimental results have shown that the proposed algorithm (CP-ACGAN) achieves better classification accuracy on the MNIST dataset, CIFAR10 dataset and CIFAR100 dataset than other solutions. Moreover, when compared with the ACGAN and CNN classification algorithms, which have the same deep network structure as CP-ACGAN, the proposed method continues to achieve better classification effects and stability than other main existing sensor solutions.
C1 [Chen, Yuantao; Tao, Jiajun; Wang, Jin; Chen, Xi] Changsha Univ Sci & Technol, Sch Comp & Commun Engn, Changsha 410114, Hunan, Peoples R China.
   [Chen, Yuantao; Tao, Jiajun; Wang, Jin; Chen, Xi] Changsha Univ Sci & Technol, Hunan Prov Key Lab Intelligent Proc Big Data Tran, Changsha 410114, Hunan, Peoples R China.
   [Wang, Jin] Fujian Univ Technol, Sch Informat Sci & Engn, Fuzhou 350118, Fujian, Peoples R China.
   [Xie, Jingbo] Hunan Inst Sci & Tech Informat, Changsha 410001, Hunan, Peoples R China.
   [Xiong, Jie] Yangtze Univ, Elect & Informat Sch, Jingzhou 434023, Peoples R China.
   [Yang, Kai] Hunan ZOOMLION Heavy Ind Intelligent Technol Corp, Tech Qual Dept, Changsha 410005, Hunan, Peoples R China.
C3 Changsha University of Science & Technology; Changsha University of
   Science & Technology; Fujian University of Technology; Yangtze
   University
RP Wang, J (corresponding author), Changsha Univ Sci & Technol, Sch Comp & Commun Engn, Changsha 410114, Hunan, Peoples R China.; Wang, J (corresponding author), Changsha Univ Sci & Technol, Hunan Prov Key Lab Intelligent Proc Big Data Tran, Changsha 410114, Hunan, Peoples R China.; Wang, J (corresponding author), Fujian Univ Technol, Sch Informat Sci & Engn, Fuzhou 350118, Fujian, Peoples R China.
EM jinwang@csust.edu.cn
RI wang, jin/AAI-7009-2020
OI wang, jin/0000-0001-5473-8738
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61811530332, 61811540410]; Open Research
   Fund of Hunan Provincial Key Laboratory of Intelligent Processing of Big
   Data on Transportation [2015TP1005]; Changsha Science and Technology
   Planning [KQ1703018, KQ1706064, KQ1703018-01, KQ1703018-04]; Research
   Foundation of Education Bureau of Hunan Province [17A007]; Changsha
   Industrial Science and Technology [2017-7]; Junior Faculty Development
   Program Project of Changsha University of Science and Technology
   [2019QJCZ011]
FX This research was funded by the National Natural Science Foundation of
   China [61811530332,61811540410], the Open Research Fund of Hunan
   Provincial Key Laboratory of Intelligent Processing of Big Data on
   Transportation [2015TP1005], the Changsha Science and Technology
   Planning [KQ1703018, KQ1706064, KQ1703018-01, KQ1703018-04], the
   Research Foundation of Education Bureau of Hunan Province [17A007],
   Changsha Industrial Science and Technology Commissioner [2017-7], the
   Junior Faculty Development Program Project of Changsha University of
   Science and Technology [2019QJCZ011].
CR Boureau Y. L., 2010, 27 INT C MACHINE LEA, P111
   Chen XY, 2019, IEEE T IMAGE PROCESS, V28, P546, DOI 10.1109/TIP.2018.2869695
   Chen Y., 2019, MULTIMED TOOLS APPL, DOI [10.1007/s11042-019-07756-1, DOI 10.1007/S11042-019-07756-1]
   Chen YT, 2019, CLUSTER COMPUT, V22, pS7435, DOI 10.1007/s10586-018-1772-4
   Chen YT, 2019, J AMB INTEL HUM COMP, V10, P4855, DOI 10.1007/s12652-018-01171-4
   Chen YT, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9112316
   Chen YT, 2019, IEEE ACCESS, V7, P58791, DOI 10.1109/ACCESS.2019.2911892
   Chen YT, 2019, CLUSTER COMPUT, V22, pS7665, DOI 10.1007/s10586-018-2368-8
   Csurka G., 2004, P WORK STAT LEARN CO, P1, DOI DOI 10.1234/12345678
   d'Acremont A, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19092040
   Donati L, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9071385
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Du PJ, 2018, IEEE T GEOSCI REMOTE, V56, P4664, DOI 10.1109/TGRS.2018.2833882
   Gao GW, 2020, NEURAL COMPUT APPL, V32, P4361, DOI 10.1007/s00521-018-3826-1
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Gui Y, 2020, VISUAL COMPUT, V36, P469, DOI 10.1007/s00371-019-01633-6
   He SM, 2018, IEEE ACCESS, V6, P17996, DOI 10.1109/ACCESS.2018.2820093
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Khan R, 2015, COMPUT VIS IMAGE UND, V132, P102, DOI 10.1016/j.cviu.2014.09.005
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.181, 10.1109/CVPR.2015.7299136]
   Kingma D., 2014, ADV NEURAL INFORM PR, V27, P3581
   Kofler C, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19092056
   Koniusz P, 2017, IEEE T PATTERN ANAL, V39, P313, DOI 10.1109/TPAMI.2016.2545667
   Krizhevsky A., 2012, ADV NEURAL INF PROCE, P1097, DOI DOI 10.1145/3065386
   Kumar V, 2016, IEEE T IMAGE PROCESS, V25, P5212, DOI 10.1109/TIP.2016.2605919
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Ling RT, 2006, ICAT 2006: 16TH INTERNATIONAL CONFERENCE ON ARTIFICIAL REALITY AND TELEXISTENCE - WORSHOPS, PROCEEDINGS, P5
   METROPOLIS N, 1949, J AM STAT ASSOC, V44, P335, DOI 10.2307/2280232
   Min XK, 2017, IEEE T IMAGE PROCESS, V26, P5462, DOI 10.1109/TIP.2017.2735192
   Mirza M, 2014, ARXIV PREPRINT ARXIV
   Odena A, 2017, PR MACH LEARN RES, V70
   Qiao T.T, 2019, P IEEE C COMP VIS PA
   Radford A., 2015, ARXIV151106434
   Salimans T., 2016, NEURIPS, P2234, DOI DOI 10.5555/3157096.3157346
   Scherer D, 2010, LECT NOTES COMPUT SC, V6354, P92, DOI 10.1007/978-3-642-15825-4_10
   Sun RX, 2019, J SUPERCOMPUT, V75, P3317, DOI 10.1007/s11227-018-2517-0
   Tan DS, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19071587
   Turajlic E, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8020163
   Ulyanov D., 2017, ARXIV170402304
   Wang J, 2019, INT J DISTRIB SENS N, V15, DOI 10.1177/1550147719839581
   [王万良 Wang Wanliang], 2018, [通信学报, Journal on Communications], V39, P135
   Xia XJ, 2019, IEEE T MULTIMEDIA, V21, P1359, DOI 10.1109/TMM.2018.2879750
   Xiang LY, 2019, NEURAL PROCESS LETT, V49, P1055, DOI 10.1007/s11063-018-9892-7
   Yin YY, 2020, MOBILE NETW APPL, V25, P391, DOI 10.1007/s11036-019-01241-7
   Yin YY, 2018, IEEE ACCESS, V6, P62815, DOI 10.1109/ACCESS.2018.2877137
   Yu Y, 2019, IEEE T NEUR NET LEAR, V30, P1250, DOI 10.1109/TNNLS.2018.2856253
   Zhan Y, 2018, IEEE GEOSCI REMOTE S, V15, P212, DOI 10.1109/LGRS.2017.2780890
   Zhang HM, 2019, IEEE T NEUR NET LEAR, V30, P2825, DOI 10.1109/TNNLS.2018.2885699
   Zhang JM, 2019, MATH BIOSCI ENG, V16, P3345, DOI 10.3934/mbe.2019167
   Zhang JM, 2020, MULTIMED TOOLS APPL, V79, P15095, DOI 10.1007/s11042-018-6562-8
   Zhou JH, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19112609
   Zhou SW, 2019, IEEE T PARALL DISTR, V30, P1390, DOI 10.1109/TPDS.2018.2883550
   Zhu L, 2018, IEEE T GEOSCI REMOTE, V56, P5046, DOI 10.1109/TGRS.2018.2805286
NR 54
TC 10
Z9 11
U1 6
U2 18
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 1424-8220
J9 SENSORS-BASEL
JI Sensors
PD JUL 12
PY 2019
VL 19
IS 14
AR 3145
DI 10.3390/s19143145
PG 20
WC Chemistry, Analytical; Engineering, Electrical & Electronic; Instruments
   & Instrumentation
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Chemistry; Engineering; Instruments & Instrumentation
GA IO1RT
UT WOS:000479160300112
PM 31319556
OA gold, Green Published, Green Submitted
DA 2022-02-06
ER

PT J
AU Ciampaglia, GL
   Mantzarlis, A
   Maus, G
   Menczer, F
AF Ciampaglia, Giovanni Luca
   Mantzarlis, Alexios
   Maus, Gregory
   Menczer, Filippo
TI Research Challenges of Digital Misinformation: Toward a Trustworthy Web
SO AI MAGAZINE
LA English
DT Editorial Material
ID NEWS
AB The deluge of online and offline misinformation is overloading the exchange of ideas upon which democracies depend. Fake news, conspiracy theories, and deceptive social bots proliferate, facilitating the manipulation of public opinion. Countering misinformation while protecting freedom of speech will require collaboration across industry, journalism, and academe. The Workshop on Digital Misinformation - held in May 2017, in conjunction with the International AAAI Conference on Web and Social Media in Montreal - was intended to foster these efforts. The meeting brought together more than 100 stakeholders from academia, media, and tech companies to discuss the research challenges implicit in building a trustworthy web. In this article, we outline the main findings from the discussion.
C1 [Ciampaglia, Giovanni Luca] Indiana Univ, Network Sci Inst, Indiana, PA USA.
   [Ciampaglia, Giovanni Luca] Wikimedia Fdn, Zurich, Switzerland.
   [Ciampaglia, Giovanni Luca] Swiss Fed Inst Technol Zurich, Zurich, Switzerland.
   [Mantzarlis, Alexios] Poynter Inst, Int Fact Checking Network, St Petersburg, FL USA.
   [Mantzarlis, Alexios] United Nations & Italian Inst Int Polit Studies, Fiesole, Italy.
   [Maus, Gregory] Indiana Univ, Bloomington, IN 47405 USA.
   [Menczer, Filippo] Indiana Univ, Informat & Comp Sci, Bloomington, IN 47405 USA.
C3 Pennsylvania State System of Higher Education (PASSHE); Indiana
   University of Pennsylvania; Wikimedia Foundation; ETH Zurich; Indiana
   University System; Indiana University Bloomington; Indiana University
   System; Indiana University Bloomington
RP Ciampaglia, GL (corresponding author), Indiana Univ, Network Sci Inst, Indiana, PA USA.; Ciampaglia, GL (corresponding author), Wikimedia Fdn, Zurich, Switzerland.; Ciampaglia, GL (corresponding author), Swiss Fed Inst Technol Zurich, Zurich, Switzerland.
FU Network Science Institute; School of Informatics, Computing, and
   Engineering at Indiana University
FX We are grateful to Alessandro Flammini, who co-organized the workshop.
   We acknowledge support from the Network Science Institute (iuni.iu.edu)
   and the School of Informatics, Computing, and Engineering
   (sice.indiana.edu) at Indiana University.
CR Alfifi M., 2017, LECT NOTES COMPUTER, p[10539, 218], DOI [10.1007/978-3-319-67217-5_14, DOI 10.1007/978-3-319-67217-5_14]
   Arif A, 2016, ACM CONFERENCE ON COMPUTER-SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING (CSCW 2016), P466, DOI 10.1145/2818048.2819964
   Bode L, 2015, J COMMUN, V65, P619, DOI 10.1111/jcom.12166
   Conover M. D., 2011, ICWSM, V133, P89, DOI DOI 10.1021/JA202932E
   Dailey D, 2014, COMPUT SUPP COOP W J, V23, P445, DOI 10.1007/s10606-014-9208-z
   Davis CA, 2016, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.87
   Davis CA, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16 COMPANION), P273, DOI 10.1145/2872518.2889302
   Diakopoulos N, 2017, STUD BIG DATA, V32, P25, DOI 10.1007/978-3-319-54024-5_2
   Diakopoulos N, 2017, DIGIT JOURNAL, V5, P809, DOI 10.1080/21670811.2016.1208053
   Diaz F, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0145406
   Ferrara E, 2016, COMMUN ACM, V59, P96, DOI 10.1145/2818717
   Fredheim R., 2017, ROBOTROLLING
   Funk C., 2016, POLITICS CLIMATE
   Garrett RK, 2016, J COMPUT-MEDIAT COMM, V21, P331, DOI 10.1111/jcc4.12164
   Glenski M, 2017, IEEE TRANS COMPUT SO, V4, P196, DOI 10.1109/TCSS.2017.2742242
   Glenski M, 2017, ACM T INTEL SYST TEC, V8, DOI 10.1145/2963104
   Huang YLL, 2015, PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON COMPUTER-SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING (CSCW'15), P969, DOI 10.1145/2675133.2675202
   Jeon-Hyung Kang, 2015, Social Computing, Behavioral-Cultural Modeling and Prediction. 8th International Conference, SBP 2015. Proceedings: LNCS 9021, P101, DOI 10.1007/978-3-319-16268-3_11
   Kaghazgaran Parisa, 2017, P 11 INT AAAI C WEB, P560
   Kosslyn J., 2017, GOOGLE BLOG     0407
   Lerman K, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0098914
   Li C, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P577, DOI 10.1145/3038912.3052643
   Ma J., 2016, P 25 INT JOINT C ART, P3818
   Maddock J, 2015, PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON COMPUTER-SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING (CSCW'15), P228, DOI 10.1145/2675133.2675280
   McGrew S., 2017, AM ED            FAL, P4
   Mikkelson D., 2016, WE HAVE BAD NEWS PRO
   Mosseri A., 2016, NEWS FEED FYI ADDRES
   Mustafaraj E., 2010, WEC SCI 2010 EXT FRO
   Mustafaraj E, 2017, PROCEEDINGS OF THE 2017 ACM WEB SCIENCE CONFERENCE (WEBSCI '17), P235, DOI 10.1145/3091478.3091523
   Nematzadeh A., 2017, ARXIV170700574V2CSCY
   Nikolov D, 2015, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.38
   Pariser E., 2011, FILTER BUBBLE WHAT I
   Pew Research Center, 2017, STAT NEWS MED
   Qazvinian V., 2011, P 2011 C EMP METH NA, P1589
   Qiu XY, 2017, NAT HUM BEHAV, V1, DOI 10.1038/s41562-017-0132
   Resnick P., 2014, COMP JOURN S NEW YAR
   Resnick P, 2008, ACM SIGECOM EXCHANGE, V7, P1, DOI DOI 10.1145/1486877.1486887
   Shao C., 2017, ARXIV170707592V2CSSI
   Shiralkar P., 2017, P IEEE INT C DAT MIN
   Silverman C., 2017, BUZZFEEDNEWS    0808
   Sunstein Cass R., 2009, REPUBLIC COM 2 0
   Sunstein CR, 2002, J POLIT PHILOS, V10, P175, DOI 10.1111/1467-9760.00148
   Suwajanakorn S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073640
   THIES J, 2016, PROC CVPR IEEE, P2387, DOI DOI 10.1109/CVPR.2016.262
   Varol O, 2017, P 11 INT AAAI C WEB
   Varol O, 2017, EPJ DATA SCI, V6, DOI 10.1140/epjds/s13688-017-0111-y
   Weng L, 2012, SCI REP-UK, V2, P1, DOI 10.1038/srep00335
   Zhao Z, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P1395, DOI 10.1145/2736277.2741637
NR 48
TC 8
Z9 8
U1 3
U2 17
PU AMER ASSOC ARTIFICIAL INTELL
PI MENLO PK
PA 445 BURGESS DRIVE, MENLO PK, CA 94025-3496 USA
SN 0738-4602
J9 AI MAG
JI AI Mag.
PD SPR
PY 2018
VL 39
IS 1
BP 65
EP 74
DI 10.1609/aimag.v39i1.2783
PG 10
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GK2HX
UT WOS:000435949900009
OA Green Submitted, Bronze
DA 2022-02-06
ER

PT J
AU Groh, M
   Epstein, Z
   Obradovich, N
   Cebrian, M
   Rahwan, I
AF Groh, Matthew
   Epstein, Ziv
   Obradovich, Nick
   Cebrian, Manuel
   Rahwan, Iyad
TI Human Detection of Machine-Manipulated Media
SO COMMUNICATIONS OF THE ACM
LA English
DT Article
ID DEEP; NEWS
AB Technologies for manipulating and faking online media may outpace people's ability to tell the difference.
C1 [Groh, Matthew; Epstein, Ziv] MIT, Media Lab, Cambridge, MA 02139 USA.
   [Obradovich, Nick; Rahwan, Iyad] Max Planck Inst Human Dev, Ctr Humans & Machines, Berlin, Germany.
   [Cebrian, Manuel] Max Planck Inst Human Dev, Ctr Humans & Machines, Digital Mobilizat Res Grp, Berlin, Germany.
C3 Massachusetts Institute of Technology (MIT); Max Planck Society; Max
   Planck Society
RP Groh, M (corresponding author), MIT, Media Lab, Cambridge, MA 02139 USA.
CR Arik SO, 2018, ADV NEURAL INFORM PR, P10019
   Averbuch-Elor H, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130818
   Bakshy E, 2015, SCIENCE, V348, P1130, DOI 10.1126/science.aaa1160
   Brock A., 2018, LARGE SCALE GAN TRAI, DOI DOI 10.1016/J.VETIMM.2015.04.007
   Chan, 2017, ARTIFICIAL INTELLIGE
   Chen CY, 2015, IEEE I CONF COMP VIS, P2722, DOI 10.1109/ICCV.2015.312
   Chesney B, 2019, CALIF LAW REV, V107, P1753, DOI 10.15779/Z38RV0D15J
   Epstein Z., 2020, ARXIV PREPRINT ARXIV
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Freedberg David, 1989, POWER IMAGES STUDIES
   Garrido P, 2015, COMPUT GRAPH FORUM, V34, P193, DOI 10.1111/cgf.12552
   Girshick R.B., 2017, ABS170306870 CORR
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hertzmann A, 2018, ARTS, V7, DOI 10.3390/arts7020018
   Iizuka S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073659
   Karras T., 2017, ARXIV171010196
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Kim H, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201283
   Kooi T, 2017, MED IMAGE ANAL, V35, P303, DOI 10.1016/j.media.2016.07.007
   Larkin K.G, 2016, ARXIV PREPRINT ARXIV
   Lazer DMJ, 2018, SCIENCE, V359, P1094, DOI 10.1126/science.aao2998
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Mervosh S, 2019, DISTORTED VIDEOS NAN
   Metz C., 2019, FAKE ZUCKERBERG VIDE
   Molodetskikh I., 2019, ARXIV PREPRINT ARXIV
   Nguyen A., 2016, ARXIV161200005
   Owens A., 2015, ABS151208512 CORR
   Pennycook G., 2019, UNDERSTANDING REDUCI
   Poplin R, 2018, NAT BIOMED ENG, V2, P158, DOI 10.1038/s41551-018-0195-0
   Radford A., 2019, LANGUAGE MODELS ARE, V1, P9
   Roberts M. E., 2018, CENSORED DISTRACTION
   Roozenbeek J, 2019, PALGR COMMUN, V5, DOI 10.1057/s41599-019-0279-9
   Saito S., 2016, ARXIV PREPRINT ARXIV
   Suwajanakorn S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073640
   Thies J, 2016, PROC CVPR IEEE, P2387, DOI 10.1109/CVPR.2016.262
   Varner E.R., 2004, MONUMENTA GRAECA ROM, V10
   Vosoughi S, 2018, SCIENCE, V359, P1146, DOI 10.1126/science.aap9559
   Yu JH, 2018, PROC CVPR IEEE, P5505, DOI 10.1109/CVPR.2018.00577
   Zakharov E, 2019, IEEE I CONF COMP VIS, P9458, DOI 10.1109/ICCV.2019.00955
   Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009
   Zhou ZL, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-08931-6
NR 42
TC 2
Z9 2
U1 4
U2 4
PU ASSOC COMPUTING MACHINERY
PI NEW YORK
PA 1601 Broadway, 10th Floor, NEW YORK, NY USA
SN 0001-0782
EI 1557-7317
J9 COMMUN ACM
JI Commun. ACM
PD OCT
PY 2021
VL 64
IS 10
BP 40
EP 47
DI 10.1145/3445972
PG 8
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UW1YZ
UT WOS:000699961600014
OA Bronze, Green Submitted
DA 2022-02-06
ER

PT J
AU Strickland, E
AF Strickland, Eliza
TI Facebook takes on deepfakes
SO IEEE SPECTRUM
LA English
DT Article
AB In September, Facebook sent out a strange casting call: We need all types of people to look into a webcam or phone camera and say very mundane things. The actors stood in bedrooms, hallways, and backyards, and they talked about topics such as the perils of junk food and the importance of arts education. It was a quick and easy gig-with an odd caveat. Facebook researchers would be altering the videos, extracting each person's face and fusing it onto another person's head. In other words, the participants had to agree to become deepfake characters.
NR 0
TC 0
Z9 0
U1 0
U2 21
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0018-9235
EI 1939-9340
J9 IEEE SPECTRUM
JI IEEE Spectr.
PD JAN
PY 2020
VL 57
IS 1
BP 40
EP 57
DI 10.1109/MSPEC.2020.8946309
PG 3
WC Engineering, Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA KB6QY
UT WOS:000506618500016
DA 2022-02-06
ER

PT J
AU Gao, CQ
   Li, XD
   Zhou, FS
   Mu, S
AF Gao, Chenqiang
   Li, Xindou
   Zhou, Fengshun
   Mu, Song
TI Face Liveness Detection Based on the Improved CNN with Context and
   Texture Information
SO CHINESE JOURNAL OF ELECTRONICS
LA English
DT Article
DE face recognition; feature extraction; image classification; image
   texture; neural nets; support vector machines; face liveness detection;
   improved CNN; texture information; key module; face recognition systems;
   fake face; improved Convolutional neural network architecture; low-level
   detailed information; face images; texture feature; conventional
   recognition framework; context information; Face liveness detection;
   Deep learning; Context information; Texture information
ID SPOOFING DETECTION; CLASSIFICATION
AB Face liveness detection, as a key module of real face recognition systems, is to distinguish a fake face from a real one. In this paper, we propose an improved Convolutional neural network (CNN) architecture with two bypass connections to simultaneously utilize low-level detailed information and high-level semantic information. Considering the importance of the texture information for describing face images, texture features are also adopted under the conventional recognition framework of Support vector machine (SVM). The improved CNN and the texture feature based SVM are fused. Context information which is usually neglected by existing methods is well utilized in this paper. Two widely used datasets are used to test the proposed method. Extensive experiments show that our method outperforms the state-of-the-art methods.
C1 [Gao, Chenqiang; Li, Xindou; Zhou, Fengshun; Mu, Song] Chongqing Univ Posts & Telecommun, Sch Commun & Informat Engn, Chongqing 400065, Peoples R China.
   [Gao, Chenqiang; Li, Xindou; Zhou, Fengshun; Mu, Song] Chongqing Key Lab Signal & Informat Proc, Chongqing 400065, Peoples R China.
C3 Chongqing University of Posts & Telecommunications
RP Gao, CQ (corresponding author), Chongqing Univ Posts & Telecommun, Sch Commun & Informat Engn, Chongqing 400065, Peoples R China.; Gao, CQ (corresponding author), Chongqing Key Lab Signal & Informat Proc, Chongqing 400065, Peoples R China.
EM gaocq@cqupt.edu.cn
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61571071]; Chongqing Research Program of
   Basic Research and Frontier Technology (No.cstc2018jcyjAX0227)
FX This work is supported by the National Natural Science Foundation of
   China (No.61571071) and Chongqing Research Program of Basic Research and
   Frontier Technology (No.cstc2018jcyjAX0227).
CR Atoum Y., 2018, IJCB, P319
   Bengio S., 2004, SPEAK LANG REC WORKS
   Bharadwaj S, 2013, IEEE COMPUT SOC CONF, P105, DOI 10.1109/CVPRW.2013.23
   Boulkenafet Z, 2016, IEEE T INF FOREN SEC, V11, P1818, DOI 10.1109/TIFS.2016.2555286
   Chingovska I., 2012, P BIOSIG, P1, DOI DOI 10.1109/VTCFALL.2012.6399116
   Dalal N., 2005, 2005 IEEE COMPUTER S, DOI DOI 10.1109/CVPR.2005.177
   Fan HH, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3243316
   Given MJ, 2012, IEEE INT POWER MODUL, P124, DOI 10.1109/IPMHVC.2012.6518695
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Li J, 2018, CHINESE J ELECTRON, V27, P1206, DOI 10.1049/cje.2018.09.008
   Li L, 2017, STRUCT MULTIDISCIP O, V6, P1, DOI DOI 10.1109/IPTA.2016.7821013
   Liu J, 2015, CHINESE J ELECTRON, V24, P245, DOI 10.1049/cje.2015.04.004
   Liu  X, 2016, FRONTIERS COMPUTER S, V11, P208
   Liu YJ, 2018, PROC CVPR IEEE, P389, DOI 10.1109/CVPR.2018.00048
   Maatta J, 2012, IET BIOMETRICS, V1, P3, DOI 10.1049/iet-bmt.2011.0009
   Nosaka R, 2011, LECT NOTES COMPUT SC, V7088, P82, DOI 10.1007/978-3-642-25346-1_8
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ojansivu V, 2008, LECT NOTES COMPUT SC, V5099, P236, DOI 10.1007/978-3-540-69905-7_27
   Peixoto B., 2011, PAC RIM C ADV IM VID, P82
   Pinto A, 2015, IEEE T IMAGE PROCESS, V24, P4726, DOI 10.1109/TIP.2015.2466088
   Rezende RA, 2012, INNOVATIVE DEVELOPMENTS ON VIRTUAL AND PHYSICAL PROTOTYPING, P121
   Wan J, 2018, CHINESE J ELECTRON, V27, P1183, DOI 10.1049/cje.2018.09.014
   Wen D, 2015, IEEE T INF FOREN SEC, V10, P746, DOI 10.1109/TIFS.2015.2400395
   Yang J., 2014, ARXIV14085601
   Yuan Y, 2016, PROCEEDINGS OF THE 2016 11TH INTERNATIONAL SYMPOSIUM ON ANTENNAS, PROPAGATION AND EM THEORY (ISAPE), P141, DOI 10.1109/ISAPE.2016.7833903
   Zhiwei Zhang, 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P26, DOI 10.1109/ICB.2012.6199754
NR 26
TC 2
Z9 2
U1 0
U2 10
PU TECHNOLOGY EXCHANGE LIMITED HONG KONG
PI BEIJING
PA BLDG#13, PUHUINANLI, SOUTH YUYUANTAN RD, HAIDIAN DIST, BEIJING, 00000,
   PEOPLES R CHINA
SN 1022-4653
EI 2075-5597
J9 CHINESE J ELECTRON
JI Chin. J. Electron.
PD NOV
PY 2019
VL 28
IS 6
BP 1092
EP 1098
DI 10.1049/cje.2019.07.012
PG 7
WC Engineering, Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA LA9JH
UT WOS:000524255900002
OA Bronze
DA 2022-02-06
ER

PT J
AU Zhu, H
   Liu, DAB
AF Zhu, He
   Liu, Dianbo
TI FakeSafe: Human Level Steganography Techniques by Disinformation Mapping
   Using Cycle-Consistent Adversarial Network
SO IEEE ACCESS
LA English
DT Article
DE Steganography; Image reconstruction; Generators; Generative adversarial
   networks; Training; Faces; Neural networks; Generative adversarial
   networks; machine learning; privacy
ID IMAGE QUALITY ASSESSMENT
AB Steganography is the task of concealing a message within an overt medium such that the presence of the hidden message is barely detectable. Recently, myriads of works have introduced the inchoate techniques of deep learning to the field of steganography. Nevertheless, existing issues like small payload capacity and image distortion have exceedingly suffocated the steganographic research. In this paper, we propose FakeSafe, a novel cycle-consistent adversarial network proffering human-level steganography. Mapping the confidential information into fake messages, FakeSafe efficaciously precludes the detection of steganalysis algorithms and human eyes. There are three contributions in our work: (i) we construct a multi-step FakeSafe mapping, which significantly impedes the steganalysis models to identify and recover the hidden message; (ii) our steganographic models are robust enough since they are applicable to multifarious data domains, including image and text information; (iii) we introduce a coverless solution to embed the clandestine message within a medium of a specific type in lieu of a dedicated cover. We have conducted experiments using both benchmark and real-world data sets to demonstrate potential applications of FakeSafe, whose open source library is available online at: https://github.com/mikemikezhu/fake-safe.
C1 [Zhu, He; Liu, Dianbo] Mila Quebec AI Inst, Montreal, PQ H2S 3H1, Canada.
RP Zhu, H (corresponding author), Mila Quebec AI Inst, Montreal, PQ H2S 3H1, Canada.
EM he.zhu@mila.quebec
CR Baluja S., 2017, ADV NEURAL INFORM PR, P2069
   Burnaev E., 2016, P NIPS WORKSH ADV TR, P1
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Holub V, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-1
   Lombardo, 2005, P STUD FAC RES DAY C, P1
   Lucey P, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P57, DOI 10.1109/FG.2011.5771462
   Maheswari SU, 2015, AEU-INT J ELECTRON C, V69, P539, DOI 10.1016/j.aeue.2014.11.004
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Rehman A.U., 2017, ARXIV171107201, P8
   Shi HC, 2018, LECT NOTES COMPUT SC, V10735, P534, DOI 10.1007/978-3-319-77380-3_51
   Srinivasan Y, 2004, 17TH IEEE SYMPOSIUM ON COMPUTER-BASED MEDICAL SYSTEMS, PROCEEDINGS, P122, DOI 10.1109/CBMS.2004.1311702
   Tang WX, 2017, IEEE SIGNAL PROC LET, V24, P1547, DOI 10.1109/LSP.2017.2745572
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zhang L, 2012, IEEE IMAGE PROC, P1477, DOI 10.1109/ICIP.2012.6467150
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 15
TC 0
Z9 0
U1 1
U2 1
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2021
VL 9
BP 159364
EP 159370
DI 10.1109/ACCESS.2021.3129851
PG 7
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA XL4PW
UT WOS:000728128100001
OA gold
DA 2022-02-06
ER

PT J
AU Zhang, SF
   Huang, KZ
   Qian, Z
   Zhang, R
   Hussain, A
AF Zhang, Shufei
   Huang, Kaizhu
   Qian, Zhuang
   Zhang, Rui
   Hussain, Amir
TI Improving generative adversarial networks with simple latent
   distributions
SO NEURAL COMPUTING & APPLICATIONS
LA English
DT Article
DE Generative adversarial network; Deep generative model; Information
   theory; Deep learning; Generation
AB Generative Adversarial Networks (GANs) have drawn great attention recently since they are the powerful models to generate high-quality images. Although GANs have achieved great success, they usually suffer from unstable training and consequently may lead to the poor generations in some cases. Such drawback is argued mainly due to the difficulties in measuring the divergence between the highly complicated the real and fake data distributions, which are normally in the high-dimensional space. To tackle this problem, previous researchers attempt to search a proper divergence capable of measuring the departure of the complex distributions. In contrast, we attempt to alleviate this problem from a different perspective: while retaining the information as much as possible of the original high dimensional distributions, we learn and leverage an additional latent space where simple distributions are defined in a low-dimensional space; as a result, we can readily compute the distance between two simple distributions with an available divergence measurement. Concretely, to retain the data information, the mutual information is maximized between the variables for the high dimensional complex distributions and the low dimensional simple distributions. The departure of the resulting simple distributions are then measured in the original way of GANs. Additionally, for simplifying the optimization further, we optimize directly the lower bound for mutual information. Termed as SimpleGAN, we conduct the proposed approach over the several different baseline models, i.e., conventional GANs, DCGAN, WGAN-GP, WGAN-GP-res, and LSWGAN-GP on the benchmark CIFAR-10 and STL-10 datasets. SimpleGAN shows the obvious superiority on these baseline models. Furthermore, in comparison with the existing methods measuring directly the distribution departure in the high-dimensional space, our method clearly demonstrates its superiority. Finally, a series of experiments show the advantages of the proposed SimpleGAN.
C1 [Zhang, Shufei; Huang, Kaizhu; Qian, Zhuang] Xian Jiaotong Liverpool Univ, Sch Adv Technol, Suzhou 215123, Peoples R China.
   [Zhang, Rui] Xian Jiaotong Liverpool Univ, Sch Sci, SIP, Suzhou 215123, Peoples R China.
   [Hussain, Amir] Edinburgh Napier Univ, Sch Comp, Merchiston Campus, Edinburgh EH10 5DT, Midlothian, Scotland.
C3 Xi'an Jiaotong-Liverpool University; Xi'an Jiaotong-Liverpool
   University; Edinburgh Napier University
RP Huang, KZ (corresponding author), Xian Jiaotong Liverpool Univ, Sch Adv Technol, Suzhou 215123, Peoples R China.
EM Shufei.Zhang@xjtlu.edu.cn; Kaizhu.Huang@xitlu.edu.cn;
   zhuang.qian20@student.xjtlu.edu.cn; rui.zhang02@xjtlu.edu.cn;
   a.hussain@napier.ac.uk
RI Hussain, Amir/AAG-6299-2020
OI Hussain, Amir/0000-0002-8080-082X
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61876155]; Jiangsu Science and Technology
   Programme (Natural Science Foundation of Jiangsu Province) [BE2020006-4,
   BK20181189]; Key Program Special Fund in XJTLU [KSF-T-06]
FX The work was partially supported by the following: National Natural
   Science Foundation of China under No. 61876155; Jiangsu Science and
   Technology Programme (Natural Science Foundation of Jiangsu Province)
   under Nos. BE2020006-4, BK20181189; Key Program Special Fund in XJTLU
   under No. KSF-T-06.
CR Adler J., 2018, ARXIV180606621, P6754
   Alam M, 2018, NEURAL NETWORKS, V107, P12, DOI 10.1016/j.neunet.2018.04.020
   Arjovsky M., 2017, ADV NEURAL INFORM PR, P5769
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Berthelot D., 2017, ARXIV170310717
   Brock A., 2018, LARGE SCALE GAN TRAI, DOI DOI 10.1016/J.VETIMM.2015.04.007
   Chaari M, 2018, NEURAL NETWORKS, V104, P26, DOI 10.1016/j.neunet.2018.04.004
   CHEN X, 2016, ADV NEUR IN, V29
   Chintala S, 2015, ARXIV151106434
   DAI Z, 2017, ADV NEUR IN
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Huang K., 2019, DEEP LEARNING FUNDAM
   Jin XB, 2019, COGN COMPUT, V11, P503, DOI 10.1007/s12559-019-09629-z
   Kamimura R, 2017, NEURAL NETWORKS, V90, P56, DOI 10.1016/j.neunet.2017.03.001
   Kiasari MA, 2018, NEURAL NETWORKS, V100, P1, DOI 10.1016/j.neunet.2018.01.002
   Kingma D., 2013, ARXIV13126114
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li CX, 2017, ADV NEUR IN, V30
   Li W, 2019, NEURAL NETWORKS, V119, P31, DOI 10.1016/j.neunet.2019.07.001
   Liu LL, 2020, IEEE T NEUR NET LEAR, V31, P3540, DOI 10.1109/TNNLS.2019.2944979
   Lyu CC, 2015, IEEE DATA MINING, P301, DOI 10.1109/ICDM.2015.84
   Mao XD, 2019, IEEE T PATTERN ANAL, V41, P2947, DOI 10.1109/TPAMI.2018.2872043
   Miyato T, 2018, INT C LEARN REPR
   Nowozin Sebastian, 2016, ADV NEURAL INFORM PR
   Roth K., 2017, ADV NEURAL INFORM PR, P2018
   Sajjadi MSM, 2018, PR MACH LEARN RES, V80
   Salimans T., 2016, NEURIPS, P2234, DOI DOI 10.5555/3157096.3157346
   Shufei Zhang, 2019, 2019 International Conference on Data Mining Workshops (ICDMW). Proceedings, P905, DOI 10.1109/ICDMW.2019.00132
   Sonderby Casper Kaae, 2016, ARXIV161004490
   Takano W, 2016, NEURAL NETWORKS, V80, P1, DOI 10.1016/j.neunet.2016.03.001
   Warde-Farley David, 2016, IMPROVING GENERATIVE
   Wu J, 2016, ADV NEURAL INFORM PR, P82, DOI DOI 10.5555/3157096.3157106
   Yang X, 2019, IEEE DATA MINING, P688, DOI 10.1109/ICDM.2019.00079
   Yang X, 2019, COGN COMPUT, V11, P778, DOI 10.1007/s12559-018-9566-9
   Zhang SF, 2019, IEEE DATA MINING, P826, DOI 10.1109/ICDM.2019.00093
   Zheng YJ, 2018, NEURAL NETWORKS, V102, P78, DOI 10.1016/j.neunet.2018.02.015
   Zhong GQ, 2020, COGN COMPUT, V12, P1, DOI 10.1007/s12559-019-09677-5
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 38
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0941-0643
EI 1433-3058
J9 NEURAL COMPUT APPL
JI Neural Comput. Appl.
PD OCT
PY 2021
VL 33
IS 20
BP 13193
EP 13203
DI 10.1007/s00521-021-05946-3
EA APR 2021
PG 11
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WL7HG
UT WOS:000640757300001
DA 2022-02-06
ER

PT J
AU Chen, Y
   Shen, CH
   Chen, H
   Wei, XS
   Liu, LQ
   Yang, J
AF Chen, Yu
   Shen, Chunhua
   Chen, Hao
   Wei, Xiu-Shen
   Liu, Lingqiao
   Yang, Jian
TI Adversarial Learning of Structure-Aware Fully Convolutional Networks for
   Landmark Localization
SO IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE
LA English
DT Article
DE Pose estimation; Two dimensional displays; Three-dimensional displays;
   Heating systems; Task analysis; Training; Pose estimation; landmark
   localization; structure-aware network; adversarial training; multi-task
   learning; deep convolutional networks
ID FLEXIBLE MIXTURES; POSE ESTIMATION; FACE ALIGNMENT
AB Landmark/pose estimation in single monocular images has received much effort in computer vision due to its important applications. It remains a challenging task when input images come with severe occlusions caused by, e.g., adverse camera views. Under such circumstances, biologically implausible pose predictions may be produced. In contrast, human vision is able to predict poses by exploiting geometric constraints of landmark point inter-connectivity. To address the problem, by incorporating priors about the structure of pose components, we propose a novel structure-aware fully convolutional network to implicitly take such priors into account during training of the deep network. Explicit learning of such constraints is typically challenging. Instead, inspired by how human identifies implausible poses, we design discriminators to distinguish the real poses from the fake ones (such as biologically implausible ones). If the pose generator G generates results that the discriminator fails to distinguish from real ones, the network successfully learns the priors. Training of the network follows the strategy of conditional Generative Adversarial Networks (GANs). The effectiveness of the proposed network is evaluated on three pose-related tasks: 2D human pose estimation, 2D facial landmark estimation and 3D human pose estimation. The proposed approach significantly outperforms several state-of-the-art methods and almost always generates plausible pose predictions, demonstrating the usefulness of implicit learning of structures using GANs.
C1 [Chen, Yu; Yang, Jian] Nanjing Univ Sci & Technol, Jiangsu Key Lab Image & Video Understanding Socia, Minist Educ, Key Lab Intelligent Percept & Syst High Dimens In, Nanjing 210094, Jiangsu, Peoples R China.
   [Shen, Chunhua; Chen, Hao; Liu, Lingqiao] Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia.
   [Shen, Chunhua; Chen, Hao; Liu, Lingqiao] Australian Ctr Robot Vis, Brisbane, Qld, Australia.
   [Wei, Xiu-Shen] Megvii Technol, Megvii Res Nanjing, Nanjing 210000, Jiangsu, Peoples R China.
C3 Nanjing University of Science & Technology; University of Adelaide;
   Australian Centre for Robotic Vision
RP Chen, Y; Yang, J (corresponding author), Nanjing Univ Sci & Technol, Jiangsu Key Lab Image & Video Understanding Socia, Minist Educ, Key Lab Intelligent Percept & Syst High Dimens In, Nanjing 210094, Jiangsu, Peoples R China.
EM chenyu1523@gmail.com; chhshen@gmail.com; hao.chen01@adelaide.edu.au;
   weixs.gm@gmail.com; lingqiao.liu@adelaide.edu.au; csjyang@njust.edu.cn
OI Shen, Chunhua/0000-0002-8648-8718; Wei, Xiu-Shen/0000-0002-8200-1845
FU National Science Fund of ChinaNational Natural Science Foundation of
   China (NSFC) [U1713208]; "111" ProgramMinistry of Education, China - 111
   Project [AH92005]; ARC Future FellowshipAustralian Research Council; ARC
   DECRA FellowshipAustralian Research Council; ARCAustralian Research
   Council [CE140100016]; Program for Changjiang ScholarsProgram for
   Changjiang Scholars & Innovative Research Team in University (PCSIRT)
FX This work was partially supported by the National Science Fund of China
   under Grant U1713208, Program for Changjiang Scholars and "111" Program
   AH92005. This work was in part supported by an ARC Future Fellowship to
   C. Shen and an ARC DECRA Fellowship to L. Liu; and ARC Grant
   CE140100016. Y. Chen and X.-S. Wei's contributions were made when
   visiting The University of Adelaide.
CR Akhter I, 2015, PROC CVPR IEEE, P1446, DOI 10.1109/CVPR.2015.7298751
   Andriluka M, 2014, PROC CVPR IEEE, P3686, DOI 10.1109/CVPR.2014.471
   Belagiannis V, 2017, IEEE INT CONF AUTOMA, P468, DOI 10.1109/FG.2017.64
   Belhumeur PN, 2013, IEEE T PATTERN ANAL, V35, P2930, DOI 10.1109/TPAMI.2013.23
   Bogo F, 2016, LECT NOTES COMPUT SC, V9909, P561, DOI 10.1007/978-3-319-46454-1_34
   Buehler P, 2011, INT J COMPUT VISION, V95, P180, DOI 10.1007/s11263-011-0480-9
   Bulat A., 2017, P IEEE INT C COMP VI
   Bulat A, 2016, LECT NOTES COMPUT SC, V9911, P717, DOI 10.1007/978-3-319-46478-7_44
   Burgos-Artizzu XP, 2013, IEEE I CONF COMP VIS, P1513, DOI 10.1109/ICCV.2013.191
   Cao XD, 2014, INT J COMPUT VISION, V107, P177, DOI 10.1007/s11263-013-0667-3
   Cao Z., 2017, CVPR, P7
   Carreira J, 2016, PROC CVPR IEEE, P4733, DOI 10.1109/CVPR.2016.512
   Chen Y., 2018, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2018.00742
   Chen Y, 2016, INT C PATT RECOG, P313, DOI 10.1109/ICPR.2016.7899652
   Chen Y, 2015, IEEE IMAGE PROC, P2115, DOI 10.1109/ICIP.2015.7351174
   Chou CJ, 2018, ASIAPAC SIGN INFO PR, P17, DOI 10.23919/APSIPA.2018.8659538
   Chrysos G. G., 2015, P IEEE INT C COMP VI, P1
   Chu X., 2017, P IEEE C COMP VIS PA
   Chu X, 2016, PROC CVPR IEEE, P4715, DOI 10.1109/CVPR.2016.510
   Collobert R., 2011, P ADV NEUR INF PROC
   Dantone M, 2012, PROC CVPR IEEE, P2578, DOI 10.1109/CVPR.2012.6247976
   Deng JK, 2016, IMAGE VISION COMPUT, V47, P19, DOI 10.1016/j.imavis.2015.11.005
   Denton E. L., 2015, ADV NEURAL INFORM PR, P1486, DOI DOI 10.5555/
   Dollar P, 2010, PROC CVPR IEEE, P1078, DOI 10.1109/CVPR.2010.5540094
   Dong XY, 2018, PROC CVPR IEEE, P379, DOI 10.1109/CVPR.2018.00047
   Du Y, 2016, LECT NOTES COMPUT SC, V9908, P20, DOI 10.1007/978-3-319-46493-0_2
   Eichner M, 2012, INT J COMPUT VISION, V99, P190, DOI 10.1007/s11263-012-0524-9
   Fan HQ, 2016, IMAGE VISION COMPUT, V47, P27, DOI 10.1016/j.imavis.2015.11.004
   Fang HS, 2017, IEEE I CONF COMP VIS, P2353, DOI 10.1109/ICCV.2017.256
   Ghezelghieh MF, 2016, INT CONF 3D VISION, P685, DOI 10.1109/3DV.2016.75
   Gkioxari G, 2016, LECT NOTES COMPUT SC, V9908, P728, DOI 10.1007/978-3-319-46493-0_44
   Gkioxari G, 2014, PROC CVPR IEEE, pCP32, DOI 10.1109/CVPR.2014.458
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI 10.1109/ICCV.2017.322
   Hu PY, 2016, PROC CVPR IEEE, P5600, DOI 10.1109/CVPR.2016.604
   Huang SL, 2017, IEEE I CONF COMP VIS, P3047, DOI 10.1109/ICCV.2017.329
   Insafutdinov E, 2016, LECT NOTES COMPUT SC, V9910, P34, DOI 10.1007/978-3-319-46466-4_3
   Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248
   Johnson S., 2010, BMVC, P5, DOI DOI 10.5244/C.24.12
   Jourabloo A, 2017, IEEE I CONF COMP VIS, P3219, DOI 10.1109/ICCV.2017.347
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   KAZEMI V, 2014, PROC CVPR IEEE, P1867, DOI DOI 10.1109/CVPR.2014.241
   Ke LP, 2018, LECT NOTES COMPUT SC, V11206, P731, DOI 10.1007/978-3-030-01216-8_44
   Kim J, 2016, CHEMNANOMAT, V2, P156, DOI 10.1002/cnma.201500171
   Koestinger Martin, 2011, P IEEE INT C COMP VI, P2144, DOI DOI 10.1109/ICCVW.2011.6130513
   Kowalski M, 2017, IEEE COMPUT SOC CONF, P2034, DOI 10.1109/CVPRW.2017.254
   Le V, 2012, LECT NOTES COMPUT SC, V7574, P679, DOI 10.1007/978-3-642-33712-3_49
   LEE HJ, 1985, COMPUT VISION GRAPH, V30, P148, DOI 10.1016/0734-189X(85)90094-5
   Li SJ, 2015, IEEE I CONF COMP VIS, P2848, DOI 10.1109/ICCV.2015.326
   Lifshitz I, 2016, LECT NOTES COMPUT SC, V9906, P246, DOI 10.1007/978-3-319-46475-6_16
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Lv JJ, 2017, PROC CVPR IEEE, P3691, DOI 10.1109/CVPR.2017.393
   Ma B, 2015, IEEE I CONF COMP VIS, P4400, DOI 10.1109/ICCV.2015.500
   Martinez B, 2016, IMAGE VISION COMPUT, V47, P36, DOI 10.1016/j.imavis.2015.09.003
   Martinez J, 2017, IEEE I CONF COMP VIS, P2659, DOI 10.1109/ICCV.2017.288
   Mathieu M., 2016, ICLR
   Mirza M, 2014, ARXIV PREPRINT ARXIV
   Moreno-Noguer F, 2017, PROC CVPR IEEE, P1561, DOI 10.1109/CVPR.2017.170
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Papandreou G, 2017, PROC CVPR IEEE, P3711, DOI 10.1109/CVPR.2017.395
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Pavlakos G, 2017, PROC CVPR IEEE, P1253, DOI 10.1109/CVPR.2017.138
   Pishchulin L, 2016, PROC CVPR IEEE, P4929, DOI 10.1109/CVPR.2016.533
   Pishchulin L, 2013, IEEE I CONF COMP VIS, P3487, DOI 10.1109/ICCV.2013.433
   Pishchulin L, 2012, PROC CVPR IEEE, P3178, DOI 10.1109/CVPR.2012.6248052
   Radford A., 2016, P INT C LEARN REPR
   Rafi U., 2016, P BRIT MACH VIS C, V1, P2
   Ramakrishna V, 2012, LECT NOTES COMPUT SC, V7575, P573, DOI 10.1007/978-3-642-33765-9_41
   Reed S., 2016, P INT C MACH LEARN, P1
   Ren Shaoqing, 2017, IEEE Trans Pattern Anal Mach Intell, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ren SQ, 2014, PROC CVPR IEEE, P1685, DOI 10.1109/CVPR.2014.218
   Sagonas C, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P397, DOI 10.1109/ICCVW.2013.59
   Salimans T., 2016, NEURIPS, P2234, DOI DOI 10.5555/3157096.3157346
   Sapp B, 2013, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2013.471
   Sapp B, 2010, LECT NOTES COMPUT SC, V6312, P406, DOI 10.1007/978-3-642-15552-9_30
   Scott J A, 1999, Breastfeed Rev, V7, P5
   Sun M, 2011, IEEE I CONF COMP VIS, P723, DOI 10.1109/ICCV.2011.6126309
   Sun Y, 2013, PROC CVPR IEEE, P3476, DOI 10.1109/CVPR.2013.446
   Tekin B., 2016, P BRIT MACH VIS C
   Tekin B, 2016, PROC CVPR IEEE, pCP8, DOI 10.1109/CVPR.2016.113
   Tompson J., 2014, ADV NEURAL INFORM PR, V1
   Tompson J, 2015, PROC CVPR IEEE, P648, DOI 10.1109/CVPR.2015.7298664
   Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214
   Trigeorgis G, 2016, PROC CVPR IEEE, P4177, DOI 10.1109/CVPR.2016.453
   Tzimiropoulos G, 2015, PROC CVPR IEEE, P3659, DOI 10.1109/CVPR.2015.7298989
   Valstar M, 2010, PROC CVPR IEEE, P2729, DOI 10.1109/CVPR.2010.5539996
   Wang XL, 2016, LECT NOTES COMPUT SC, V9908, P318, DOI 10.1007/978-3-319-46493-0_20
   Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511
   Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75
   Yan JJ, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P392, DOI 10.1109/ICCVW.2013.126
   Yang W, 2018, PROC CVPR IEEE, P5255, DOI 10.1109/CVPR.2018.00551
   Yang W, 2017, IEEE I CONF COMP VIS, P1290, DOI 10.1109/ICCV.2017.144
   Yang W, 2016, PROC CVPR IEEE, P3073, DOI 10.1109/CVPR.2016.335
   Yang Y, 2013, IEEE T PATTERN ANAL, V35, P2878, DOI 10.1109/TPAMI.2012.261
   Yang Y, 2011, PROC CVPR IEEE, P1385, DOI 10.1109/CVPR.2011.5995741
   Yoo D, 2016, LECT NOTES COMPUT SC, V9912, P517, DOI 10.1007/978-3-319-46484-8_31
   Zhan J, 2014, DES AUT CON, DOI 10.1145/2593069.2593165
   Zhao J., 2017, P INT C LEARN REPR P INT C LEARN REPR
   Zhou EJ, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P386, DOI 10.1109/ICCVW.2013.58
   Zhou XW, 2017, IEEE T PATTERN ANAL, V39, P1648, DOI 10.1109/TPAMI.2016.2605097
   Zhou XY, 2016, LECT NOTES COMPUT SC, V9915, P186, DOI 10.1007/978-3-319-49409-8_17
   Zhou YP, 2016, LECT NOTES COMPUT SC, V9912, P262, DOI 10.1007/978-3-319-46484-8_16
   Zhu SZ, 2016, PROC CVPR IEEE, P3409, DOI 10.1109/CVPR.2016.371
   Zhu SZ, 2015, PROC CVPR IEEE, P4998, DOI 10.1109/CVPR.2015.7299134
   Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014
NR 106
TC 4
Z9 4
U1 5
U2 18
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 0162-8828
EI 1939-3539
J9 IEEE T PATTERN ANAL
JI IEEE Trans. Pattern Anal. Mach. Intell.
PD JUL 1
PY 2020
VL 42
IS 7
BP 1654
EP 1669
DI 10.1109/TPAMI.2019.2901875
PG 16
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MC0DH
UT WOS:000542967200011
PM 30835211
OA Green Published, Green Submitted
DA 2022-02-06
ER

PT J
AU Zhao, R
   Shi, ZW
AF Zhao, Rui
   Shi, Zhenwei
TI Text-to-Remote-Sensing-Image Generation With Structured Generative
   Adversarial Networks
SO IEEE GEOSCIENCE AND REMOTE SENSING LETTERS
LA English
DT Article
DE Remote sensing; Generators; Task analysis; Bridges; Sensors; Semantics;
   Image segmentation; Generative adversarial networks (GANs); remote
   sensing image synthesize; structural rationality; text description
AB Synthesizing high-resolution remote sensing images based on the given text descriptions has great potential in expanding the image data set to release the power of deep learning in the remote sensing image processing field. However, there has been no efficient research carried out on this formidable task yet. Given a remote sensing image, the structural rationality of ground objects is critical to judge it whether real or fake, e.g., real bridges are always straight, while a sinuous one can be easily judged as fake. Inspired by this, we propose a multistage structured generative adversarial network (StrucGAN) to synthesize remote sensing images in a structured way given the text descriptions. StrucGAN utilizes structural information extracted by an unsupervised segmentation module to enable the discriminators to distinguish the image in a structured way. The generators of StrucGAN are, thus, forced to synthesize structural reasonable image contents, which could enhance the image authenticity. The multistage framework enables the StrucGAN to generate remote sensing images with increasing resolution stage by stage. The quantitative and qualitative experiments' results show that the proposed StrucGAN achieves better performance compared with the baseline, and it could synthesize high resolution, realistic, structural reasonable remote sensing images that are semantically consistent with the given text descriptions.
C1 [Zhao, Rui; Shi, Zhenwei] Beihang Univ, Image Proc Ctr, Sch Astronaut, Beijing 100191, Peoples R China.
   [Zhao, Rui; Shi, Zhenwei] Beihang Univ, Beijing Key Lab Digital Media, Beijing 100191, Peoples R China.
   [Zhao, Rui; Shi, Zhenwei] Beihang Univ, Sch Astronaut, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
C3 Beihang University; Beihang University; Beihang University
RP Shi, ZW (corresponding author), Beihang Univ, Image Proc Ctr, Sch Astronaut, Beijing 100191, Peoples R China.
EM ruizhaoipc@buaa.edu.cn; shizhenwei@buaa.edu.cn
OI Zhao, Rui/0000-0003-4271-0206
FU National Key Research and Development Program of China [2019YFC1510905];
   National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61671037]; Beijing Natural Science
   FoundationBeijing Natural Science Foundation [4192034]
FX This work was supported in part by the National Key Research and
   Development Program of China under Grant 2019YFC1510905, in part by the
   National Natural Science Foundation of China under Grant 61671037, and
   in part by the Beijing Natural Science Foundation under Grant 4192034.
CR Bejiga MB, 2021, IEEE GEOSCI REMOTE S, V18, P622, DOI 10.1109/LGRS.2020.2983851
   Bejiga MB, 2020, 2020 MEDITERRANEAN AND MIDDLE-EAST GEOSCIENCE AND REMOTE SENSING SYMPOSIUM (M2GARSS), P89, DOI 10.1109/M2GARSS47143.2020.9105139
   Bejiga MB, 2019, IEEE J-STARS, V12, P950, DOI 10.1109/JSTARS.2019.2895693
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Lu XX, 2018, IEEE T GEOSCI REMOTE, V56, P2183, DOI 10.1109/TGRS.2017.2776321
   Qiao TT, 2019, PROC CVPR IEEE, P1505, DOI 10.1109/CVPR.2019.00160
   Le Q, 2014, PR MACH LEARN RES, V32, P1188
   Reed S., 2016, P ADV NEURAL INFORM
   Reed S, 2016, PR MACH LEARN RES, V48
   Salimans T., 2016, NEURIPS, P2234, DOI DOI 10.5555/3157096.3157346
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Shi ZW, 2017, IEEE T GEOSCI REMOTE, V55, P3623, DOI 10.1109/TGRS.2017.2677464
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Xu T, 2018, PROC CVPR IEEE, P1316, DOI 10.1109/CVPR.2018.00143
   Zhang H, 2019, IEEE T PATTERN ANAL, V41, P1947, DOI 10.1109/TPAMI.2018.2856256
   Zhang H, 2017, IEEE I CONF COMP VIS, P5908, DOI 10.1109/ICCV.2017.629
   Zheng ZY, 2021, IEEE GEOSCI REMOTE S, V18, P994, DOI 10.1109/LGRS.2020.2992324
NR 18
TC 0
Z9 0
U1 0
U2 0
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1545-598X
EI 1558-0571
J9 IEEE GEOSCI REMOTE S
JI IEEE Geosci. Remote Sens. Lett.
PY 2022
VL 19
DI 10.1109/LGRS.2021.3068391
EA MAR 2021
PG 5
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA XY1VP
UT WOS:000733471900001
DA 2022-02-06
ER

PT J
AU Ali, T
   Jan, S
   Alkhodre, A
   Nauman, M
   Amin, M
   Siddiqui, MS
AF Ali, Toqeer
   Jan, Salman
   Alkhodre, Ahmad
   Nauman, Mohammad
   Amin, Muhammad
   Siddiqui, Muhammad Shoaib
TI DeepMoney: counterfeit money detection using generative adversarial
   networks
SO PEERJ COMPUTER SCIENCE
LA English
DT Article
DE Deep Learning; Counterfeit Money; Generative Adversarial Networks
AB Conventional paper currency and modem electronic currency are two important modes of transactions. In several parts of the world, conventional methodology has clear precedence over its electronic counterpart. However, the identification of forged currency paper notes is now becoming an increasingly crucial problem because of the new and improved tactics employed by counterfeiters. In this paper, a machine assisted system-dubbed DeepMoney-is proposed which has been developed to discriminate fake notes from genuine ones. For this purpose, state-of-the-art models of machine learning called Generative Adversarial Networks (GANs) are employed. GANs use unsupervised learning to train a model that can then be used to perform supervised predictions. This flexibility provides the best of both worlds by allowing unlabelled data to be trained on whilst still making concrete predictions. This technique was applied to Pakistani banknotes. State-of-the-art image processing and feature recognition techniques were used to design the overall approach of a valid input. Augmented samples of images were used in the experiments which show that a high-precision machine can be developed to recognize genuine paper money. An accuracy of 80% has been achieved. The code is available as an open source to allow others to reproduce and build upon the efforts already made.
C1 [Ali, Toqeer; Alkhodre, Ahmad; Siddiqui, Muhammad Shoaib] Islamic Univ Madinah, Fac Comp & Informat Syst, Madinah, Saudi Arabia.
   [Jan, Salman] Univ Kuala Lumpur, Malaysian Inst Informat Technol, Kuala Lumpur, Malaysia.
   [Nauman, Mohammad; Amin, Muhammad] FAST NUCES, Comp Sci, Peshawar, Pakistan.
C3 Islamic University of Al Madinah; University of Kuala Lumpur
RP Ali, T (corresponding author), Islamic Univ Madinah, Fac Comp & Informat Syst, Madinah, Saudi Arabia.
EM toqeer@iu.edu.sa
RI jan, salman/AAT-6209-2021
OI Ali, Toqeer/0000-0002-3936-5483; alkhodre, ahmad/0000-0001-6168-3552
CR Abburu V, 2017, CONT COMP IC3 2017 1, P1
   Alicherry M, 2017, TECHNICAL DISCLOSURE
   Bartkiewicz K, 2017, NPJ QUANTUM INFORM, V3, DOI 10.1038/s41534-017-0010-x
   Berenguel A, 2016, PROCEEDINGS OF 12TH IAPR WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS, (DAS 2016), P66, DOI 10.1109/DAS.2016.34
   Chakraborty K., 2013, INT J RES ENG TECHNO, V2, P222, DOI DOI 10.15623/IJRET.2013.0211034
   Choi WJ, 2010, J OPT SOC KOREA, V14, P316, DOI 10.3807/JOSK.2010.14.4.316
   Derrida Jacques, 1994, GIVEN TIME
   Goodfellow I., 2016, DEEP LEARNING, V1
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Hassanpour H, 2009, EXPERT SYST APPL, V36, P10105, DOI 10.1016/j.eswa.2009.01.057
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735
   Kang K., 2016, INF INT SYST APPL II, P1
   Kayani S., 2017, US Patent, Patent No. [9,761,077, 9761077]
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kusy B, 2009, 2009 INTERNATIONAL CONFERENCE ON INFORMATION PROCESSING IN SENSOR NETWORKS (IPSN 2009), P109
   Magdaleno A, 2016, WOMAN PLEADS GUILTY
   Micali S, 2017, US Patent Application, Patent No. [15/522,348, 15522348]
   Mirza R, 2012, INT J ENG RES DEV, V3, P41
   Murakami-Fester A., 2016, US TODAY
   Phillips R., 2018, US Patent Application, Patent No. [15/817,848, 15817848]
   Prasanthi B. S., 2015, INT J SCI RES ENG TE, V4, P973
   Radford A., 2015, ARXIV151106434
   Ross DJ, 2016, US Patent Application, Patent No. [15/208,339, 15208339]
   Rubeena Mirza, 2012, INT J ENG ADV TECHNO, V1, P68
   Sak H., 2014, 15 ANN C INT SPEECH
   Salimans T., 2016, ADV NEURAL INFORM PR, P2234
   Shoaib M, 2013, 2013 EIGHTH INTERNATIONAL CONFERENCE ON DIGITAL INFORMATION MANAGEMENT (ICDIM), P346, DOI 10.1109/ICDIM.2013.6693982
   Snehlata Saxena V, 2017, INT J ADV RES COMPUT, V8, P213
   Syuhada N., 2014, SCI INT, P1865
   Taillard M, 2018, EC MODERN WELFARE, P153
   Tanaka T, 1996, US Patent, Patent No. [5582103A, 5582103]
   Thakur M., 2014, INT J TECHNOLOGICAL, V1, P1309
   Warrington E, 2017, EXPLORING WORKING ME, P18
NR 33
TC 1
Z9 1
U1 0
U2 1
PU PEERJ INC
PI LONDON
PA 341-345 OLD ST, THIRD FLR, LONDON, EC1V 9LL, ENGLAND
SN 2376-5992
J9 PEERJ COMPUT SCI
JI PeerJ Comput. Sci.
PD SEP 2
PY 2019
AR e216
DI 10.7717/peerj-cs.216
PG 21
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory & Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IU6FK
UT WOS:000483681600002
PM 33816869
OA Green Published, gold
DA 2022-02-06
ER

PT J
AU Zareapoor, M
   Celebi, ME
   Yang, J
AF Zareapoor, Masoumeh
   Celebi, M. Emre
   Yang, Jie
TI Diverse adversarial network for image super-resolution
SO SIGNAL PROCESSING-IMAGE COMMUNICATION
LA English
DT Article
DE Super-resolution; Adversarial network; Diverse GAN; Deep learning
AB Recently, there is a fast growth in Generative adversarial network and many works have appeared focusing not only images but also videos. Despite of remarkable success of GAN in image super resolution, it suffers from the major problem of poor perceptual quality. While employing a GAN for super resolution, it tends to generate over-smoothed images that lacks high frequency textures and do not look natural. We propose an intuitive generalization to Generative Adversarial Network and its conditional variations to address the problem of image super-resolution and improves the test quality of images. DGAN is a diverse GAN architecture incorporating multiple generators and a single discriminator. The main intuition is to employ multiple generators, instead of using a single one as in the original GAN. To enforce that multiple generators produce diverse samples, the discriminator trains a loss function to distinguish between real and fake samples by designed margins, and multiple generators alternately produce realistic samples by minimizing their losses. In fact, this paper addresses 2 main challenges; recovering realistic texture low resolution images and speed up the training process. We perform extensive experiments and compare the proposed model with other variants of GAN to demonstrate the efficiency and stability of the proposed model in both quantitative and qualitative benchmarks.
C1 [Zareapoor, Masoumeh; Yang, Jie] Shanghai Jiao Tong Univ, Dept Automat, Shanghai, Peoples R China.
   [Zareapoor, Masoumeh] Tokyo Univ Technol, Dept Comp Sci, Tokyo, Japan.
   [Celebi, M. Emre] UCA, Dept Comp Sci, Conway, AK USA.
C3 Shanghai Jiao Tong University; Tokyo University of Technology
RP Yang, J (corresponding author), Shanghai Jiao Tong Univ, Dept Automat, Shanghai, Peoples R China.
EM jieyang@sjtu.edu.cn
RI Zareapoor, Masoumeh/AAE-6067-2019; Celebi, M. Emre/G-2129-2012
OI Celebi, M. Emre/0000-0002-2721-6317
FU NSFC, ChinaNational Natural Science Foundation of China (NSFC)
   [U1803261, 61876107, 61572315]; 973 Plan, ChinaNational Basic Research
   Program of China [2015CB856004]
FX This research is partly supported by NSFC, China (U1803261, 61876107,
   61572315); and 973 Plan, China (2015CB856004).
CR Abadi M., 2015, TENSORFLOW LARGE SCA
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Berthelot D., 2017, ARXIV170310717
   Chintala S, 2015, ARXIV151106434
   Dash Ayushman, 2017, ARXIV PREPRINT ARXIV
   Denton E. L., 2015, ADV NEURAL INFORM PR, P1486, DOI DOI 10.5555/
   Trinh DH, 2014, IEEE T IMAGE PROCESS, V23, P1882, DOI 10.1109/TIP.2014.2308422
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Durugkar I., 2017, P INT C LEARN REPR, P1
   Ghosh A, 2017, MULTIAGENT DIVERSE G
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Hui Z., FAST ACCURATE SINGLE
   Isola P., 2017, P IEEE C COMPUTER VI, P5967, DOI DOI 10.1109/CVPR.2017.632
   Kim J. H., 2018, IEEE C COMP VIS PATT
   Kim J, 2016, PROC CVPR IEEE, P1646, DOI 10.1109/CVPR.2016.182
   KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694
   Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618
   Laine, 2018, INT C LEARN REPR
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li Fang, 2017, ARXIV170704881V1
   Lin GM, 2018, SIGNAL PROCESS-IMAGE, V68, P88, DOI 10.1016/j.image.2018.07.003
   Liu M. Y., 2016, P ADV NEUR PROC SYST, P469
   Metz Luke, 2016, ARXIV PREPRINT
   Nasrollahi K, 2014, MACH VISION APPL, V25, P1423, DOI 10.1007/s00138-014-0623-4
   Nowozin Sebastian, 2016, ADV NEURAL INFORM PR
   Phung D., 2017, ARXIV170802556
   Qi G. J., 2018, ARXIV170106264
   Salimans T., 2016, NEURIPS, P2234, DOI DOI 10.5555/3157096.3157346
   Shamsolmoali P, 2019, MULTIMED TOOLS APPL, V78, P23815, DOI 10.1007/s11042-018-5915-7
   SOnderby CK, 2016, AMORTISED MAP INFERE
   Tai Y, 2017, IEEE I CONF COMP VIS, P4549, DOI 10.1109/ICCV.2017.486
   Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298
   Tong T, 2017, IEEE I CONF COMP VIS, P4809, DOI 10.1109/ICCV.2017.514
   Nguyen TD, 2017, ADV NEUR IN, V30
   Villani C, 2009, GRUNDLEHR MATH WISS, V338, P1, DOI 10.1007/978-3-540-71050-9
   Wang Ting Chun, 2017, HIGH RESOLUTION IMAG
   Wang XT, 2018, PROC CVPR IEEE, P606, DOI 10.1109/CVPR.2018.00070
   Wang Y., 2017, ARXIV180402900V2
   Wu Huikai, 2017, P 27 ACM INT C MULT
   Zareapoor M., 2018, J INTELL FUZZY SYSTE, DOI [10.3233/J1FS-18136, DOI 10.3233/J1FS-18136]
   Zareapoor M, 2018, COGN SYST RES, V52, P49, DOI 10.1016/j.cogsys.2018.06.007
   Zareapoor M, 2018, PATTERN RECOGN LETT, V115, P4, DOI 10.1016/j.patrec.2017.09.018
   Zhang Han, 2017, IEEE INT C COMP VIS
   Zhang Z., PHOTOGRAPHIC TEXT IM
   2018, SIGNAL PROCESS-IMAGE, V66, P1, DOI DOI 10.1016/J.IMAGE.2018.04.012
   2010, IEEE T INFORM THEORY, V56, P5847, DOI DOI 10.1109/TIT.2010.2068870
   2016, J SYST ARCHITECT, V64, P63, DOI DOI 10.1016/J.SYSARC.2015.11.005
NR 47
TC 10
Z9 10
U1 5
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0923-5965
EI 1879-2677
J9 SIGNAL PROCESS-IMAGE
JI Signal Process.-Image Commun.
PD MAY
PY 2019
VL 74
BP 191
EP 200
DI 10.1016/j.image.2019.02.008
PG 10
WC Engineering, Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA HU6CL
UT WOS:000465366200018
DA 2022-02-06
ER

PT J
AU Lin, SY
   Kung, YC
   Leu, FY
AF Lin, Szu-Yin
   Kung, Yun-Ching
   Leu, Fang-Yie
TI Predictive intelligence in harmful news identification by BERT-based
   ensemble learning model with text sentiment analysis
SO INFORMATION PROCESSING & MANAGEMENT
LA English
DT Article
DE Information disorder; Harmful news analysis; Natural language
   processing; News sentiment analysis; Ensemble learning; BERT model
ID INFORMATION
AB In an environment full of disordered information, the media spreads fake or harmful information into the public arena with a speed which is faster than ever before. A news report should ideally be neutral and factual. Excessive personal emotions or viewpoints should not be included. News articles ought not to be intentionally or maliciously written or create a media framing. A harmful news is defined as those explicit or implicit harmful speech in news text that harms people or affects readers' perception. However, in the current situation, it is difficult to effectively identify and predict fake or harmful news in advance, especially harmful news. Therefore, in this study, we propose a Bidirectional Encoder Representation from Transformers (BERT) based model which applies ensemble learning methods with a text sentiment analysis to identify harmful news, aiming to provide readers with a way to identify harmful news content so as to help them to judge whether the information provided is in a more neutral manner. The working model of the proposed system has two phases. The first phase is collecting harmful news and establishing a development model for analyzing the correlation between text sentiment and harmful news. The second phase is identifying harmful news by analyzing text sentiment with an ensemble learning technique and the BERT model. The purpose is to determine whether the news has harmful intentions. Our experimental results show that the F1-score of the proposed model reaches 66.3%, an increase of 7.8% compared with that of the previous term frequency-inverse document frequency approach which adopts a Lagrangian Support Vector Machine (LSVM) model without using a text sentiment. Moreover, the proposed method achieves a better performance in recognizing various cases of information disorder.
C1 [Lin, Szu-Yin] Natl Ilan Univ, Dept Comp Sci & Informat Engn, Yilan, Taiwan.
   [Kung, Yun-Ching] Chung Yuan Christian Univ, Dept Informat Management, Taoyuan, Taiwan.
   [Leu, Fang-Yie] Tunghai Univ, Dept Comp Sci, Taichung, Taiwan.
C3 National Ilan University; Chung Yuan Christian University; Tunghai
   University
RP Lin, SY (corresponding author), Natl Ilan Univ, Dept Comp Sci & Informat Engn, Yilan, Taiwan.
EM szuyin@niu.edu.tw; leufy@thu.edu.tw
FU Ministry of Science and Technology of TaiwanMinistry of Science and
   Technology, Taiwan [MOST 109-2410-H-197-002-MY3]
FX This work was supported by the Ministry of Science and Technology of
   Taiwan under Grant MOST 109-2410-H-197-002-MY3.
CR Abualigah LM, 2017, J SUPERCOMPUT, V73, P4773, DOI 10.1007/s11227-017-2046-2
   Ahmed Hadeer, 2018, Security and Privacy, V1, DOI 10.1002/spy2.9
   Ahmed H, 2017, LECT NOTES COMPUT SC, V10618, P127, DOI 10.1007/978-3-319-69155-8_9
   Ajao O, 2019, INT CONF ACOUST SPEE, P2507, DOI 10.1109/ICASSP.2019.8683170
   Arndt J., 1967, RISK TAKING INFORM H, P188
   Behera RK, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2020.102435
   Calefato F, 2017, INT CONF AFFECT, P79, DOI 10.1109/ACIIW.2017.8272591
   Chen MY, 2019, FUTURE GENER COMP SY, V96, P692, DOI 10.1016/j.future.2017.10.028
   Devlin J, 2019, PROC C N AM CHAPTER, P4171, DOI DOI 10.18653/V1/N19-1423
   Elmurngi E., 2017, 6 INT C DAT AN, P65
   FOLKES VS, 1984, J CONSUM RES, V10, P398, DOI 10.1086/208978
   Gan BQ, 2020, INT REV FINANC ANAL, V67, DOI 10.1016/j.irfa.2019.101390
   Gong LY, 2019, PR MACH LEARN RES, V97
   Harris C, 2018, JOINT P ACM IUI 2018
   HERR PM, 1991, J CONSUM RES, V17, P454, DOI 10.1086/208570
   Heston SL, 2017, FINANC ANAL J, V73, P67, DOI 10.2469/faj.v73.n3.3
   Ito TA, 1998, J PERS SOC PSYCHOL, V75, P887, DOI 10.1037/0022-3514.75.4.887
   Kai Shu, 2017, ACM SIGKDD Explorations Newsletter, V19, P22, DOI 10.1145/3137597.3137600
   Karadzhov G., 2017, RANLP 2017 RECENT AD, P334, DOI [10.26615/978-954-452-049-6_045, DOI 10.26615/978-954-452-049-6_045]
   Lee W, 2007, LECT NOTES COMPUT SC, V4489, P18
   Lin J., 2021, SYNTHESIS LECT HUMAN, V14, P1, DOI [10.2200/S01123ED1V01Y202108HLT053, DOI 10.2200/S01123ED1V01Y202108HLT053]
   Ma Y, 2012, ENSEMBLE MACHINE LEARNING: METHODS AND APPLICATIONS, P1, DOI 10.1007/978-1-4419-9326-7
   Mohammad SM, 2013, COMPUT INTELL-US, V29, P436, DOI 10.1111/j.1467-8640.2012.00460.x
   Ogiela L, 2016, 2016 10TH INTERNATIONAL CONFERENCE ON INNOVATIVE MOBILE AND INTERNET SERVICES IN UBIQUITOUS COMPUTING (IMIS), P198, DOI 10.1109/IMIS.2016.119
   Ogiela MR, 2015, 2015 9TH INTERNATIONAL CONFERENCE ON INNOVATIVE MOBILE AND INTERNET SERVICES IN UBIQUITOUS COMPUTING IMIS 2015, P179, DOI 10.1109/IMIS.2015.29
   Ogiela U, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.5557
   Rinker T, 2021, CALCULATE TEXT POLAR, P1
   Rubin V., 2016, P 2 WORKSH COMP APPR, P7, DOI DOI 10.18653/V1/W16-0802
   Samadi M, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2021.102723
   Seebacher U, 2021, PREDICTIVE INTELLIGE, DOI [10.1007/978-3-030-69403-6, DOI 10.1007/978-3-030-69403-6]
   Silge J., 2016, J OPEN SOURCE SOFTW, V1, P1, DOI [10.21105/joss.00037,37, DOI 10.21105/JOSS.00037, 10.21105/joss.00037]
   Vijayarani S., 2015, J COMPUTER SCI COMMU, V5, P7, DOI DOI 10.1016/J.PR0CS.2013.05.286
   Wardle C, 2017, INFORM DISORDER INTE
   WHO, 2012, WORLD MALARIA REPORT 2012, P1
NR 34
TC 0
Z9 0
U1 0
U2 0
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 0306-4573
EI 1873-5371
J9 INFORM PROCESS MANAG
JI Inf. Process. Manage.
PD MAR
PY 2022
VL 59
IS 2
AR 102872
DI 10.1016/j.ipm.2022.102872
PG 18
WC Computer Science, Information Systems; Information Science & Library
   Science
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Information Science & Library Science
GA YP5MM
UT WOS:000748666800001
DA 2022-02-06
ER

PT J
AU Holliday, C
AF Holliday, Christopher
TI Rewriting the stars: Surface tensions and gender troubles in the online
   media production of digital deepfakes
SO CONVERGENCE-THE INTERNATIONAL JOURNAL OF RESEARCH INTO NEW MEDIA
   TECHNOLOGIES
LA English
DT Article
DE digital; stardom; hollywood; performance; cinephilia; internet;
   computer; technology
AB This article examines a cross-section of viral Deepfake videos that utilise the recognisable physiognomies of Hollywood film stars to exhibit the representative possibilities of Deepfakes as a sophisticated technology of illusion. Created by a number of online video artists, these convincing 'mash-ups' playfully rewrite film history by retrofitting canonical cinema with new star performers, from Jim Carrey in The Shining (Stanley Kubrick, 1980) to Tom Cruise in American Psycho (Mary Harron, 2000). The particular remixing of stardom in these videos can - as this article contends - be situated within the technological imaginary of 'take two' cinephilia, and the 'technological performativity of digitally remastered sounds and images' in an era of 'the download, the file swap, [and] the sampling' (Elsaesser 2005: 36-40). However, these 'take two' Deepfake cyberstars further aestheticize an entertaining surface tension between coherency and discontinuity, and in their modularity function as 'puzzling' cryptograms written increasingly in digital code. Fully representing the star-as-rhetorical digital asset, Deepfakes therefore make strange contemporary Hollywood's many digitally mediated performances, while the reskinning of (cisgender white male) stars sharpens the ontology of gender as it is understood through discourses of performativity (Butler 1990; 2004). By identifying Deepfakes as a 'take two' undoing, this article frames their implications for the cultural politics of identity; Hollywood discourses of hegemonic masculinity; overlaps with non-normative subjectivities, 'body narratives' and 'second skins' (Prosser 1998); and how star-centred Deepfakes engage gender itself as a socio-techno phenomenon of fakery that is produced - and reproduced - over time.
C1 [Holliday, Christopher] Kings Coll London, Dept Liberal Arts, VWB4-52,Virginia Woolf Bldg,22 Kingsway, London WC2B 6LE, England.
C3 University of London; King's College London
RP Holliday, C (corresponding author), Kings Coll London, Dept Liberal Arts, VWB4-52,Virginia Woolf Bldg,22 Kingsway, London WC2B 6LE, England.
EM christopher.holliday@kcl.ac.uk
OI Holliday, Christopher/0000-0002-1261-5024
CR Abel R, 1924, FRENCH FILM THEORY C, P314
   Abel R, 1911, FRENCH FILM THEORY C, P58
   Arendt H, 1972, CRISES REPUBLIC LYIN
   Bal?zs, 1930, THEORY FILM CHARACTE
   Bode L, 2010, CINEMA J, V49, P46
   Butler J., 2004, UNDOING GENDER
   Butler Judith, 2014, BODIES MATTER DISCUR
   Cavna, 2017, POST WASHINGTON 1117
   Chilton L, 2020, INDEPENDENT
   Clarke, 2019, H R 3230 116 C 2019
   Cohen M, 1933, FILM THEORY CRITICIS, P243
   Derrida J., 1994, SPECTERS MARX STATE
   Dyer Richard, 1986, HEAVENLY BODIES FILM
   Dyer Richard, 1979, STARS
   Eiland Howard, 1931, SELECTED WRITINGS, V2, P507
   Elsaesser Thomas, 2005, CINEPHILIA MOVIES LO, P27
   Fletcher J, 2018, THEATRE J, V70, P455, DOI 10.1353/tj.2018.0097
   G Austin., 2017, REVISITING STAR STUD, P162
   Gaines, 1992, CONTESTED CULTURE IM
   Guenther-Pal A, 1913, GERMAN ESSAYS FILM, P11
   Hewitt MA., 1993, METH THEORY STUD REL, V5, P135
   Judith Butler, 1990, GENDER TROUBLE FEMIN
   Kietzmann J, 2020, BUS HORIZONS, V63, P135, DOI 10.1016/j.bushor.2019.11.006
   Lindsay V., 1916, ART MOVING PICTURE
   McDonald, 2013, HOLLYWOOD STARDOM
   McGowan D, 2017, CELEBR STUD, V8, P209, DOI 10.1080/19392397.2016.1238310
   Moszkowicz J, 2002, SCREEN, V43, P293, DOI 10.1093/screen/43.3.293
   MS Micale., 2004, MIND MODERNISM MED P, P141
   Navas Eduardo, 2012, REMIX THEORY AESTHET
   Prince, 2012, DIGITAL VISUAL EFFEC
   Prosser Jay, 1998, 2 SKINS BODY NARRATI
   Rodowick D. N., 2007, VIRTUAL LIFE FILM
   Ronen Ruth, 1994, POSSIBLE WORLDS LIT
   Sargeant A., 2017, NEW ATLANTIS, V53, P17
   Scahill Andrew, 2016, CYCLES SEQUELS SPIN, P316
   Sharf Zack, 2018, INDIEWIRE
   Simonite T., 2019, WIRED
   Sitney PA, 1932, AVANT GARDE FILM REA, P36
   Sontag Susan., 1996, NEW YORK TIMES
   Spangler T., 2018, VARIETY 0417
   Sperb J, 2009, CINEPHILIA AGE DIGIT, V1, P1
   Taussig M., 1999, DEFACEMENT PUBLIC SE
   Thomas S, 2019, CELEBR STUD, V10, P453, DOI 10.1080/19392397.2019.1672996
   Tolosana Ruben, 2020, DEEPFAKES SURVEY FAC
   Willemen Paul, 1994, LOOKS FRICTIONS ESSA
NR 45
TC 0
Z9 0
U1 6
U2 6
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 1354-8565
EI 1748-7382
J9 CONVERGENCE-US
JI Convergence
PD AUG
PY 2021
VL 27
IS 4
SI SI
BP 899
EP 918
AR 13548565211029412
DI 10.1177/13548565211029412
EA JUL 2021
PG 20
WC Communication
WE Social Science Citation Index (SSCI)
SC Communication
GA UK7UP
UT WOS:000678279500001
OA hybrid
DA 2022-02-06
ER

PT J
AU Lee, MS
   Yang, SW
   Lee, HJ
AF Lee, Min Seok
   Yang, Seok Woo
   Lee, Hong Joo
TI Weight attention layer based document classification by incorporating
   information gain
SO EXPERT SYSTEMS
LA English
DT Article
DE attention mechanism; document classification; feature selection;
   information gain; weight attention layer
ID MODEL
AB The performance of document classifiers largely depends on their internal representations of text data. Recent studies have been conducted to identify areas of focus and find latent data spaces to increase the representativeness and the performance of classifiers. In this study, we propose a weight attention layer (WAL) that uses an additional feature of words when computing their attention weights for deep learning models based on attention mechanisms. In the WAL, the attention distribution is calculated through the dot product of the attention weight matrix and a word weight matrix. We utilized information gain, which is one of the feature selection algorithms for the additional feature. To evaluate the proposed method, datasets of helpful reviews, sentiment reviews, and fake reviews were used. These datasets were applied to two deep learning models based on attention mechanisms, including an attention-based bidirectional long short-term memory (LSTM) and a hierarchical attention network. As a result of 10-fold cross validation, the improved performance of the models in terms of accuracy and F1-score when using WAL is demonstrated.
C1 [Lee, Min Seok; Yang, Seok Woo] Korea Univ, Sch Ind & Management Engn, Seoul, South Korea.
   [Lee, Hong Joo] Catholic Univ Korea, Dept Business Adm, Bucheon, South Korea.
C3 Korea University; Catholic University of Korea
RP Lee, HJ (corresponding author), 43 Jibong Ro, Bucheon 14662, Gyeonggi, South Korea.
EM hongjoo@catholic.ac.kr
OI Lee, Hong Joo/0000-0002-3499-0466
FU National Research Foundation of KoreaNational Research Foundation of
   Korea; Ministry of Education of the Republic of Korea
FX National Research Foundation of Korea; Ministry of Education of the
   Republic of Korea
CR Ambartsoumian A, 2018, P 9 WORKSH COMP APPR, P130, DOI DOI 10.18653/V1/W18-6219
   Bahdanau D., 2014, NEURAL MACHINE TRANS, DOI DOI 10.1146/ANNUREV.NEURO.26.041002.131047
   Collobert R, 2008, P 25 INT C MACH LEAR, DOI 10.1145/1390156.1390177
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Dai AM., 2015, ARXIV150707998
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1
   He RN, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16), P507, DOI 10.1145/2872427.2883037
   Hermann KM, 2015, P ANN C NEUR INF PRO, P1693
   Hochreiter S, 1998, INT J UNCERTAIN FUZZ, V6, P107, DOI 10.1142/S0218488598000094
   Jeong Jaeyun, 2018, [Journal of the Korean Institute of Industrial Engineers, 대한산업공학회지], V44, P442, DOI 10.7232/JKIIE.2018.44.6.442
   Le Q., 2014, P 31 INT C INT C MAC
   이민석, 2019, [Journal of Intelligence and Information Systems, 지능정보연구], V25, P105
   LEWIS DD, 1992, SPEECH AND NATURAL LANGUAGE, P212
   Li JD, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3136625
   Maas A, 2011, P 49 ANN M ASS COMP
   Mihalcea R., 2004, P EMNLP, P404
   Mikolov T., 2013, P INT C LEARN REPR I, DOI DOI 10.5555/2999792.2999959
   Onan A., 2019, INT C BIG DAT INN AP, P80
   Onan A, 2021, IEEE ACCESS, V9, P7701, DOI 10.1109/ACCESS.2021.3049734
   Onan A, 2019, IEEE ACCESS, V7, P145614, DOI 10.1109/ACCESS.2019.2945911
   Onan A, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.5909
   Onan A, 2021, COMPUT APPL ENG EDUC, V29, P675, DOI 10.1002/cae.22252
   Onan A, 2020, COMPUT APPL ENG EDUC, V28, P117, DOI 10.1002/cae.22179
   Onan A, 2016, EXPERT SYST APPL, V57, P232, DOI 10.1016/j.eswa.2016.03.045
   Pang B., 2009, COMPUT LINGUIST, V35, P311, DOI [10.1162/coli.2009.35.2.311, DOI 10.1162/COLI.2009.35.2.311]
   Pennington J., 2014, EMNLP, P1532, DOI [10.3115/v1/D14-1162, DOI 10.3115/V1/D14-1162]
   Rayana S, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P985, DOI 10.1145/2783258.2783370
   Robertson S, 2004, J DOC, V60, P503, DOI 10.1108/00220410410560582
   Sahami M., 1998, LEARNING TEXT CATEGO
   Sahlgren M, 2008, ITAL J LINGUIST, V20, P33
   Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang S., 2012, 50 ANN M ASS COMP LI, V2, P90
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang Z., 2016, NAACL HLT, P1480
   Zhang RC, 2011, KNOWL INF SYST, V26, P419, DOI 10.1007/s10115-010-0287-y
   Zhou P, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P207, DOI 10.18653/v1/p16-2034
NR 37
TC 0
Z9 0
U1 4
U2 4
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0266-4720
EI 1468-0394
J9 EXPERT SYST
JI Expert Syst.
PD JAN
PY 2022
VL 39
IS 1
DI 10.1111/exsy.12833
EA SEP 2021
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XU4ZS
UT WOS:000700170400001
DA 2022-02-06
ER

PT J
AU Kim, S
   Jang, J
   Kim, CO
AF Kim, Sinyoung
   Jang, Jaeyeon
   Kim, Chang Ouk
TI A run-to-run controller for a chemical mechanical planarization process
   using least squares generative adversarial networks
SO JOURNAL OF INTELLIGENT MANUFACTURING
LA English
DT Article
DE Chemical mechanical planarization; Run-to-run control; Least squares
   generative adversarial networks; Convolutional neural network; Bayesian
   optimization
ID VIRTUAL METROLOGY; RATE PREDICTION; SEMICONDUCTOR
AB Achieving high processing quality for chemical mechanical planarization (CMP) in semiconductor manufacturing is difficult due to the distinct process variations associated with this method, such as drift and shift. Run-to-run control aims to maintain the targeted process quality by reducing the effect of process variations. The goal of controller learning is to infer an underlying output-input reverse mapping based on input-output samples considering the process variations. Existing controllers learn reverse mapping by minimizing the total mapping error for sample data. However, this approach often fails to generate inputs for unseen target outputs because conditional input distributions on target outputs are not captured in the learning. In this study, we propose a controller based on a least squares generative adversarial network (LSGAN) that can capture the input distributions. GANs are deep-learning architectures composed of two neural nets: a generator and a discriminator. In the proposed model, the generator attempts to produce fake input distributions that are similar to the real input distributions considering the process variation features extracted using convolutional layers, while the discriminator attempts to detect the fake distributions. Competition in this game drives both networks to improve their performance until the generated input distributions are indistinguishable from the real distributions. An experiment using the data obtained from a work-site CMP tool verified that the proposed model outperformed the comparison models in terms of control accuracy and computation time.
C1 [Kim, Sinyoung; Jang, Jaeyeon; Kim, Chang Ouk] Yonsei Univ, Dept Ind Engn, Seoul 03722, South Korea.
C3 Yonsei University
RP Kim, CO (corresponding author), Yonsei Univ, Dept Ind Engn, Seoul 03722, South Korea.
EM kimco@yonsei.ac.kr
OI Jang, Jaeyeon/0000-0001-6255-2044
FU National Research Foundation of Korea (NRF) - Korean government (MSIT)
   [NRF-2019R1A2B5B01070358]
FX This work was supported by the National Research Foundation of Korea
   (NRF) Grant funded by the Korean government (MSIT)
   (NRF-2019R1A2B5B01070358).
CR Bergstra J, 2012, J MACH LEARN RES, V13, P281
   Bhat N. V., 1990, IEEE Control Systems Magazine, V10, P24, DOI 10.1109/37.55120
   BUTLER SW, 1994, IEEE T SEMICONDUCT M, V7, P193, DOI 10.1109/66.286855
   Chang JYC, 2005, IEEE IND ELEC, P124
   Chang YJ, 2006, IEEE IJCNN, P5289
   Chen A, 2001, IEEE T SEMICONDUCT M, V14, P11, DOI 10.1109/66.909650
   Chen CT, 2010, IEEE T SEMICONDUCT M, V23, P109, DOI 10.1109/TSM.2009.2039186
   Chen P. H, 2005, P IEEE INT S SEM MAN, P155, DOI [10.1109/ISSM.2005.1513322, DOI 10.1109/ISSM.2005.1513322]
   Ding BJ, 1996, IEEE T COMPON PACK A, V19, P76, DOI 10.1109/95.486565
   Fan SKS, 2002, INT J PROD RES, V40, P3093, DOI 10.1080/00207540210141652
   Goodfellow I., 2016, ARXIV170100160
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735
   Hung MH, 2007, IEEE-ASME T MECH, V12, P308, DOI 10.1109/TMECH.2007.897275
   INGOLFSSON A, 1993, J QUAL TECHNOL, V25, P271, DOI 10.1080/00224065.1993.11979473
   Jolicoeur-Martineau Alexia, 2018, ARXIV180700734
   Kang P, 2011, EXPERT SYST APPL, V38, P2508, DOI 10.1016/j.eswa.2010.08.040
   Ko HH, 2012, J INTELL MANUF, V23, P443, DOI 10.1007/s10845-010-0383-6
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee KB, 2020, J INTELL MANUF, V31, P73, DOI 10.1007/s10845-018-1437-4
   Li TS, 2006, J INTELL MANUF, V17, P355, DOI 10.1007/s10845-005-0008-7
   Liu K, 2018, ISA T, V83, P107, DOI 10.1016/j.isatra.2018.09.005
   Maggipinto M, 2018, IEEE T SEMICONDUCT M, V31, P376, DOI 10.1109/TSM.2018.2849206
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Metz L., 2017, 5 INT C LEARNING REP, P1
   Moyne J, 2000, RUN TO RUN CONTROL S
   Moyne J, 2016, IEEE T SEMICONDUCT M, V29, P283, DOI 10.1109/TSM.2016.2574130
   Park S, 2021, J INTELL MANUF, V32, P251, DOI 10.1007/s10845-020-01571-4
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Rietman EA, 1996, IEEE T SEMICONDUCT M, V9, P95, DOI 10.1109/66.484288
   SACHS E, 1991, IEEE T SEMICONDUCT M, V4, P134, DOI 10.1109/66.79725
   Sheu DD, 2012, J INTELL MANUF, V23, P1637, DOI 10.1007/s10845-010-0466-4
   Snoek J., 2012, ADV NEURAL INFORM PR, V25, P2960
   Wan J, 2018, IEEE T SEMICONDUCT M, V31, P12, DOI 10.1109/TSM.2017.2768241
   Wang GJ, 2005, INT J ADV MANUF TECH, V26, P759, DOI 10.1007/s00170-003-1859-8
   Wang P, 2017, CIRP ANN-MANUF TECHN, V66, P429, DOI 10.1016/j.cirp.2017.04.013
   Wu YJ, 2018, INTL CONF POWER SYST, P3855, DOI 10.1109/POWERCON.2018.8602223
   Xie Y, 2018, CHIN AUTOM CONGR, P1309, DOI 10.1109/CAC.2018.8623346
   Yi JG, 2003, 42ND IEEE CONFERENCE ON DECISION AND CONTROL, VOLS 1-6, PROCEEDINGS, P5955
   Zantye PB, 2004, MAT SCI ENG R, V45, P89, DOI 10.1016/j.mser.2004.06.002
   Zhang J, 2008, CHEM ENG SCI, V63, P1273, DOI 10.1016/j.ces.2007.07.047
   Zhang R, 2016, LECT NOTES COMPUT SC, V9907, P649, DOI 10.1007/978-3-319-46487-9_40
NR 43
TC 3
Z9 3
U1 8
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0956-5515
EI 1572-8145
J9 J INTELL MANUF
JI J. Intell. Manuf.
PD DEC
PY 2021
VL 32
IS 8
BP 2267
EP 2280
DI 10.1007/s10845-020-01639-1
EA AUG 2020
PG 14
WC Computer Science, Artificial Intelligence; Engineering, Manufacturing
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WH9JZ
UT WOS:000557120000001
DA 2022-02-06
ER

PT J
AU Song, Q
   Xu, F
   Zhu, XX
   Jin, YQ
AF Song, Qian
   Xu, Feng
   Zhu, Xiao Xiang
   Jin, Ya-Qiu
TI Learning to Generate SAR Images With Adversarial Autoencoder
SO IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING
LA English
DT Article
DE Radar polarimetry; Training; Synthetic aperture radar; Task analysis;
   Target recognition; Generative adversarial networks; Generators;
   Adversarial autoencoder (AAE); deep learning (DL); few-shot learning
   (FSL); image representation; synthetic aperture radar (SAR)
ID SPACE
AB Deep learning-based synthetic aperture radar (SAR) target recognition often suffers from sparsely distributed training samples and rapid angular variations due to scattering scintillation. Thus, data-driven SAR target recognition is considered a typical few-shot learning (FSL) task. This article first reviews the key issues of FSL and provides a definition of the FSL task. A novel adversarial autoencoder (AAE) is then proposed as an SAR representation and generation network. It consists of a generator network that decodes target knowledge to SAR images and an adversarial discriminator network that not only learns to discriminate ``fake'' generated images from real ones but also encodes the input SAR image back to target knowledge. The discriminator employs progressively expanding convolution layers and a corresponding layer-by-layer training strategy. It uses two cyclic loss functions to enforce consistency between the inputs and outputs. Moreover, rotated cropping is introduced as a mechanism to address the challenge of representing the target orientation. The moving and stationary Target recognition (MSTAR) 7-target dataset is used to evaluate the AAE's performance, and the results demonstrate its ability to generate SAR images with aspect angular diversity. Using only 90 training samples with at least 25 degrees of orientation interval, the trained AAE is able to generate the remaining 1748 samples of other orientation angles with an unprecedented level of fidelity. Thus, it can be used for data augmentation in SAR target recognition FSL tasks. Our experimental results show that the AAE could boost the test accuracy by 5.77%.
C1 [Song, Qian; Xu, Feng; Jin, Ya-Qiu] Fudan Univ, Key Lab Informat Sci Electromagnet Waves MoE, Shanghai 200433, Peoples R China.
   [Song, Qian; Zhu, Xiao Xiang] Remote Sensing Technol Inst, German Aerosp Ctr, D-82234 Wessling, Germany.
   [Zhu, Xiao Xiang] Tech Univ Munich, Data Sci Earth Observ, D-80333 Munich, Germany.
C3 Fudan University; Helmholtz Association; German Aerospace Centre (DLR);
   Technical University of Munich
RP Xu, F (corresponding author), Fudan Univ, Key Lab Informat Sci Electromagnet Waves MoE, Shanghai 200433, Peoples R China.
EM fengxu@fudan.edu.cn
OI Zhu, Xiao Xiang/0000-0001-5530-3613; Song, Qian/0000-0003-2746-6858
FU Natural Science Foundation of ChinaNational Natural Science Foundation
   of China (NSFC) [61991422, 61822107]
FX This work was supported by the Natural Science Foundation of China under
   Grant 61991422 and Grant 61822107.
CR Arjovsky M., 2017, ADV NEURAL INFORM PR, P5769
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Chen SZ, 2016, IEEE T GEOSCI REMOTE, V54, P4806, DOI 10.1109/TGRS.2016.2551720
   Chintala S, 2015, ARXIV151106434
   Cui ZY, 2019, IEEE ACCESS, V7, P42255, DOI 10.1109/ACCESS.2019.2907728
   Fu SL, 2021, SCI CHINA INFORM SCI, V64, DOI 10.1007/s11432-020-3077-5
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   GUO J, 2017, IEEE GEOSCI REMOTE S, V14, P1
   Hou Xiyue, 2020, [Science China. Information Science, 中国科学. 信息科学], V63
   Huang ZL, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9090907
   Kang CY, 2016, INT GEOSCI REMOTE SE, P1146, DOI 10.1109/IGARSS.2016.7729290
   Karras T., 2017, ARXIV171010196
   Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79
   Liu L, 2018, INT GEOSCI REMOTE SE, P4411, DOI 10.1109/IGARSS.2018.8517866
   Liu XX, 2020, SCI CHINA LIFE SCI, V63, P1006, DOI 10.1007/s11427-020-1705-0
   Llanas B, 2008, NEURAL PROCESS LETT, V27, P209, DOI 10.1007/s11063-007-9070-9
   Malmgren-Hansen D, 2017, IEEE GEOSCI REMOTE S, V14, P1484, DOI 10.1109/LGRS.2017.2717486
   Simonyan K, 2019, ADV NEURAL INFORM PR
   Song Q, 2020, IEEE GEOSCI REMOTE S, V17, P1092, DOI 10.1109/LGRS.2019.2936897
   Song Q, 2019, INT GEOSCI REMOTE SE, P9498, DOI 10.1109/IGARSS.2019.8898922
   Song Q, 2017, IEEE GEOSCI REMOTE S, V14, P2245, DOI 10.1109/LGRS.2017.2758900
   Sun YS, 2020, IEEE GEOSCI REMOTE S, V17, P1928, DOI 10.1109/LGRS.2019.2958379
   Toizumi T, 2018, INT GEOSCI REMOTE SE, P17, DOI 10.1109/IGARSS.2018.8517299
   Vapnik V., 1998, STAT LEARNING THEORY
   Wang YQ, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3386252
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xu F, 2020, SCI CHINA INFORM SCI, V63, DOI 10.1007/s11432-020-2810-x
   Yuming Shen, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12361), P614, DOI 10.1007/978-3-030-58517-4_36
   Zhang F, 2019, REMOTE SENS LETT, V10, P998, DOI 10.1080/2150704X.2019.1635287
   Zheng C, 2019, IEEE SENS J, V19, P7525, DOI 10.1109/JSEN.2019.2915379
   Zhou Y, 2019, PROC CVPR IEEE, P5738, DOI 10.1109/CVPR.2019.00589
   Zhu XX, 2021, IEEE GEOSC REM SEN M, DOI 10.1109/MGRS.2020.3046356
   Zien, 2005, P 10 INT WORKSH ART, P57
NR 33
TC 0
Z9 0
U1 4
U2 4
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0196-2892
EI 1558-0644
J9 IEEE T GEOSCI REMOTE
JI IEEE Trans. Geosci. Remote Sensing
PY 2022
VL 60
DI 10.1109/TGRS.2021.3086817
EA JUN 2021
PG 15
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA YG3HV
UT WOS:000733476000001
OA Green Accepted
DA 2022-02-06
ER

PT J
AU Wang, WW
   Hong, W
   Wang, F
   Yu, JK
AF Wang, Wanwei
   Hong, Wei
   Wang, Feng
   Yu, Jinke
TI GAN-Knowledge Distillation for One-Stage Object Detection
SO IEEE ACCESS
LA English
DT Article
DE Object detection; generative adversarial networks; knowledge
   distillation
AB Convolutional neural networks (CNN) have a significant improvement in the accuracy of object detection. As networks become deeper, the precision of detection becomes obviously improved, and more floating-point calculations are also needed. Because of the great amount of calculation, it is inconvenient for mobile and embedded vision applications. Many researchers apply the knowledge distillation method to improve the precision of object detection by transferring knowledge from a deeper and larger teachers network to a small student one. Most methods of knowledge distillation are needed to design complex cost functions and mainly aim at the two-stage object detection algorithm. Therefore, we propose a clean and effective knowledge distillation method called Generative Adversarial Networks - Knowledge Distillation(GAN-KD) for the one-stage object detection. The feature maps generated by teacher network and student network are employed as true and fake samples respectively, and generating adversarial training for both of them to improve the performance of the student network in one-stage object detection. The experimental result shows that our approach achieves the performance gain of 5% mAP when compared with MobilenetV1 on COCO dataset.
C1 [Wang, Wanwei] Civil Aviat Univ China, Tianjin Key Lab Adv Signal Proc, Tianjin 300300, Peoples R China.
   [Hong, Wei; Wang, Feng; Yu, Jinke] Beijing Zeusee Technol Co Ltd, Beijing 100101, Peoples R China.
C3 Civil Aviation University of China
RP Wang, WW (corresponding author), Civil Aviat Univ China, Tianjin Key Lab Adv Signal Proc, Tianjin 300300, Peoples R China.
EM wwwang@cauc.edu.cn
OI hong wei, hong wei/0000-0002-9107-7550; WANG, WANWEI/0000-0002-3737-6795
FU National Key Research and Development Program of China [2016YFB0502405];
   Fundamental Research Funds for the Central Universities of the Civil
   Aviation University of China [3122013D020]
FX This work was supported in part by the National Key Research and
   Development Program of China under Grant 2016YFB0502405, and in part by
   the Fundamental Research Funds for the Central Universities of the Civil
   Aviation University of China under Grant 3122013D020.
CR Chen G., 2017, P NEUR INF PROC SYST NEURIPS, P742
   Chen X, 2016, ADV NEUR IN, V29
   DAI J, 2016, ADV NEURAL INFORM PR, P1796, DOI DOI 10.5555/3157096.3157139
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Han S., 2015, DEEP COMPRESSION COM
   Hao Y, 2018, IEEE INT CON INF VIS, P6, DOI 10.1109/iV.2018.00012
   Hariharan B, 2011, IEEE I CONF COMP VIS, P991, DOI 10.1109/ICCV.2011.6126343
   He YH, 2017, IEEE I CONF COMP VIS, P1398, DOI 10.1109/ICCV.2017.155
   Hinton G., 2015, ARXIVABS150302531
   Howard A. G., 2017, TECH REP
   Huang XW, 2015, ACTA POLYM SIN, P1133
   Iandola F. N., 2016, P IEEE C COMP VIS PA
   Jacob B, 2018, PROC CVPR IEEE, P2704, DOI 10.1109/CVPR.2018.00286
   Li CG, 2019, 2019 2ND INTERNATIONAL CONFERENCE ON MECHANICAL, ELECTRONIC AND ENGINEERING TECHNOLOGY (MEET 2019), P460, DOI 10.23977/meet.2019.93771
   Li Q, 2017, P IEEE C COMP VIS PA, P6356
   Li SY, 2019, PROC CVPR IEEE, P3833, DOI 10.1109/CVPR.2019.00396
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W, 2016, EUR C COMP VIS, V21, P37, DOI DOI 10.1007/978-3-319-46448-0_2
   Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8
   MIRZA M, 2014, TECH REP
   Radford A., 2015, ARXIV151106434
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren Shaoqing, 2017, IEEE Trans Pattern Anal Mach Intell, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Romero A., 2014, ARXIV14126550, DOI 10.1109/acpr.2015.7486451
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Shen Z., 2019, PROCEEDINGS OF THE A, V33, P4886, DOI 10.1609/aaai.v33i01.33014886
   Shmelkov K, 2017, IEEE I CONF COMP VIS, P3420, DOI 10.1109/ICCV.2017.368
   WANG L, 2018, P ADV NEUR INF PROC, P775
   Wang T, 2019, PROC CVPR IEEE, P4928, DOI 10.1109/CVPR.2019.00507
   Wen W., 2016, NIPS, P2074
   Wu JX, 2016, PROC CVPR IEEE, P4820, DOI 10.1109/CVPR.2016.521
   Yim J, 2017, PROC CVPR IEEE, P7130, DOI 10.1109/CVPR.2017.754
   Zagoruyko S., 2016, ARXIV161203928
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhou H, 2016, LECT NOTES COMPUT SC, V9908, P662, DOI 10.1007/978-3-319-46493-0_40
   Zhuang Z., 2018, ADV NEURAL INFORM PR, P875
NR 39
TC 3
Z9 4
U1 12
U2 14
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2020
VL 8
BP 60719
EP 60727
DI 10.1109/ACCESS.2020.2983174
PG 9
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA LF4TX
UT WOS:000527413100087
OA gold, Green Submitted
DA 2022-02-06
ER

PT J
AU Gnanha, AT
   Cao, WM
   Mao, XD
   Wu, S
   Wong, HS
   Li, Q
AF Gnanha, Aurele Tohokantche
   Cao, Wenming
   Mao, Xudong
   Wu, Si
   Wong, Hau-San
   Li, Qing
TI The residual generator: An improved divergence minimization framework
   for GAN
SO PATTERN RECOGNITION
LA English
DT Article
DE Generative adversarial networks; Image synthesis; Deep learning
ID ADVERSARIAL NETWORK
AB GAN is a generative modelling framework which has been proven as able to minimise various types of divergence measures under an optimal discriminator. However, there is a gap between the loss function of GAN used in theory and in practice. In theory, the proof of the Jensen divergence minimisation involves the min-max criterion, but in practice the non-saturating criterion is instead used to avoid gradient vanishing. We argue that the formulation of divergence minimization via GAN is biased and may yield a poor convergence of the algorithm. In this paper, we propose the Residual Generator for GAN (Rg-GAN), which is inspired by the closed-loop control theory, to bridge the gap between theory and practice. Rg-GAN minimizes the residual between the loss of the generated data to be real and the loss of the generated data to be fake from the perspective of the discriminator. In this setting, the loss terms of the generator depend only on the generated data and therefore contribute to the optimisation of the model. We formulate the residual generator for standard GAN and least-squares GAN and show that they are equivalent to the minimisation of reverse-KL divergence and a novel instance of f-divergence, respectively. Furthermore, we prove that Rg-GAN can be reduced to Integral Probability Metrics (IPMs) GANs (e.g., Wasserstein GAN) and bridge the gap between IPMs and f-divergence. Additionally, we further improve on Rg-GAN by proposing a loss function for the discriminator that has a better discrimination ability. Experiments on synthetic and natural images data sets show that Rg-GAN is robust to mode collapse, and improves the generation quality of GAN in terms of FID and IS scores. (c) 2021 Elsevier Ltd. All rights reserved.
C1 [Gnanha, Aurele Tohokantche; Wong, Hau-San] City Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China.
   [Cao, Wenming] Chongqing Jiaotong Univ, Dept Informat & Comp Sci, Chongqing, Peoples R China.
   [Mao, Xudong; Li, Qing] Hong Kong Polytech Univ, Dept Comp, Hong Kong, Peoples R China.
   [Wu, Si] South China Univ Technol, Sch Comp Sci & Engn, Guangzhou 510006, Guangdong, Peoples R China.
C3 City University of Hong Kong; Chongqing Jiaotong University; Hong Kong
   Polytechnic University; South China University of Technology
RP Wong, HS (corresponding author), City Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China.
EM tagnanha2-c@my.cityu.edu.hk; wmingcao@hku.hk; xudong.xdmao@gmail.com;
   cswusi@scut.edu.cn; cshswong@cityu.edu.hk; csqli@comp.polyu.edu.hk
OI GNANHA, Aurele Tohokantche/0000-0002-5645-2220
FU Research Grants Council of the Hong Kong Special Administration
   RegionHong Kong Research Grants Council [CityU 11201220]; Hong Kong
   Research Grants Council under the General Research Fund [11204919];
   National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [62072189]; Natural Science Foundation of
   Guangdong ProvinceNational Natural Science Foundation of Guangdong
   Province [2020A1515010484]
FX This work was supported in part by the Research Grants Council of the
   Hong Kong Special Administration Region (Project No. CityU 11201220), in
   part by the Hong Kong Research Grants Council under the General Research
   Fund (Project no. 11204919), in part by the National Natural Science
   Foundation of China (Project No. 62072189), and in part by the Natural
   Science Foundation of Guangdong Province (Project No. 2020A1515010484).
CR Arjovsky M, 2017, PR MACH LEARN RES, V70
   Arora S, 2017, PR MACH LEARN RES, V70
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dong JH, 2020, PROC CVPR IEEE, P4022, DOI 10.1109/CVPR42600.2020.00408
   Dong JH, 2019, IEEE I CONF COMP VIS, P10711, DOI 10.1109/ICCV.2019.01081
   Dumoulin Vincent, 2017, INT C LEARN REPR
   Elfeki M, 2019, PR MACH LEARN RES, V97
   Frey BJ, 1996, ADV NEUR IN, V8, P661
   Ganin Y, 2015, PR MACH LEARN RES, V37, P1180
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gretton A, 2012, J MACH LEARN RES, V13, P723
   Gulrajani I., 2017, ADV NEURAL INFORM PR, P5769, DOI DOI 10.5555/3295222.3295327
   Heusel M., 2017, GANS TRAINED 2 TIME, P6629
   Isola P., 2017, P IEEE C COMPUTER VI, P5967, DOI DOI 10.1109/CVPR.2017.632
   Jichao Zhao, 2016, 2016 13th International Conference on Service Systems and Service Management (ICSSSM), P1, DOI 10.1109/ICSSSM.2016.7538614
   Jolicoeur-Martineau A., 2019, RELATIVISTIC F DIVER
   Jolicoeur-Martineau Alexia, 2019, RELATIVISTIC DISCRIM
   Kingma DP, 2015, 3 INT C LEARN REPR I, DOI DOI 10.1145/1830483.1830503
   Kingma DP, 2014, 2 INT C LEARN REPR I, P1
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li C., 2017, MMD GAN DEEPER UNDER, P2203
   Li D, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107085
   Li J, 2018, IEEE ROBOT AUTOM LET, V3, P387, DOI 10.1109/LRA.2017.2730363
   Li YJ, 2015, PR MACH LEARN RES, V37, P1718
   Lim J.H., 2017, ARXIVABS170502894
   Liu Z., 2020, OPEN COMPOUND DOMAIN, P12403
   Mao X., 2018, IEEE T PATTERN ANAL, P1
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Metz L., 2017, 5 INT C LEARNING REP, P1
   Miyato T, 2018, INT C LEARN REPR
   Nguyen T.D., 2017, DUAL DISCRIMINATOR G, P2667
   Nowozin Sebastian, 2016, P 30 INT C NEURAL IN, P271
   Oord A.v.d., 2016, CONDITIONAL IMAGE GE, P4797
   Qiao T., 2019, LEARN IMAGINE CREATE, P32
   Radford A, 2016, PROC 4 INT C LEARN R
   Salimans T., 2016, ADV NEURAL INFORM PR, P2234
   Sonderby C.K., 2017, AMORTISED MAP INFERE
   Sriperumbudur Bharath K., 2009, INTEGRAL PROBABILITY
   Srivastava A., 2017, VEEGAN REDUCING MODE, P3308
   Tran D, 2017, ADV NEUR IN, V30
   Wang L., 2018, IMPROVING IMPROVED T
   Wang Q, 2019, PATTERN RECOGN, V88, P493, DOI 10.1016/j.patcog.2018.11.020
   Wang W., 2019, IMPROVING MMD GAN TR
   Yu F., 2015, ARXIV CONSTRUCTION LARGE S
   Zhang H., 2020, CONSISTENCY REGULARI
   Zhang WW, 2008, LECT NOTES COMPUT SC, V5305, P802, DOI 10.1007/978-3-540-88693-8_59
   Zhang YQ, 2019, PATTERN RECOGN, V94, P74, DOI 10.1016/j.patcog.2019.05.023
   Zhang ZH, 2020, PATTERN RECOGN, V105, DOI 10.1016/j.patcog.2019.107179
   Zhao SC, 2020, AAAI CONF ARTIF INTE, V34, P12975
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 52
TC 0
Z9 0
U1 10
U2 10
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 0031-3203
EI 1873-5142
J9 PATTERN RECOGN
JI Pattern Recognit.
PD JAN
PY 2022
VL 121
AR 108222
DI 10.1016/j.patcog.2021.108222
PG 15
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UX9SO
UT WOS:000701175900009
DA 2022-02-06
ER

PT J
AU Chen, ZF
   Zhu, TQ
   Xiong, P
   Wang, CG
   Ren, W
AF Chen, Zhenfei
   Zhu, Tianqing
   Xiong, Ping
   Wang, Chenguang
   Ren, Wei
TI Privacy preservation for image data: A GAN-based method
SO INTERNATIONAL JOURNAL OF INTELLIGENT SYSTEMS
LA English
DT Article
DE computer vision; generative adversarial networks; image privacy; privacy
   preservation
AB The importance of protecting personal information, like, a person's address or health history, is well known and commonly discussed. However, images also contain sensitive information that can compromise a person's privacy or be used for nefarious purposes. To date, most methods for preserving privacy with images have relied on obfuscation techniques, such as pixelation, blurring, or masking parts of the image. However, new face-recognition technologies driven by deep learning are showing cracks in the old techniques. Moreover, faceless recognition is presenting a whole new set of challenges for image privacy. The core of these issues it is how to ensure privacy while still being able to see and use the image. Our solution is a model based on a generative adversarial network that protects identity information while preserving face features of the original image as much as possible. The premise is to generate a fake image of a face that shares all the same attributes as the original image, for example, a brown-eyed child smiling. With this strategy, the image remains useful, but no person or algorithm could determine the identity of the pictured individual. The framework consists of three parts: a detection module, an image creation module, and an image transformation module. The detection module extracts the attribute labels. The image creation module generates images of faces, and the image transformation module transforms the fake features to match the attributes in the original image. A comprehensive set of experiments shows the effectiveness of the proposed framework.
C1 [Chen, Zhenfei; Zhu, Tianqing; Wang, Chenguang; Ren, Wei] China Univ Geosci Wuhan, Sch Comp Sci, Wuhan 430074, Peoples R China.
   [Xiong, Ping] Zhongnan Univ Econ & Law, Sch Informat & Safety Engn, Wuhan, Peoples R China.
   [Ren, Wei] Guangxi Key Lab Cryptog & Informat Secur, Guilin, Peoples R China.
   [Ren, Wei] Chinese Acad Sci, Key Lab Network Assessment Technol, Beijing, Peoples R China.
C3 China University of Geosciences; Zhongnan University of Economics & Law;
   Chinese Academy of Sciences
RP Zhu, TQ (corresponding author), China Univ Geosci Wuhan, Sch Comp Sci, Wuhan 430074, Peoples R China.
EM caohaitao@njnu.edu.cn
OI Chen, Zhenfei Chen/0000-0003-3493-5149; Ren, Wei/0000-0001-8590-1737
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61972366]
FX National Natural Science Foundation of China, Grant/Award Number:
   61972366
CR Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Bhattacharjee K, 2020, COMPUT GRAPH FORUM, V39, P675, DOI 10.1111/cgf.14032
   Boyle M., 2000, CSCW 2000. ACM 2000 Conference on Computer Supported Cooperative Work, P1
   Chhabra S, 2018, COMPUT VISION PATTER, P656
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Duong T, 2018, PROCEEDINGS OF THE 2ND ACM WORKSHOP ON BLOCKCHAINS, CRYPTOCURRENCIES, AND CONTRACTS (BCC'18), P1, DOI 10.1145/3205230.3205233
   Fontenla-Romero O, 2021, INT J INTELL SYST, V36, P177, DOI 10.1002/int.22296
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Hill Steven, 2016, Proceedings on Privacy Enhancing Technologies, V2016, P403, DOI 10.1515/popets-2016-0047
   Hukkelarings Haringkon, 2019, Advances in Visual Computing. 14th International Symposium on Visual Computing, ISVC 2019. Proceedings. Lecture Notes in Computer Science (LNCS 11844), P565, DOI 10.1007/978-3-030-33720-9_44
   Ioffe S, 2015, ARXIV LEARNING
   Isola P., 2017, 2017 IEEE C COMP VIS
   Karras T, 2018, PROGRESSIVE GROWING
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Lander K, 2001, APPL COGNITIVE PSYCH, V15, P101, DOI 10.1002/1099-0720(200101/02)15:1<101::AID-ACP697>3.0.CO;2-7
   Liu B, 2019, CONCURR COMP-PRACT E, V31, DOI 10.1002/cpe.5102
   Liu BZ, 2018, PR IEEE COMP DESIGN, P1, DOI 10.1109/ICCD.2018.00012
   Liu C., 2020, ARXIV200812199
   Liu M. Y., 2016, P ADV NEUR PROC SYST, P469
   Liu M, 2019, PROC CVPR IEEE, P3668, DOI 10.1109/CVPR.2019.00379
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Mcpherson R, 2016, ARXIV CRYPTOGRAPHY S
   Mirjalili V, 2018, INT CONF BIOMETR, P82, DOI 10.1109/ICB2018.2018.00023
   Newton EM, 2005, IEEE T KNOWL DATA EN, V17, P232, DOI 10.1109/TKDE.2005.32
   Oh SJ, 2016, LECT NOTES COMPUT SC, V9907, P19, DOI 10.1007/978-3-319-46487-9_2
   Radford A, 2015, 2018 37 CHIN CONTR C, P9159
   Ratliff LJ, 2013, ANN ALLERTON CONF, P917, DOI 10.1109/Allerton.2013.6736623
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Sun QR, 2018, LECT NOTES COMPUT SC, V11205, P570, DOI 10.1007/978-3-030-01246-5_34
   WynMew, 6 FAC ATTR PRED SING
   Yinka-Banjo C, 2020, ARTIF INTELL REV, V53, P1721, DOI 10.1007/s10462-019-09717-4
   Yu, 2020, IEEE T KNOWL DATA EN
   Yuan D, 2019, 2019 IEEE GLOB COMM
   Yuan L, 2017, IET SIGNAL PROCESS, V11, P1031, DOI 10.1049/iet-spr.2016.0756
   Zhao Q, 2020, INT J INTELL SYST, V35, P1262, DOI 10.1002/int.22241
   Zhu JY, 2017, REGULAR BLUE EYES IN
   Zhu TQ, 2019, INT CON DISTR COMP S, P1601, DOI 10.1109/ICDCS.2019.00159
NR 37
TC 3
Z9 3
U1 5
U2 12
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0884-8173
EI 1098-111X
J9 INT J INTELL SYST
JI Int. J. Intell. Syst.
PD APR
PY 2021
VL 36
IS 4
BP 1668
EP 1685
DI 10.1002/int.22356
EA JAN 2021
PG 18
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QN3BK
UT WOS:000604706600001
DA 2022-02-06
ER

PT J
AU Wu, LF
   Xu, YW
   Jian, M
   Xu, X
   Qi, W
AF Wu, Lifang
   Xu, Yaowen
   Jian, Meng
   Xu, Xiao
   Qi, Wei
TI Face liveness detection scheme with static and dynamic features
SO INTERNATIONAL JOURNAL OF WAVELETS MULTIRESOLUTION AND INFORMATION
   PROCESSING
LA English
DT Article
DE Face liveness detection; deep learning; convolutional neural network
   (CNN); static features; dynamic features
AB Face liveness detection is a significant research topic in face-based online authentication. The current face liveness detection approaches utilize either static or dynamic features, but not both. In fact, the dynamic and static features have different advantages in face liveness detection. In this paper, we propose a scheme combining dynamic and static features to capture merits of them for face liveness detection. First, the dynamic maps are captured from the inter-frame motion in the video, which investigates motion information of the face in the video. Then, with a Convolutional Neural Network (CNN), the dynamic and static features are extracted from the dynamic maps and the frame images, respectively. Next, in CNN, the fully connected layers containing the dynamic and static features are concatenated to form a fused feature. Finally, the fused features are used to train a binary Support Vector Machine (SVM) classifier, which classifies the frames into two categories, i.e. frame with real or fake face. Experimental results and the corresponding analysis demonstrate that the proposed scheme is capable of discovering face liveness by fusing dynamic and static features and it outperforms the current state-of-the-art face liveness detection approaches.
C1 [Wu, Lifang; Xu, Yaowen; Jian, Meng; Xu, Xiao; Qi, Wei] Beijing Univ Technol, Fac Informat Technol, Beijing 100124, Peoples R China.
C3 Beijing University of Technology
RP Jian, M (corresponding author), Beijing Univ Technol, Fac Informat Technol, Beijing 100124, Peoples R China.
EM lfwu@bjut.edu.cn; xuyao_wen@126.com; jianmeng648@163.com
FU Beijing Municipal Education Commission Science and Technology Innovation
   Project [KZ201610005012]; China Postdoctoral Science FoundationChina
   Postdoctoral Science Foundation [2017M610027, 2017M610026]; National
   Natural Science Foundation of ChinaNational Natural Science Foundation
   of China (NSFC) [61702022]; Beijing Postdoctoral Research
   FoundationChina Postdoctoral Science Foundation [2017-ZZ-032]
FX This work was supported in part by the Beijing Municipal Education
   Commission Science and Technology Innovation Project under Grant
   KZ201610005012, in part by the China Postdoctoral Science Foundation
   funded project under Grant 2017M610027 and Grant 2017M610026, in part by
   the National Natural Science Foundation of China under Grant 61702022
   and in part by the Beijing Postdoctoral Research Foundation under Grant
   2017-ZZ-032.
CR Anjos A, 2014, IET BIOMETRICS, V3, P147, DOI 10.1049/iet-bmt.2012.0071
   Bharadwaj S, 2013, IEEE COMPUT SOC CONF, P105, DOI 10.1109/CVPRW.2013.23
   Bouguet J. Y., 2000, ACTA PATHOL JAPON, P363
   Chingovska I., 2012, P BIOSIG, P1, DOI DOI 10.1109/VTCFALL.2012.6399116
   de Freitas Pereira T., 2013, BIOM ICB 2013 INT C, P1, DOI DOI 10.1109/ICB.2013.6612981
   Erdogmus N, 2014, IEEE T INF FOREN SEC, V9, P1084, DOI 10.1109/TIFS.2014.2322255
   Housam K. B., 2014, FACE SPOOFING DETECT
   Kim S, 2013, EUR CONF NETW OPTIC, P1, DOI 10.1109/NOC-OCI.2013.6582859
   Komulainen J., 2012, ACCV, P146
   Maatta J, 2012, IET BIOMETRICS, V1, P3, DOI 10.1049/iet-bmt.2011.0009
   Maatta J., 2011, P INT JOINT C BIOM I, P1, DOI [10.1109/IJCB.2011.6117510, DOI 10.1109/IJCB.2011.6117510]
   Menotti D, 2015, IEEE T INF FOREN SEC, V10, P864, DOI 10.1109/TIFS.2015.2398817
   Pan G., 2007, IEEE INT C COMP VIS, P1, DOI DOI 10.1109/ICCV.2007.4409068
   Patel K, 2016, IEEE T INF FOREN SEC, V11, P2268, DOI 10.1109/TIFS.2016.2578288
   Pereira TD, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-2
   Phan QT, 2016, IEEE IMAGE PROC, P404, DOI 10.1109/ICIP.2016.7532388
   Schwartz W.R., 2011, INT JOINT C BIOM, P1
   Siddiqui TA, 2016, INT C PATT RECOG, P1035, DOI 10.1109/ICPR.2016.7899772
   Sun Yi, 2014, ADV NEURAL INFORM PR
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tan XY, 2010, LECT NOTES COMPUT SC, V6316, P504, DOI 10.1007/978-3-642-15567-3_37
   Tirunagari S, 2015, IEEE T INF FOREN SEC, V10, P762, DOI 10.1109/TIFS.2015.2406533
   Wu L., 2014, LIVE FACE DETECTION
   Wu L., 2016, FACE LIVENESS DETECT
   Yan JJ, 2012, I C CONT AUTOMAT ROB, P188, DOI 10.1109/ICARCV.2012.6485156
   Yoo J. H., 2006, INT J BIOL LIFE SCI, V1, P235
   Zhiwei Zhang, 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P26, DOI 10.1109/ICB.2012.6199754
NR 27
TC 2
Z9 2
U1 2
U2 8
PU WORLD SCIENTIFIC PUBL CO PTE LTD
PI SINGAPORE
PA 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE
SN 0219-6913
EI 1793-690X
J9 INT J WAVELETS MULTI
JI Int. J. Wavelets Multiresolut. Inf. Process.
PD MAR
PY 2018
VL 16
IS 2
SI SI
AR 1840001
DI 10.1142/S0219691318400015
PG 16
WC Computer Science, Software Engineering; Mathematics, Interdisciplinary
   Applications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Mathematics
GA GA6AW
UT WOS:000428416300002
DA 2022-02-06
ER

PT J
AU Dong, LY
   Ji, SJ
   Zhang, CJ
   Zhang, Q
   Chiu, DW
   Qiu, LQ
   Li, D
AF Dong, Lu-yu
   Ji, Shu-juan
   Zhang, Chun-jin
   Zhang, Qi
   Chiu, DicksonK. W.
   Qiu, Li-Qing
   Li, Da
TI An unsupervised topic-sentiment joint probabilistic model for detecting
   deceptive reviews
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Review
DE Deceptive review detection; Topic-sentiment joint probabilistic model;
   Latent dirichlet allocation; Gibbs sampling
ID REPUTATION
AB In electronic commerce, online reviews play very important roles in customers' purchasing decisions. Unfortunately, malicious sellers often hire buyers to fabricate fake reviews to improve their reputation. In order to detect deceptive reviews and mine the topics and sentiments from the reviews, in this paper, we propose an unsupervised topic-sentiment joint probabilistic model (UTSJ) based on Latent Dirichlet Allocation (LDA) model. This model first employs Gibbs sampling algorithm to approximate parameters of maximum likelihood function offline and obtain topic-sentiment joint probabilistic distribution vector for each review. Secondly, a Random Forest classifier and a SVM (Support Vector Machine) classifier are trained offline, respectively. Experimental results on real-life datasets show that our proposed model is better than baseline models such as n-grams, character n-grams in token, POS (part-of-speech), LDA, and JST (Joint Sentiment/Topic). Moreover, our UTSJ model outperforms or performs similarly to benchmark models in detecting deceptive reviews over balanced dataset and unbalanced dataset in different domains. Particularly, our UTSJ model is good at dealing with real-life unbalanced big data, which makes it very suitable for being applied in e-commerce environment. (C) 2018 Elsevier Ltd. All rights reserved.
C1 [Dong, Lu-yu; Zhang, Qi; Qiu, Li-Qing; Li, Da] Shandong Univ Sci & Technol, Coll Informat Sci & Engn, Qingdao, Peoples R China.
   [Ji, Shu-juan] Shandong Univ Sci & Technol, Key Lab Wisdom Mine Informat Technol Shandong Pro, Qingdao, Peoples R China.
   [Ji, Shu-juan] Shandong Normal Univ, Shandong Prov Key Lab Novel Distributed Comp Soft, Jinan, Shandong, Peoples R China.
   [Zhang, Chun-jin] Shandong Univ Sci & Technol, Network Informat Ctr NIC, Qingdao, Peoples R China.
   [Chiu, DicksonK. W.] Univ Hong Kong, Fac Educ, Hong Kong, Hong Kong, Peoples R China.
C3 Shandong University of Science & Technology; Shandong University of
   Science & Technology; Shandong Normal University; Shandong University of
   Science & Technology; University of Hong Kong
RP Ji, SJ (corresponding author), Shandong Univ Sci & Technol, Coll Informat Sci & Engn, Qingdao, Peoples R China.
EM 2281514572@qq.com; jane_ji2003@aliyun.com; 601041109@qq.com;
   dicksonchiu@ieee.org
RI Li, Wang/M-1612-2019
FU Natural Science Foundation of ChinaNational Natural Science Foundation
   of China (NSFC) [71772107, 71403151, 61502281, 61433012]; Key R&D Plan
   of Shandong Province [2018GGX101045]; Natural Science Foundation of
   Shandong ProvinceNatural Science Foundation of Shandong Province
   [ZR2018BF013, ZR2013FM023, ZR2014FP011]; Shandong Education Quality
   Improvement Plan for Postgraduate; China's Post-doctoral Science
   FundChina Postdoctoral Science Foundation [2014M561948]; Postdoctoral
   innovation project special funds of Shandong Province [201403007];
   Applied research project for Qingdao postdoctoral researcher; Project of
   Shandong Province Higher Educational Science and Technology Program
   [J14LN33]; Leading talent development program of Shandong University of
   Science and Technology; Special funding for Taishan scholar construction
   project
FX This paper is supported in part by the Natural Science Foundation of
   China (No. 71772107, 71403151, 61502281, 61433012), the Key R&D Plan of
   Shandong Province (NO.2018GGX101045,), the Natural Science Foundation of
   Shandong Province (Nos. ZR2018BF013, ZR2013FM023, ZR2014FP011), Shandong
   Education Quality Improvement Plan for Postgraduate, China's
   Post-doctoral Science Fund (No. 2014M561948), Postdoctoral innovation
   project special funds of Shandong Province (No. 201403007), Applied
   research project for Qingdao postdoctoral researcher, Project of
   Shandong Province Higher Educational Science and Technology Program
   (J14LN33), the Leading talent development program of Shandong University
   of Science and Technology and Special funding for Taishan scholar
   construction project.
CR Bartcus M., 2015, P INT JOINT C NEUR N, P1
   Bauman K, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P717, DOI 10.1145/3097983.3098170
   Bilici E, 2017, EXPERT SYST APPL, V68, P185, DOI 10.1016/j.eswa.2016.10.001
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Blei M. D., 2007, ADV NEURAL INFORM PR, V3, P327
   Boyd RL, 2016, CONSUMER PSYCHOLOGY IN A SOCIAL MEDIA WORLD, P222
   Cagnina L., 2015, P 6 WORKSH COMP APPR, P58
   Cagnina LC, 2017, INT J UNCERTAIN FUZZ, V25, P151, DOI 10.1142/S0218488517400165
   Chiu DKW, 2010, INFORM SYST FRONT, V12, P29, DOI 10.1007/s10796-009-9165-0
   Chiu DKW, 2009, EXPERT SYST APPL, V36, P3293, DOI 10.1016/j.eswa.2008.01.055
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Deerwester S, 1988, INFORM SCI, V100, P105
   Drummond C, 2003, P ICML WORKSH LEARN, V11, P1
   Elberrichi Z., 2006, INT C COMP SCI ITS A
   Feng S., 2012, P 50 ANN M ASS COMP, V50, P171
   Hancock, 2011, P 49 ANN M ASS COMP, P309, DOI DOI 10.1145/2567948.2577293
   He Y., 2009, P 18 ACM C INF KNOWL, P375, DOI DOI 10.1145/1645953.1646003
   Fusilier DH, 2015, LECT NOTES COMPUT SC, V9042, P285, DOI 10.1007/978-3-319-18117-2_21
   Fusilier DH, 2015, INFORM PROCESS MANAG, V51, P433, DOI 10.1016/j.ipm.2014.11.001
   Hofmann T, 1999, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS, P289
   Jindal N., 2008, P 2008 INT C WEB SEA, P219
   Johansson R., 2013, P INT C REC ADV NAT, P302
   Johnson M. J., 2012, P 26 C ANN C UNC ART, P252
   Johnson R, 2014, P 2015 C N AM CHAPT, P103
   Kalchbrenner N., 2014, P 52 ANN M ASS COMP, P212
   Li FT, 2010, PROCEEDINGS OF THE TWENTY-FOURTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-10), P1371
   Li JW, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1106, DOI 10.3115/v1/p15-1107
   Li Jiwei, 2015, ARXIV150300185, P2304
   Li KL, 2011, PROCEDIA ENGINEER, V15, DOI 10.1016/j.proeng.2011.08.366
   Li LY, 2017, NEUROCOMPUTING, V254, P33, DOI 10.1016/j.neucom.2016.10.080
   Li S, 2013, P 51 ANN M ASS COMP, V2, P217
   Lin CH, 2012, IEEE T KNOWL DATA EN, V24, P1134, DOI 10.1109/TKDE.2011.48
   Liu R., 2015, INT C HUM SOC SCI RE
   Condori REL, 2017, EXPERT SYST APPL, V78, P124, DOI 10.1016/j.eswa.2017.02.006
   Luca M, 2016, MANAGE SCI, V62, P3412, DOI 10.1287/mnsc.2015.2304
   MANN HB, 1947, ANN MATH STAT, V18, P50, DOI 10.1214/aoms/1177730491
   Mei Q., 2007, P 16 INT WORLD WID W, P171, DOI DOI 10.1145/1242572.1242596
   Mukherjee Arjun, 2013, 7 INT AAAI C WEBL SO
   Mukherjee S., 2016, JOINT EUR C MACH LEA, DOI DOI 10.1007/978-3-319-46227-1_13
   Oh, 2011, P 4 ACM INT C WEB SE, P815, DOI DOI 10.1145/1935826.1935932
   Pennebaker J.W., 2007, DEV PSYCHOMETRIC PRO, V29, P1020
   Pennebaker JW, 2010, CLOSE RELATIONSHIPS, P103
   Ren YF, 2017, INFORM SCIENCES, V385, P213, DOI 10.1016/j.ins.2017.01.015
   Suess E. A., 2010, INTRO PROBABILITY SI, P219
   Tang D, 2015, P 2015 C EMP METH NA, P1422, DOI DOI 10.18653/V1/D15-1167
   Tian G., 2016, MATH PROBL ENG, V1, P1
   Titov Ivan, 2008, P 17 INT C WORLD WID, P111, DOI DOI 10.1145/1367497.1367513
   Zhang X. W., 2016, INT C FUZZ SYST KNOW, P710
   Zhao Z., 2017, J INTELL FUZZY SYST, V33, P1, DOI DOI 10.3233/JIFS-15982
   Zhao ZY, 2015, INT J DATA WAREHOUS, V11, P98, DOI 10.4018/IJDWM.2015070105
   최우식, 2015, [Journal of the Korean Institute of Industrial Engineers, 대한산업공학회지], V41, P381, DOI 10.7232/JKIIE.2015.41.4.381
NR 51
TC 22
Z9 23
U1 6
U2 111
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD DEC 30
PY 2018
VL 114
BP 210
EP 223
DI 10.1016/j.eswa.2018.07.005
PG 14
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic; Operations Research & Management Science
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Operations Research & Management Science
GA GW5DG
UT WOS:000446949300016
DA 2022-02-06
ER

PT J
AU Huang, GKW
   Lee, JC
AF Huang, Gerald Ki Wei
   Lee, Jun Choi
TI Hyperpartisan News Classification with ELMo and Bias Feature
SO JOURNAL OF INFORMATION SCIENCE AND ENGINEERING
LA English
DT Article
DE natural language processing; classification; hyperpartisan; ELMo; bias
   detection
AB Hyperpartisan news is a kind of news riddled with twisted, untruthful, and often extremely one-sided. This kind of news can spread more successfully than the others. One of the obvious traits of hyperpartisan news content is that it can mimic regular news articles. Most are favour fake news detection algorithms, and there is less research conducted for hyperpartisan news. This research aims to perform classification on the hyperpartisan news using ELMo and bias features. ELMo was used to develop a classification model to perform classification on the BuzzFeed Webis News Corpus dataset. The model uses ELMo embedding with bias word score generated from bias lexicon to train a deep learning model using Tensorflow and Keras. We had compared the final result with two proposed baseline models that utilized ELMo from other research. The discussion section further investigated the contribution of ELMo and bias feature in the hyperpartisan task.
C1 [Huang, Gerald Ki Wei; Lee, Jun Choi] Univ Malaysia Sarawak, Fac Comp Sci & Informat Technol, Kota Samarahan 94300, Malaysia.
C3 University of Malaysia Sarawak
RP Huang, GKW (corresponding author), Univ Malaysia Sarawak, Fac Comp Sci & Informat Technol, Kota Samarahan 94300, Malaysia.
EM 19020037@siswa.unimas.my; jclee@unimas.my
CR Agerri R., 2019, P 13 INT WORKSH SEM, P944
   Chen Y., 2015, P 78 ASIS T ANN M IN, V52, P1, DOI DOI 10.1002/PRA2.2015.145052010081
   Ciampaglia GL, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0141938
   Devlin J, 2019, PROC C N AM CHAPTER, P4171, DOI DOI 10.18653/V1/N19-1423
   Horne BD, 2017, THIS JUST FAKE NEWS, P9
   Huang CR, 2017, P 8 INT JOINT C NAT, V2, P252
   Isbister T., 2019, P 13 INT WORKSH SEM, P939
   Jiang Y., 2019, P 13 INT WORKSH SEM, P840
   Ki Wei Huang Gerald, 2019, 2019 International Conference on Computer and Drone Applications (IConDA), P29, DOI 10.1109/IConDA47345.2019.9034917
   Kiesel J., 2019, P 13 INT WORKSH SEM
   Lee Nayeon, 2018, P C EMP METH NAT LAN, P1133
   Magdy A., 2010, P 2 INT WORKSH SEARC, P103, DOI 10.1145/1871985.1872002
   Pennington J., 2014, EMNLP, P1532, DOI [10.3115/v1/D14-1162, DOI 10.3115/V1/D14-1162]
   Peters ME, 2018, P C N AM CHAPT ASS C, DOI DOI 10.18653/V1/N18-1202
   Potthast M, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P231
   Procter R., 2017, SEMEVAL 2017 TASK 8, P69
   Recasens M., 2013, ACL, V1, P1650
   Sengupta S., 2019, P 13 INT WORKSH SEM, P949
   Wang WY, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P422, DOI 10.18653/v1/P17-2067
   Wei Z., 2013, M ASS COMP LING, P58
NR 20
TC 0
Z9 0
U1 0
U2 0
PU INST INFORMATION SCIENCE
PI TAIPEI
PA ACADEMIA SINICA, TAIPEI 115, TAIWAN
SN 1016-2364
J9 J INF SCI ENG
JI J. Inf. Sci. Eng.
PD SEP
PY 2021
VL 37
IS 5
SI SI
BP 1177
EP 1186
DI 10.6688/JISE.202109_37(5).0013
PG 10
WC Computer Science, Information Systems
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UL4DW
UT WOS:000692604600012
DA 2022-02-06
ER

PT J
AU Revi, KR
   Wilscy, M
   Antony, R
AF Revi, K. Remya
   Wilscy, M.
   Antony, Rahul
TI Portrait photography splicing detection using ensemble of convolutional
   neural networks
SO JOURNAL OF INTELLIGENT & FUZZY SYSTEMS
LA English
DT Article
DE Image splicing detection; deep learning; convolutional neural networks;
   transfer learning; ensemble classifier
ID IMAGE FORGERY DETECTION
AB Forged portraits of people are widely used for creating deceitful propaganda of individuals or events in social media, and even for cooking up fake pieces of evidence in court proceedings. Hence, it is very important to find the authenticity of the images, and image forgery detection is a significant research area now. This work proposes an ensemble learning technique by combining predictions of different Convolutional Neural Networks (CNNs) for detecting forged portrait photographs. In the proposed method seven different pretrained CNN architectures such as AlexNet, VGG-16, GoogLeNet, Res-Net-18, ResNet-101, Inception-v3, and Inception-ResNet-v2 are utilized. As an initial step, we fine-tune the seven pretrained networks for portrait forgery detection with illuminant maps of images as input, and then uses a majority voting ensemble scheme to combine predictions from the fine-tuned networks. Ensemble methods had been found out to be good for improving the generalization capability of classification models. Experimental analysis is conducted using two publicly available portrait splicing datasets (DSO-1 and DSI-1). The results show that the proposed method outperforms the state-of-the-art methods using traditional machine learning techniques as well as the methods using single CNN classification models.
C1 [Revi, K. Remya; Wilscy, M.; Antony, Rahul] APJ Abdul Kalam Technol Univ, SAINTGITS Coll Engn, Thiruvananthapuram, Kerala, India.
C3 Saintgits College of Engineering
RP Revi, KR (corresponding author), APJ Abdul Kalam Technol Univ, SAINTGITS Coll Engn, Dept Comp Sci & Engn, Thiruvananthapuram, Kerala, India.
EM remya.revircs16@saintgits.org
CR Abd El-Latif EI, 2020, ARAB J SCI ENG, V45, P3379, DOI 10.1007/s13369-020-04401-0
   Vega EAA, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18103372
   Becherer N, 2019, NEURAL COMPUT APPL, V31, P3469, DOI 10.1007/s00521-017-3285-0
   Carvalho T, 2016, IEEE T INF FOREN SEC, V11, P720, DOI 10.1109/TIFS.2015.2506548
   Cristin R, 2018, IET IMAGE PROCESS, V12, P1439, DOI 10.1049/iet-ipr.2017.1120
   D'souza RN, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-57866-2
   de Carvalho TJ, 2013, IEEE T INF FOREN SEC, V8, P1182, DOI 10.1109/TIFS.2013.2265677
   Dhillon A, 2020, PROG ARTIF INTELL, V9, P85, DOI 10.1007/s13748-019-00203-0
   Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1, DOI 10.1007/3-540-45014-9_1
   Evon D, PRESIDENT OBAMA AWAR
   Fridrich J., 2003, P DIG FOR RES WORKSH, DOI 10.1109/PACIIA.2008.240
   Giacinto G, 2001, IMAGE VISION COMPUT, V19, P699, DOI 10.1016/S0262-8856(01)00045-2
   Gompertz W, BBC NEWS
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hsu YF, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P549, DOI 10.1109/ICME.2006.262447
   Isaac MM, 2017, MULTIMED TOOLS APPL, V76, P25851, DOI 10.1007/s11042-017-5189-5
   Jing Dong, 2013, 2013 IEEE China Summit and International Conference on Signal and Information Processing (ChinaSIP), P422, DOI 10.1109/ChinaSIP.2013.6625374
   Ju C, 2018, J APPL STAT, V45, P2800, DOI 10.1080/02664763.2018.1441383
   Kanwal N, 2020, MULTIMED TOOLS APPL, V79, P12829, DOI 10.1007/s11042-020-08621-2
   King DB, 2015, ACS SYM SER, V1214, P1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuncheva L. I, 2014, COMBINING PATTERN CL, V2nd
   Ng TT, 2004, IEEE IMAGE PROC, P1169
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Revi KR, 2020, J INTELL FUZZY SYST, V38, P6391, DOI 10.3233/JIFS-179720
   Riess C, 2010, LECT NOTES COMPUT SC, V6387, P66, DOI 10.1007/978-3-642-16435-4_6
   Rokach L, 2010, ARTIF INTELL REV, V33, P1, DOI 10.1007/s10462-009-9124-7
   Rota P, 2016, INT C PATT RECOG, P2503, DOI 10.1109/ICPR.2016.7900012
   Sadasivan S, 2020, J INTELL FUZZY SYST, V38, P6415, DOI 10.3233/JIFS-179722
   Sagi O, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1249
   Simonyan K, 2015, ICLR 2015, DOI DOI 10.1109/CVPR.2015.7298594
   Szegedy C, 2017, THIRTY-FIRST AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4278
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tan RT, 2004, J OPT SOC AM A, V21, P321, DOI 10.1364/JOSAA.21.000321
   Phung VH, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9214500
   Vidyadharan DS, 2017, J INTELL FUZZY SYST, V32, P3177, DOI 10.3233/JIFS-169261
   Xiao B, 2020, INFORM SCIENCES, V511, P172, DOI 10.1016/j.ins.2019.09.038
   Yosinski J, 2014, ADV NEUR IN, V27
   Zhang XS, 2019, IEEE ACCESS, V7, P33822, DOI 10.1109/ACCESS.2019.2903550
   Zhou JH, 2017, LECT NOTES COMPUT SC, V10431, P65, DOI 10.1007/978-3-319-64185-0_6
NR 42
TC 1
Z9 1
U1 1
U2 1
PU IOS PRESS
PI AMSTERDAM
PA NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS
SN 1064-1246
EI 1875-8967
J9 J INTELL FUZZY SYST
JI J. Intell. Fuzzy Syst.
PY 2021
VL 41
IS 5
BP 5347
EP 5357
DI 10.3233/JIFS-189857
PG 11
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XC4SX
UT WOS:000722005700013
DA 2022-02-06
ER

PT J
AU Park, J
   Park, C
   Kim, J
   Cho, M
   Park, S
AF Park, Jinuk
   Park, Chanhee
   Kim, Jeongwoo
   Cho, Minsoo
   Park, Sanghyun
TI ADC: Advanced document clustering using contextualized representations
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Natural language processing; Document clustering; Contextualized
   representations; Cosine similarity; Deep clustering
ID NETWORK; IMAGE
AB Document representation is central to modern natural language processing systems including document clustering. Empirical experiments in recent studies provide strong evidence that unsupervised language models can learn context-aware representations in the given documents and advance several NLP benchmark results. However, existing clustering approaches focus on the dimensionality reduction and do not exploit these informative representations. In this paper, we propose a conceptually simple but experimentally effective clustering framework called Advanced Document Clustering (ADC). In contrast to previous clustering methods, ADC is designed to leverage syntactically and semantically meaningful features through feature-extraction and clustering modules in the framework. We first extract features from pre-trained language models and initialize cluster centroids to spread out uniformly. In the clustering module of ADC, the semantic similarity can be measured using the cosine similarity and centroids update while assigning centroids to a mini-batch input. Also, we utilize cross entropy loss partially, as the self-training scheme can be biased when parameters in the model are inaccurate. As a result, ADC can take advantages of contextualized representations while mitigating the limitations introduced by high-dimensional vectors. In numerous experiments with four datasets, the proposed ADC outperforms other existing approaches. In particular, experiments on categorizing news corpus with fake news demonstrated the effectiveness of our method for contextualized representations. (C) 2019 Elsevier Ltd. All rights reserved.
C1 [Park, Jinuk; Park, Chanhee; Kim, Jeongwoo; Cho, Minsoo; Park, Sanghyun] Yonsei Univ, Dept Comp Sci, 50 Yonsei Ro, Seoul 03722, South Korea.
C3 Yonsei University
RP Park, S (corresponding author), Yonsei Univ, Dept Comp Sci, 50 Yonsei Ro, Seoul 03722, South Korea.
EM parkju536@yonsei.ac.kr; channy_12@yonsei.ac.kr; jwkim2013@yonsei.ac.kr;
   minsoo0104@yonsei.ac.kr; sanghyun@yonsei.ac.kr
FU MSIT (Ministry of Science and ICT), Korea, under the SW Starlab program
   [IITP-2017-0-00477]
FX This research was supported by the MSIT (Ministry of Science and ICT),
   Korea, under the SW Starlab support program (IITP-2017-0-00477)
   supervised by the IITP (Institute for Information & communications
   Technology Promotion).
CR Arthur D, 2007, PROCEEDINGS OF THE EIGHTEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1027
   Bishop CM., 2006, PATTERN RECOGN
   Blitzer John, 2006, P C EMP METH NAT LAN, P120
   Caron M, 2018, LECT NOTES COMPUT SC, V11218, P139, DOI 10.1007/978-3-030-01264-9_9
   Chen X, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY (CIT), P172, DOI 10.1109/CIT.2016.65
   Chlamtac I, 1996, MILCOM 96, CONFERENCE PROCEEDINGS, VOLS 1-3, P108, DOI 10.1109/MILCOM.1996.568594
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   De la Torre Fernando, 2006, P 23 INT C MACH LEAR, DOI DOI 10.1145/1143844.1143875
   Devlin J, 2019, PROC C N AM CHAPTER, P4171, DOI DOI 10.18653/V1/N19-1423
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Graves A, 2012, STUD COMPUT INTELL, V385, P47
   Guo X., 2017, P 26 INT JOINT C ART, P1753, DOI [DOI 10.24963/IJCAI.2017/243, 10.24963/ijcai.2017/243]
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735
   Hofmann T, 2008, ANN STAT, V36, P1171, DOI 10.1214/009053607000000677
   Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328
   Hsu CC, 2018, IEEE T MULTIMEDIA, V20, P421, DOI 10.1109/TMM.2017.2745702
   Huang PH, 2014, INT C PATT RECOG, P1532, DOI 10.1109/ICPR.2014.272
   Jiang Z., 2017, P INT JOINT C ART IN
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Koltun V., 2018, DEEP CONTINUOUS CLUS
   Krizhevsky A., 2012, ADV NEURAL INF PROCE, P1097, DOI DOI 10.1145/3065386
   Lewis DD, 2004, J MACH LEARN RES, V5, P361
   MacQueen J., 1967, P 5 BERK S MATH STAT
   Manning CD., 2008, P INT COMM ASS COMP, DOI 10.1017/CBO9780511809071
   Mikolov T, 2013, P ICLR WORKSH, V1, P1
   Perez-Rosas V, 2018, P 27 INT C COMPUTATI, P3391
   Peters ME, 2018, P C N AM CHAPT ASS C, DOI DOI 10.18653/V1/N18-1202
   Rajpurkar P., 2016, ARXIV160605250
   Simonyan K, 2015, ICLR 2015, DOI DOI 10.1109/CVPR.2015.7298594
   Socher R, 2014, P 19 C EMPIRICAL MET, V2014, P1532, DOI DOI 10.3115/V1/D14-1162
   Socher R., 2013, ADV NEURAL INFORM PR, P1
   Song JK, 2018, PATTERN RECOGN, V75, P175, DOI 10.1016/j.patcog.2017.03.021
   Springenberg J T, 2015, UNSUPERVISED SEMI SU
   Sun MX, 2016, 2016 13TH IEEE INTERNATIONAL CONFERENCE ON SOLID-STATE AND INTEGRATED CIRCUIT TECHNOLOGY (ICSICT), P478, DOI 10.1109/ICSICT.2016.7998956
   Sutskever Ilya, 2018, TECHNICAL REPORT
   Tian F, 2014, PROCEEDINGS OF THE TWENTY-EIGHTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1293
   Vaswani A, 2017, ADV NEUR IN, P5998
   von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z
   Xiong H, 2004, SIAM PROC S, P279
   Xu W., 2003, P 26 ANN INT ACM SIG, P267, DOI DOI 10.1145/860435.860485
   Yang B, 2017, PR MACH LEARN RES, V70
   Zhang X., 2015, ADV NEURAL INFORM PR, V28, P649, DOI DOI 10.1063/1.4906785
NR 42
TC 7
Z9 7
U1 0
U2 38
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD DEC 15
PY 2019
VL 137
BP 157
EP 166
DI 10.1016/j.eswa.2019.06.068
PG 10
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic; Operations Research & Management Science
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Operations Research & Management Science
GA IZ6BT
UT WOS:000487167500011
DA 2022-02-06
ER

PT J
AU Zhang, M
   Li, CY
   Zhou, ZP
AF Zhang, Min
   Li, Chunye
   Zhou, Zhiping
TI Text to image synthesis using multi-generator text conditioned
   generative adversarial networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Text to image; Generative adversarial networks; Mode collapse; Text
   description; Multiple generators
AB Recently, Generative Adversarial Network(GAN) has been the most mainstream technology in the task of Text to Image. However, the vanilla deep neural networks tend to approximate continuous mappings in real generation tasks rather than discontinuous mappings with discrete points. When training on datasets with multiple types, GAN fails to synthesize diverse images, which we call as mode collapse. To deal with it, we propose the Multi-generator Text Conditioned Generative Adversarial Network (MTC-GAN) in this paper. Textual description of real images is embedded on the noise vector as a constraint. Based on Deep Convolutional Generative Adversarial Networks(DCGAN), multiple generators are incorporated to capture high probability among the target distribution. To identify the generated fake sample from a particular generator, the discriminator must enforce multiple generators to have different identifiable modes. The method based on global constraints can make the generated images more diverse. Multiple generators can improve the particular functional shape of the discriminators indirectly, which should make the GAN more stable when trained in high dimensional spaces. The experimental results on the standard dataset demonstrate the good performance of the proposed method. The problem of mode collapse can be improved, and the generated samples can be more diverse.
C1 [Zhang, Min; Li, Chunye; Zhou, Zhiping] Jiangnan Univ, Sch Internet Things Engn, Wuxi 214122, Jiangsu, Peoples R China.
   [Zhou, Zhiping] Jiangnan Univ, Minist Educ, Engn Res Ctr Internet Things Technol Applicat, Wuxi 214122, Jiangsu, Peoples R China.
C3 Jiangnan University; Jiangnan University
RP Zhou, ZP (corresponding author), Jiangnan Univ, Sch Internet Things Engn, Wuxi 214122, Jiangsu, Peoples R China.; Zhou, ZP (corresponding author), Jiangnan Univ, Minist Educ, Engn Res Ctr Internet Things Technol Applicat, Wuxi 214122, Jiangsu, Peoples R China.
EM zzp@jiangnan.edu.cn
CR Arjovsky M, 2017, ARXIV170107875
   Bishop CM., 2006, PATTERN RECOGN
   Bodnar C, 2018, ARXIV180500676
   Che Tong, 2016, ARXIV161202136
   Chidambaram Muthuraman, 2017, ARXIV170206762
   Dash Ayushman, 2017, ARXIV PREPRINT ARXIV
   Ghosh A, 2018, PROC CVPR IEEE, P8513, DOI 10.1109/CVPR.2018.00888
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Guo HF, 2018, INT J PATTERN RECOGN, V32, DOI 10.1142/S021800141859005X
   Heusel M., 2017, ADV NEURAL INFORM PR, P6629
   Li Jiwei, 2017, ARXIV170106547, P198, DOI [DOI 10.18653/V1/D17-1230, 10.18653/v1/D17-1019]
   Lin Zinan, 2018, ADV NEURAL INFORM PR, P1505
   Lu X, 2019, IEEE T CIRCUITS SYST, P69
   Luxburg U. V., 2016, P NEURIPS, V29, P4790
   Mansimov E., 2015, ARXIV151102793
   Metz L., 2016, ARXIV161102163
   Mirza M., 2014, ARXIV14111784, P1
   Moradshahi M, 2018, LANGUAGE MODELING GE
   Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47
   Odena A, 2017, PR MACH LEARN RES, V70
   Reed S., 2016, P ADV NEURAL INFORM
   Reed S, 2016, INT C INT C MACH LEA, P2
   Reed S, 2016, PR MACH LEARN RES, V48
   Salimans T., 2016, NEURIPS, P2234, DOI DOI 10.5555/3157096.3157346
   Shim H., 2018, ARXIV180404391
   Song YB, 2018, PROC CVPR IEEE, P8990, DOI 10.1109/CVPR.2018.00937
   Srivastava Akash, 2017, ADV NEURAL INFORM PR
   Thanh-Tung H., 2018, ARXIV180704015
   Welinder P, CALTECH UCSD BIRDS 2, P2
   Xiang S, 2017, EFFECTS BATCH WEIGHT
   Xu C, 2019, MULTIMEDIA SYSTEMS
   Zhang H., 2017, IEEE T PATTERN ANAL, P1
   Zhang H, 2017, IEEE I CONF COMP VIS, P5908, DOI 10.1109/ICCV.2017.629
NR 33
TC 0
Z9 0
U1 6
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 7789
EP 7803
DI 10.1007/s11042-020-09965-5
EA OCT 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000587058000002
DA 2022-02-06
ER

PT J
AU Li, Y
   Jung, C
   Kim, J
AF Li, Ying
   Jung, Cheolkon
   Kim, Jinyoung
TI Single Image Depth Estimation Using Edge Extraction Network and Dark
   Channel Prior
SO IEEE ACCESS
LA English
DT Article
DE Image edge detection; Estimation; Generators; Generative adversarial
   networks; Image color analysis; Deep learning; Channel estimation; Depth
   estimation; dark channel prior; deep learning; edge extraction;
   generative adversarial network; transmission
ID SEGMENTATION
AB The key to the depth estimation from a single image lies in inferring the distance of various objects without copying texture while maintaining clear object boundaries. In this paper, we propose depth estimation from a single image using edge extraction network and dark channel prior (DCP). We build an edge extraction network based on generative adversarial networks (GANs) to select valid depth edges from a number of edges in an image. We use DCP to generate a transmission map that is able to represent distance from the camera. Transmission map is generated by conducting minimum value filtering on DCP. First, we concatenate the transmission map with the original RGB image to form a tensor, i.e. RGB + T. Second, we generate an initial depth image from the tensor through the generator by inferring depth from stacked residual blocks. Third, we compare the edge map of the initial depth image with that of the input RGB image to select valid depth edges. Both edge maps are generated by the edge extraction network. Finally, we distinguish real and fake on the generated depth image using a discriminator, and enhances the performance of the generator. Various experiments on NYU, Make3D and MPI Sintel datasets demonstrate that the proposed network generates clear edges in depth images as well as outperforms state-of-the-art methods in terms of visual quality and quantitative measurements.
C1 [Li, Ying; Jung, Cheolkon] Xidian Univ, Sch Elect Engn, Xian 710071, Peoples R China.
   [Kim, Jinyoung] Chonnam Natl Univ, Dept ICT Convergence Syst Engn, Gwangju 61186, South Korea.
C3 Xidian University; Chonnam National University
RP Jung, C (corresponding author), Xidian Univ, Sch Elect Engn, Xian 710071, Peoples R China.
EM zhengzk@xidian.edu.cn
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61872280]
FX This work was supported by the National Natural Science Foundation of
   China under Grant 61872280.
CR Bazazian D., 2015, P INT C DIG IM COMP, P1
   Belkin M, 2008, PROCEEDINGS OF THE TWENTY-FOURTH ANNUAL SYMPOSIUM ON COMPUTATIONAL GEOMETRY (SGG'08), P278, DOI 10.1145/1377676.1377725
   Butler DJ, 2012, LECT NOTES COMPUT SC, V7577, P611, DOI 10.1007/978-3-642-33783-3_44
   Chen BL, 2018, IEEE T MULTIMEDIA, V20, P2882, DOI 10.1109/TMM.2018.2825883
   Dubayah RO, 2000, J FOREST, V98, P44
   Eigen D, 2014, ADV NEUR IN, V27
   Fan JP, 2001, IEEE T IMAGE PROCESS, V10, P1454, DOI 10.1109/83.951532
   Fu H, 2018, PROC CVPR IEEE, P2002, DOI 10.1109/CVPR.2018.00214
   Gatys LA, 2016, PROC CVPR IEEE, P2414, DOI 10.1109/CVPR.2016.265
   Ge LZ, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19051132
   Godard C, 2019, IEEE I CONF COMP VIS, P3827, DOI 10.1109/ICCV.2019.00393
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gulrajani I., 2017, ADV NEURAL INFORM PR, P5769, DOI DOI 10.5555/3295222.3295327
   Hambarde P, 2019, IEEE IMAGE PROC, P989, DOI 10.1109/ICIP.2019.8803027
   Hamzah RA, 2016, 2016 1ST INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY, INFORMATION SYSTEMS AND ELECTRICAL ENGINEERING (ICITISEE), P119, DOI 10.1109/ICITISEE.2016.7803059
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2009, PROC CVPR IEEE, P1956, DOI [10.1109/CVPRW.2009.5206515, 10.1109/CVPR.2009.5206515]
   He YB, 2018, INT J MOD PHYS C, V29, DOI 10.1142/S0129183118500079
   Hollandi R, 2020, CELL SYST, V10, P453, DOI 10.1016/j.cels.2020.04.003
   Ismail SM, 2020, SIGNAL PROCESS, V167, DOI 10.1016/j.sigpro.2019.107280
   Ji RR, 2020, IEEE T PATTERN ANAL, V42, P2410, DOI 10.1109/TPAMI.2019.2936024
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   KANOPOULOS N, 1988, IEEE J SOLID-ST CIRC, V23, P358, DOI 10.1109/4.996
   Kingma DP, 2015, 3 INT C LEARN REPR I, DOI DOI 10.1145/1830483.1830503
   Kiran B.R., ARXIV200200444
   Krishnan K. Bala, 2017, INDIAN J SCI TECHNOL, V10, DOI DOI 10.17485/ijst/2017/v10i4/108963
   Laga H., 2020, ARXIV200602535
   Liu MY, 2017, ADV NEUR IN, V30
   Lowd Daniel, 2005, ACM KDD, P641, DOI DOI 10.1145/1081870.1081950
   Lu S., 2019, P 4 INT C ROB CONTR, P219
   Mirza M, 2014, ARXIV PREPRINT ARXIV
   Myerson R. B., 2013, GAME THEORY
   Pan JS, 2016, PROC CVPR IEEE, P1628, DOI 10.1109/CVPR.2016.180
   Pilzer A, 2018, INT CONF 3D VISION, P587, DOI 10.1109/3DV.2018.00073
   RogersRamachandran DC, 1998, VISION RES, V38, P71, DOI 10.1016/S0042-6989(97)00131-4
   Rogister P, 2012, IEEE T NEUR NET LEAR, V23, P347, DOI 10.1109/TNNLS.2011.2180025
   ROSENFELD A, 1981, IEEE T PATTERN ANAL, V3, P101, DOI 10.1109/TPAMI.1981.4767056
   Smisek J., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1154, DOI 10.1109/ICCVW.2011.6130380
   Song X, 2020, INT J COMPUT VISION, V128, P910, DOI 10.1007/s11263-019-01287-w
   Tong-qing W., 2009, COMPUT ENG
   ULUPINAR F, 1990, COMPUT VISION GRAPH, V51, P275, DOI 10.1016/0734-189X(90)90004-F
   Wang L, 2014, IEEE T MULTIMEDIA, V16, P1905, DOI 10.1109/TMM.2014.2341599
   Wu WX, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.5263
   Xie SN, 2017, INT J COMPUT VISION, V125, P3, DOI 10.1007/s11263-017-1004-z
   Yang AM, 2018, CHAOS SOLITON FRACT, V117, P215, DOI 10.1016/j.chaos.2018.09.028
   Yang GR, 2018, LECT NOTES COMPUT SC, V11211, P660, DOI 10.1007/978-3-030-01234-2_39
   Zhan HY, 2018, PROC CVPR IEEE, P340, DOI 10.1109/CVPR.2018.00043
   Zhang J., 2018, INT J ADV COMPUT SC, V9, P1
   Zhang Y., 2019, P INT C MACH LEARN C, P1
   Ziou D., 1998, Pattern Recognition and Image Analysis, V8, P537
NR 50
TC 0
Z9 0
U1 1
U2 1
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2021
VL 9
BP 112454
EP 112465
DI 10.1109/ACCESS.2021.3100037
PG 12
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA UB5LF
UT WOS:000685886600001
OA gold
DA 2022-02-06
ER

PT J
AU Kietzmann, J
   Mills, AJ
   Plangger, K
AF Kietzmann, Jan
   Mills, Adam J.
   Plangger, Kirk
TI Deepfakes: perspectives on the future "reality" of advertising and
   branding
SO INTERNATIONAL JOURNAL OF ADVERTISING
LA English
DT Article
DE Deepfake; fake media; advertising and realities; popper&#8217; s three
   worlds
ID SOCIAL MEDIA; FAKE NEWS; DARK SIDE
AB Deepfakes are real videos with fake content. Leveraging artificial intelligence technologies to superimpose voices and likenesses, deepfakes can, quite literally, put someone's words in anyone else's mouth. Deepfakes are exploding across mass and social media, and these outlets are feverously trying to manage the proliferation of content with potentially deceitful authenticity on their platforms. This paper introduces what deepfakes are, how they work, and the potential for deepfakes' influence on advertising. We provide a conceptual model that explores the influence of deepfakes on advertising practice in a holistic context of consumer consumption and cultural influence to explore how deepfakes influence three perspective dimensions of advertising - not only the tangible ads themselves, but also how consumers perceive those ads and the greater sociocultural context in which the ads are created and consumed. Deepfakes present both threats to and opportunities for advertisers, and we leverage this conceptual model to highlight several critical areas of practice that warrant further investigation.
C1 [Kietzmann, Jan] Univ Victoria, Gustavson Sch Business, Victoria, BC, Canada.
   [Mills, Adam J.] Loyola Univ, 6363 St Charles Ave,Box 15, New Orleans, LA 70115 USA.
   [Plangger, Kirk] Kings Coll London, Bush House, London, England.
C3 University of Victoria; University of London; King's College London
RP Mills, AJ (corresponding author), Loyola Univ, 6363 St Charles Ave,Box 15, New Orleans, LA 70115 USA.
EM ajmills@loyno.edu
RI Kietzmann, Jan/ABF-6025-2020; Plangger, Kirk/P-7532-2018
OI Plangger, Kirk/0000-0002-0354-9707; Mills, Adam/0000-0002-2924-0150
CR [Anonymous], 2020, ECONOMIST
   Baccarella CV, 2018, EUR MANAG J, V36, P431, DOI 10.1016/j.emj.2018.07.002
   BEARD F. K., 2004, JOURNALISM HIST, V30, P141
   Berthon P., 2018, GFK MARKETING INTELL, V10, P19
   Berton P, 2018, ROUTL CONTEMP JPN SE, V75, P1, DOI [10.4324/9781315229010, 10.1177/0276146718755869]
   Brucato B, 2015, SURVEILL SOC, V13, P455
   Chen CH, 2019, J HIGH ENERGY PHYS, DOI 10.1007/JHEP10(2019)005
   Chesney B., 2019, CALIF L REV, V107
   Coldewey D., 2020, FACEBOOKS DEEPFAKE D
   Culkin, 1967, SCHOOLMANS GUIDE MAR
   D'Rozario D., 2016, J CUSTOMER BEHAV, V15, P395
   De Veirman M, 2017, INT J ADVERT, V36, P798, DOI 10.1080/02650487.2017.1348035
   Diaz A.-C., 2020, SEE JEFF GOODBY DORI
   Gelfert A, 2018, INFORMAL LOG, V38, P84, DOI 10.22329/il.v38i1.5068
   Granot Y, 2018, PSYCHOL PUBLIC POL L, V24, P93, DOI 10.1037/law0000137
   Ham CD, 2017, INT J ADVERT, V36, P632, DOI 10.1080/02650487.2016.1239878
   Hayes JL, 2018, INT J ADVERT, V37, P142, DOI 10.1080/02650487.2017.1360576
   Hovland CI, 1951, PUBLIC OPIN QUART, V15, P635, DOI 10.1086/266350
   Howes S. A., 2018, COLUM J ARTS, V42
   Johnstone L, 2018, J CONSUM BEHAV, V17, pE127, DOI 10.1002/cb.1693
   Kietzmann J. H., 2020, BUSINESS HORIZONS, V63
   Kietzmann JH, 2012, J PUBLIC AFF, V12, P109, DOI 10.1002/pa.1412
   Lazer DMJ, 2018, SCIENCE, V359, P1094, DOI 10.1126/science.aao2998
   Maras MH, 2019, INT J EVID PROOF, V23, P255, DOI 10.1177/1365712718807226
   MICK DG, 1992, J CONSUM RES, V19, P317, DOI 10.1086/209305
   Mills AJ, 2020, J PROD BRAND MANAG, V29, P159, DOI 10.1108/JPBM-12-2018-2150
   Mills AJ, 2012, J PUBLIC AFF, V12, P162, DOI 10.1002/pa.1418
   Nickerson R.S., 1998, REV GEN PSYCHOL, V2, P175, DOI [10.1037/1089-2680.2.2.175, DOI 10.1037/1089-2680.2.2.175]
   Nyilasy G, 2019, INT J ADVERT, V38, P336, DOI 10.1080/02650487.2019.1586210
   Okazaki S, 2010, J ADVERTISING, V39, P5, DOI 10.2753/JOA0091-3367390201
   Plangger K, 2020, J PROD BRAND MANAG, V29, P141, DOI 10.1108/JPBM-03-2020-008
   Popper, 1978, TANN LECT HUM VAL
   Porter G, 2012, AUST J FORENSIC SCI, V44, P183, DOI 10.1080/00450618.2011.634835
   Roggeveen AL, 2002, J CONSUM PSYCHOL, V12, P81, DOI 10.1207/S15327663JCP1202_02
   Ruiz D., 2020, DEEPFAKES LAWS PROPO
   Solsman J., 2020, DEEPFAKES THREAT 202
   Sundar SS., 2008, DIGITAL MEDIA YOUTH, P73, DOI DOI 10.1162/DMAL.9780262562324.073
   Thompson A., 2019, POPULAR MECH
   Toews, 2020, FORBES
   Vaccari C., 2020, WASHINGTON POST
   Van Duyn E, 2019, MASS COMMUN SOC, V22, P29, DOI 10.1080/15205436.2018.1511807
   Vosoughi S, 2018, SCIENCE, V359, P1146, DOI 10.1126/science.aap9559
   Weidner K, 2020, J PROD BRAND MANAG, V29, P180, DOI 10.1108/JPBM-12-2018-2155
NR 43
TC 1
Z9 1
U1 14
U2 48
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 0265-0487
EI 1759-3948
J9 INT J ADVERT
JI Int. J. Advert.
PD MAY 21
PY 2021
VL 40
IS 3
BP 473
EP 485
DI 10.1080/02650487.2020.1834211
EA NOV 2020
PG 13
WC Business; Communication
WE Social Science Citation Index (SSCI)
SC Business & Economics; Communication
GA SG5IA
UT WOS:000585445700001
DA 2022-02-06
ER

PT J
AU Hu, C
   Feng, ZH
   Wu, XJ
   Kittler, J
AF Hu, Cong
   Feng, Zhenhua
   Wu, Xiaojun
   Kittler, Josef
TI Dual Encoder-Decoder Based Generative Adversarial Networks for
   Disentangled Facial Representation Learning
SO IEEE ACCESS
LA English
DT Article
DE Face; Gallium nitride; Generative adversarial networks; Training;
   Generators; Face recognition; Task analysis; Disentangled representation
   learning; encoder-decoder; generative adversarial networks; face
   synthesis; pose invariant face recognition
ID FACE RECOGNITION
AB To learn disentangled representations of facial images, we present a Dual Encoder-Decoder based Generative Adversarial Network (DED-GAN). In the proposed method, both the generator and discriminator are designed with deep encoder-decoder architectures as their backbones. To be more specific, the encoder-decoder structured generator is used to learn a pose disentangled face representation, and the encoder-decoder structured discriminator is tasked to perform real/fake classification, face reconstruction, determining identity and estimating face pose. We further improve the proposed network architecture by minimizing the additional pixel-wise loss defined by the Wasserstein distance at the output of the discriminator so that the adversarial framework can be better trained. Additionally, we consider face pose variation to be continuous, rather than discrete in existing literature, to inject richer pose information into our model. The pose estimation task is formulated as a regression problem, which helps to disentangle identity information from pose variations. The proposed network is evaluated on the tasks of pose-invariant face recognition (PIFR) and face synthesis across poses. An extensive quantitative and qualitative evaluation carried out on several controlled and in-the-wild benchmarking datasets demonstrates the superiority of the proposed DED-GAN method over the state-of-the-art approaches.
C1 [Hu, Cong; Wu, Xiaojun] Jiangnan Univ, Sch Artificial Intelligence & Comp Sci, Wuxi 214122, Jiangsu, Peoples R China.
   [Hu, Cong; Wu, Xiaojun] Jiangnan Univ, Jiangsu Prov Engn Lab Pattern Recognit & Computat, Wuxi 214122, Jiangsu, Peoples R China.
   [Hu, Cong] Minjiang Univ, Fujian Prov Key Lab Informat Proc & Intelligent C, Fuzhou 350121, Peoples R China.
   [Feng, Zhenhua] Univ Surrey, Dept Comp Sci, Guildford GU2 7XH, Surrey, England.
   [Feng, Zhenhua; Kittler, Josef] Univ Surrey, Ctr Vis Speech & Signal Proc, Guildford GU2 7XH, Surrey, England.
C3 Jiangnan University; Jiangnan University; Minjiang University;
   University of Surrey; University of Surrey
RP Wu, XJ (corresponding author), Jiangnan Univ, Sch Artificial Intelligence & Comp Sci, Wuxi 214122, Jiangsu, Peoples R China.; Wu, XJ (corresponding author), Jiangnan Univ, Jiangsu Prov Engn Lab Pattern Recognit & Computat, Wuxi 214122, Jiangsu, Peoples R China.
EM wu_xiaojun@jiangnan.edu.cn
RI Feng, Zhenhua/T-3139-2019
OI Kittler, Josef/0000-0002-8110-9205; Feng, Zhenhua/0000-0002-4485-4249
FU Engineering and Physical Sciences Research Council (EPSRC)UK Research &
   Innovation (UKRI)Engineering & Physical Sciences Research Council
   (EPSRC) [EP/N007743/1]; National Natural Science Foundation of
   ChinaNational Natural Science Foundation of China (NSFC) [U1836218,
   61672265, 61876072, 61902153]; 111 Project of Chinese Ministry of
   Education [B12018]; Open Fund Project of Fujian Provincial Key
   Laboratory of Information Processing and Intelligent Control, Minjiang
   University [MJUKF-IPIC202002]; EPSRCUK Research & Innovation
   (UKRI)Engineering & Physical Sciences Research Council (EPSRC)
   [EP/R018456/1, EP/N007743/1] Funding Source: UKRI
FX This work was supported in part by the Engineering and Physical Sciences
   Research Council (EPSRC) Programme under Grant (FACER2VM) EP/N007743/1,
   in part by the National Natural Science Foundation of China under Grant
   U1836218, Grant 61672265, Grant 61876072, and Grant 61902153, in part by
   the 111 Project of Chinese Ministry of Education under Grant B12018, and
   in part by the Open Fund Project of Fujian Provincial Key Laboratory of
   Information Processing and Intelligent Control, Minjiang University,
   under Grant MJUKF-IPIC202002.
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   An ZF, 2019, IEEE ACCESS, V7, P14653, DOI 10.1109/ACCESS.2019.2894162
   [Anonymous], 2014, ADV NEURAL INFORM PR
   Antipov G, 2017, IEEE IMAGE PROC, P2089, DOI 10.1109/ICIP.2017.8296650
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Berthelot David, 2017, ARXIV170310717
   Chan CH, 2013, IEEE T PATTERN ANAL, V35, P1164, DOI 10.1109/TPAMI.2012.199
   Chan JS, 2017, IEEE IMAGE PROC, P3825, DOI 10.1109/ICIP.2017.8296998
   Chen D, 2013, PROC CVPR IEEE, P3025, DOI 10.1109/CVPR.2013.389
   Chen Wei, 2009, P 22 INT C NEUR INF, V22, P315
   Chen X, 2016, ADV NEUR IN, V29
   Chintala S., 2017, ARXIV170107875
   Dalal N., 2005, 2005 IEEE COMPUTER S, DOI DOI 10.1109/CVPR.2005.177
   DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Denton E. L., 2015, ADV NEURAL INFORM PR, P1486, DOI DOI 10.5555/
   Feng Z.-H., 2016, ARXIV161209548
   Gauthier J., 2014, CLASS PROJECT STANFO, V2014, P2
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002
   HASSNER T, 2015, PROC CVPR IEEE, P4295, DOI DOI 10.1109/CVPR.2015.7299058
   He ZL, 2019, IEEE T IMAGE PROCESS, V28, P5464, DOI 10.1109/TIP.2019.2916751
   Heusel M., 2017, NIPS, V30, P6629
   Higgins I., 2017, ICLR
   Higgins I., 2017, ARXIV170703389
   Hu C, 2019, IEEE T COGN DEV SYST, V11, P539, DOI 10.1109/TCDS.2018.2875462
   Hu C, 2019, NEURAL PROCESS LETT, V50, P1079, DOI 10.1007/s11063-018-9898-1
   Huang GQ, 2009, INT J COMPUT INTEG M, V22, P579, DOI 10.1080/09511920701724934
   Kan M, 2014, PROC CVPR IEEE, P1883, DOI 10.1109/CVPR.2014.243
   Karras T, 2018, PROGRESSIVE GROWING
   Kasabov N, 2016, 2016 IEEE 8TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS (IS), P15, DOI 10.1109/IS.2016.7737434
   Kingma D. P., 2014, ARXIV13126114, DOI DOI 10.1007/S11042-018-6187-Y
   Kingma DP, 2015, 3 INT C LEARN REPR I, DOI DOI 10.1145/1830483.1830503
   Kittler J, 2016, LECT NOTES COMPUT SC, V9756, P185, DOI 10.1007/978-3-319-41778-3_19
   Kong J, 2018, IEEE ACCESS, V6, P45153, DOI 10.1109/ACCESS.2018.2865425
   Koppen P, 2018, PATTERN RECOGN, V74, P617, DOI 10.1016/j.patcog.2017.09.006
   Kulkarni Tejas D, 2015, ADV NEURAL INFORM PR, P2539, DOI DOI 10.1063/1.4914407
   Lake BM, 2017, BEHAV BRAIN SCI, V40, DOI 10.1017/S0140525X16001837
   LeCun Yann, 2016, ARXIV 1609 03126
   Ledig C, 2017, PROC IEEE C COMPUT V, P4681
   Li C, 2016, PROC CVPR IEEE, P2479, DOI 10.1109/CVPR.2016.272
   Li Y., 2017, CVPR, V1, P3, DOI DOI 10.1002/ADMA.201700981
   Li YN, 2017, IEEE I CONF COMP VIS, P3439, DOI 10.1109/ICCV.2017.370
   Lu Y., 2017, ARXIV170509966
   Luan X, 2020, IEEE ACCESS, V8, P104676, DOI 10.1109/ACCESS.2020.2996637
   Masi I, 2016, PROC CVPR IEEE, P4838, DOI 10.1109/CVPR.2016.523
   Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Peng X, 2017, IEEE I CONF COMP VIS, P1632, DOI 10.1109/ICCV.2017.180
   Radford A., 2015, ARXIV151106434
   Ridgeway K., 2016, ARXIVCSLG161205299
   Sagonas C, 2015, IEEE I CONF COMP VIS, P3871, DOI 10.1109/ICCV.2015.441
   Salimans T., 2016, ADV NEURAL INFORM PR, P2234
   Sankaranarayanan Swami, 2016, 2016 IEEE 8 INT C BI, DOI DOI 10.1109/BTAS.2016.7791205
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Shen W., 2017, P IEEE C COMP VIS PA, P4030
   Shrivastava A., 2017, P IEEE C COMP VIS PA, P2107
   Song XN, 2018, IEEE T INF FOREN SEC, V13, P2734, DOI 10.1109/TIFS.2018.2833052
   Sun Y., 2015, ARXIV150200873
   Sun Y, 2015, PROC CVPR IEEE, P2892, DOI 10.1109/CVPR.2015.7298907
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Tang ZY, 2019, IEEE ACCESS, V7, P97641, DOI 10.1109/ACCESS.2019.2930203
   Tran L., 2017, CVPR, V4, P7
   Tran L, 2019, IEEE T PATTERN ANAL, V41, P3007, DOI 10.1109/TPAMI.2018.2868350
   Wang WW, 2020, IEEE ACCESS, V8, P45023, DOI 10.1109/ACCESS.2020.2977729
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Wu X, 2018, IEEE T INF FOREN SEC, V13, P2884, DOI 10.1109/TIFS.2018.2833032
   Xie Y, 2015, 2015 INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE AND MANAGEMENT ENGINEERING (ICISME 2015), P142
   Yang J., 2017, ARXIV170301560
   Yi D., 2014, ARXIV14117923
   Yim J, 2015, PROC CVPR IEEE, P676, DOI 10.1109/CVPR.2015.7298667
   Yin XX, 2017, HEALTH INFOR SCI, P1, DOI 10.1007/978-3-319-57027-3_1
   Zhang KP, 2016, IEEE SIGNAL PROC LET, V23, P1499, DOI 10.1109/LSP.2016.2603342
   Zhao B., 2017, ARXIV170404886
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhu XY, 2015, PROC CVPR IEEE, P787, DOI 10.1109/CVPR.2015.7298679
NR 77
TC 3
Z9 3
U1 1
U2 3
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2020
VL 8
BP 130159
EP 130171
DI 10.1109/ACCESS.2020.3009512
PG 13
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA MO9HD
UT WOS:000551826400001
OA gold, Green Submitted
DA 2022-02-06
ER

PT J
AU Turner, G
AF Turner, Graeme
TI The media and democracy in the digital era: is this what we had in mind?
SO MEDIA INTERNATIONAL AUSTRALIA
LA English
DT Article
DE democracy; journalism; media; public interest; the digital era
AB In the mass media era, the role of the media was universally regarded as fundamental to the proper functioning of the democratic state: the media's capacity to provide information freely to all citizens ensured they had equal access to the democratic process. There were many, though, who registered concern at the top-down, government-led and highly concentrated structures of power embedded here; it was easy to demonstrate how the flow of information could be manipulated and the power of the media abused. Consequently, the arrival of the digital era seemed to radically modify that power relation for the better. The initial enthusiasm, though, has been challenged by what, a decade or two later, we have ended up with: a digital landscape that does indeed offer unprecedented access to information, in ways that have been transformative - but that is also awash with socially regressive content: fake news, hate speech revenge porn and so on. In this article, I want to discuss some aspects of what we have got from the digital era so far, with a particular focus on the changing relationship between the media and democracy - and within that, the role of news, information and the practice of journalism.
C1 [Turner, Graeme] Univ Queensland, Brisbane, Qld, Australia.
C3 University of Queensland
RP Turner, G (corresponding author), Univ Queensland, Inst Adv Studies Humanities, 4th Floor,Forgan Smith Tower, Brisbane, Qld 4072, Australia.
EM graeme.turner@uq.edu.au
CR Andrejevic M, 2013, INFOGLUT TOO MUCH IN
   Barry P, 2017, MEDIA WATCH     0619
   Bogle A., 2018, ABC NEWS
   Bornstein J, 2018, SYDNEY MORNING HERAL
   Bruns A., 2008, BLOGS WIKIPEDIA 2 LI
   Christian A.J., 2018, OPEN TV INNOVATION H
   Coleman S, 2017, CAN INTERNET STRENGT
   Craig, SOCIAL MEDIA ENTERTA
   Curran J, 2010, JOURNALISM STUD, V11, P464, DOI 10.1080/14616701003722444
   Curran James, 2011, MEDIA AND DEMOCRACY
   Feik N, 2017, MONTHLY, P25
   Gillespie T, 2010, NEW MEDIA SOC, V12, P347, DOI 10.1177/1461444809342738
   Guaglione S, 2017, MEDIAPOST       1010
   Hindman M. S., 2009, MYTH DIGITAL DEMOCRA
   Hutchinson A, 2017, SOCIALMEDIATODA 0830
   Klein Naomi, 2017, NO IS NOT ENOUGH RES
   Lewis A, 2017, CTR STRATEGIC I 1101
   Loechner J, 2017, MEDIAPOST       0629
   Mandese J, 2017, MEDIAPOST       0918
   McGuigan J., 2009, COOL CAPITALISM
   Mcnamee R., 2018, GUARDIAN
   Miller Toby., 2007, CULTURAL CITIZENSHIP
   Napoli PM, 2017, 1 MONDAY, P225
   Omidyar P, 2017, WASHINGTON POST
   Quinn K., 2017, SYDNEY MORNING HERAL
   ROSEN J, 2006, PEOPLE FORMERLY KNOW
   Rowson M, 2017, GUARDIAN OPINIO 0620
   Rutenberg J., 2017, NY TIMES
   Sass E, 2017, MEDIAPOST       0607
   Shirky C., 2008, HERE COMES EVERYBODY
   Smith A, 1977, SUBSIDIES PRESS EURO
   Taplin J, 2017, MOVE FAST BREAK THIN
   Turner, 2006, COUNTERCULTURE CYBER
   Turner, 2012, WHATS BECOME CULTURA
   Turner G., 2006, INT J CULTURAL STUD, V9, P153, DOI DOI 10.1177/1367877906064028
   Turner G., 2010, ORDINARY PEOPLE MEDI
   Turner G, 2016, RE-INVENTING THE MEDIA, P1
NR 37
TC 5
Z9 5
U1 1
U2 24
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 1329-878X
EI 2200-467X
J9 MEDIA INT AUST
JI Media Int. Aust.
PD AUG
PY 2018
VL 168
IS 1
BP 3
EP 14
DI 10.1177/1329878X18782987
PG 12
WC Communication
WE Social Science Citation Index (SSCI)
SC Communication
GA GQ1PJ
UT WOS:000441406800001
DA 2022-02-06
ER

PT J
AU Fahfouh, A
   Riffi, J
   Mahraz, MA
   Yahyaouy, A
   Tairi, H
AF Fahfouh, Anass
   Riffi, Jamal
   Adnane Mahraz, Mohamed
   Yahyaouy, Ali
   Tairi, Hamid
TI PV-DAE: A hybrid model for deceptive opinion spam based on neural
   network architectures
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Article
DE Deceptive opinion spam; Neural networks; Machine learning; Deep
   learning; Paragraph vector model; Denoising autoencoder model
AB Opinion review is of great importance for both customers and organizations. Indeed, it helps customers in buying decisions and represents a valuable feedback for the companies, allowing them to improve their productions. However, numerous greedy companies resort to fake reviews in order to influence the customer and brighten the brand image, or to defame the one of their competitors. Various models are proposed in order to detect deceptive opinion reviews. Most of these models adopt traditional methods focusing on feature extraction and traditional classifiers. Unfortunately, these models do not capture the semantic aspect while ignoring the opinion's context. In order to tackle this issue, we propose a new approach based on Paragraph Vector Distributed Bag of Words (PV-DBOW) and the Denoising Autoencoder (DAE). The proposed customized model provides a strong representation which is based on a global representation of the opinions while preserving their semantics. Indeed, the embedding vectors capture the semantic meaning of all words in the context of each opinion. The generated review representations are fed into a fully connected neural network in order to detect deceptive opinion spam. The obtained results concerning the deception dataset show that our model is effective and outperforms the existing state-of-the-art methodologies. (C) 2020 Elsevier Ltd. All rights reserved.
C1 [Fahfouh, Anass; Riffi, Jamal; Adnane Mahraz, Mohamed; Yahyaouy, Ali; Tairi, Hamid] Univ Sidi Mohamed Ben Abdelah, Fac Sci Dhar El Mahraz, LIIAN Lab, Fes, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez
RP Fahfouh, A (corresponding author), Univ Sidi Mohamed Ben Abdelah, Fac Sci Dhar El Mahraz, LIIAN Lab, Fes, Morocco.
EM anassfahfouh@gmail.com
OI Mahraz, Mohamed adnane/0000-0002-0966-9654
CR Bandhakavi A, 2017, IEEE INTELL SYST, V32, P102, DOI 10.1109/MIS.2017.22
   Banerjee S, 2015, 2015 6TH INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION AND NETWORKING TECHNOLOGIES (ICCCNT), P12
   Banerjee S, 2014, ONLINE INFORM REV, V38, P634, DOI 10.1108/OIR-02-2014-0047
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Cagnina L., 2015, P 6 WORKSH COMP APPR, P58
   Cambria E, 2018, THIRTY-SECOND AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTIETH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / EIGHTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P1795
   Cambria E, 2016, IEEE INTELL SYST, V31, P102, DOI 10.1109/MIS.2016.31
   Dong LY, 2018, EXPERT SYST APPL, V114, P210, DOI 10.1016/j.eswa.2018.07.005
   Du YP, 2019, IEEE ACCESS, V7, P39321, DOI 10.1109/ACCESS.2019.2906398
   Feng S., 2012, P 50 ANN M ASS COMP, V50, P171
   Feng VW., 2013, P 6 INT JOINT C NAT, P338
   Fusilier D. H., 2015, INFORM PROCESSING MA, P1
   Hancock, 2011, P 49 ANN M ASS COMP, P309, DOI DOI 10.1145/2567948.2577293
   Hernandez-Castaneda A, 2017, SOFT COMPUT, V21, P585, DOI 10.1007/s00500-016-2409-2
   Huang E., 2011, EMNLP 2011 C EMP MET, P151
   Jia SH, 2018, 2018 4TH INTERNATIONAL CONFERENCE ON INFORMATION MANAGEMENT (ICIM2018), P280, DOI 10.1109/INFOMAN.2018.8392850
   Lauren P, 2018, COGN COMPUT, V10, P625, DOI 10.1007/s12559-018-9548-y
   Le Q., 2014, P 31 INT C INT C MAC
   Li JW, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1566
   Li LY, 2017, NEUROCOMPUTING, V254, P33, DOI 10.1016/j.neucom.2016.10.080
   Liu B., 2012, SENTIMENT ANAL OPINI
   Mani S, 2018, MACHINE LEARNING DAT
   Mikolov T, 2013, P ICLR WORKSH, V1, P1
   Molla Alemu, 2018, Mobile and Wireless Technologies, ICMWT 2017. LNEE 425, P329, DOI 10.1007/978-981-10-5281-1_36
   Patel R, 2014, 2014 6TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMMUNICATION NETWORKS, P560, DOI 10.1109/CICN.2014.127
   Perez-Rosas Veronica, 2015, P C EMP METH NAT LAN, P2336
   Poria S, 2017, NEUROCOMPUTING, V261, P217, DOI 10.1016/j.neucom.2016.09.117
   Poria S, 2016, KNOWL-BASED SYST, V108, P42, DOI 10.1016/j.knosys.2016.06.009
   Prusa, 2016, P 29 INT FLOR ART IN, P304
   Ren Y., 2014, P C EMP METH NAT LAN, P488
   Ren YF, 2019, IEEE ACCESS, V7, P42934, DOI 10.1109/ACCESS.2019.2908495
   Ren YF, 2016, THIRTIETH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3038
   Ren YF, 2017, INFORM SCIENCES, V385, P213, DOI 10.1016/j.ins.2017.01.015
   Sabour S., 2017, P C NEUR INF PROC SY, P1
   Saini M., 2018, ADV COMPUTER COMMUNI, P3, DOI [10.1007/978-981-13-0341-8, DOI 10.1007/978-981-13-0341-8]
   Saumya Sunil, 2018, CSI Transactions on ICT, V6, P137, DOI 10.1007/s40012-018-0193-0
   Shojaee S, 2013, INT CONF INTELL SYST, P53, DOI 10.1109/ISDA.2013.6920707
   Siagian AAM, 2017, P INT COMP SOFTW APP, P828, DOI 10.1109/COMPSAC.2017.90
   Tang DY, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1555
   Vincent P., 2008, P 25 INT C ENC MACH, V1316, P1
   Wang BH, 2016, PROCEEDINGS OF 2016 12TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS), P116, DOI [10.1109/CIS.2016.0035, 10.1109/CIS.2016.34]
   Wang C., 2018, P 2 INT C E COMM BUS
   Wang X, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1343
   Wang XP, 2018, LECT NOTES ARTIF INT, V10619, P866, DOI 10.1007/978-3-319-73618-1_76
   Wang YQ, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P1165, DOI 10.1145/3178876.3186015
   Wu CH, 2018, KNOWL-BASED SYST, V148, P66, DOI 10.1016/j.knosys.2018.01.019
   Xiong SF, 2018, NEUROCOMPUTING, V275, P2459, DOI 10.1016/j.neucom.2017.11.023
   Yang C, 2019, INFORM PROCESS MANAG, V56, P463, DOI 10.1016/j.ipm.2018.12.004
   Young T, 2018, IEEE COMPUT INTELL M, V13, P55, DOI 10.1109/MCI.2018.2840738
   Zhang BW, 2018, IEEE ACCESS, V6, P58284, DOI 10.1109/ACCESS.2018.2874623
   Zhang L, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1253
   Zhang W, 2018, INFORM PROCESS MANAG, V54, P576, DOI 10.1016/j.ipm.2018.03.007
   Zhang Xuejie, 2017, 2017 C EMP METH NAT, P534, DOI DOI 10.18653/VL/D17-1056
   Zhao, 2012, P COLING 2012, P1341
   Zhao S., 2018, MATH PROBL ENG, P1
NR 55
TC 3
Z9 3
U1 3
U2 19
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD NOV 1
PY 2020
VL 157
AR 113517
DI 10.1016/j.eswa.2020.113517
PG 9
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic; Operations Research & Management Science
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Operations Research & Management Science
GA MK2AI
UT WOS:000548587800017
DA 2022-02-06
ER

PT J
AU Tyagi, S
   Yadav, D
AF Tyagi, Shobhit
   Yadav, Divakar
TI A detailed analysis of image and video forgery detection techniques
SO VISUAL COMPUTER
LA English
DT Article; Early Access
DE Visual imagery forgery detection; Image and video manipulation and
   forensics; Deep learning
ID COPY-MOVE FORGERY; LOCALIZATION
AB With the recent advancement in modern technology, one can easily manipulate a digital image or video using computer software or a mobile application. The purpose of editing visual media could be as simple as to look good before sharing to the social networking site's or can be as malicious as to defame or hurt one's reputation in the real world through such morphed visual imagery. Identity theft is one of the examples where one's identity get stolen by some impersonator who can access the personal and financial information of an innocent person. To avoid such drastic situations, law enforcement authorities must use some automatic tools and techniques to find out whether a person is innocent or the culprit. One major question that arises here is how and what parts of visual imagery can be manipulated or edited. The answer to this question is important to distinguish the authentic images/videos from the doctored multimedia. This survey provides a detailed analysis of image and video manipulation types, popular visual imagery manipulation methods, and state-of-the-art image and video forgery detection techniques. It also surveys different fake image and video datasets used in tampering. The goal is to develop a sense of privacy and security in the research community. Finally, it focuses to motivate researchers to develop generalized methods to capture artificial visual imagery which is capable of detecting any type of manipulation in given visual imagery.
C1 [Tyagi, Shobhit; Yadav, Divakar] Natl Inst Technol, Dept Comp Sci & Engn, Hamirpur, HP, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Hamirpur
RP Yadav, D (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Hamirpur, HP, India.
EM shobhit.tya@gmail.com; dsy99@rediffmail.com
RI Yadav, Divakar/AAF-1777-2020
OI Yadav, Divakar/0000-0001-6051-479X
CR Abd Warif NB, 2017, J VIS COMMUN IMAGE R, V46, P219, DOI 10.1016/j.jvcir.2017.04.004
   Amerini I., DEEPFAKE VIDEO DETEC
   Amerini I, 2017, IEEE COMPUT SOC CONF, P1865, DOI 10.1109/CVPRW.2017.233
   Amerini I, 2013, SIGNAL PROCESS-IMAGE, V28, P659, DOI 10.1016/j.image.2013.03.006
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   [Anonymous], 2018, CONVERSATION MEDIA G
   [Anonymous], IEEE IFS TC IMAGE FO
   [Anonymous], DEEPFAKES GITHUB
   Ardizzone E, 2015, IEEE T INF FOREN SEC, V10, P2084, DOI 10.1109/TIFS.2015.2445742
   Bahrami K, 2015, IEEE T INF FOREN SEC, V10, P999, DOI 10.1109/TIFS.2015.2394231
   Banerjee A, 2020, VISUAL COMPUT, DOI 10.1007/s00371-020-02017-x
   Bappy JH, 2019, IEEE T IMAGE PROCESS, V28, P3286, DOI 10.1109/TIP.2019.2895466
   Bas Patrick, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P59, DOI 10.1007/978-3-642-24178-9_5
   Bashar M, 2010, IEEE Trans Image Process, DOI 10.1109/TIP.2010.2046599
   Bay Herbert, 2006, EUR C COMP VIS, DOI DOI 10.1007/11744023_32
   Bayar B., 2016, P 4 ACM WORKSH INF H, P5, DOI DOI 10.1145/2909827.2930786
   Bi XL, 2019, IEEE COMPUT SOC CONF, P30, DOI 10.1109/CVPRW.2019.00010
   Bondi L, 2017, IEEE COMPUT SOC CONF, P1855, DOI 10.1109/CVPRW.2017.232
   Bowling M, 2002, ARTIF INTELL, V136, P215, DOI 10.1016/S0004-3702(02)00121-2
   Bunk J, 2017, IEEE COMPUT SOC CONF, P1881, DOI 10.1109/CVPRW.2017.235
   Carrington D ., 2020, MANY PHOTOS 2020 DET
   Chen JS, 2015, IEEE SIGNAL PROC LET, V22, P1849, DOI 10.1109/LSP.2015.2438008
   Chen W, 2007, PROC SPIE, V6505, DOI 10.1117/12.704321
   Chouhan SS, 2019, ARCH COMPUT METHOD E, V26, P533, DOI 10.1007/s11831-018-9257-4
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Cozzolino D., 2016, 2016 IEEE INT WORKSH, P1
   Cozzolino D, 2015, IEEE T INF FOREN SEC, V10, P2284, DOI 10.1109/TIFS.2015.2455334
   Dang H, 2020, PROC CVPR IEEE, P5780, DOI 10.1109/CVPR42600.2020.00582
   Dolhansky B., 2019, DEEPFAKE DETECTION C
   Eveleth Rose, 2012, BBC NEWS 1213
   Farid H, PHOTOTAMPERING HIST
   Farid H., 2005, P ACM MULT SEC WORKS, P1, DOI DOI 10.1145/1073170.1073171
   Farid H., 2004, TR2004518 DARTM COLL, P13
   Fridrich AJ., 2003, P DIG FOR RES WORKSH
   Gloe T., 2010, J DIGIT FORENSIC PRA, V3, P150, DOI [10.1080/15567281.2010.531500, DOI 10.1080/15567281.2010.531500]
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Google AI Blog, GOOGLE AI BLOG
   Hailing Huang, 2008, 2008 Pacific-Asia Workshop on Computational Intelligence and Industrial Application. PACIIA 2008, P272, DOI 10.1109/PACIIA.2008.240
   He JF, 2006, LECT NOTES COMPUT SC, V3953, P423
   Hossein-Nejad Z., VISUAL COMPUT, V1-17
   Hsu YF, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P549, DOI 10.1109/ICME.2006.262447
   Iizuka S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073659
   Jiang LM, 2020, PROC CVPR IEEE, P2886, DOI 10.1109/CVPR42600.2020.00296
   Jing Dong, 2013, 2013 IEEE China Summit and International Conference on Signal and Information Processing (ChinaSIP), P422, DOI 10.1109/ChinaSIP.2013.6625374
   Jung T, 2020, IEEE ACCESS, V8, P83144, DOI 10.1109/ACCESS.2020.2988660
   Karras T., 2019, ARXIV191204958
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Korshunov P., 2018, DEEPFAKES NEW THREAT
   Kuznetsov A., 2019, Journal of Physics: Conference Series, V1368, DOI 10.1088/1742-6596/1368/3/032028
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Lee JC, 2015, INFORM SCIENCES, V321, P250, DOI 10.1016/j.ins.2015.03.009
   Li B, 2015, IEEE T INF FOREN SEC, V10, P558, DOI 10.1109/TIFS.2015.2389148
   Li HD, 2017, IEEE T INF FOREN SEC, V12, P1240, DOI 10.1109/TIFS.2017.2656823
   Li Y., 2019, NEW DATASET DEEPFAKE
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   LTD RTP, 2017, FAC SWAP BOOTH PHOT
   Madsen R. E., 2004, PRACTICAL APPROACH M, V1, P1, DOI DOI 10.1007/0-306-47815-3_5
   Marra F, 2019, IEEE INT WORKS INFOR
   Marra F, 2020, IEEE ACCESS, V8, P133488, DOI 10.1109/ACCESS.2020.3009877
   Matern F, 2019, IEEE WINT CONF APPL, P83, DOI 10.1109/WACVW.2019.00020
   Muzaffer G, 2019, 2019 SCIENTIFIC MEETING ON ELECTRICAL-ELECTRONICS & BIOMEDICAL ENGINEERING AND COMPUTER SCIENCE (EBBT)
   Ng A, 2018, MACHINE LEARNING YEA
   Ng T., 2004, DATA SET AUTHENTIC S
   Ng TT, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 5, PROCEEDINGS, P688
   Nguyen HV, 2019, 2019 2ND INTERNATIONAL CONFERENCE ON APPLIED INFORMATION TECHNOLOGY AND INNOVATION (ICAITI2019), P1, DOI 10.1109/ICAITI48442.2019.8982119
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Popescu AC, 2004, LECT NOTES COMPUT SC, V3200, P128
   Rao Y, 2016, IEEE INT WORKS INFOR
   Rathgeb C, 2020, IET BIOMETRICS, V9, P154, DOI 10.1049/iet-bmt.2019.0196
   Rossler A., 2018, FACEFORENSICS LARGE
   Sabir Ekraam, 2019, INTERFACES GUI, P80
   Salloum R, 2018, J VIS COMMUN IMAGE R, V51, P201, DOI 10.1016/j.jvcir.2018.01.010
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Schetinger V, 2017, COMPUT GRAPH-UK, V68, P142, DOI 10.1016/j.cag.2017.08.010
   Schonfeld E, 2020, 2020 IEEE CVF C COMP, P8204
   Shi YQ, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P51
   Shlens, 2014, ARXIV PREPRINT ARXIV
   Singh KK, 2019, PROC CVPR IEEE, P6483, DOI 10.1109/CVPR.2019.00665
   Sneumueller, 2016, AUT FAC SWAP
   Sun DQ, 2018, PROC CVPR IEEE, P8934, DOI 10.1109/CVPR.2018.00931
   Tang SC, 2020, IEEE ACCESS, V8, P165044, DOI 10.1109/ACCESS.2020.3022820
   Team B ., 2013, ADOBE PHOTOSHOP 200
   The GIMP Development Team, 2019, GIMP
   Thies J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323035
   Thies J, 2016, PROC CVPR IEEE, P2387, DOI 10.1109/CVPR.2016.262
   Thyagharajan KK, 2021, ARCH COMPUT METHOD E, V28, P897, DOI 10.1007/s11831-020-09400-w
   Toews Rob, 2020, FORBES 0525
   Tolosana R., 2020, ARXIV PREPRINT ARXIV
   Tralic Dijana, 2013, Proceedings of the 2013 55th International Symposium. ELMAR-2013, P49
   Tuba V, 2017, 2017 5TH INTERNATIONAL SYMPOSIUM ON DIGITAL FORENSIC AND SECURITY (ISDFS)
   Vinolin V, 2021, VISUAL COMPUT, V37, P2369, DOI 10.1007/s00371-020-01992-5
   Wang R, 2019, ARXIV PREPRINT ARXIV
   Wang SY, 2019, IEEE I CONF COMP VIS, P10071, DOI 10.1109/ICCV.2019.01017
   Wang W, 2009, LECT NOTES COMPUT SC, V5703, P308, DOI 10.1007/978-3-642-03688-0_27
   Wang XY, 2019, MATH BIOSCI ENG, V16, P4581, DOI 10.3934/mbe.2019229
   Wen BH, 2016, IEEE IMAGE PROC, P161, DOI 10.1109/ICIP.2016.7532339
   Wu Y, 2018, IEEE WINT CONF APPL, P1907, DOI 10.1109/WACV.2018.00211
   Xie DR, 2015, IEEE SYS MAN CYBERN, P1821, DOI 10.1109/SMC.2015.319
   Yang C., 2017, P IEEE C COMP VIS PA, P6721
   Yang X, 2019, INT CONF ACOUST SPEE, P8261, DOI 10.1109/ICASSP.2019.8683164
   Yin T, 2015, COMPUT SECUR, V55, P130, DOI 10.1016/j.cose.2015.09.003
   Yu F, 2017, PROC CVPR IEEE, P636, DOI 10.1109/CVPR.2017.75
   Yu JJ, 2017, LECT NOTES COMPUT SC, V10082, P3, DOI 10.1007/978-3-319-53465-7_1
   Zampoglou M., 2015, 2015 IEEE INT C MULT, P1, DOI [10.1109/ICMEW.2015.7169839., DOI 10.1109/ICMEW.2015.7169839]
   Zhang W., 2017, WORLD ACAD SCI ENG T, V11, P231
   Zhang X, 2019, IEEE INT WORKS INFOR
   Zhang Y, 2016, CRYPTOL INF SEC SER, V14, P1, DOI 10.3233/978-1-61499-617-0-1
   Zhao XD, 2015, IEEE T CIRC SYST VID, V25, P185, DOI 10.1109/TCSVT.2014.2347513
   Zhen Y, 2020, IEEE T INF FOREN SEC, V15, P620, DOI 10.1109/TIFS.2019.2926777
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu Y, 2016, MULTIMED TOOLS APPL, V75, P3221, DOI 10.1007/s11042-014-2431-2
NR 113
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
DI 10.1007/s00371-021-02347-4
EA JAN 2022
PG 21
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA YF7IT
UT WOS:000741976400001
DA 2022-02-06
ER

PT J
AU Gosse, C
   Burkell, J
AF Gosse, Chandell
   Burkell, Jacquelyn
TI Politics and porn: how news media characterizes problems presented by
   deepfakes
SO CRITICAL STUDIES IN MEDIA COMMUNICATION
LA English
DT Article
DE Deepfakes; image abuse; artificial intelligence; cybermisogyny;
   disinformation
ID REVENGE PORN
AB "Deepfake" is a form of machine learning that creates fake videos by superimposing the face of one person on to the body of another in a new video. The technology has been used to create non-consensual fake pornography and sexual imagery, but there is concern that it will soon be used for politically nefarious ends. This study seeks to understand how the news media has characterized the problem(s) presented by deepfakes. We used discourse analysis to examine news articles about deepfakes, finding that news media discuss the problems of deepfakes in four ways: as (too) easily produced and distributed; as creating false beliefs; as undermining the political process; and as non-consensual sexual content. We provide an overview of how news media position each problem followed by a discussion about the varying degrees of emphasis given to each problem and the implications this has for the public's perception and construction of deepfakes.
C1 [Gosse, Chandell; Burkell, Jacquelyn] Western Univ, Fac Informat & Media Studies, London, ON, Canada.
C3 Western University (University of Western Ontario)
RP Gosse, C (corresponding author), FIMS & Nursing Bldg,Room 4056, London, ON N6A 5B9, Canada.
EM cgosse@uwo.ca
OI Gosse, Chandell/0000-0002-9868-2796; Burkell,
   Jacquelyn/0000-0003-2645-8127
FU Social Sciences and Humanities Research Council of Canada (SSHRC)Social
   Sciences and Humanities Research Council of Canada (SSHRC)CGIAR
   [895-2015-1002]
FX This work was supported by the Social Sciences and Humanities Research
   Council of Canada (SSHRC) under [grant number 895-2015-1002].
CR Ajder H, 2019, STATE DEEPFAKES LAND
   Bates S, 2017, FEM CRIMINOL, V12, P22, DOI 10.1177/1557085116654565
   BLEWER A., 2019, OPEN INFORM SCI, V3, P32, DOI DOI 10.1515/OPIS-2019-0003
   BuzzFeedVideo, 2018, YOU WONT BEL WHAT OB
   Chesney B, 2019, CALIF LAW REV, V107, P1753, DOI 10.15779/Z38RV0D15J
   Citron Danielle Keats, 2014, WAKE FOREST LAW REV, V49, P345
   Cole M, 2017, MARX EDUC, P11, DOI 10.1057/978-1-137-53540-5_2
   Cole S, 2018, MOTHERBOARD
   Cole S., 2018, VICE
   Cox J., 2018, SUN
   Day C, 2019, COMPUT SCI ENG, V21, P108, DOI 10.1109/MCSE.2018.2874117
   Durant J., 1999, SCI PUBL POLICY, V26, P313, DOI DOI 10.3152/147154399781782329
   Fairclough Norman, 1989, LANGUAGE POWER
   Fletcher J, 2018, THEATRE J, V70, P455, DOI 10.1353/tj.2018.0097
   Galante L., 2018, DEFINING RUSSIAN INT
   Gosse, 2019, 1 MONDAY, V24, DOI [10.5210/fm.v24i12.10287, DOI 10.5210/FM.V24I12.10287]
   Johannesson IA, 2010, DISCOURSE-ABINGDON, V31, P251, DOI 10.1080/01596301003679768
   Kilbourne J., 1979, KILLING US SOFTLY AD
   LATHER P, 1986, HARVARD EDUC REV, V56, P257, DOI 10.17763/haer.56.3.bj2h231877069482
   Lazar Michelle, 2007, CRITICAL DISCOURSE S, V4, P141, DOI DOI 10.1080/17405900701464816
   Li YZ, 2018, IEEE INT WORKS INFOR
   Maddocks Sophie, 2020, PORN STUDIES, V0, P1, DOI DOI 10.1080/23268743.2020.1757499
   McGlynn C, 2017, FEM LEGAL STUD, V25, P25, DOI 10.1007/s10691-017-9343-2
   Mulvey Laura, 1975, SEXUAL SUBJECT SCREE, V16, P6, DOI DOI 10.1093/SCREEN/16.3.6
   Murphy M, 2018, TELEGRAPH
   O'Reilly S., 2018, IRISH TIMES
   Olson P, 2018, FORBES
   Powell A, 2018, ROUT INT HANDB, P305
   TONKISS F, 1998, RES SOC CULTURE, P245
   van der Nagel E., 2020, PORN STUDIES, P1, DOI [10.1080/23268743.2020.1741434, DOI 10.1080/23268743.2020.1741434]
   Vickery J, 2018, MEDIATING MISOGYNY G
NR 31
TC 1
Z9 1
U1 9
U2 48
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 1529-5036
EI 1479-5809
J9 CRIT STUD MEDIA COMM
JI Crit. Stud. Media Comm.
PD OCT 19
PY 2020
VL 37
IS 5
BP 497
EP 511
DI 10.1080/15295036.2020.1832697
EA OCT 2020
PG 15
WC Communication
WE Social Science Citation Index (SSCI)
SC Communication
GA OQ4NK
UT WOS:000582138600001
DA 2022-02-06
ER

PT J
AU Yang, GC
   Niu, DM
   Zhang, CM
   Zhao, XY
AF Yang, Guangchao
   Niu, Dongmei
   Zhang, Caiming
   Zhao, Xiuyang
TI Recognizing novel patterns via adversarial learning for one-shot
   semantic segmentation
SO INFORMATION SCIENCES
LA English
DT Article
DE Semantic segmentation; One-shot learning; Adversarial learning;
   Generative adversarial networks
ID IMAGE; MODEL
AB One-shot semantic segmentation aims to recognize unseen object regions by using the reference of only one annotated example. Many deep convolutional neural networks have achieved enormous success on this task. However, most of the existing methods only use a fixed annotated dataset to train the network. The remaining unannotated examples remain difficult to be leveraged and recognized. In this study, we propose a procedure based on the generative adversarial network to enable the one-shot semantic segmentation model for learning information from previously unknown categories. Our method contains a segmentation network that generates segmentation predictions. We then use a discriminator to differentiate the probability maps of segmentation prediction from the ground truth distribution. Consequently, we can ignore the pixels classified as fake and only use trustworthy regions as the label to train the segmentation network, thus achieving semi-supervised learning. Experimental results demonstrate the effectiveness of the proposed adversarial learning method with an average gain of 49.7% accuracy score on the PASCAL VOC 2012 dataset. (C) 2020 Elsevier Inc. All rights reserved.
C1 [Yang, Guangchao; Niu, Dongmei; Zhao, Xiuyang] Univ Jinan, Shandong Prov Key Lab Network Based Intelligent C, Jinan 250022, Peoples R China.
   [Zhang, Caiming] Shandong Univ, Sch Software, 1500 Shunhua Rd, Jinan 250101, Peoples R China.
C3 University of Jinan; Shandong University
RP Zhao, XY (corresponding author), Univ Jinan, Shandong Prov Key Lab Network Based Intelligent C, Jinan 250022, Peoples R China.
EM xiuyangzhao@hotmail.com
FU Natural Science Foundation of Shandong ProvinceNatural Science
   Foundation of Shandong Province [ZR2019MF013, ZR201913F026]; Project of
   Jinan Scientific Research Leaders Laboratory [2018GXRCO23]; Doctoral
   Program of University of Jinan [160100313]
FX This work was supported by the Natural Science Foundation of Shandong
   Province [grant numbers ZR2019MF013, ZR201913F026]; the Project of Jinan
   Scientific Research Leaders Laboratory [grant number 2018GXRCO23]; and
   the Doctoral Program of University of Jinan [grant number 160100313].
CR Banerjee S, 2018, INFORM SCIENCES, V424, P337, DOI 10.1016/j.ins.2017.10.011
   Boots B., 2017, ARXIV170903410
   Caelles S, 2017, PROC CVPR IEEE, P5320, DOI 10.1109/CVPR.2017.565
   Cai Q, 2018, PROC CVPR IEEE, P4080, DOI 10.1109/CVPR.2018.00429
   Chen H, 2018, THIRTY-SECOND AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTIETH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / EIGHTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P2836
   Chen XY, 2019, IEEE T IMAGE PROCESS, V28, P546, DOI 10.1109/TIP.2018.2869695
   Chintala S, 2015, ARXIV151106434
   Cui W, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11091044
   Delic M, 2019, INFORM SCIENCES, V494, P155, DOI 10.1016/j.ins.2019.04.053
   Dong Nanqing, 2018, BMVC
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Faktor A, 2013, IEEE I CONF COMP VIS, P1297, DOI 10.1109/ICCV.2013.164
   Fiore U, 2019, INFORM SCIENCES, V479, P448, DOI 10.1016/j.ins.2017.12.030
   Gan C, 2017, IEEE I CONF COMP VIS, P1829, DOI 10.1109/ICCV.2017.201
   Gidaris S, 2018, PROC CVPR IEEE, P4367, DOI 10.1109/CVPR.2018.00459
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI 10.1109/ICCV.2017.322
   Hong CQ, 2019, IEEE T IND INFORM, V15, P3952, DOI 10.1109/TII.2018.2884211
   Hung KM, 2018, PROCEEDINGS OF 2018 INTERNATIONAL CONFERENCE ON DIGITAL MEDICINE AND IMAGE PROCESSING (DMIP 2018), P65, DOI 10.1145/3299852.3299858
   Karlinsky L, 2019, PROC CVPR IEEE, P5192, DOI 10.1109/CVPR.2019.00534
   Khoreva A, 2017, PROC CVPR IEEE, P1665, DOI 10.1109/CVPR.2017.181
   Kozerawski J, 2018, PROC CVPR IEEE, P3446, DOI 10.1109/CVPR.2018.00363
   Liu ST, 2019, INT CONF ACOUST SPEE, P1902, DOI 10.1109/ICASSP.2019.8683590
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Miao JQ, 2018, INFORM SCIENCES, V447, P52, DOI 10.1016/j.ins.2018.02.007
   Michaelis C., 2018, P MACHINE LEARNING R, V80, P3549
   Michaelis Claudio, 2018, CORR
   Park T, 2019, PROC CVPR IEEE, P2332, DOI 10.1109/CVPR.2019.00244
   Qin Y., 2018, CORR
   Rakelly Kate, 2018, P ICLR
   Redmon J, 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.91
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sharma S, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19112577
   Siam M., 2019, ARXIV190211123
   Souly N, 2017, IEEE I CONF COMP VIS, P5689, DOI 10.1109/ICCV.2017.606
   Soviany Petru, 2018, 2018 20th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing (SYNASC). Proceedings, P209, DOI 10.1109/SYNASC.2018.00041
   Tang M, 2018, LECT NOTES COMPUT SC, V11220, P524, DOI 10.1007/978-3-030-01270-0_31
   Tang M, 2018, PROC CVPR IEEE, P1818, DOI 10.1109/CVPR.2018.00195
   Vinyals O., 2016, NIPS, P3637
   Xian YQ, 2018, PROC CVPR IEEE, P5542, DOI 10.1109/CVPR.2018.00581
   Yan SP, 2019, THIRTY-THIRD AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTY-FIRST INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / NINTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P9079
   Yu J, 2022, IEEE T PATTERN ANAL, V44, P563, DOI 10.1109/TPAMI.2019.2932058
   Yu J, 2020, IEEE T NEUR NET LEAR, V31, P661, DOI 10.1109/TNNLS.2019.2908982
   Yu J, 2017, IEEE T CYBERNETICS, V47, P4014, DOI 10.1109/TCYB.2016.2591583
   Zhang HL, 2019, INFORM SCIENCES, V493, P152, DOI 10.1016/j.ins.2019.04.048
   Zhang J, 2018, IEEE T IMAGE PROCESS, V27, P2420, DOI 10.1109/TIP.2018.2804218
   Zhang XL, 2018, LECT NOTES COMPUT SC, V11216, P610, DOI 10.1007/978-3-030-01258-8_37
   Zhang Xiaolin, 2018, ARXIV181009091
   ZHOU B, 2016, PROC CVPR IEEE, P2921, DOI DOI 10.1109/CVPR.2016.319
NR 49
TC 1
Z9 1
U1 0
U2 0
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 0020-0255
EI 1872-6291
J9 INFORM SCIENCES
JI Inf. Sci.
PD MAY
PY 2020
VL 518
BP 225
EP 237
DI 10.1016/j.ins.2020.01.016
PG 13
WC Computer Science, Information Systems
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KR5KZ
UT WOS:000517658600015
DA 2022-02-06
ER

PT J
AU Yu, C
   Wang, WM
AF Yu, Cheng
   Wang, Wenmin
TI Fast transformation of discriminators into encoders using pre-trained
   GANs
SO PATTERN RECOGNITION LETTERS
LA English
DT Article
DE Generative adversarial net (GAN); Auto-encoder; Image synthesis; Image
   reconstruction
AB A typical generative adversarial network (GAN) consists of a generator and a discriminator. Currently, finely tuned deep GANs can synthesize high-quality (HQ) images via their generators. However, the discriminator in typical GANs is only able to distinguish true or fake images in the training process. Moreover, some synthesized images from GANs are imperfect, and we can not reconstruct images via GANs. In this paper, we revisit pre-trained GANs and offer a self-supervised method to quickly transform GAN's discriminators into encoders. We reuse parameters of the GAN's discriminator and replace its output layer, so it can be transformed into an encoder and output reformed latent vectors. The transformation makes GAN architecture more symmetrical and allows for better performance. Based on the method, GANs can be made to reconstruct synthesized images via GAN encoders. Compared to synthesized images, these reconstructions can maintain or even attain higher quality. The code and pre-trained models are available at https://github.com/disanda/GAN-Encoder- Sym . (c) 2021 Elsevier B.V. All rights reserved.
C1 [Yu, Cheng] Macau Univ Sci & Technol, Fac Informat Technol, Macau 999078, Peoples R China.
   [Wang, Wenmin] Macau Univ Sci & Technol, Int Inst Next Generat Internet, Macau 999078, Peoples R China.
   [Wang, Wenmin] Macau Univ Sci & Technol, State Key Lab Lunar & Planetary Sci, Macau 999078, Peoples R China.
   [Yu, Cheng] Chongqing Coll Elect Engn, Chongqing 401331, Peoples R China.
C3 Macau University of Science & Technology; Macau University of Science &
   Technology; Macau University of Science & Technology; Chongqing College
   of Electronic Engineering
RP Wang, WM (corresponding author), Macau Univ Sci & Technol, Int Inst Next Generat Internet, Macau 999078, Peoples R China.; Wang, WM (corresponding author), Macau Univ Sci & Technol, State Key Lab Lunar & Planetary Sci, Macau 999078, Peoples R China.
EM wmwang@must.edu.mo
FU Science and Technology Development Fund (FDCT) of Macau [0016/2019/A1]
FX This work was supported by the Science and Technology Development Fund
   (FDCT) of Macau (0016/2019/A1) .
CR Abdal R, 2019, IEEE I CONF COMP VIS, P4431, DOI 10.1109/ICCV.2019.00453
   Brock A., 2018, INT C LEARN REPR
   Chen R., 2020, 2020 IEEE CVF C COMP, P8165, DOI 10.1109/CVPR42600.2020.00819
   Creswell A, 2019, IEEE T NEUR NET LEAR, V30, P1967, DOI 10.1109/TNNLS.2018.2875194
   Goceri E, IZMIR KATIP CELEBI U, V6, P91
   Goceri E, 2021, COMPUT BIOL MED, V134, DOI 10.1016/j.compbiomed.2021.104458
   Goceri E, 2021, COMPUT BIOL MED, V128, DOI 10.1016/j.compbiomed.2020.104118
   Goceri E, 2020, IET IMAGE PROCESS, V14, P882, DOI 10.1049/iet-ipr.2019.0312
   Goceri E, 2019, INT J NUMER METH BIO, V35, DOI 10.1002/cnm.3225
   Hensel M, 2017, ADV NEUR IN, V30
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Ji Z, 2020, PATTERN RECOGN LETT, V135, P131, DOI 10.1016/j.patrec.2020.04.011
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Karras Tero, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8107, DOI 10.1109/CVPR42600.2020.00813
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Kervadec H, 2020, ARXIV190404205
   Kingma DP, 2014, 2 INT C LEARN REPR I, P1
   Laine, 2018, INT C LEARN REPR
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Metz L., 2016, P 4 INT C LEARNING R
   Miyato T., 2018, ICLR
   Patacchiola M, 2020, PATTERN RECOGN LETT, V140, P59, DOI 10.1016/j.patrec.2020.09.025
   Ribeiro M, 2018, PATTERN RECOGN LETT, V105, P13, DOI 10.1016/j.patrec.2017.07.016
   Valle R, 2020, PATTERN RECOGN LETT, V136, P326, DOI 10.1016/j.patrec.2019.10.012
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yu C., ARXIV210810201, V2021
   Yu C, 2020, IEEE ACCESS, V8, P128140, DOI 10.1109/ACCESS.2020.3008523
   Yu F., 2015, ARXIV150603365
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu JY, 2016, LECT NOTES COMPUT SC, V9909, P597, DOI 10.1007/978-3-319-46454-1_36
NR 31
TC 0
Z9 0
U1 0
U2 0
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0167-8655
EI 1872-7344
J9 PATTERN RECOGN LETT
JI Pattern Recognit. Lett.
PD JAN
PY 2022
VL 153
BP 92
EP 99
DI 10.1016/j.patrec.2021.11.026
PG 8
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XU6HM
UT WOS:000734363300013
DA 2022-02-06
ER

PT J
AU Kartal, YS
   Kutlu, M
AF Kartal, Yavuz Selim
   Kutlu, Mucahid
TI Re-Think Before You Share: A Comprehensive Study on Prioritizing
   Check-Worthy Claims
SO IEEE TRANSACTIONS ON COMPUTATIONAL SOCIAL SYSTEMS
LA English
DT Article; Early Access
DE Task analysis; Fake news; Data models; Training; Bit error rate;
   Training data; Predictive models; Check-worthy claims; fact-checking;
   misinformation
AB The massive amount of misinformation spreading on the internet on a daily basis has enormous negative impacts on societies. Therefore, we need systems to help fact-checkers to combat misinformation and to raise public awareness of this important problem. In this article, we propose a hybrid model which combines bidirectional encoder representations from transformer (BERT) model with various features to prioritize claims based on their check-worthiness. Features we use include domain-specific controversial topics (CT), word embeddings (WE), part-of-speech (POS) tags, and others. In addition, we explore various ways of increasing labeled data size to effectively train the models, such as increasing positive (IncPos) samples, active learning (AL), and utilizing labeled data in other languages. In our extensive experiments, we show that our model outperforms all state-of-the-art models in test collections of Conference and Labs of Evaluation Forum (CLEF) CheckThat! Lab (CTL) 2018 and 2019. In addition, when positive samples are increased in the training set, our model achieves the best mean average precision (MAP) score reported so far for the test collection of CTL 2020. Furthermore, we show that cross-lingual training is effective for prioritizing Arabic and Turkish claims, but not for English.
C1 [Kartal, Yavuz Selim] GESIS Leibniz Inst Social Sci, D-50667 Cologne, Germany.
   [Kutlu, Mucahid] TOBB Univ Econ & Technol, Dept Comp Engn, TR-06510 Ankara, Turkey.
C3 Leibniz Institut fur Sozialwissenschaften (GESIS); TOBB Ekonomi ve
   Teknoloji University
RP Kartal, YS (corresponding author), GESIS Leibniz Inst Social Sci, D-50667 Cologne, Germany.
EM yavuzselim.kartal@gesis.org; m.kutlu@etu.edu.tr
CR Agez R., 2018, P 9 C LABS EV FOR LI, V2125, P1
   Altun B., 2019, P WORK NOT CLEF C LA, P1
   Atanasova P., 2019, P CEUR WORKSH, P1
   Barron-Cedeno Alberto, 2020, Experimental IR Meets Multilinguality, Multimodality, and Interaction. 11th International Conference of the CLEF Association, CLEF 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12260), P215, DOI 10.1007/978-3-030-58219-7_17
   Barron-Cedeno Alberto, 2020, Advances in Information Retrieval. 42nd European Conference on IR Research, ECIR 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12036), P499, DOI 10.1007/978-3-030-45442-5_65
   Bird S, 2006, P ACL 2004 INTERACTI, P69, DOI DOI 10.3115/1225403.1225421
   Cherubini Federica, 2016, RISE FACT CHECKING S
   Coca L. G., 2019, P WORK NOT CLEF C LA, P1
   Cornia L. Graves, 2018, MEASURING REACH FAKE
   Devlin J, 2019, PROC C N AM CHAPTER, P4171, DOI DOI 10.18653/V1/N19-1423
   Dharmasena RDIG, 2019, P IEEE, V107, P2118, DOI 10.1109/JPROC.2019.2929286
   Favano L., 2019, P WORK NOT CLEF C LA, V2380, P1
   Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
   Gasior J., 2019, P CLEF WORK NOT, P1
   Gencheva P., 2017, P REC ADV NAT LANG P, P267
   Ghanem B., 2018, P WORK NOT CLEF C LA, P1
   Hansen C., 2019, P WORK NOT CLEF C LA, P1
   Hansen C., 2018, P CLEF WORK NOT, P1
   Hassan N, 2017, PROC VLDB ENDOW, V10, P1945
   Jaradat I., 2018, P C N AM CHAPT ASS C, P26
   Kartal Y. S., 2020, P CLEF WORK NOT, P1
   Kartal Y. S., 2020, P 24 C COMP NAT LANG, P386
   Kutlu M, 2018, ACM/SIGIR PROCEEDINGS 2018, P805, DOI 10.1145/3209978.3210033
   Lespagnol C, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P941, DOI 10.1145/3331184.3331298
   Marty-Dugas J, 2021, PSYCHOL RES-PSYCH FO, V85, P2682, DOI 10.1007/s00426-020-01433-x
   McDonald T, 2020, P CLEF WORK NOT, P1
   Mikolov T., 2013, ARXIV13013781
   Morstatter F, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), P621, DOI 10.1145/3184558.3188733
   Nakov P, 2018, LECT NOTES COMPUT SC, V11018, P372, DOI 10.1007/978-3-319-98932-7_32
   Patwari A, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P2259, DOI 10.1145/3132847.3133150
   Ren PZ., 2020, ARXIV200602903
   Smith L.N, 2018, ARXIV PREPRINT ARXIV
   Su T., 2019, P WORK NOT CLEF C LA, P1
   Vasileva S., 2019, P INT C REC ADV NAT, P1229
   Vosoughi S, 2018, SCIENCE, V359, P1146, DOI 10.1126/science.aap9559
   Williams E., 2020, ARXIV200902431
   Wu QA, 2010, INFORM RETRIEVAL, V13, P254, DOI 10.1007/s10791-009-9112-1
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Yasser K., 2018, P CLEF WORK NOT, P1
   Zuo C., 2018, P CEUR WORKSH, V2125, P1
NR 40
TC 0
Z9 0
U1 0
U2 0
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2329-924X
J9 IEEE T COMPUT SOC SY
JI IEEE Trans. Comput. Soc. Syst.
DI 10.1109/TCSS.2021.3138642
EA JAN 2022
PG 14
WC Computer Science, Cybernetics; Computer Science, Information Systems
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA YK9MA
UT WOS:000745526600001
DA 2022-02-06
ER

PT J
AU Tao, HF
   Wang, P
   Chen, YY
   Stojanovic, V
   Yang, HZ
AF Tao, Hongfeng
   Wang, Peng
   Chen, Yiyang
   Stojanovic, Vladimir
   Yang, Huizhong
TI An unsupervised fault diagnosis method for rolling bearing using STFT
   and generative neural networks
SO JOURNAL OF THE FRANKLIN INSTITUTE-ENGINEERING AND APPLIED MATHEMATICS
LA English
DT Article
ID STACKED DENOISING AUTOENCODER; PRINCIPAL COMPONENT ANALYSIS;
   TIME-FREQUENCY ANALYSIS; INTELLIGENT DIAGNOSIS; ALGORITHM
AB In recent years, the technique of machine learning or deep learning has been employed in intelligent fault diagnosis methods to achieve much success using massive labeled data. However, it is generally difficult or expensive to label the monitoring data in practical engineering due to its complex working conditions. Therefore, an unsupervised fault diagnosis method is proposed in this paper for rolling bearings, which incorporates short-time Fourier transform (STFT) as well as categorical generative adversarial networks (CatGAN). The proposed method first adopts STFT to transform raw 1-D vibration signals into 2-D time-frequency maps to serve as the input of CatGAN. Then, it obtains a CatGAN model via an adversarial training process to generate fake samples with a similar distribution to the maps extracted by STFT and cluster the input samples into certain categories. Furthermore, the performance of the proposed ST-CatGAN method is verified using a classic rotating machinery dataset, and the experimental results demonstrate its high diagnosis accuracy and strong robustness against the motor load changes. (C) 2020 The Franklin Institute. Published by Elsevier Ltd. All rights reserved.
C1 [Tao, Hongfeng; Wang, Peng; Yang, Huizhong] Jiangnan Univ, Key Lab Adv Proc Control Light Ind, Minist Educ, Wuxi 214122, Jiangsu, Peoples R China.
   [Chen, Yiyang] Univ Southampton, Dept Civil Maritime & Environm Engn, Southampton SO16 7QF, Hants, England.
   [Stojanovic, Vladimir] Univ Kragujevac, Dept Automat Control Robot & Fluid Tech, Fac Mech & Civil Engn, Kraljevo 36000, Serbia.
C3 Jiangnan University; University of Southampton; University of Kragujevac
RP Stojanovic, V (corresponding author), Univ Kragujevac, Dept Automat Control Robot & Fluid Tech, Fac Mech & Civil Engn, Kraljevo 36000, Serbia.
EM taohongfeng@jiangnan.edu.cn; 1173602600@qq.com; Yiyang.Chen@soton.ac.uk;
   vladostojanovic@mts.rs; yhz@jiangnan.edu.cn
RI Chen, Yiyang/T-3492-2019
OI Chen, Yiyang/0000-0001-9960-9040; Stojanovic,
   Vladimir/0000-0002-6005-2086
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61773181, 61203092]; Funda-mental Research
   Funds for the Central UniversitiesFundamental Research Funds for the
   Central Universities [JUSRP51733B]; National Science Centre in
   PolandNational Science Centre, Poland [2014/15/B/ST7/03208]; Serbian
   Ministry of Education, Science and Technological Development
   [451-03-68/202014/200108]
FX This work is supported by National Natural Science Foundation of China
   (61773181, 61203092), the Funda-mental Research Funds for the Central
   Universities (JUSRP51733B), National Science Centre in Poland, grant No.
   2014/15/B/ST7/03208, and Serbian Ministry of Education, Science and
   Technological Development (451-03-68/202014/200108)
CR Abid Anam, 2018, IEEE T SYST MAN CYB, P1
   [Anonymous], 2016, CASE W RESERVE U BEA
   Chintala S., 2017, ARXIV170107875
   Delechelle E, 2005, IEEE SIGNAL PROC LET, V12, P764, DOI 10.1109/LSP.2005.856878
   Feng ZP, 2013, MECH SYST SIGNAL PR, V38, P165, DOI 10.1016/j.ymssp.2013.01.017
   Frey, 2016, ADVERSARIAL AUTOENCO
   Gomes R., 2010, ADV NEURAL INFORM PR, V23
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Gu YK, 2018, J MECH SCI TECHNOL, V32, P5079, DOI 10.1007/s12206-018-1004-0
   Han T, 2019, KNOWL-BASED SYST, V165, P474, DOI 10.1016/j.knosys.2018.12.019
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   [胡晓依 Hu Xiaoyi], 2019, [振动与冲击, Journal of Vibration and Shock], V38, P173
   Ioffe S., 2015, ICML, P448
   Lei YG, 2016, IEEE T IND ELECTRON, V63, P3137, DOI 10.1109/TIE.2016.2519325
   [雷亚国 Lei Yaguo], 2015, [机械工程学报, Journal of Mechanical Engineering], V51, P49
   [李恒 Li Heng], 2018, [振动与冲击, Journal of Vibration and Shock], V37, P124
   Liang P.F., 2019, COMPUT IND, V113, P103
   Liu H, 2018, NEUROCOMPUTING, V315, P412, DOI 10.1016/j.neucom.2018.07.034
   Liu YK, 2010, MECH SYST SIGNAL PR, V24, P2961, DOI 10.1016/j.ymssp.2010.03.008
   Lu C, 2017, ADV ENG INFORM, V32, P139, DOI 10.1016/j.aei.2017.02.005
   Pezzotti N, 2017, IEEE T VIS COMPUT GR, V23, P1739, DOI 10.1109/TVCG.2016.2570755
   Radford A., 2015, ARXIV
   Ren ZH, 2015, COMPUT ELECTR ENG, V45, P33, DOI 10.1016/j.compeleceng.2015.04.010
   Salakhutdinov R.R., 2012, ARXIV PREPRINT ARXIV
   Springenberg J.T., 2016, UNSUPERVISED SEMISUP
   Sun C. F., 2017, ACTA AERONAUTICA AST, V38, P1
   Sun MD, 2019, MEASUREMENT, V146, P305, DOI 10.1016/j.measurement.2019.06.029
   Sun WJ, 2016, MEASUREMENT, V89, P171, DOI 10.1016/j.measurement.2016.04.007
   Thomazella R, 2019, MEASUREMENT, V145, P71, DOI 10.1016/j.measurement.2019.05.079
   Wang YL, 2020, ISA T, V96, P457, DOI 10.1016/j.isatra.2019.07.001
   Wang ZR, 2018, NEUROCOMPUTING, V310, P213, DOI 10.1016/j.neucom.2018.05.024
   Wei ZX, 2017, KNOWL-BASED SYST, V116, P1, DOI 10.1016/j.knosys.2016.10.022
   Xu F, 2018, APPL SOFT COMPUT, V73, P898, DOI 10.1016/j.asoc.2018.09.037
   Yu JB, 2012, IEEE T IND ELECTRON, V59, P2363, DOI 10.1109/TIE.2011.2167893
   Yuan XF, 2020, IEEE T IND INFORM, V16, P3168, DOI [10.1002/er.4607, 10.1109/TII.2019.2902129]
   Yuan XF, 2018, IEEE T IND INFORM, V14, P3235, DOI 10.1109/TII.2018.2809730
   Zhang K, 2019, MECH SYST SIGNAL PR, V131, P243, DOI 10.1016/j.ymssp.2019.05.049
   Zhang W, 2019, ISA T, V95, P295, DOI 10.1016/j.isatra.2018.12.025
   Zhang W, 2018, MECH SYST SIGNAL PR, V100, P439, DOI 10.1016/j.ymssp.2017.06.022
   Zhang W, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17020425
NR 40
TC 67
Z9 68
U1 52
U2 80
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0016-0032
EI 1879-2693
J9 J FRANKLIN I
JI J. Frankl. Inst.-Eng. Appl. Math.
PD JUL
PY 2020
VL 357
IS 11
BP 7286
EP 7307
DI 10.1016/j.jfranklin.2020.04.024
PG 22
WC Automation & Control Systems; Engineering, Multidisciplinary;
   Engineering, Electrical & Electronic; Mathematics, Interdisciplinary
   Applications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Automation & Control Systems; Engineering; Mathematics
GA MK0UW
UT WOS:000548504000016
DA 2022-02-06
ER

PT J
AU Bindu, PV
   Mishra, R
   Thilagam, PS
AF Bindu, P. V.
   Mishra, Rahul
   Thilagam, P. Santhi
TI Discovering spammer communities in twitter
SO JOURNAL OF INTELLIGENT INFORMATION SYSTEMS
LA English
DT Article
DE Spammer detection; Anomaly detection; Spammer community; Twitter; Online
   social networks; Multilayer social networks
AB Online social networks have become immensely popular in recent years and have become the major sources for tracking the reverberation of events and news throughout the world. However, the diversity and popularity of online social networks attract malicious users to inject new forms of spam. Spamming is a malicious activity where a fake user spreads unsolicited messages in the form of bulk message, fraudulent review, malware/virus, hate speech, profanity, or advertising for marketing scam. In addition, it is found that spammers usually form a connected community of spam accounts and use them to spread spam to a large set of legitimate users. Consequently, it is highly desirable to detect such spammer communities existing in social networks. Even though a significant amount of work has been done in the field of detecting spam messages and accounts, not much research has been done in detecting spammer communities and hidden spam accounts. In this work, an unsupervised approach called SpamCom is proposed for detecting spammer communities in Twitter. We model the Twitter network as a multilayer social network and exploit the existence of overlapping community-based features of users represented in the form of Hypergraphs to identify spammers based on their structural behavior and URL characteristics. The use of community-based features, graph and URL characteristics of user accounts, and content similarity among users make our technique very robust and efficient.
C1 [Bindu, P. V.; Mishra, Rahul; Thilagam, P. Santhi] Natl Inst Technol Karnataka, Dept Comp Sci & Engn, Surathkal, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Karnataka
RP Bindu, PV (corresponding author), Natl Inst Technol Karnataka, Dept Comp Sci & Engn, Surathkal, India.
EM bindupv007@gmail.com; mishrahul11@gmail.com; santhi@nitk.ac.in
RI PV, Bindu/AAZ-2788-2020; THILAGAM, P.SANTHI/L-8316-2018
OI THILAGAM, P.SANTHI/0000-0002-8359-1330
CR AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1007/BF00153759
   Baumes J, 2005, LECT NOTES COMPUT SC, V3495, P27
   Baumes J, 2004, LECT NOTES COMPUT SC, V3073, P378
   Benevenuto F., 2010, COLLABORATION ELECT, V6, P12, DOI DOI 10.1109/ICDE.2012.16
   Benevenuto F., 2008, P 4 INT WORKSH ADV I, P45
   Bindu PV, 2017, COMPUT HUM BEHAV, V73, P568, DOI 10.1016/j.chb.2017.04.001
   Bindu PV, 2016, J NETW COMPUT APPL, V68, P213, DOI 10.1016/j.jnca.2016.02.021
   Brodka Piotr, 2014, ENCY SOCIAL NETWORK, P998
   Caverlee J, 2011, P INT AAAI C WEB SOC
   Chu Z, 2010, 26TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE (ACSAC 2010), P21
   DeBarr D., 2009, 6 C EMAIL ANT MOUNT
   Fire M., 2012, HUM J, V1, P26
   Freund Y, 1999, MACHINE LEARNING, PROCEEDINGS, P124
   Gao H., 2010, P 10 ACM SIGCOMM C I, P35, DOI DOI 10.1145/1879141.1879147
   Ghosh S, 2012, P 21 INT C WORLD WID, P61, DOI DOI 10.1145/2187836.2187846
   Grier C, 2010, PROCEEDINGS OF THE 17TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'10), P27, DOI 10.1145/1866307.1866311
   Haythornthwaite C., 2005, Information Communication & Society, V8, P125, DOI 10.1080/13691180500146185
   Hu X, 2013, P 23 INT JOINT C ART, P2633
   John G. H., 1995, Uncertainty in Artificial Intelligence. Proceedings of the Eleventh Conference (1995), P338
   Kohavi R, 2002, HDB DATA MINING KNOW, P267
   Lee K, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P435, DOI 10.1145/1835449.1835522
   Martinez-Romo J, 2013, EXPERT SYST APPL, V40, P2992, DOI 10.1016/j.eswa.2012.12.015
   Mustafaraj E., 2010, P WEBSCI10 EXT FRONT
   Ratkiewicz J, 2011, ICWSM, V11, P297, DOI DOI 10.1145/1963192.1963301
   Ratkiewicz J., 2011, PROC 20 INTERNAT C C, P249
   Reichardt J, 2006, PHYS REV E, V74, DOI 10.1103/PhysRevE.74.016110
   Shrivastava N, 2008, PROC INT CONF DATA, P486, DOI 10.1109/ICDE.2008.4497457
   Song J, 2011, LECT NOTES COMPUT SC, V6961, P301, DOI 10.1007/978-3-642-23644-0_16
   Stringhini G, 2010, 26TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE (ACSAC 2010), P1
   Swamynathan G., 2008, P 1 WORKSH ONL SOC N, P1, DOI DOI 10.1145/1397735.1397737
   Thomas K., 2011, P 2011 ACM SIGCOMM C, P243, DOI DOI 10.1145/2068816.2068840
   Yang C., 2012, P 21 INT C WORLD WID, P71, DOI DOI 10.1145/2187836.2187847
   Yang C., 2014, P 30 ANN COMP SEC AP, P86
   Yang C, 2013, IEEE T INF FOREN SEC, V8, P1280, DOI 10.1109/TIFS.2013.2267732
   Yardi S, 2009, 1 MONDAY, V15, P1, DOI [10.5210/fm.v15i1.2793, DOI 10.5210/FM.V15I1.2793]
   Ying XW, 2011, PROC INT CONF DATA, P912, DOI 10.1109/ICDE.2011.5767910
   Yousuf S. B., 2013, P 2013 IEEE ACM INT, P100, DOI DOI 10.1145/2492517.2492567
   Zheng XH, 2015, NEUROCOMPUTING, V159, P27, DOI 10.1016/j.neucom.2015.02.047
   [No title captured]
NR 39
TC 15
Z9 16
U1 1
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0925-9902
EI 1573-7675
J9 J INTELL INF SYST
JI J. Intell. Inf. Syst.
PD DEC
PY 2018
VL 51
IS 3
BP 503
EP 527
DI 10.1007/s10844-017-0494-z
PG 25
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GZ3NV
UT WOS:000449294200003
DA 2022-02-06
ER

PT J
AU Chai, CL
   Liao, J
   Zou, N
   Sun, LY
AF Chai, Chunlei
   Liao, Jing
   Zou, Ning
   Sun, Lingyun
TI A one-to-many conditional generative adversarial network framework for
   multiple image-to-image translations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image-to-image translation; Generative adversarial network; One-to-many
   conditional generative adversarial network; Deep learning
ID INFORMATION
AB Image-to-Image translation was proposed as a general form of many image learning problems. While generative adversarial networks were successfully applied on many image-to-image translations, many models were limited to specific translation tasks and were difficult to satisfy practical needs. In this work, we introduce a One-to-Many conditional generative adversarial network, which could learn from heterogeneous sources of images. This is achieved by training multiple generators against a discriminator in synthesized learning way. This framework supports generative models to generate images in each source, so output images follow corresponding target patterns. Two implementations, hybrid fake and cascading learning, of the synthesized adversarial training scheme are also proposed, and experimented on two benchmark datasets, UTZap50K and MVOD5K, as well as a new high-quality dataset BehTex7K. We consider five challenging image-to-image translation tasks: edges-to-photo, edges-to-similar-photo translation on UTZap50K, cross-view translation on MVOD5K, and grey-to-color, grey-to-Oil-Paint on BehTex7K. We show that both implementations are able to faithfully translate from an image to another image in edges-to-photo, edges-to-similar-photo, grey-to-color, and grey-to-Oil-Paint translation tasks. The quality of output images in cross-view translation need to be further boosted.
C1 [Chai, Chunlei; Liao, Jing; Zou, Ning; Sun, Lingyun] Zhejiang Univ, Lab CAD&CG, Hangzhou, Zhejiang, Peoples R China.
C3 Zhejiang University
RP Zou, N (corresponding author), Zhejiang Univ, Lab CAD&CG, Hangzhou, Zhejiang, Peoples R China.
EM dishengchai@126.com; jingl@zju.edu.cn; zouning@zju.edu.cn;
   sunly@zju.edu.cn
OI Liao, Jing/0000-0002-2948-5043; LIAO, Jing/0000-0001-7014-5377
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61303137]; National Science and Technology
   Support Program [2015BAH21F01]; Art Project for National Social-Science
   Foundation [15BG084]
FX This paper is supported by the National Natural Science Foundation of
   China (61303137), the National Science and Technology Support Program
   (2015BAH21F01) and the Art Project for National Social-Science
   Foundation (15BG084). We thank Dr. Preben Hansen from Stockholm
   University, Department of Computer Science, for assistance in
   proofreading and technical editing of the manuscript.
CR Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Calisir F, 2017, MULTIMED TOOLS APPL, V76, P12433, DOI 10.1007/s11042-016-3659-9
   Chen M, 2016, ARXIV161102019
   Elgammal A., 2017, ARXIV170607068
   Gao Z, 2015, SIGNAL PROCESS, V112, P83, DOI 10.1016/j.sigpro.2014.08.034
   GATYS LA, 2016, PROC CVPR IEEE, P2414, DOI DOI 10.1109/CVPR.2016.265
   Ghosh A, 2017, ARXIV160607536
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Isola P., P IEEE C COMP VIS PA
   Jacob VG, 2009, 2009 16TH IEEE INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOLS 1-6, P1653, DOI 10.1109/ICIP.2009.5413392
   Kim T., 2017, ARXIV170305192
   Liu AA, 2015, IEEE T CYBERNETICS, V45, P1194, DOI 10.1109/TCYB.2014.2347057
   Liu M.Y., 2016, COUPLED GENERATIVE A
   Liu Yifan, 2017, ARXIV170501908
   Liu ZG, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P109, DOI 10.1145/3123266.3123436
   Luan F., 2017, ARXIV170307511
   Mirza M., 2014, ARXIV14111784, P1
   Nie L, 2011, MULTIMEDIA ANSWERING, P695
   Perarnau G, 2016, C WORKSH NEUR INF PR
   Salimans T., 2016, ARXIV160603498
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Vukotic V, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL (ICMR'17), P421, DOI 10.1145/3078971.3079038
   Wang CY, 2018, IEEE T IMAGE PROCESS, V27, P4066, DOI 10.1109/TIP.2018.2836316
   Wang X, 2016, ARXIV EPRINT ARXIV 1
   Wang Y, 2016, ARXIV EPRINT ARXIV 1
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Xie SN, 2017, INT J COMPUT VISION, V125, P3, DOI 10.1007/s11263-017-1004-z
   Yang Y, 2013, IEEE T MULTIMEDIA, V15, P661, DOI 10.1109/TMM.2012.2237023
   Yi Z., 2017, ARXIV170402510
   Yu A, 2014, PROC CVPR IEEE, P192, DOI 10.1109/CVPR.2014.32
   Zhang B.-T., 2016, ARXIV161101455
   Zhang H., 2017, ARXIV170105957V2
   Zhang HW, 2016, PROC CVPR IEEE, P2809, DOI 10.1109/CVPR.2016.307
   Zhang L, 2012, IEEE IMAGE PROC, P1477, DOI 10.1109/ICIP.2012.6467150
   Zhang R., 2016, ARXIV160308511
   Zhu J.-Y., 2017, ARXIV170310593
NR 37
TC 5
Z9 6
U1 3
U2 47
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 17
BP 22339
EP 22366
DI 10.1007/s11042-018-5968-7
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ1DD
UT WOS:000441364500033
DA 2022-02-06
ER

PT J
AU Casero-Ripolles, A
   Mico-Sanz, JL
   Diez-Bosch, M
AF Casero-Ripolles, Andreu
   Mico-Sanz, Josep-Lluis
   Diez-Bosch, Miriam
TI Digital Public Sphere and Geography: The Influence of Physical Location
   on Twitter's Political Conversation
SO MEDIA AND COMMUNICATION
LA English
DT Article
DE big data; democracy; digital public sphere; geography; political
   communication; political discussion; social media; Twitter
ID SOCIAL MEDIA; COMMUNICATION; DEMOCRACY
AB Social media has instituted new parameters for the political conversation in the digital public sphere. Previous research had identified several of these new phenomena: political polarisation, hate speech discourses, and fake news, among others. However, little attention has been paid to the users' geographical location, specifically to the role location plays in political discussion on social media, and to its further implications in the digital public sphere. A priori, we might think that on the digital landscape geographical restrictions no longer condition political debate, allowing increasingly diverse users to participate in, and influence, the discussion. To analyse this, machine learning techniques were used to study Twitter's political conversation about the negotiation process for the formation of the government in Spain that took place between 2015 and 2016. A big data sample of 127,3 million tweets associated with three Spanish cities (Madrid, Barcelona, and Valencia) was used. The results show that the geographical location of the users directly affects the political conversation on Twitter, despite the dissolution of the physical restrictions that the online environment favours. Demographics, cultural factors, and proximity to the centres of political power are factors conditioning the structure of digital political debate. These findings are a novel contribution to the design of more effective political campaigns and strategies, and provide a better understanding of the dynamics of the digital public sphere provided by Twitter.
C1 [Casero-Ripolles, Andreu] Univ Jaume 1, Dept Commun Sci, Castellon de La Plana 12071, Spain.
   [Mico-Sanz, Josep-Lluis; Diez-Bosch, Miriam] Univ Ramon Llull, Blanquerna Sch Commun & Int Relat, Barcelona 08001, Spain.
C3 Universitat Jaume I; Universitat Ramon Llull
RP Casero-Ripolles, A (corresponding author), Univ Jaume 1, Dept Commun Sci, Castellon de La Plana 12071, Spain.
EM casero@uji.es; joseplluisms@blanquerna.url.edu;
   miriamdb@blanquerna.url.edu
RI Mico, Josep-Lluis/B-1201-2009; Bosch, Miriam Diez/G-5032-2016;
   Casero-Ripolles, Andreu/G-1722-2013
OI Mico, Josep-Lluis/0000-0003-1191-226X; Bosch, Miriam
   Diez/0000-0002-3120-9443; Casero-Ripolles, Andreu/0000-0001-6986-4163
FU Spanish State Research Agency-Agencia Espanola de Investigacion
   (AEI)Spanish Government [CSO2017-88620-P]
FX This article is funded by the Spanish State Research Agency-Agencia
   Espanola de Investigacion (AEI) under the grant number CSO2017-88620-P.
CR Arthur R, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0214466
   Barnidge M, 2019, MEDIA COMMUN-LISBON, V7, P4, DOI 10.17645/mac.v7i3.2257
   Bastos M, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0206841
   Benkler Y., 2006, WEALTH NETWORKS SOCI
   Bennett WL, 2018, J COMMUN, V68, P243, DOI 10.1093/joc/jqx017
   Bennett WL, 2018, EUR J COMMUN, V33, P122, DOI 10.1177/0267323118760317
   Boyd D, 2010, P ANN HICSS, P1657
   Cairncross, 1997, DEATH DISTANCE COMMU
   Campos-Dominguez E, 2017, PROF INFORM, V26, P785, DOI 10.3145/epi.2017.sep.01
   Carlson M., 2017, JOURNALISTIC AUTHORI
   Casero-Ripolles A, 2020, REV ICONO 14, V18, P33, DOI 10.7195/ri14.v18i1.1527
   Casero-Ripolles A, 2018, PROF INFORM, V27, P964, DOI 10.3145/epi.2018.sep.01
   Castells Manuel., 2013, COMMUNICATION POWER
   Cha M., 2010, ICWSM, DOI DOI 10.1145/2897659.2897663
   Chadwick Andrew., 2017, HYBRID MEDIA SYSTEM
   Coleman S, 2017, CAN INTERNET STRENGT
   Couldry N., 2017, MEDIATED CONSTRUCTIO
   Dagoula C, 2019, MEDIA COMMUN-LISBON, V7, P225, DOI 10.17645/mac.v7i1.1764
   Dahlgren P, 2013, POLITICAL WEB: MEDIA, PARTICIPATION AND ALTERNATIVE DEMOCRACY, P1, DOI 10.1057/9781137326386
   De Blasio E, 2019, INT J COMMUN-US, V13, P5715
   Dubois E, 2014, AM BEHAV SCI, V58, P1260, DOI 10.1177/0002764214527088
   Esser F, 2012, INT J PRESS/POLIT, V17, P247, DOI 10.1177/1940161212442956
   Fearnley F, 2018, GEOGRAPHY, V103, P97
   Feenstra RA, 2017, R ST ANTIPOLIT DEM C
   Fuchs C., 2017, SOCIAL MEDIA CRITICA
   Fuchs C, 2014, TRIPLEC-COMMUN CAPIT, V12, P57
   de Zuniga HG, 2018, PROF INFORM, V27, P1172, DOI 10.3145/epi.2018.nov.01
   Habermas J, 2006, COMMUN THEOR, V16, P411, DOI 10.1111/j.1468-2885.2006.00280.x
   Han SY, 2018, INT J DIGIT EARTH, V11, P451, DOI 10.1080/17538947.2017.1330366
   Hepp A, 2020, KEY IDEAS MEDIA CUL, P1, DOI 10.4324/9781351064903
   Kellerman A., 2016, GEOGRAPHIC INTERPRET
   Kliegr T, 2020, AM BEHAV SCI, V64, P145, DOI 10.1177/0002764219859639
   Kulshrestha J., 2012, P 6 INT AAAI C WEBL, P202
   Laniado D, 2018, INFORM SYST FRONT, V20, P1203, DOI 10.1007/s10796-017-9784-9
   Lansley G, 2016, COMPUT ENVIRON URBAN, V58, P85, DOI 10.1016/j.compenvurbsys.2016.04.002
   Lazarsfeld P. F, 1944, PEOPLES CHOICE VOTER
   Leamer EE, 2001, J INT BUS STUD, V32, P641, DOI 10.1057/palgrave.jibs.84909988
   Leetaru K., 2013, 1 MONDAY, V18, DOI [10.5210/fm.v18i5.4366, DOI 10.5210/FM.V18I5.4366]
   Lengyel B, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0137248
   Lievrouw Leah, 2011, ALTERNATIVE ACTIVIST
   Longley PA, 2016, INT J GEOGR INF SCI, V30, P369, DOI 10.1080/13658816.2015.1089441
   Mico JL, 2017, AM BEHAV SCI, V61, P428, DOI 10.1177/0002764217693277
   Molla T., 2014, DESCONNEXIO VALENCIA
   Palmer S, 2016, J APPL RES HIGH EDUC, V8, P88, DOI 10.1108/JARHE-01-2015-0002
   Papacharissi Z., 2015, AFFECTIVE PUBLICS SE
   Rasmussen T., 2016, INTERNET SOAPBOX
   Riquelme F, 2016, INFORM PROCESS MANAG, V52, P949, DOI 10.1016/j.ipm.2016.04.003
   Ruiz C, 2011, INT J PRESS/POLIT, V16, P463, DOI 10.1177/1940161211415849
   Shelton T, 2014, GEOFORUM, V52, P167, DOI 10.1016/j.geoforum.2014.01.006
   Shirky C, 2011, FOREIGN AFF, V90, P28
   Stephens M, 2015, COMPUT ENVIRON URBAN, V53, P87, DOI 10.1016/j.compenvurbsys.2014.07.002
   Takhteyev Y, 2012, SOC NETWORKS, V34, P73, DOI 10.1016/j.socnet.2011.05.006
   Tormey Simon., 2015, END REPRESENTATIVE P
   Tufekci Z., 2017, TWITTER TEAR GAS POW
   Van Aelst P., 2017, ANN INT COMMUNICATIO, V41, DOI [10.1080/23808985.2017.1288551, DOI 10.1080/23808985.2017.1288551]
   Van Dijck J., 2013, CULTURE CONNECTIVITY
   Varnelis K., 2008, NETWORKED PUBLICS, P1, DOI 10.7551/mitpress/9780262220859.003.0001
   Villacanas J. L., 2014, HIST PODER POLITICO
   Warf B., 2013, GLOBAL GEOGRAPHIES I
   Winograd T., 1999, WORLD WIDE WEB INTER
   Yardi Sarita, 2010, P 4 INT AAAI C WEBL
NR 61
TC 4
Z9 4
U1 3
U2 5
PU COGITATIO PRESS
PI LISBON
PA RUA FIALHO ALMEIDA 14, 2 ESQ, LISBON, 1070-129, PORTUGAL
SN 2183-2439
J9 MEDIA COMMUN-LISBON
JI Media Commun.
PY 2020
VL 8
IS 4
BP 96
EP 106
DI 10.17645/mac.v8i4.3145
PG 11
WC Communication
WE Social Science Citation Index (SSCI)
SC Communication
GA OE6FO
UT WOS:000580624700008
OA Green Published, gold
DA 2022-02-06
ER

PT J
AU Vizoso, A
   Vaz-Alvarez, M
   Lopez-Garcia, X
AF Vizoso, Angel
   Vaz-Alvarez, Martin
   Lopez-Garcia, Xose
TI Fighting Deepfakes: Media and Internet Giants' Converging and Diverging
   Strategies Against Hi-Tech Misinformation
SO MEDIA AND COMMUNICATION
LA English
DT Article
DE deepfake; Facebook; fact-checking; fake news; information verification;
   Google; misinformation; social media; Twitter
ID FAKE NEWS; JOURNALISM
AB Deepfakes, one of the most novel forms of misinformation, have become a real challenge in the communicative environment due to their spread through online news and social media spaces. Although fake news have existed for centuries, its circulation is now more harmful than ever before, thanks to the ease of its production and dissemination. At this juncture, technological development has led to the emergence of deepfakes, doctored videos, audios or photos that use artificial intelligence. Since its inception in 2017, the tools and algorithms that enable the modification of faces and sounds in audiovisual content have evolved to the point where there are mobile apps and web services that allow average users its manipulation. This research tries to show how three renowned media outlets-The Wall Street Journal, The Washington Post, and Reuters-and three of the biggest Internet-based companies-Google, Facebook, and Twitter-are dealing with the spread of this new form of fake news. Results show that identification of deepfakes is a common practice for both types of organizations. However, while the media is focused on training journalists for its detection, online platforms tended to fund research projects whose objective is to develop or improve media forensics tools.
C1 [Vizoso, Angel; Vaz-Alvarez, Martin; Lopez-Garcia, Xose] Univ Santiago de Compostela, Fac Commun Sci, Santiago De Compostela 15782, Spain.
C3 University of Santiago De Compostela
RP Vizoso, A (corresponding author), Univ Santiago de Compostela, Fac Commun Sci, Santiago De Compostela 15782, Spain.
EM angel.vizoso@usc.es; martin.vaz.alvarez@usc.es; xose.lopez.garcia@usc.es
RI Garcia, Xose Lopez/I-4418-2019; Vizoso, Angel/K-8370-2018
OI Garcia, Xose Lopez/0000-0002-1873-8260; Vaz Alvarez,
   Martin/0000-0002-4848-9795; Vizoso, Angel/0000-0001-7898-9267
FU Ministry of Science, Innovation and Universities (Government of
   Spain)Spanish Government [RTI2018-093346-B-C33, RTI2018-096065-B-100];
   European Regional Development Fund (ERDF)European Commission; Spanish
   Ministry of Science, Innovation and Universities (Government of Spain)
FX This article has been developed within the research projects "Digital
   Native Media in Spain: Storytelling Formats and Mobile Strategy
   (RTI2018-093346-B-C33)" and "New Values, Governance, Funding and Public
   Media Services for the Internet Society: European and Spanish Contrasts
   (RTI2018-096065-B-100)" funded by the Ministry of Science, Innovation
   and Universities (Government of Spain) and co-funded by the European
   Regional Development Fund (ERDF). Furthermore, authors Angel Vizoso and
   Martin Vaz-Alvarez are also beneficiary of the Training University
   Lecturers' Program (FPU), funded by the Spanish Ministry of Science,
   Innovation and Universities (Government of Spain).
CR Ajaka N., 2019, WASHINGTON POST
   Akhtar Z., 2019, 2019 IEEE INT S TECH, DOI [10.1109/hst47167.2019, DOI 10.1109/HST47167.2019]
   Amoros M., 2018, FAKE NEWS VERDAD NOT
   Bennett WL, 2018, EUR J COMMUN, V33, P122, DOI 10.1177/0267323118760317
   Bergstrom A, 2018, DIGIT JOURNAL, V6, P583, DOI 10.1080/21670811.2018.1423625
   Bickert M., 2020, ENFORCING MANIPULATE
   Bingquan Zhu, 2020, AIES '20: Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society, P414, DOI 10.1145/3375627.3375849
   Bloch M., 1999, HISTORIA HISTORIADOR
   Brandtzaeg PB, 2017, COMMUN ACM, V60, P65, DOI 10.1145/3122803
   Brandtzaeg PB, 2016, JOURNAL PRACT, V10, P323, DOI 10.1080/17512786.2015.1020331
   Bressnan S., 2019, CAN EU PREVENT DEEPF
   Burkhardt J., 2017, LIB TECHNOLOGY REPOR, V53, P5
   Carlson M., 2017, JOURNALISTIC AUTHORI
   Castro D., 2020, DEEPFAKES ARE RISE S
   Chesney R., 2019, FOREIGN AFFAIRS
   Ciampaglia Giovanni Luca, 2015, PLOS ONE, V10, P6, DOI [10.1371/journal.pone.0128193, DOI 10.1371/J0URNAL.P0NE.0128193]
   Codina L., 2017, LLUISCODINA
   Crosse G., REUTERS
   Deeptrace Labs, 2018, STATE DEEPFAKES REAL
   Dufour Nick, 2019, CONTRIBUTING DATA DE
   Ekstrom M, 2020, NEW MEDIA SOC, V22, P205, DOI 10.1177/1461444819856914
   European Commission, 2020, TACKLING ONLINE DISI
   European Commission, 2018, ACTION PLAN DISINFOR
   Farid H., 2019, DEEPFAKES AUDIO VISU
   Fernandes S, 2019, IEEE INT CONF COMP V, P1721, DOI 10.1109/ICCVW.2019.00213
   Galston W. A., 2020, IS SEEING STILL BELI
   Geham F., 2017, FACT CHECKING REPONS
   Gorbach J, 2018, AMER JOURNAL, V35, P236, DOI 10.1080/08821127.2018.1457915
   Graves L., 2016, DECIDING WHATS TRUE
   Graves L, 2018, JOURNALISM STUD, V19, P613, DOI 10.1080/1461670X.2016.1196602
   Harvey D., 2019, HELP US SHAPE OUR AP
   Kessler G., 2019, WASHINGTON POST
   Kitchenham B., 2004, PROCEDURES PERFORM I
   Kovach B., 2014, ELEMENTS JOURNALISM, V3rd
   Lazer DMJ, 2018, SCIENCE, V359, P1094, DOI 10.1126/science.aao2998
   Levush R., 2019, GOVT RESPONSES DISIN
   Lopez-Garcia G, 2019, CONTEMP SOC SCI, V14, P1, DOI 10.1080/21582041.2018.1479040
   Lowrey W, 2017, JOURNALISM STUD, V18, P376, DOI 10.1080/1461670X.2015.1052537
   Luo ZR, 2018, ADV MECH ENG, V10, P1, DOI 10.1177/1687814018785286
   Maras MH, 2019, INT J EVID PROOF, V23, P255, DOI 10.1177/1365712718807226
   Marconi F., 2018, WALL STREET J IS PRE
   Masip P, 2020, PROF INFORM, V29, DOI 10.3145/epi.2020.sep.27
   McIntyre Karen., 2017, J MEDIA INNOVATIONS, V4, P20, DOI 10.5617/jomi.v4i2.2403
   McNair B., 2017, FAKE NEWS FALSEHOOD
   Moltzau A., 2020, MEDIUM
   Nelson JL, 2018, NEW MEDIA SOC, V20, P3720, DOI 10.1177/1461444818758715
   Nirkin Y., 2019, FSGAN SUBJECT AGNOST
   Palomo B., 2020, INFORM VISUALIZATION, P161
   Patadia D., 2020, REUTERS
   Peters MA, 2018, EDUC PHILOS THEORY, V50, P1161, DOI 10.1080/00131857.2017.1417200
   Rochlin N, 2017, LIBR HI TECH, V35, P386, DOI 10.1108/LHT-03-2017-0062
   Salaverria R, 2020, PROF INFORM, V29, DOI 10.3145/epi.2020.may.15
   SCHWARTZ O., 2018, GUARDIAN
   Shapiro I, 2013, JOURNAL PRACT, V7, P657, DOI 10.1080/17512786.2013.765638
   Shimizu K, 2020, LANCET, V395, P685, DOI 10.1016/S0140-6736(20)30357-3
   Southern L., 2019, DIGIDAY
   Stencel M., 2020, ANN CENSUS FINDS NEA
   Stupp C., 2019, WALL STREET J
   Tandoc EC, 2018, DIGIT JOURNAL, V6, P137, DOI 10.1080/21670811.2017.1360143
   Thurman N, 2021, JOURNALISM, V22, P1892, DOI 10.1177/1464884919892411
   Vaccari C, 2020, SOC MEDIA SOC, V6, DOI 10.1177/2056305120903408
   Vargo CJ, 2018, NEW MEDIA SOC, V20, P2028, DOI 10.1177/1461444817712086
   Vosoughi S, 2018, SCIENCE, V359, P1146, DOI 10.1126/science.aap9559
   Waisbord S, 2018, JOURNALISM STUD, V19, P1866, DOI 10.1080/1461670X.2018.1492881
   Westerlund M, 2019, TECHNOL INNOV MANAG, V9, P39, DOI 10.22215/timreview/1282
NR 65
TC 1
Z9 1
U1 18
U2 21
PU COGITATIO PRESS
PI LISBON
PA RUA FIALHO ALMEIDA 14, 2 ESQ, LISBON, 1070-129, PORTUGAL
SN 2183-2439
J9 MEDIA COMMUN-LISBON
JI Media Commun.
PY 2021
VL 9
IS 1
BP 291
EP 300
DI 10.17645/mac.v9i1.3494
PG 10
WC Communication
WE Social Science Citation Index (SSCI)
SC Communication
GA QR8IM
UT WOS:000625456900007
OA gold
DA 2022-02-06
ER

PT J
AU Lu, XQ
   Wang, BQ
   Zheng, XT
AF Lu, Xiaoqiang
   Wang, Binqiang
   Zheng, Xiangtao
TI Sound Active Attention Framework for Remote Sensing Image Captioning
SO IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING
LA English
DT Article
DE Active attention; remote sensing image captioning; semantic
   understanding
ID SEMANTIC SEGMENTATION; CLASSIFICATION
AB Attention mechanism-based image captioning methods have achieved good results in the remote sensing field, but are driven by tagged sentences, which is called passive attention. However, different observers may give different levels of attention to the same image. The attention of observers during testing, then, may not be consistent with the attention during training. As a direct and natural human-machine interaction, speech is much faster than typing sentences. Sound can represent the attention of different observers. This is called active attention. Active attention can be more targeted to describe the image; for example, in disaster assessments, the situation can be obtained quickly and the corresponding disaster areas can be located related to the specific disaster. A novel sound active attention framework is proposed for more specific caption generation according to the interest of the observer. First, sound is modeled by mel-frequency cepstral coefficients (MFCCs) and the image is encoded by convolutional neural networks (CNNs). Then, to handle the continuity characteristic of sound, a sound module and an attention module are designed based on the gated recurrent units (GRUs). Finally, the sound-guided image feature processed by the attention module is imported into the output module to generate descriptive sentence. Experiments based on both fake and real sound data sets show that the proposed method can generate sentences that can capture the focus of human.
C1 [Lu, Xiaoqiang; Wang, Binqiang; Zheng, Xiangtao] Chinese Acad Sci, Xian Inst Opt & Precis Mech, Key Lab Spectral Imaging Technol, Xian 710119, Peoples R China.
   [Wang, Binqiang] Univ Chinese Acad Sci, Sch Elect Elect & Commun Engn, Beijing 100049, Peoples R China.
C3 Chinese Academy of Sciences; Xi'an Institute of Optics & Precision
   Mechanics, CAS; Chinese Academy of Sciences; University of Chinese
   Academy of Sciences, CAS
RP Lu, XQ (corresponding author), Chinese Acad Sci, Xian Inst Opt & Precis Mech, Key Lab Spectral Imaging Technol, Xian 710119, Peoples R China.
EM luxq666666@gmail.com
RI WANG, binqiang/AAW-6000-2020
OI Lu, Xiaoqiang/0000-0002-7037-5188; Wang, Binqiang/0000-0001-9406-167X
FU National Key Research and Development Program of China [2017YFB0502900];
   National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61806193, 61702498, 61772510]; Young
   Top-Notch Talent Program of the Chinese Academy of Sciences
   [QYZDB-SSW-JSC015]; Open Research Fund of the State Key Laboratory of
   Transient Optics and Photonics, Chinese Academy of Sciences
   [SKLST2017010]; CAS "Light of West China" Program [XAB2017B26,
   XAB2017B15]; Xi'an Postdoctoral Innovation Base Scientific Research
   Project
FX This work was supported in part by the National Key Research and
   Development Program of China under Grant 2017YFB0502900; in part by the
   National Natural Science Foundation of China under Grant 61806193, Grant
   61702498, and Grant 61772510; in part by the Young Top-Notch Talent
   Program of the Chinese Academy of Sciences under Grant QYZDB-SSW-JSC015;
   in part by the Open Research Fund of the State Key Laboratory of
   Transient Optics and Photonics, Chinese Academy of Sciences, under Grant
   SKLST2017010; in part by the CAS "Light of West China" Program under
   Grant XAB2017B26 and Grant XAB2017B15; and in part by the Xi'an
   Postdoctoral Innovation Base Scientific Research Project.
CR Anderson P, 2016, LECT NOTES COMPUT SC, V9909, P382, DOI 10.1007/978-3-319-46454-1_24
   Aneja J, 2018, PROC CVPR IEEE, P5561, DOI 10.1109/CVPR.2018.00583
   Arandjelovic R, 2018, LECT NOTES COMPUT SC, V11205, P451, DOI 10.1007/978-3-030-01246-5_27
   Baltrusaitis T, 2019, IEEE T PATTERN ANAL, V41, P423, DOI 10.1109/TPAMI.2018.2798607
   Banerjee S, 2005, ANN M ASS COMP LING, P65
   Borji A, 2015, REMOTE SENS
   Chen F, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10030443
   Chen GZ, 2018, IEEE J-STARS, V11, P1633, DOI 10.1109/JSTARS.2018.2810320
   Chen JB, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10020290
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Cho K., 2014, EMNLP, DOI DOI 10.3115/V1/D14-1179
   Chung J., 2014, EMPIRICAL EVALUATION
   Chung J, 2017, NEURIPS
   Fisher JW, 2001, ADV NEUR IN, V13, P772
   Flick C., 2004, P ACL WORKSH TEXT SU, P10
   Gao R., 2018, IEEE C COMP VIS PATT
   Guo M, 2018, PROCEEDINGS OF 2018 INTERNATIONAL CONFERENCE ON MATHEMATICS AND ARTIFICIAL INTELLIGENCE (ICMAI 2018), P1, DOI 10.1145/3208788.3208790
   Harwath D, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P506, DOI 10.18653/v1/P17-1047
   Jegou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235
   Kemker R, 2018, ISPRS J PHOTOGRAMM, V145, P60, DOI 10.1016/j.isprsjprs.2018.04.014
   Kemker R, 2018, IEEE T GEOSCI REMOTE, V56, P6214, DOI 10.1109/TGRS.2018.2833808
   Kida T, 2006, EXP BRAIN RES, V175, P609, DOI 10.1007/s00221-006-0578-4
   King DB, 2015, ACS SYM SER, V1214, P1
   Leidal K, 2017, 2017 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU), P424, DOI 10.1109/ASRU.2017.8268967
   Li LH, 2017, THIRTY-FIRST AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4133
   Li XL, 2018, MULTIMED TOOLS APPL, V77, P29847, DOI 10.1007/s11042-018-5856-1
   Li Y, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10020243
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu XX, 2018, IEEE T GEOSCI REMOTE, V56, P2183, DOI 10.1109/TGRS.2017.2776321
   Lu XQ, 2017, IEEE T GEOSCI REMOTE, V55, P5148, DOI 10.1109/TGRS.2017.2702596
   Lu XQ, 2017, IEEE T CYBERNETICS, V47, P884, DOI 10.1109/TCYB.2016.2531179
   Mroueh Y, 2015, INT CONF ACOUST SPEE, P2130, DOI 10.1109/ICASSP.2015.7178347
   Nogueira K, 2017, PATTERN RECOGN, V61, P539, DOI 10.1016/j.patcog.2016.07.001
   Owens A., 2018, EUR C COMP VIS ECCV, P631
   Owens A, 2016, PROC CVPR IEEE, P2405, DOI 10.1109/CVPR.2016.264
   Owens A, 2016, LECT NOTES COMPUT SC, V9905, P801, DOI 10.1007/978-3-319-46448-0_48
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   PERRONNIN F, 2010, PROC CVPR IEEE, P3384, DOI DOI 10.1109/CVPR.2010.5540009
   Qiu SH, 2018, REMOTE SENS LETT, V9, P237, DOI 10.1080/2150704X.2017.1415473
   Qu B, 2016, INT CONF COMP INFO, P124
   Revathi A. R., 2012, P INT C ADV COMP SCI, P375
   Shi ZW, 2017, IEEE T GEOSCI REMOTE, V55, P3623, DOI 10.1109/TGRS.2017.2677464
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Socher R, 2014, P 19 C EMPIRICAL MET, V2014, P1532, DOI DOI 10.3115/V1/D14-1162
   Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087
   Wang SS, 2018, LECT NOTES COMPUT SC, V11266, P567, DOI 10.1007/978-3-030-02698-1_49
   Wang Y, 2018, PROCEEDINGS OF THE 2018 EURO-ASIA CONFERENCE ON ENVIRONMENT AND CSR: TOURISM, SOCIETY AND EDUCATION SESSION (PART II), P167
   Wei X, 2018, REMOTE SENS LETT, V9, P199, DOI 10.1080/2150704X.2017.1410291
   Xu XD, 2018, IEEE T GEOSCI REMOTE, V56, P937, DOI 10.1109/TGRS.2017.2756851
   Xu X, 2015, IEEE ICC, P2048, DOI 10.1109/ICC.2015.7248627
   Yang Y, 2010, PROC 18 SIGSPATIAL I, ppp270
   You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503
   Zhang F, 2015, IEEE T GEOSCI REMOTE, V53, P2175, DOI 10.1109/TGRS.2014.2357078
   Zhang XR, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11060612
   Zhang XR, 2017, INT GEOSCI REMOTE SE, P4798, DOI 10.1109/IGARSS.2017.8128075
   Zheng F, 2001, J COMPUT SCI TECHNOL, V16, P582, DOI 10.1007/BF02943243
   Zheng XT, 2016, NEUROCOMPUTING, V216, P331, DOI 10.1016/j.neucom.2016.08.015
   Zou ZX, 2018, IEEE T IMAGE PROCESS, V27, P1100, DOI 10.1109/TIP.2017.2773199
NR 59
TC 16
Z9 16
U1 0
U2 9
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0196-2892
EI 1558-0644
J9 IEEE T GEOSCI REMOTE
JI IEEE Trans. Geosci. Remote Sensing
PD MAR
PY 2020
VL 58
IS 3
BP 1985
EP 2000
DI 10.1109/TGRS.2019.2951636
PG 16
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA KU3GZ
UT WOS:000519598700037
DA 2022-02-06
ER

PT J
AU Zhang, HL
   Wang, R
   Pan, RL
   Pan, HY
AF Zhang, Hongliang
   Wang, Rui
   Pan, Ruilin
   Pan, Haiyang
TI Imbalanced Fault Diagnosis of Rolling Bearing Using Enhanced Generative
   Adversarial Networks
SO IEEE ACCESS
LA English
DT Article
DE Fault diagnosis; rolling bearing; generative adversarial networks;
   imbalanced data; convolutional neural networks
ID SMOTE; MACHINERY
AB Machinery fault diagnosis tasks have been well addressed when sufficient and abundant data are available. However, the data imbalance problem widely exists in real-world scenarios, which leads to the performance deterioration of fault diagnosis markedly. To solve this problem, we present a novel imbalanced fault diagnosis method based on the enhanced generative adversarial networks (GAN). By artificially generating fake samples, the proposed method can mitigate the loss caused by the lack of real fault data. Specifically, in order to improve the quality of generated samples, a new discriminator is designed using spectrum normalization (SN) strategy and a two time-scale update rule (TTUR) method is used to stabilize the training process of GAN. Then, an enhanced Wasserstein GAN with gradient penalty is developed to generate high-quality synthetic samples for the fault samples set. Finally, a deep convolutional classifier is constructed to carry out fault classification. The performance and effectiveness of the proposed method are validated on the Case Western Reserve University bearing dataset and rolling bearing dataset acquired from our laboratory. The simulation results show that the proposed method has a superior performance than other methods for imbalanced fault diagnosis tasks.
C1 [Zhang, Hongliang; Wang, Rui; Pan, Ruilin] Anhui Univ Technol, Sch Management Sci & Engn, Maanshan 243032, Peoples R China.
   [Pan, Ruilin] Dept Educ Anhui Prov, Key Lab Multidisciplinary Management & Control Co, Maanshan 243032, Peoples R China.
   [Pan, Haiyang] Anhui Univ Technol, Sch Mech Engn, Maanshan 243032, Peoples R China.
C3 Anhui University of Technology; Anhui University of Technology
RP Pan, RL (corresponding author), Anhui Univ Technol, Sch Management Sci & Engn, Maanshan 243032, Peoples R China.; Pan, RL (corresponding author), Dept Educ Anhui Prov, Key Lab Multidisciplinary Management & Control Co, Maanshan 243032, Peoples R China.
EM alltimefight@gmail.com
OI Pan, Ruilin/0000-0002-8268-739X; Pan, Haiyang/0000-0001-9868-8154
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [71772002, 61702006]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 71772002 and Grant 61702006.
CR Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Chen BJ, 2019, MEASUREMENT, V131, P400, DOI 10.1016/j.measurement.2018.07.043
   Chintala S., 2017, ARXIV170107875
   Courville A., 2017, ARXIV170400028
   Douzas G, 2018, INFORM SCIENCES, V465, P1, DOI 10.1016/j.ins.2018.06.056
   Duan LX, 2016, EXPERT SYST APPL, V64, P239, DOI 10.1016/j.eswa.2016.07.039
   Elreedy D, 2019, INFORM SCIENCES, V505, P32, DOI 10.1016/j.ins.2019.07.070
   Gao X, 2020, NEUROCOMPUTING, V396, P487, DOI 10.1016/j.neucom.2018.10.109
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   He HB, 2008, IEEE IJCNN, P1322, DOI 10.1109/IJCNN.2008.4633969
   Heusel M., 2017, ARXIV170608500
   Jia F, 2018, MECH SYST SIGNAL PR, V110, P349, DOI 10.1016/j.ymssp.2018.03.025
   Li C, 2017, KNOWL-BASED SYST, V129, P39, DOI 10.1016/j.knosys.2017.05.007
   Li FH, 2019, MECH SYST SIGNAL PR, V116, P462, DOI 10.1016/j.ymssp.2018.06.055
   Li Q, 2019, MEAS SCI TECHNOL, V30, DOI 10.1088/1361-6501/ab3072
   Li X, 2019, IEEE T IND ELECTRON, V66, P5525, DOI 10.1109/TIE.2018.2868023
   Li Y, 2018, INFORM SCIENCES, V450, P301, DOI 10.1016/j.ins.2018.03.050
   Maldonado S, 2019, APPL SOFT COMPUT, V76, P380, DOI 10.1016/j.asoc.2018.12.024
   Mao WT, 2019, IEEE ACCESS, V7, P9515, DOI 10.1109/ACCESS.2018.2890693
   Mao WT, 2017, MECH SYST SIGNAL PR, V83, P450, DOI 10.1016/j.ymssp.2016.06.024
   Miyato T., 2018, P INT C LEARN REPR
   Salimans T., 2016, ARXIV160603498
   Shao SY, 2019, COMPUT IND, V106, P85, DOI 10.1016/j.compind.2019.01.001
   Tian Y, 2019, MECH SYST SIGNAL PR, V114, P658, DOI 10.1016/j.ymssp.2016.04.028
   Togo R, 2019, IEEE ACCESS, V7, P87448, DOI 10.1109/ACCESS.2019.2925863
   Wang JR, 2019, NEUROCOMPUTING, V329, P53, DOI 10.1016/j.neucom.2018.10.049
   Wang J, 2019, IEEE ACCESS, V7, P35089, DOI 10.1109/ACCESS.2019.2903147
   Wei ZX, 2017, KNOWL-BASED SYST, V116, P1, DOI 10.1016/j.knosys.2016.10.022
   Yan T, 2019, IEEE ACCESS, V7, P164203, DOI 10.1109/ACCESS.2019.2951917
   Yuan Y, 2018, IEEE ACCESS, V6, P5573, DOI 10.1109/ACCESS.2018.2796118
   Zhang YY, 2018, J MANUF SYST, V48, P34, DOI 10.1016/j.jmsy.2018.04.005
   Zhou FN, 2020, KNOWL-BASED SYST, V187, DOI 10.1016/j.knosys.2019.07.008
NR 32
TC 2
Z9 2
U1 19
U2 33
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2020
VL 8
BP 185950
EP 185963
DI 10.1109/ACCESS.2020.3030058
PG 14
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA OI9EU
UT WOS:000583573300001
OA gold
DA 2022-02-06
ER

PT J
AU Guo, ZQ
   Yang, GB
   Chen, JY
   Sun, XM
AF Guo, Zhiqing
   Yang, Gaobo
   Chen, Jiyou
   Sun, Xingming
TI Fake face detection via adaptive manipulation traces extraction network
SO COMPUTER VISION AND IMAGE UNDERSTANDING
LA English
DT Article
DE Face image manipulation; Passive image forensics; Manipulation traces
   extraction
AB With the proliferation of face image manipulation (FIM) techniques such as Face2Face and Deepfake, more fake face images are spreading over the internet, which brings serious challenges to public confidence. Face image forgery detection has made considerable progresses in exposing specific FIM, but it is still in scarcity of a robust fake face detector to expose face image forgeries under complex scenarios such as with further compression, blurring, scaling, etc. Due to the relatively fixed structure, convolutional neural network (CNN) tends to learn image content representations. However, CNN should learn subtle manipulation traces for image forensics tasks. Thus, we propose an adaptive manipulation traces extraction network (AMTEN), which serves as pre-processing to suppress image content and highlight manipulation traces. AMTEN exploits an adaptive convolution layer to predict manipulation traces in the image, which are reused in subsequent layers to maximize manipulation artifacts by updating weights during the back-propagation pass. A fake face detector, namely AMTENnet, is constructed by integrating AMTEN with CNN. Experimental results prove that the proposed AMTEN achieves desirable pre-processing. When detecting fake face images generated by various FIM techniques, AMTENnet achieves an average accuracy up to 98.52%, which outperforms the state-of-the-art works. When detecting face images with unknown post-processing operations, the detector also achieves an average accuracy of 95.17%.
C1 [Guo, Zhiqing; Yang, Gaobo; Chen, Jiyou] Hunan Univ, Sch Informat Sci & Engn, Changsha 410082, Hunan, Peoples R China.
   [Sun, Xingming] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Peoples R China.
C3 Hunan University; Nanjing University of Information Science & Technology
RP Yang, GB (corresponding author), Hunan Univ, Sch Informat Sci & Engn, Changsha 410082, Hunan, Peoples R China.
EM yanggaobo@hnu.edu.cn
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61972143, 61972142]; National Key R&D
   Project of China [2018YFB1003205]; Natural Science Foundation of Hunan
   Province, ChinaNatural Science Foundation of Hunan Province
   [2020JJ4626]; Scientific Research Foundation of Hunan Provincial
   Education Department of China [19B004]
FX This work is supported in part by the National Natural Science
   Foundation of China (No. 61972143, 61972142), National Key R&D Project
   of China (No. 2018YFB1003205), Natural Science Foundation of Hunan
   Province, China (No. 2020JJ4626) and the Scientific Research Foundation
   of Hunan Provincial Education Department of China (No. 19B004).
CR Afchar D, 2018, IEEE INT WORKS INFOR
   Agarwal S., 2019, P CVPR WORKSH LONG B, P38
   Bayar B, 2018, IEEE T INF FOREN SEC, V13, P2691, DOI 10.1109/TIFS.2018.2825953
   Berthelot D., 2017, ARXIV170310717
   Chen JS, 2015, IEEE SIGNAL PROC LET, V22, P1849, DOI 10.1109/LSP.2015.2438008
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Ciftci U. A., 2019, ARXIV PREPRINT ARXIV
   Cozzolino D., 2018, ARXIV PREPRINT ARXIV
   Cozzolino Davide, 2017, P 5 ACM WORKSH INF H, P159, DOI DOI 10.1145/3082031.3083247
   Dang H, 2020, PROC CVPR IEEE, P5780, DOI 10.1109/CVPR42600.2020.00582
   Dang LM, 2019, EXPERT SYST APPL, V129, P156, DOI 10.1016/j.eswa.2019.04.005
   Dang LM, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8122610
   Do Nhu-Tai, 2018, FORENSICS FACE DETEC
   Feng XY, 2012, IEEE T MULTIMEDIA, V14, P536, DOI 10.1109/TMM.2012.2191946
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Glorot X., 2011, JMLR WORKSHOP C, V15, P315, DOI DOI 10.1.1.208.6449
   Glorot X., 2010, P 13 INT C ART INT S, P249
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Guera D, 2018, 2018 15TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P127
   Guo C., 2018, 10 INT C DIG IM PROC 10 INT C DIG IM PROC, V0806
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hsu CC, 2018, INT SYMP COMP CONS, P388, DOI 10.1109/IS3C.2018.00104
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang H., 2018, NEURAL INFORM PROCES, P52
   Karras T, 2018, PROGRESSIVE GROWING
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Kingma D.P., 2016, ADV NEURAL INFORM PR
   Kingma Durk P, 2018, P 32 C NEURAL INFORM, P10215
   Korshunov P., 2018, ARXIV PREPRINT ARXIV
   Korshunova I, 2017, IEEE I CONF COMP VIS, P3697, DOI 10.1109/ICCV.2017.397
   Li Haodong, 2018, ARXIV PREPRINT ARXIV
   Li L., 2020, P IEEE CVF C COMP VI, P5001
   Li Y., 2019, ARXIV PREPRINT ARXIV
   Li Yuezun, 2018, 2018 IEEE INT WORKSH, P1, DOI DOI 10.1109/WIFS.2018.8630787
   Liang Y, 2018, ARXIV PREPRINT ARXIV
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Marra F, 2018, IEEE 1ST CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2018), P384, DOI 10.1109/MIPR.2018.00084
   Matern F, 2019, IEEE WINT CONF APPL, P83, DOI 10.1109/WACVW.2019.00020
   Mo HX, 2018, PROCEEDINGS OF THE 6TH ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY (IH&MMSEC'18), P43, DOI 10.1145/3206004.3206009
   Nguyen HH, 2019, INT CONF ACOUST SPEE, P2307, DOI 10.1109/ICASSP.2019.8682602
   Pevny T, 2010, IEEE T INF FOREN SEC, V5, P215, DOI 10.1109/TIFS.2010.2045842
   Popescu AC, 2005, IEEE T SIGNAL PROCES, V53, P758, DOI 10.1109/TSP.2004.839932
   Pumarola A, 2018, LECT NOTES COMPUT SC, V11214, P835, DOI 10.1007/978-3-030-01249-6_50
   Rossler A, 2019, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2019.00009
   Rossler A., 2018, ARXIV PREPRINT ARXIV
   Simonyan K, 2015, ICLR 2015, DOI DOI 10.1109/CVPR.2015.7298594
   Thies J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323035
   Thies J, 2016, PROC CVPR IEEE, P2387, DOI 10.1109/CVPR.2016.262
   Xuan XS, 2019, LECT NOTES COMPUT SC, V11818, P134, DOI 10.1007/978-3-030-31456-9_15
   Yang X, 2019, IH&MMSEC '19: PROCEEDINGS OF THE ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, P113, DOI 10.1145/3335203.3335724
   Yang X, 2019, INT CONF ACOUST SPEE, P8261, DOI 10.1109/ICASSP.2019.8683164
   Yu N, 2019, IEEE I CONF COMP VIS, P7555, DOI 10.1109/ICCV.2019.00765
   Yu W, 2018, COMPUT VIS IMAGE UND, V169, P40, DOI 10.1016/j.cviu.2018.01.001
   Zhang Y, 2017, 2017 IEEE 2ND INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP), P15, DOI 10.1109/SIPROCESS.2017.8124497
   Zhao XC, 2018, IEEE T MULTIMEDIA, V20, P552, DOI 10.1109/TMM.2017.2750415
   Zhou P, 2018, PROC CVPR IEEE, P1053, DOI 10.1109/CVPR.2018.00116
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 57
TC 2
Z9 2
U1 10
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1077-3142
EI 1090-235X
J9 COMPUT VIS IMAGE UND
JI Comput. Vis. Image Underst.
PD MAR
PY 2021
VL 204
AR 103170
DI 10.1016/j.cviu.2021.103170
PG 10
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TI1SM
UT WOS:000672565100001
OA Green Submitted
DA 2022-02-06
ER

PT J
AU He, C
   Huang, SH
   Cheng, R
   Tan, KC
   Jin, YC
AF He, Cheng
   Huang, Shihua
   Cheng, Ran
   Tan, Kay Chen
   Jin, Yaochu
TI Evolutionary Multiobjective Optimization Driven by Generative
   Adversarial Networks (GANs)
SO IEEE TRANSACTIONS ON CYBERNETICS
LA English
DT Article
DE Optimization; Computational modeling; Generative adversarial networks;
   Machine learning; Evolutionary computation; Training data; Adaptation
   models; Deep learning; machine learning; evolutionary algorithm;
   generative adversarial networks (GANs); machine learning; multiobjective
   optimization
ID DIFFERENTIAL EVOLUTION; GENETIC ALGORITHM; COMPUTATION; EFFICIENCY
AB Recently, increasing works have been proposed to drive evolutionary algorithms using machine-learning models. Usually, the performance of such model-based evolutionary algorithms is highly dependent on the training qualities of the adopted models. Since it usually requires a certain amount of data (i.e., the candidate solutions generated by the algorithms) for model training, the performance deteriorates rapidly with the increase of the problem scales due to the curse of dimensionality. To address this issue, we propose a multiobjective evolutionary algorithm driven by the generative adversarial networks (GANs). At each generation of the proposed algorithm, the parent solutions are first classified into real and fake samples to train the GANs; then the offspring solutions are sampled by the trained GANs. Thanks to the powerful generative ability of the GANs, our proposed algorithm is capable of generating promising offspring solutions in high-dimensional decision space with limited training data. The proposed algorithm is tested on ten benchmark problems with up to 200 decision variables. The experimental results on these test problems demonstrate the effectiveness of the proposed algorithm.
C1 [He, Cheng; Huang, Shihua; Cheng, Ran] Southern Univ Sci & Technol, Dept Comp Sci & Engn, Guangdong Prov Key Lab Brain Inspired Intelligent, Shenzhen 518055, Peoples R China.
   [Tan, Kay Chen] City Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China.
   [Jin, Yaochu] Univ Surrey, Dept Comp Sci, Guildford GU2 7XH, Surrey, England.
C3 Southern University of Science & Technology; City University of Hong
   Kong; University of Surrey
RP Cheng, R (corresponding author), Southern Univ Sci & Technol, Dept Comp Sci & Engn, Guangdong Prov Key Lab Brain Inspired Intelligent, Shenzhen 518055, Peoples R China.
EM chenghehust@gmail.com; shihuahuang95@gmail.com; ranchengcn@gmail.com;
   kaytan@cityu.edu.hk; yaochu.jin@surrey.ac.uk
RI He, Cheng/P-6615-2019; Jin, Yaochu/B-3776-2012
OI He, Cheng/0000-0003-4218-8454; Jin, Yaochu/0000-0003-1100-0631
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61903178, 61906081]; Program for Guangdong
   Introducing Innovative and Entrepreneurial Teams [2017ZT07X386];
   Shenzhen Peacock Plan [KQTD2016112514355531]; Program for University Key
   Laboratory of Guangdong Province [2017KSYS008]; Research Grants Council
   of the Hong KongHong Kong Research Grants Council [CityU11202418,
   CityU11209219]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61903178 and Grant 61906081, in part by
   the Program for Guangdong Introducing Innovative and Entrepreneurial
   Teams under Grant 2017ZT07X386, in part by the Shenzhen Peacock Plan
   under Grant KQTD2016112514355531, in part by the Program for University
   Key Laboratory of Guangdong Province under Grant 2017KSYS008, and in
   part by the Research Grants Council of the Hong Kong under Grant
   CityU11202418 and Grant CityU11209219.
CR Allmendinger R, 2017, J MULTI-CRITERIA DEC, V24, P5, DOI 10.1002/mcda.1605
   Arjovsky M., 2017, WASSERSTEIN GAN
   Balakrishnan N, 2014, STAT REFERENCE ONLIN
   Beume N, 2007, EUR J OPER RES, V181, P1653, DOI 10.1016/j.ejor.2006.08.008
   Bhattacharjee K. S., 2015, P 11 WORLD C STRUCT, P1041
   Bosman PAN, 2006, STUD FUZZ SOFT COMP, V192, P123
   Cheng R, 2018, COMPLEX INTELL SYST, V4, P283, DOI 10.1007/s40747-018-0080-1
   Cheng R, 2016, IEEE T EVOLUT COMPUT, V20, P773, DOI 10.1109/TEVC.2016.2519378
   Cheng R, 2015, IEEE T EVOLUT COMPUT, V19, P838, DOI 10.1109/TEVC.2015.2395073
   Deb K, 2002, IEEE T EVOLUT COMPUT, V6, P182, DOI 10.1109/4235.996017
   Deb K., 1996, COMPUT SCI INFORM, V26, P30
   Deb K., 2014, MULTIOBJECTIVE OPTIM
   Deb K., 2001, WIL INT S SYS OPT, V16
   Eiben AE, 2015, NATURE, V521, P476, DOI 10.1038/nature14544
   Ferreira P. V., 2017, 2017 COGN COMM AER A, P1
   Giagkiozis I, 2014, EVOL COMPUT, V22, P651, DOI 10.1162/EVCO_a_00128
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Haynes W., 2013, ENCY SYSTEMBIOL, P2354
   He C, 2016, IEEE C EVOL COMPUTAT, P5230, DOI 10.1109/CEC.2016.7748353
   Hernandez-Diaz AG, 2007, EVOL COMPUT, V15, P493, DOI 10.1162/evco.2007.15.4.493
   Jain A. K., 1988, TECHNOMETRICS, V32, P227
   Jin Y., 2000, P GEN EV COMP C, P786
   Jin YC, 2011, SWARM EVOL COMPUT, V1, P61, DOI 10.1016/j.swevo.2011.05.001
   Jin YC, 2009, IEEE COMPUT INTELL M, V4, P62, DOI 10.1109/MCI.2009.933094
   Karshenas H, 2014, IEEE T EVOLUT COMPUT, V18, P519, DOI 10.1109/TEVC.2013.2281524
   Ketkar N., 2017, DEEP LEARNING PYTHON
   Kingma D. P., 2014, ARXIV13126114, DOI DOI 10.1007/S11042-018-6187-Y
   Kingma DP, 2015, 3 INT C LEARN REPR I, DOI DOI 10.1145/1830483.1830503
   Knowles JD, 2000, IEEE C EVOL COMPUTAT, P325, DOI 10.1109/CEC.2000.870313
   KOZA JR, 1994, STAT COMPUT, V4, P87
   Larranaga P., 2001, ESTIMATION DISTRIBUT, V2
   Laumanns M., 2002, Parallel Problem Solving from Nature - PPSN VII. 7th International Conference. Proceedings (Lecture Notes in Computer Science Vol.2439), P298
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   LESHNO M, 1993, NEURAL NETWORKS, V6, P861, DOI 10.1016/S0893-6080(05)80131-5
   Li H, 2017, IEEE T CYBERNETICS, V47, P52, DOI 10.1109/TCYB.2015.2507366
   Li H, 2009, IEEE T EVOLUT COMPUT, V13, P284, DOI 10.1109/TEVC.2008.925798
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P2450, DOI 10.1109/TNNLS.2017.2695223
   Loshchilov I., 2010, P 12 ANN C GEN EV CO, P471
   Loshchilov I, 2013, 2013 IEEE CONGRESS ON EVOLUTIONARY COMPUTATION (CEC), P369
   Lu XF, 2012, J COMPUT SCI TECH-CH, V27, P1024, DOI 10.1007/s11390-012-1282-4
   Martinez SZ, 2014, LECT NOTES COMPUT SC, V8672, P682
   Antonio LM, 2013, 2013 IEEE CONGRESS ON EVOLUTIONARY COMPUTATION (CEC), P2758
   Ocenasek J, 2004, LECT NOTES COMPUT SC, V3242, P352
   Pan LQ, 2019, IEEE T EVOLUT COMPUT, V23, P74, DOI 10.1109/TEVC.2018.2802784
   Parsons L., 2004, SIGKDD EXPLORATIONS, V6, P90, DOI DOI 10.1145/1007730.1007731
   Ponweiser W, 2008, LECT NOTES COMPUT SC, V5199, P784, DOI 10.1007/978-3-540-87700-4_78
   Praditwong K, 2006, 2006 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY, PTS 1 AND 2, PROCEEDINGS, P286, DOI 10.1109/ICCIAS.2006.294139
   Radford A., 2015, ARXIV151106434
   Seah C.-W., 2012, P IEEE C EV COMP BRI, P1
   Siddique N, 2013, NEURAL NETWORKS EVOL
   Storn R, 1997, J GLOBAL OPTIM, V11, P341, DOI 10.1023/A:1008202821328
   Sun YA, 2018, IEEE T EVOLUT COMPUT, V22, P662, DOI 10.1109/TEVC.2018.2794319
   Svozil D, 1997, CHEMOMETR INTELL LAB, V39, P43, DOI 10.1016/S0169-7439(97)00061-0
   Tian Y, 2017, COMPLEX INTELL SYST, V3, P247, DOI 10.1007/s40747-017-0057-5
   Tian Y, 2017, IEEE COMPUT INTELL M, V12, P73, DOI 10.1109/MCI.2017.2742868
   Wang HD, 2017, IEEE T CYBERNETICS, V47, P1510, DOI 10.1109/TCYB.2016.2550502
   Wang HD, 2015, EVOL COMPUT, V23, P69, DOI 10.1162/EVCO_a_00122
   While L, 2006, IEEE T EVOLUT COMPUT, V10, P29, DOI 10.1109/TEVC.2005.851275
   Yu W, 2015, ENERG BUILDINGS, V88, P135, DOI 10.1016/j.enbuild.2014.11.063
   Zhang JY, 2018, INFORM SCIENCES, V465, P388, DOI 10.1016/j.ins.2018.06.073
   Zhang JY, 2015, IEEE C EVOL COMPUTAT, P2883, DOI 10.1109/CEC.2015.7257247
   Zhang J, 2011, IEEE COMPUT INTELL M, V6, P68, DOI 10.1109/MCI.2011.942584
   Zhang QF, 2008, IEEE T EVOLUT COMPUT, V12, P41, DOI 10.1109/TEVC.2007.894202
   Zhang QF, 2007, IEEE T EVOLUT COMPUT, V11, P712, DOI 10.1109/TEVC.2007.892759
   Zhang QF, 2010, IEEE T EVOLUT COMPUT, V14, P456, DOI 10.1109/TEVC.2009.2033671
   Zhang X, 2018, ADV SCI, V5, DOI 10.1002/advs.201700520
   Zhang XY, 2015, IEEE T EVOLUT COMPUT, V19, P201, DOI 10.1109/TEVC.2014.2308305
   Zhou AM, 2006, IEEE C EVOL COMPUTAT, P892
   Zitzler E, 1999, IEEE T EVOLUT COMPUT, V3, P257, DOI 10.1109/4235.797969
   Zitzler E, 2004, LECT NOTES COMPUT SC, V3242, P832
   Ziztler E., 2001, P EV METH DES OPT CO
NR 72
TC 15
Z9 15
U1 18
U2 54
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2168-2267
EI 2168-2275
J9 IEEE T CYBERNETICS
JI IEEE T. Cybern.
PD JUN
PY 2021
VL 51
IS 6
BP 3129
EP 3142
DI 10.1109/TCYB.2020.2985081
PG 14
WC Automation & Control Systems; Computer Science, Artificial Intelligence;
   Computer Science, Cybernetics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Automation & Control Systems; Computer Science
GA SE4TE
UT WOS:000652065400024
PM 32365041
OA Green Submitted
DA 2022-02-06
ER

PT J
AU Smith, LN
   McMenemy, D
AF Smith, Lauren N.
   McMenemy, David
TI Young people's conceptions of political information Insights into
   information experiences and implications for intervention
SO JOURNAL OF DOCUMENTATION
LA English
DT Article
DE Information literacy; Information behaviour; Young people;
   Misinformation; Political participation; Civic engagement; Fake news
ID MEDIA COVERAGE; FALSE BALANCE; KNOWLEDGE; SEEKING; PERCEPTIONS;
   LITERACY; NEWS; ENTERTAINMENT; EMOTIONS; INTERNET
AB Purpose - The purpose of this paper is to explore young people's conceptions of political information. The study sought to identify what political information sources young people encounter, how they construe these sources and the messages they communicate, and how the information experiences of young people may be better understood to inform information literacy interventions to support the development of political agency.
   Design/methodology/approach - Using personal construct theory as a conceptual framework, repertory grid (RG) interviews were used to explore the different ways in which 23 young people aged 14-15 from a town in Northern England conceive of political information and how they evaluate its quality and authority.
   Findings - The study identified the sources of information young people engage with for finding and receiving what they understand as political information. The results from the RG interviews indicated that young people use a wide range of sources of political information to become informed about politics and the world around them. These sources of information include family, friends, teachers, television news, newspapers, radio shows, comedy shows, social media and community meetings. Participants were aware that they passively encounter information sources as well as actively engage in debate and discussion with other sources. Some participants had difficulty critically evaluating the political information sources they encounter. The nature of young people's experiences of political information varied greatly. The degree of complexity in the experiences of political information varied not only between participants but was also dependent on their particular relationship with the information sources under scrutiny.
   Research limitations/implications - The paper has implications for personal construct analysis as a research approach broadly, from the point of view of its use within library and information science research. It is the first study to apply the personal construct approach to the study of young people's political information use and to consider implications for information literacy support that would have been difficult to access using other approaches.
   Practical implications - The paper provides insight into an understudied area; that of young people's conceptions of political information. This insight may be used to inform the improvement of political information provision and information literacy support for young people. Social implications - A deeper understanding of the different ways in which young people identify, engage with and use information for political purposes may contribute to a clearer understanding of young people's information needs, ideally leading to improved political education and a strengthened democratic process.
   Originality/value - The paper explores a relatively under-researched area of library and information science research, and does so using a relatively under-used method in the domain. Insightsinto the perceived characteristics of different sources of political information are novel and contribute to the development of information behaviour and information literacy fields in terms of information for empowerment and democracy.
C1 [Smith, Lauren N.; McMenemy, David] Univ Strathclyde, Dept Comp & Informat Sci, Glasgow, Lanark, Scotland.
C3 University of Strathclyde
RP Smith, LN (corresponding author), Univ Strathclyde, Dept Comp & Informat Sci, Glasgow, Lanark, Scotland.
EM lauren.n.smith@strath.ac.uk
RI Smith, Lauren/I-5914-2014; McMenemy, David/N-7486-2018
OI Smith, Lauren/0000-0002-4467-2234; McMenemy, David/0000-0002-3203-9001
FU ESRCUK Research & Innovation (UKRI)Economic & Social Research Council
   (ESRC); Economic and Social Research Council under the Scottish ESRC
   Doctoral Training Centre DTG initiativeUK Research & Innovation
   (UKRI)Economic & Social Research Council (ESRC) [17435RS4729]; Economic
   and Social Research CouncilUK Research & Innovation (UKRI)Economic &
   Social Research Council (ESRC) [1108184] Funding Source: researchfish
FX The authors would like to thank the research participants for their
   contributions, the ESRC for providing the funding to support this
   research, colleagues and reviewers for their insightful comments that
   have aided the improvement of the paper. This work was supported by the
   Economic and Social Research Council under the Scottish ESRC Doctoral
   Training Centre DTG initiative (Grant No. 17435RS4729).
CR Achter P, 2008, CRIT STUD MEDIA COMM, V25, P274, DOI 10.1080/15295030802192038
   Agosto DE, 2002, LIBR INFORM SCI RES, V24, P311, DOI 10.1016/S0740-8188(02)00131-7
   Amna E, 2012, J ADOLESCENCE, V35, P611, DOI 10.1016/j.adolescence.2012.04.011
   Andersen J, 2006, J DOC, V62, P213, DOI 10.1108/00220410610653307
   Ashworth S, 2014, AM POLIT SCI REV, V108, P565, DOI 10.1017/S0003055414000264
   Bannister D., 2003, INT HDB PERSONAL CON, P181
   Bartlett J., 2011, TRUTH LIES INTERNET
   Bates, 1997, SCH LIB MEDIA Q, V25, P103
   Baum MA, 2003, POLIT COMMUN, V20, P173, DOI 10.1080/10584600390211181
   Baxter G., 2015, INDEPENDENCE REFEREN
   Becker A.B., 2013, REV COMMUNICATION, V13, P161, DOI [https://doi.org/10.1080/15358593.2013.826816, DOI 10.1080/15358593.2013.826816]
   Becker N. J., 2003, New Review of Academic Librarianship, V9, P84, DOI 10.1080/13614530410001692059
   Birdi B, 2011, ASLIB PROC, V63, P275, DOI 10.1108/00012531111135709
   Bruce C., 2004, 3 INT LIF LEARN C QU, P8
   Bruggemann M, 2017, GLOBAL ENVIRON CHANG, V42, P58, DOI 10.1016/j.gloenvcha.2016.11.004
   Cao XX, 2008, MASS COMMUN SOC, V11, P43, DOI 10.1080/15205430701585028
   Chater N, 2003, TRENDS COGN SCI, V7, P19, DOI 10.1016/S1364-6613(02)00005-0
   CLARKE PB, 1996, DEEP CITIZENSHIP
   Cody DE, 2006, J ACAD LIBR, V32, P403, DOI 10.1016/j.acalib.2006.03.007
   Cope Jonathan, 2017, J CRITICAL LIB INFOR, V1, P1
   Crudge SE, 2004, J AM SOC INF SCI TEC, V55, P794, DOI 10.1002/asi.20023
   Dixon GN, 2013, SCI COMMUN, V35, P358, DOI 10.1177/1075547012458290
   DUNCAN CP, 1985, J ADVERTISING, V14, P33, DOI 10.1080/00913367.1985.10672944
   Economic and Social Research Council, 2012, ESRC FRAM RES ETH
   Fisher J. M., 1999, BEYOND EXPT INTO MEA, P1
   Frankfurt HG, 2005, ON BULLSHIT, P1
   FRANSELL.F, 1967, ACTA PSYCHOL, V26, P97, DOI 10.1016/0001-6918(67)90010-8
   Fransella Fay, 2004, MANUAL REPERTORY GRI
   Gans HJ, 2014, INT J COMMUN-US, V8, P2484
   Garner S., 2005, HIGH LEV C INF LIT L
   Gronlund K, 2007, SCAND POLIT STUD, V30, P397, DOI 10.1111/j.1467-9477.2007.00186.x
   Gross M, 2009, COLL RES LIBR, V70, P336, DOI 10.5860/crl.70.4.336
   Hamilton L., 2015, J CIVIC LIT, V2
   Harlan M., 2016, SJSU SCH INFORM
   Herman Edward S., 1994, MANUFACTURING CONSEN
   Hollander BA, 2005, J BROADCAST ELECTRON, V49, P402, DOI 10.1207/s15506878jobem4904_3
   Hunt E., 2016, WHAT IS FAKE NEWS SP
   Jane EA, 2017, INT J CULTURAL STUD, V20, P459, DOI 10.1177/1367877916637151
   Jankowicz Devi, 2004, EASY GUIDE REPERTORY
   Johnson FC, 2007, J DOC, V63, P259, DOI 10.1108/00220410710737213
   Johnson M., 2016, KNOWLEDGE QUEST
   Johnson TJ, 2000, JOURNALISM MASS COMM, V77, P865, DOI 10.1177/107769900007700409
   Kalekin-Fishman D., 1993, INT J PERSONAL CONST, V6, P27, DOI [10.1080/08936039308404330, DOI 10.1080/08936039308404330]
   Kalekin-Fishman D., 2003, INT HDB PERSONAL CON, P143
   Kapitzke C., 2003, ED THEORY, V53, P37, DOI DOI 10.1111/J.1741-5446.2003.00037.X
   Kapitzke C., 2001, J ADOLESC ADULT LIT, V44, P59
   Kari J, 2007, J AM SOC INF SCI TEC, V58, P1131, DOI 10.1002/asi.20585
   Kates S, 1998, J BUS ETHICS, V17, P1871, DOI 10.1023/A:1005796113389
   Keating A., 2015, YOUNG ADULTS POLITIC
   Kelly G., 1991, PERSONAL CONSTRUCT P
   Kim YM, 2008, J COMMUN, V58, P338, DOI 10.1111/j.1460-2466.2008.00388.x
   Kuhlthau C., 2016, THEORY DEV INFORM SC, P68
   KUHLTHAU CC, 1993, J DOC, V49, P339, DOI 10.1108/eb026918
   Lasswell HaroldDwight., 1936, POLITICS WHO GETS WH
   LATTA GF, 1992, J AM SOC INFORM SCI, V43, P115, DOI 10.1002/(SICI)1097-4571(199203)43:2<115::AID-ASI2>3.0.CO;2-I
   Lee G, 2001, POLIT COMMUN, V18, P369, DOI 10.1080/10584600152647092
   Levinsen K, 2015, SOCIOL REV, V63, P72, DOI 10.1111/1467-954X.12263
   Lewandowsky S, 2012, PSYCHOL SCI PUBL INT, V13, P106, DOI 10.1177/1529100612451018
   LIN CA, 1993, HUM COMMUN RES, V20, P224, DOI 10.1111/j.1468-2958.1993.tb00322.x
   Lombrozo T, 2007, COGNITIVE PSYCHOL, V55, P232, DOI 10.1016/j.cogpsych.2006.09.006
   Lombrozo T, 2006, TRENDS COGN SCI, V10, P464, DOI 10.1016/j.tics.2006.08.004
   Lopatovska I, 2011, INFORM PROCESS MANAG, V47, P575, DOI 10.1016/j.ipm.2010.09.001
   Lupia Arthur., 1998, DEMOCRATIC DILEMMA C
   Madden AD, 2006, J DOC, V62, P744, DOI 10.1108/00220410610714958
   McKnight C, 2000, J AM SOC INFORM SCI, V51, P730, DOI 10.1002/(SICI)1097-4571(2000)51:8<730::AID-ASI50>3.0.CO;2-8
   McQuail D., 2005, MASS COMMUNICATION T
   Meddaugh PM, 2010, CRIT STUD MEDIA COMM, V27, P376, DOI 10.1080/15295030903583606
   Neal DM, 2011, J MED LIBR ASSOC, V99, P127, DOI 10.3163/1536-5050.99.2.004
   Neal DM, 2011, LIBR INFORM SCI RES, V33, P25, DOI 10.1016/j.lisr.2010.07.015
   Neben, 2015, 36 INT C INF SYST FO
   Nicholas D., 2009, ASSESSING INFORM NEE
   OBERMAN C, 1991, LIBR TRENDS, V39, P189
   Oxford Dictionaries, 2016, WORD YEAR 2016
   Pariser, 2011, FILTER BUBBLE WHAT I
   Pawley C, 2003, LIBR QUART, V73, P422
   Pfau M, 2001, HARV INT J PRESS/POL, V6, P88, DOI 10.1177/108118001129172350
   Pickard AJ, 2014, J LIBR INF SCI, V46, P3, DOI 10.1177/0961000612467813
   Potthoff JK, 2000, COLL RES LIBR, V61, P191, DOI 10.5860/crl.61.3.191
   Prior M, 2005, AM J POLIT SCI, V49, P577, DOI 10.1111/j.1540-5907.2005.00143.x
   RIEH SY, 2008, DIGITAL MEDIA YOUTH, P00049
   SAVOLAINEN R, 1995, LIBR INFORM SCI RES, V17, P259, DOI 10.1016/0740-8188(95)90048-9
   Savolainen R, 2014, LIBR INFORM SCI RES, V36, P59, DOI 10.1016/j.lisr.2013.10.004
   Schroeder R, 2010, PORTAL-LIBR ACAD, V10, P127
   Shenton AK, 2004, LIBR INFORM SCI RES, V26, P177, DOI 10.1016/j.lisr.2003.12.003
   Smith L., 2016, J INFORM LITERACY, V10, P3, DOI DOI 10.11645/10.2.2097
   Smith M., 2010, YOUNG PEOPLE PHENOME
   Taylor A, 2012, INFORM RES, V17
   Terriquez V, 2015, J ETHN MIGR STUD, V41, P425, DOI 10.1080/1369183X.2014.921567
   Tiffany K., 2016, THE VERGE
   Vromen A, 2015, J YOUTH STUD, V18, P80, DOI 10.1080/13676261.2014.933198
   Weeks BE, 2015, J COMMUN, V65, P699, DOI 10.1111/jcom.12164
   Whitworth A, 2009, CHANDOS INF PROF SER, P1, DOI 10.1533/9781780630045
   Whitworth A., 2014, RADICAL INFORM LIT R
   WILSON TD, 1981, J DOC, V37, P3, DOI 10.1108/eb026702
   Yadamsuren B, 2011, INFORM RES, V16
   Young DG, 2004, J BROADCAST ELECTRON, V48, P1, DOI 10.1207/s15506878jobem4801_1
   Zhang XM, 2001, J AM SOC INF SCI TEC, V52, P445, DOI 10.1002/1532-2890(2001)9999:9999<::AID-ASI1092>3.3.CO;2-V
   [No title captured]
   [No title captured]
NR 99
TC 5
Z9 5
U1 5
U2 64
PU EMERALD GROUP PUBLISHING LTD
PI BINGLEY
PA HOWARD HOUSE, WAGON LANE, BINGLEY BD16 1WA, W YORKSHIRE, ENGLAND
SN 0022-0418
EI 1758-7379
J9 J DOC
JI J. Doc.
PY 2017
VL 73
IS 5
BP 877
EP 902
DI 10.1108/JD-03-2017-0041
PG 26
WC Computer Science, Information Systems; Information Science & Library
   Science
WE Social Science Citation Index (SSCI)
SC Computer Science; Information Science & Library Science
GA FJ6NL
UT WOS:000412874400006
OA Green Accepted
DA 2022-02-06
ER

PT J
AU Hu, YC
   Lu, MQ
   Xie, C
   Lu, XB
AF Hu, Yaocong
   Lu, Mingqi
   Xie, Chao
   Lu, Xiaobo
TI Driver Drowsiness Recognition via 3D Conditional GAN and Two-Level
   Attention Bi-LSTM
SO IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS FOR VIDEO TECHNOLOGY
LA English
DT Article
DE Generative adversarial networks; Vehicles; Three-dimensional displays;
   Gallium nitride; Feature extraction; Machine learning; Generators;
   Driver drowsiness; generative adversarial network; two-level attention
   mechanism; bidirectional long short-term memory
ID SPATIAL-TEMPORAL ATTENTION; STATE
AB Driver drowsiness has currently been a severe issue threatening road safety, hence it is vital to develop an effective drowsiness recognition algorithm to avoid traffic accidents. However, recognizing drowsiness is still very challenging, due to the large intra-class variations in facial expression, head pose and illumination condition. In this paper, a new deep learning framework based on the hybrid of 3D conditional generative adversarial network and two-level attention bidirectional long short-term memory network (3DcGAN-TLABiLSTM) has been proposed for robust driver drowsiness recognition. Aiming at extracting short-term spatial-temporal features with abundant drowsiness-related information, we design a 3D encoder-decoder generator with the condition of auxiliary information to generate high-quality fake image sequences and devise a 3D discriminator to learn drowsiness-related representation from spatial-temporal domain. In addition, for long-term spatial-temporal fusion, we investigate the use of two-level attention mechanism to guide the bidirectional long short-term memory learn the saliency of short-term memory information and long-term temporal information. For experiment, we evaluate our 3DcGAN-TLABiLSTM framework on a public NTHU-DDD dataset. Experimental results show that the proposed approach achieves higher precision of drowsiness recognition compared to the state-of-the-art.
C1 [Hu, Yaocong; Lu, Mingqi; Lu, Xiaobo] Southeast Univ, Sch Automat, Nanjing 210096, Peoples R China.
   [Hu, Yaocong; Lu, Mingqi; Lu, Xiaobo] Southeast Univ, Minist Educ, Key Lab Measurement & Control Complex Syst Engn, Nanjing 210096, Peoples R China.
   [Xie, Chao] Nanjing Forestry Univ, Coll Mech & Elect Engn, Nanjing 210037, Peoples R China.
C3 Southeast University - China; Southeast University - China; Nanjing
   Forestry University
RP Lu, XB (corresponding author), Southeast Univ, Sch Automat, Nanjing 210096, Peoples R China.
EM xblu2013@126.com
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61871123, 61901221]; Postgraduate Research &
   Practice Innovation Program of Jiangsu Province [KYCX19_0087]; Key
   Research and Development Program in Jiangsu Province [BE2016739]; State
   Scholarship Fund from China Scholarship CouncilChina Scholarship Council
   [201906090126]; Priority Academic Program Development of Jiangsu Higher
   Education Institutions
FX This work was supported by the National Natural Science Foundation of
   China (No. 61871123), the National Natural Science Foundation of China
   (No. 61901221), the Postgraduate Research & Practice Innovation Program
   of Jiangsu Province (No. KYCX19_0087), Key Research and Development
   Program in Jiangsu Province (No. BE2016739), the State Scholarship Fund
   from China Scholarship Council (No. 201906090126) and a Project Funded
   by the Priority Academic Program Development of Jiangsu Higher Education
   Institutions.
CR Ba J. L., 2016, LAYER NORMALIZATION
   Bao JM, 2017, IEEE I CONF COMP VIS, P2764, DOI 10.1109/ICCV.2017.299
   Heilbron FC, 2015, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2015.7298698
   CHEN X, 2016, ADV NEUR IN, V29
   Chen YA, 2017, IEEE IMAGE PROC, P1202, DOI 10.1109/ICIP.2017.8296472
   Chowdhury A, 2018, IEEE SENS J, V18, P3055, DOI 10.1109/JSEN.2018.2807245
   Dasgupta A, 2019, IEEE T INTELL TRANSP, V20, P4045, DOI 10.1109/TITS.2018.2879609
   Dehzangi O, 2018, INT C PATT RECOG, P3598, DOI 10.1109/ICPR.2018.8545427
   Du WB, 2018, IEEE T IMAGE PROCESS, V27, P1347, DOI 10.1109/TIP.2017.2778563
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Fu JL, 2017, PROC CVPR IEEE, P4476, DOI 10.1109/CVPR.2017.476
   Fujiwara K, 2019, IEEE T BIO-MED ENG, V66, P1769, DOI 10.1109/TBME.2018.2879346
   Gao ZK, 2019, IEEE T NEUR NET LEAR, V30, P2755, DOI 10.1109/TNNLS.2018.2886414
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Guo JM, 2019, MULTIMED TOOLS APPL, V78, P29059, DOI 10.1007/s11042-018-6378-6
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI 10.1109/ICCV.2017.322
   Hearst MA, 1998, IEEE INTELL SYST APP, V13, P18, DOI 10.1109/5254.708428
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735
   Huo XQ, 2016, IEEE IJCNN, P897, DOI 10.1109/IJCNN.2016.7727294
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Kaplan S, 2015, IEEE T INTELL TRANSP, V16, DOI 10.1109/TITS.2015.2462084
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Ketkar N., 2017, DEEP LEARNING PYTHON, DOI DOI 10.1007/978-1-4842-2766-4_12
   Khan SA, 2018, IEEE ACCESS, V6, P67459, DOI 10.1109/ACCESS.2018.2878601
   Kingma DP, 2015, 3 INT C LEARN REPR I, DOI DOI 10.1145/1830483.1830503
   Krizhevsky A., 2012, ADV NEURAL INF PROCE, P1097, DOI DOI 10.1145/3065386
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Lyu J, 2017, LECT NOTES COMPUT SC, V10118, P178, DOI 10.1007/978-3-319-54526-4_14
   Masci J, 2011, LECT NOTES COMPUT SC, V6791, P52, DOI 10.1007/978-3-642-21735-7_7
   Mbouna RO, 2013, IEEE T INTELL TRANSP, V14, P1462, DOI 10.1109/TITS.2013.2262098
   Mirza M, 2014, ARXIV PREPRINT ARXIV
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Omidyeganeh M, 2016, IEEE T INSTRUM MEAS, V65, P570, DOI 10.1109/TIM.2015.2507378
   Park S, 2017, LECT NOTES COMPUT SC, V10118, P154, DOI 10.1007/978-3-319-54526-4_12
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Peng YX, 2019, IEEE T CIRC SYST VID, V29, P773, DOI 10.1109/TCSVT.2018.2808685
   Ramzan M, 2019, IEEE ACCESS, V7, P61904, DOI 10.1109/ACCESS.2019.2914373
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2015, ADV NEUR IN, V28
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   SHENSA MJ, 1992, IEEE T SIGNAL PROCES, V40, P2464, DOI 10.1109/78.157290
   Shih TH, 2017, LECT NOTES COMPUT SC, V10118, P146, DOI 10.1007/978-3-319-54526-4_11
   Sikander G, 2019, IEEE T INTELL TRANSP, V20, P2339, DOI 10.1109/TITS.2018.2868499
   Simonyan K, 2015, ICLR 2015, DOI DOI 10.1109/CVPR.2015.7298594
   Sinopoli B, 2004, IEEE T AUTOMAT CONTR, V49, P1453, DOI 10.1109/TAC.2004.834121
   Sun W, 2017, IEEE T INTELL TRANSP, V18, P3408, DOI 10.1109/TITS.2017.2690914
   Sundermeyer M, 2015, IEEE-ACM T AUDIO SPE, V23, P517, DOI 10.1109/TASLP.2015.2400218
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Tran L, 2017, PROC CVPR IEEE, P1283, DOI 10.1109/CVPR.2017.141
   Venugopalan S, 2015, IEEE I CONF COMP VIS, P4534, DOI 10.1109/ICCV.2015.515
   Wang Y., 2019, P ICLR
   Wang ZW, 2018, PROC CVPR IEEE, P7939, DOI 10.1109/CVPR.2018.00828
   Weng CH, 2017, LECT NOTES COMPUT SC, V10118, P117, DOI 10.1007/978-3-319-54526-4_9
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu Qing, 2010, 2010 Proceedings of the Third International Symposium on Information Processing (ISIP 2010), P437, DOI 10.1109/ISIP.2010.116
   Huynh XP, 2017, LECT NOTES COMPUT SC, V10118, P134, DOI 10.1007/978-3-319-54526-4_10
   Yu J, 2019, IEEE T INTELL TRANSP, V20, P4206, DOI 10.1109/TITS.2018.2883823
   Yu J, 2017, STRUCTURES CONGRESS 2017: BLAST, IMPACT LOADING, AND RESPONSE OF STRUCTURES, P165
   Zhang KP, 2016, IEEE SIGNAL PROC LET, V23, P1499, DOI 10.1109/LSP.2016.2603342
   Zhang Y, 2019, J VIS COMMUN IMAGE R, V59, P501, DOI 10.1016/j.jvcir.2019.02.007
   Zhou P, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P207, DOI 10.18653/v1/p16-2034
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 64
TC 3
Z9 3
U1 4
U2 15
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1051-8215
EI 1558-2205
J9 IEEE T CIRC SYST VID
JI IEEE Trans. Circuits Syst. Video Technol.
PD DEC
PY 2020
VL 30
IS 12
BP 4755
EP 4768
DI 10.1109/TCSVT.2019.2958188
PG 14
WC Engineering, Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering
GA PD5VE
UT WOS:000597751000029
DA 2022-02-06
ER

PT J
AU Liu, B
   Tan, C
   Li, SQ
   He, JR
   Wang, HY
AF Liu, Bin
   Tan, Cheng
   Li, Shuqin
   He, Jinrong
   Wang, Hongyan
TI A Data Augmentation Method Based on Generative Adversarial Networks for
   Grape Leaf Disease Identification
SO IEEE ACCESS
LA English
DT Article
DE Generative adversarial networks; convolutional neural networks; data
   augmentation; grape leaf disease identification
ID CONVOLUTIONAL NEURAL-NETWORK; RECOGNITION; MODELS; GAN
AB The identification of grape leaf diseases based on deep learning is critical to controlling the spread of diseases and ensuring the healthy development of the grape industry. Focusing on the lack of training images of grape leaf diseases, this paper proposes a novel model named Leaf GAN, which is based on generative adversarial networks (GANs), to generate images of four different grape leaf diseases for training identification models. A generator model with degressive channels is first designed to generate grape leaf disease images; then, the dense connectivity strategy and instance normalization are fused into an efficient discriminator to identify real and fake disease images by utilizing their excellent feature extraction capability on grape leaf lesions. Finally, the deep regret gradient penalty method is applied to stabilize the training process of the model. Using a total of 4,062 grape leaf disease images, the Leaf GAN model ultimately generates 8,124 grape leaf disease images. The generated grape leaf disease images based on Leaf GAN model can obtain better performance than DCGAN and WGAN in terms of the Frechet inception distance. The experimental results show that the proposed Leaf GAN model generates sufficient grape leaf disease images with prominent lesions, providing a feasible solution for the data augmentation of grape leaf disease images. For the eight prevailing classification models with the expanded dataset, the identification performance based on CNNs indicated higher accuracies, whereby all the accuracies were better than those of the initial dataset with other data augmentation methods. Among them, Xception achieves a recognition accuracy of 98.70% on the testing set. The results demonstrate that the proposed data augmentation method represents a new approach to overcoming the overfitting problem in disease identification and can effectively improve the identification accuracy.
C1 [Liu, Bin; Tan, Cheng; Li, Shuqin] Northwest A&F Univ, Coll Informat Engn, Yangling 712100, Shaanxi, Peoples R China.
   [Liu, Bin; Li, Shuqin] Northwest A&F Univ, Key Lab Agr Internet Things, Minist Agr & Rural Affairs, Yangling 712100, Shaanxi, Peoples R China.
   [Liu, Bin] Northwest A&F Univ, Shaanxi Key Lab Agr Informat Percept & Intelligen, Yangling 712100, Shaanxi, Peoples R China.
   [He, Jinrong] Yanan Univ, Coll Math & Comp Sci, Yanan 712100, Peoples R China.
   [Li, Shuqin; Wang, Hongyan] Ningxia Smart Agr Ind Technol Collaborat Innovat, Yinchuan 750004, Ningxia, Peoples R China.
   [Wang, Hongyan] West Elect Business Co Ltd, Yinchuan 750004, Ningxia, Peoples R China.
C3 Northwest A&F University - China; Northwest A&F University - China;
   Northwest A&F University - China; Yanan University
RP Liu, B (corresponding author), Northwest A&F Univ, Coll Informat Engn, Yangling 712100, Shaanxi, Peoples R China.; Liu, B (corresponding author), Northwest A&F Univ, Key Lab Agr Internet Things, Minist Agr & Rural Affairs, Yangling 712100, Shaanxi, Peoples R China.; Liu, B (corresponding author), Northwest A&F Univ, Shaanxi Key Lab Agr Informat Percept & Intelligen, Yangling 712100, Shaanxi, Peoples R China.
EM liubin0929@nwsuaf.edu.cn
FU Key Research and Development Program of Shaanxi [2019ZDLNY07-06-01];
   Ningxia Smart Agricultural Industry Technology Collaborative Innovation
   Center [2017DC53]; Fundamental Research Funds for the Central
   UniversitiesFundamental Research Funds for the Central Universities
   [2452019064]; National Natural Science Foundation of ChinaNational
   Natural Science Foundation of China (NSFC) [61602388, 61902339]; China
   Postdoctoral Science FoundationChina Postdoctoral Science Foundation
   [2017M613216]; Natural Science Basic Research Plan in Shaanxi Province
   of China [2017JM6059]; Postdoctoral Science Foundation of Shaanxi
   Province of China [2016BSHEDZZ121]; Shaanxi Key Laboratory of
   Intelligent Processing for Big Energy Data; Yan'an University [IPBED14];
   Doctoral Starting Up Foundation of Yan'an University [YDBK2019-06];
   Innovation and Entrepreneurship Training Program of Northwest A&F
   University of China [201910712048]
FX This work was supported in part by the Key Research and Development
   Program of Shaanxi under Grant 2019ZDLNY07-06-01, in part by the Ningxia
   Smart Agricultural Industry Technology Collaborative Innovation Center
   under Grant 2017DC53, in part by the Fundamental Research Funds for the
   Central Universities under Grant 2452019064, in part by the National
   Natural Science Foundation of China under Grant 61602388 and Grant
   61902339, in part by the China Postdoctoral Science Foundation under
   Grant 2017M613216, in part by the Natural Science Basic Research Plan in
   Shaanxi Province of China under Grant 2017JM6059, in part by the
   Postdoctoral Science Foundation of Shaanxi Province of China under Grant
   2016BSHEDZZ121, in part by the Shaanxi Key Laboratory of Intelligent
   Processing for Big Energy Data, in part by the Yan'an University under
   Grant IPBED14, in part by the Doctoral Starting Up Foundation of Yan'an
   University under Grant YDBK2019-06, and in part by the Innovation and
   Entrepreneurship Training Program of Northwest A&F University of China
   under Grant 201910712048.
CR Ali-Gombe A, 2019, NEUROCOMPUTING, V361, P212, DOI 10.1016/j.neucom.2019.06.043
   Arjovsky M, 2017, ARXIV170107875
   Boulent J, 2019, FRONT PLANT SCI, V10, DOI 10.3389/fpls.2019.00941
   Bresilla K, 2019, FRONT PLANT SCI, V10, DOI 10.3389/fpls.2019.00611
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Din NU, 2020, IEEE ACCESS, V8, P44276, DOI 10.1109/ACCESS.2020.2977386
   Ferentinos KP, 2018, COMPUT ELECTRON AGR, V145, P311, DOI 10.1016/j.compag.2018.01.009
   Fuentes A, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17092022
   Ge CJ, 2020, IEEE ACCESS, V8, P22560, DOI 10.1109/ACCESS.2020.2969805
   Geetharamani G, 2019, COMPUT ELECTR ENG, V76, P323, DOI 10.1016/j.compeleceng.2019.04.011
   Glorot X., 2010, P 13 INT C ART INT S, P249
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Gulrajani I, 2017, ADV NEURAL INFORM PR, P5767
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Heusel M., P ADV NEUR INF PROC, V2017, P6626
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Ioffe S., 2015, P INT C MACH LEARN, P456
   Jiang P, 2019, IEEE ACCESS, V7, P59069, DOI 10.1109/ACCESS.2019.2914929
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Khan MA, 2018, COMPUT ELECTRON AGR, V155, P220, DOI 10.1016/j.compag.2018.10.013
   Kingma DP, 2014, 2 INT C LEARN REPR I, P1
   Kodali Naveen, 2017, ARXIV170507215
   Krizhevsky A., 2012, ADV NEURAL INF PROCE, P1097, DOI DOI 10.1145/3065386
   Laine, 2018, INT C LEARN REPR
   Larsen ABL, 2016, PR MACH LEARN RES, V48
   Lee H, 2020, IEEE ACCESS, V8, P48049, DOI 10.1109/ACCESS.2020.2979239
   Li F, 2020, RSC ADV, V10, P1, DOI 10.1039/c9ra08789c
   Liang WJ, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-38966-0
   Liu B, 2017, SYMMETRY, V10, P11
   Lu Y, 2017, NEUROCOMPUTING, V267, P378, DOI 10.1016/j.neucom.2017.06.023
   Metz L., 2016, P 4 INT C LEARNING R
   Mohanty SP, 2016, FRONT PLANT SCI, V7, DOI 10.3389/fpls.2016.01419
   Oppenheim D, 2019, PHYTOPATHOLOGY, V109, P1083, DOI 10.1094/PHYTO-08-18-0288-R
   Polder G, 2019, FRONT PLANT SCI, V10, DOI 10.3389/fpls.2019.00209
   Pu YY, 2019, ENERGIES, V12, DOI 10.3390/en12091735
   Qi GJ, 2020, INT J COMPUT VISION, V128, P1118, DOI 10.1007/s11263-019-01265-2
   Qu Y., 2019, P IEEE C COMP VIS PA, P8160
   Ramcharan A, 2019, FRONT PLANT SCI, V10, DOI 10.3389/fpls.2019.00272
   Saleem MH, 2019, PLANTS-BASEL, V8, DOI 10.3390/plants8110468
   Salimans T., 2016, ADV NEURAL INFORM PR, P2234
   Simonyan K, 2015, ICLR 2015, DOI DOI 10.1109/CVPR.2015.7298594
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tan MX, 2019, PR MACH LEARN RES, V97
   Ulyanov D., 2016, INSTANCE NORMALIZATI
   Warde-Farley D, 2016, NEURAL INF PROCESS S, P311
   Wu S, 2019, PROC CVPR IEEE, P10083, DOI 10.1109/CVPR.2019.01033
   Xian YQ, 2019, PROC CVPR IEEE, P10267, DOI 10.1109/CVPR.2019.01052
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yang YQ, 2020, IEEE ACCESS, V8, P42169, DOI 10.1109/ACCESS.2020.2977007
   Zhang H, 2017, IEEE I CONF COMP VIS, P5908, DOI 10.1109/ICCV.2017.629
   Zhang H, 2018, PROC INT CONF PARAL, DOI [10.1145/3225058.3225100, 10.1109/ICCChina.2018.8641243]
   Zhang SW, 2019, COMPUT ELECTRON AGR, V162, P422, DOI 10.1016/j.compag.2019.03.012
   Zhang SW, 2019, COGN SYST RES, V53, P31, DOI 10.1016/j.cogsys.2018.04.006
   Zheng ZD, 2019, PROC CVPR IEEE, P2133, DOI 10.1109/CVPR.2019.00224
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu YX, 2019, NEUROCOMPUTING, V365, P191, DOI 10.1016/j.neucom.2019.07.016
NR 58
TC 14
Z9 15
U1 19
U2 34
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2020
VL 8
BP 102188
EP 102198
DI 10.1109/ACCESS.2020.2998839
PG 11
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA MH0HC
UT WOS:000546410800028
OA gold
DA 2022-02-06
ER

PT J
AU Bimber, B
   de.Zuniga, HG
AF Bimber, Bruce
   Gil de Zuniga, Homero
TI The unedited public sphere
SO NEW MEDIA & SOCIETY
LA English
DT Article
DE Artificial intelligence; bot; computational propaganda; deepfake;
   machine learning; propaganda; public opinion; public sphere; social
   media army
ID POLITICAL COMMUNICATION; NEWS; DEMOCRACY; INTERNET; TWITTER; FALSE;
   TECHNOLOGIES; AFFORDANCES; KNOWLEDGE; MESSAGE
AB The health of democratic public spheres is challenged by the circulation of falsehoods. These epistemic problems are connected to social media and they raise a classic problem of how to understand the role of technology in political developments. We discuss three sets of technological affordances of social media that facilitate the spread of false beliefs: obscuring the provenance of information, facilitating deception about authorship, and providing for manipulation of social signals. We argue that these do not make social media a "cause" of problems with falsehoods, but explanations of epistemic problems should account for social media to understand the timing and widespread occurrence of epistemic problems. We argue that "the marketplace of ideas" cannot be adequate as a remedy for these problems, which require epistemic editing by the press.
C1 [Bimber, Bruce] Univ Calif Santa Barbara, Ctr Informat Technol & Soc, POLS 9420, Santa Barbara, CA 93106 USA.
   [Bimber, Bruce] Univ Calif Santa Barbara, Dept Polit Sci, POLS 9420, Santa Barbara, CA 93106 USA.
   [Gil de Zuniga, Homero] Univ Salamanca, Democracy Res Unit, Salamanca, Spain.
   [Gil de Zuniga, Homero] Penn State Univ, University Pk, PA 16802 USA.
C3 University of California System; University of California Santa Barbara;
   University of California System; University of California Santa Barbara;
   University of Salamanca; Pennsylvania Commonwealth System of Higher
   Education (PCSHE); Pennsylvania State University; Pennsylvania State
   University - University Park
RP Bimber, B (corresponding author), Univ Calif Santa Barbara, Ctr Informat Technol & Soc, POLS 9420, Santa Barbara, CA 93106 USA.; Bimber, B (corresponding author), Univ Calif Santa Barbara, Dept Polit Sci, POLS 9420, Santa Barbara, CA 93106 USA.
EM bimber@ucsb.edu
RI de Zuniga, Homero Gil/B-1651-2009
OI de Zuniga, Homero Gil/0000-0002-4187-3604; Bimber,
   Bruce/0000-0002-4458-5413
CR Abernathy P, 2018, U N CAROLINA SCH MED
   Abramowitz M, 2018, NY TIMES
   Bakker TP, 2011, COMMUN RES, V38, P451, DOI 10.1177/0093650210381738
   Benedictus L, 2016, GUARDIAN
   Benkler Yochai., 2018, NETWORK PROPAGANDA M
   Bennett L., 2019, NZ HERALD
   Bennett L. W., 1997, DEMOCRACY MARKETPLAC
   Bennett WL, 2018, J COMMUN, V68, P243, DOI 10.1093/joc/jqx017
   Bennett WL, 2018, EUR J COMMUN, V33, P122, DOI 10.1177/0267323118760317
   Bessi A, 2016, 1 MONDAY, V21, P11, DOI [DOI 10.5210/FM.V21I11.7090, 10.5210/fm.v21i11.7090]
   Blumler JG, 2018, JAVNOST-PUBLIC, V25, P83, DOI 10.1080/13183222.2018.1418799
   Blumler JG, 1999, POLIT COMMUN, V16, P209, DOI 10.1080/105846099198596
   Boczkowski PJ, 2018, NEW MEDIA SOC, V20, P3523, DOI 10.1177/1461444817750396
   Boukes M, 2019, J INF TECHNOL POLITI, V16, P36, DOI 10.1080/19331681.2019.1572568
   boyd d., 2011, NETWORKED SELF IDENT, P47, DOI DOI 10.4324/9780203876527
   Bradshaw S., 2017, 201712 OXF INT I
   Brazeal G, 2012, SO CALIFORNIA LAW IN, V21, P2
   Bucher J, 2018, STORYTELLING FOR VIRTUAL REALITY: METHODS AND PRINCIPLES FOR CRAFTING IMMERSIVE NARRATIVES, P233
   Castells M., 2015, NETWORKS OUTRAGE HOP, V2nd Edn
   Chang YT, 2015, J BUS RES, V68, P777, DOI 10.1016/j.jbusres.2014.11.027
   Dahlgren P, 2005, POLIT COMMUN, V22, P147, DOI 10.1080/10584600590933160
   Davis E., 2017, POST TRUTH WHY WE HA
   De Keersmaecker J, 2017, INTELLIGENCE, V65, P107, DOI 10.1016/j.intell.2017.10.005
   Dounoucos VA, 2019, J INF TECHNOL POLITI, V16, P66, DOI 10.1080/19331681.2019.1572566
   Evans SK, 2017, J COMPUT-MEDIAT COMM, V22, P35, DOI 10.1111/jcc4.12180
   Fagella D, 2018, VALUING ARTIFICIAL I
   Flynn DJ, 2017, POLIT PSYCHOL, V38, P127, DOI 10.1111/pops.12394
   Fourelle M, 2015, POLITICAL BOTS MANIP
   Gibson J. J., 1979, ECOLOGICAL APPROACH
   De Zuniga HG, 2015, INT J COMMUN-US, V9, P3152
   Good N, 2016, GUARDIAN
   Habermas J., 1989, STRUCTURAL TRANSFORM
   Hong S, 2018, J INF TECHNOL POLITI, V15, P388, DOI 10.1080/19331681.2018.1534703
   Howard P, 2016, SSRN, DOI [10.2139/ssrn.2798311, DOI 10.2139/SSRN.2798311]
   Hutchby I, 2001, SOCIOLOGY, V35, P441, DOI 10.1177/S0038038501000219
   King G, 2013, AM POLIT SCI REV, V107, P326, DOI 10.1017/S0003055413000014
   Leonardi PM, 2011, MIS QUART, V35, P147
   Leonardi PM, 2008, INFORM ORGAN-UK, V18, P159, DOI 10.1016/j.infoandorg.2008.03.001
   Levitsky Steven., 2018, DEMOCRACIES
   Majchrzak A, 2013, J COMPUT-MEDIAT COMM, V19, P38, DOI 10.1111/jcc4.12030
   Malnik E, 2018, TELEGRAPH
   Marconi F., 2018, WALL STREET J IS PRE
   Margolin DB, 2018, POLIT COMMUN, V35, P196, DOI 10.1080/10584609.2017.1334018
   Messing S, 2014, COMMUN RES, V41, P1042, DOI 10.1177/0093650212466406
   MILL JS, 2010, LIBERTY
   Milton J, 2006, AREOPAGITICA
   Mutz Diana C., 2015, YOUR FACE POLITICS C
   Najar A, 2015, BBC NEWS
   Neuman W. R., 2016, DIGITAL DIFFERENCE M
   Nyhan B, 2010, POLIT BEHAV, V32, P303, DOI 10.1007/s11109-010-9112-2
   Oren E, 2017, REPORT KNIGHT FDN
   Petty R., 1986, COMMUNICATION PERSUA, DOI DOI 10.1016/S0065-2601(08)60214-2
   Pfetsch B, 2018, JAVNOST-PUBLIC, V25, P59, DOI 10.1080/13183222.2018.1423942
   Rose J, 2017, PUBLIC INTEGR, V19, P555, DOI 10.1080/10999922.2017.1285540
   Statt N, 2018, VERGE           1102
   Suiter J., 2016, POLITICAL INSIGHT, V7, P25
   Suwajanakorn S, 2017, SIGGRAPH
   Swaine Jon, 2018, GUARDIAN
   Tabor C, 2013, RATIONALIZING VOTER
   Tucker J, 2018, SSRN, DOI 10.2139/ssrn.3144139
   Van Aelst P., 2017, ANN INT COMMUNICATIO, V41, DOI [10.1080/23808985.2017.1288551, DOI 10.1080/23808985.2017.1288551]
   Vosoughi S, 2018, SCIENCE, V359, P1146, DOI 10.1126/science.aap9559
   Vraga EK, 2018, INFORM COMMUN SOC, V21, P1337, DOI 10.1080/1369118X.2017.1313883
   Waisbord S, 2018, COMMUN RES PRACT, V4, P17, DOI 10.1080/22041451.2018.1428928
   Weeks BE, 2017, INT J PUBLIC OPIN R, V29, P214, DOI 10.1093/ijpor/edv050
   Wells T, 2013, THINK-PHILOS EVERYON, V12, P75, DOI 10.1017/S1477175612000309
   Wood T, 2019, POLIT BEHAV, V41, P135, DOI 10.1007/s11109-018-9443-y
   Woolley S, 2018, INT POLIT ECON SER, P127, DOI 10.1007/978-3-319-51466-6_7
   Zaller J., 1992, NATURE ORIGINS MASS NATURE ORIGINS MASS
NR 69
TC 20
Z9 20
U1 11
U2 45
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 1461-4448
EI 1461-7315
J9 NEW MEDIA SOC
JI New Media Soc.
PD APR
PY 2020
VL 22
IS 4
SI SI
BP 700
EP 715
DI 10.1177/1461444819893980
PG 16
WC Communication
WE Social Science Citation Index (SSCI)
SC Communication
GA KZ1PJ
UT WOS:000523041400007
DA 2022-02-06
ER

PT J
AU Wang, CY
   Ding, GL
   Liu, YT
   Xin, HLL
AF Wang, Chunyang
   Ding, Guanglei
   Liu, Yitong
   Xin, Huolin L.
TI 0.7 angstrom Resolution Electron Tomography Enabled by
   Deep-Learning-Aided Information Recovery
SO ADVANCED INTELLIGENT SYSTEMS
LA English
DT Article
DE 3D imaging; artificial intelligence; atomic structures; electron
   tomography; machine learning; sub-angstrom
ID RECONSTRUCTION; MICROTOMOGRAPHY; DIMENSIONS; MICROSCOPY
AB The 3D determination of a nanomaterial's atomic structure is crucial for understanding their physical, chemical, and electronic properties. Electron tomography, as an important 3D imaging method, offers a powerful method to probe the 3D structure of materials from nanoscale to atomic scale. However, the grand challenge-the missing-wedge-induced information loss and artifacts-has greatly hindered them from obtaining 3D atomic structures with high contrast, high precision, and high fidelity. Herein, for the first time, by combining atomic electron tomography with an artificially intelligent "deepfake" neural network, this work demonstrates that the resolution of 3D imaging can be improved down to 0.71 angstrom, which is a record high resolution achieved by electron tomography. It is also shown that the lost information in reconstructed tomograms can be effectively recovered by only acquiring data from -50 to +50 degrees (44% reduction of dosage compared with -90 to +90 degrees full tilt series). In contrast to conventional methods, the deep-learning model shows outstanding performance for both macroscopic objects and atomic features solving the long-standing dosage and missing-wedge problems in electron tomography. This work provides important guidance for the application of machine learning methods to tomographic imaging atomic-scale features in nanomaterials.
C1 [Wang, Chunyang; Ding, Guanglei; Xin, Huolin L.] Univ Calif Irvine, Dept Phys & Astron, Irvine, CA 92697 USA.
   [Ding, Guanglei; Liu, Yitong] Beijing Univ Posts & Telecommun, Sch Informat & Commun Engn, Beijing 100876, Peoples R China.
C3 University of California System; University of California Irvine;
   Beijing University of Posts & Telecommunications
RP Xin, HLL (corresponding author), Univ Calif Irvine, Dept Phys & Astron, Irvine, CA 92697 USA.; Liu, YT (corresponding author), Beijing Univ Posts & Telecommun, Sch Informat & Commun Engn, Beijing 100876, Peoples R China.
EM liuyitong@bupt.edu.cn; huolinx@uci.edu
RI WANG, CHUNYANG/AAM-6770-2021; Xin, Huolin L./E-2747-2010
OI WANG, CHUNYANG/0000-0001-8461-3952; Xin, Huolin L./0000-0002-6521-868X
CR Bals S, 2014, ANGEW CHEM INT EDIT, V53, P10600, DOI 10.1002/anie.201401059
   Bartolac S, 2009, MED PHYS, V36, P500, DOI 10.1118/1.3062875
   Batenburg KJ, 2009, ULTRAMICROSCOPY, V109, P730, DOI 10.1016/j.ultramic.2009.01.009
   Boudjelal A, 2017, J MED IMAGING RADIAT, V48, P385, DOI 10.1016/j.jmir.2017.09.005
   Candes E. J., 2006, P INT C MATH, V3, P1433, DOI DOI 10.4171/022-3/69
   Cardoso M.J., 2017, DEEP LEARNING MED IM
   Chen CC, 2013, NATURE, V496, P74, DOI 10.1038/nature12009
   Dearnaley WJ, 2019, NANO LETT, V19, P6734, DOI 10.1021/acs.nanolett.9b01309
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   DEROSIER DJ, 1968, NATURE, V217, P130, DOI 10.1038/217130a0
   Ding CX, 2018, IEEE T PATTERN ANAL, V40, P1002, DOI 10.1109/TPAMI.2017.2700390
   Ding GL, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-49267-x
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Fan QY, 2016, NEUROIMAGE, V124, P1108, DOI 10.1016/j.neuroimage.2015.08.075
   Frank J., 2006, ELECT TOMOGRAPHY MET, V2nd, pXIV
   Goris B, 2012, ULTRAMICROSCOPY, V113, P120, DOI 10.1016/j.ultramic.2011.11.004
   Goris B, 2012, NAT MATER, V11, P930, DOI [10.1038/NMAT3462, 10.1038/nmat3462]
   Hagita K, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-24330-1
   Han LL, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms13335
   Hesamian MH, 2019, J DIGIT IMAGING, V32, P582, DOI 10.1007/s10278-019-00227-x
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Iandola F., 2014, ARXIV PREPRINT ARXIV
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Jinnai H, 2010, MACROMOLECULES, V43, P1675, DOI 10.1021/ma902035p
   Jolicoeur-Martineau A., 2018, ARXIV PREPRINT ARXIV
   Kawase N, 2007, ULTRAMICROSCOPY, V107, P8, DOI 10.1016/j.ultramic.2006.04.007
   Klambauer G., 2017, PROC 31 INT C NEURAL, P971, DOI DOI 10.5555/3294771.3294864
   Li XM, 2018, IEEE T MED IMAGING, V37, P2663, DOI 10.1109/TMI.2018.2845918
   Lim J, 2015, OPT EXPRESS, V23, P16933, DOI 10.1364/OE.23.016933
   Lin Yang, 2017, Medical Image Computing and Computer Assisted Intervention - MICCAI 2017. 20th International Conference. Proceedings: LNCS 10435, P399, DOI 10.1007/978-3-319-66179-7_46
   Lustig M, 2007, MAGN RESON MED, V58, P1182, DOI 10.1002/mrm.21391
   Mao Xudong, 2017, P IEEE INT C COMP VI
   Midgley PA, 2003, ULTRAMICROSCOPY, V96, P413, DOI 10.1016/S0304-3991(03)00105-0
   Midgley PA, 2009, NAT MATER, V8, P271, DOI 10.1038/nmat2406
   Nehme E, 2018, OPTICA, V5, P458, DOI 10.1364/OPTICA.5.000458
   Nicholas A, 2012, J NUCL MED, V53
   Ouyang W, 2018, NAT BIOTECHNOL, V36, P460, DOI 10.1038/nbt.4106
   Scott MC, 2012, NATURE, V483, P444, DOI 10.1038/nature10934
   Simonyan K, 2015, ICLR 2015, DOI DOI 10.1109/CVPR.2015.7298594
   Song M, 2016, METALL MATER TRANS A, V47A, P2410, DOI 10.1007/s11661-016-3380-3
   Sun H., 2019, INT WORKSH STAT ATL, P280
   Van Aert S, 2011, NATURE, V470, P374, DOI 10.1038/nature09741
   Wang CY, 2018, PHYS REV LETT, V120, DOI 10.1103/PhysRevLett.120.186102
   Wang HD, 2019, NAT METHODS, V16, P103, DOI 10.1038/s41592-018-0239-0
   Xu R, 2015, NAT MATER, V14, P1099, DOI [10.1038/nmat4426, 10.1038/NMAT4426]
   Yan HF, 2020, MRS BULL, V45, P264, DOI 10.1557/mrs.2020.90
   Yang YS, 2017, NATURE, V542, P75, DOI 10.1038/nature21042
   Zheng HL, 2017, IEEE I CONF COMP VIS, P5219, DOI 10.1109/ICCV.2017.557
   Zhou JH, 2019, NATURE, V570, P500, DOI 10.1038/s41586-019-1317-x
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI 10.1007/978-3-030-00889-5_1
   Zhou ZW, 2020, IEEE T MED IMAGING, V39, P1856, DOI 10.1109/TMI.2019.2959609
NR 52
TC 9
Z9 10
U1 2
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
EI 2640-4567
J9 ADV INTELL SYST-GER
JI Adv. Intell. Syst.
PD DEC
PY 2020
VL 2
IS 12
AR 2000152
DI 10.1002/aisy.202000152
PG 9
WC Automation & Control Systems; Computer Science, Artificial Intelligence;
   Robotics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Automation & Control Systems; Computer Science; Robotics
GA TE1SR
UT WOS:000669797300010
OA gold
DA 2022-02-06
ER

PT J
AU Alipour-Fard, T
   Arefi, H
AF Alipour-Fard, Tayeb
   Arefi, Hossein
TI Structure Aware Generative Adversarial Networks for Hyperspectral Image
   Classification
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE
   SENSING
LA English
DT Article
DE Training; Gallium nitride; Hyperspectral imaging; Training data;
   Generators; Task analysis; Deep learning (DL); hyperspectral images
   (HSIs); convolutional neural network (CNN); generative adversarial
   networks (GANs); remote sensing
ID NEURAL-NETWORK
AB Generative adversarial networks (GANs) have shown striking performances in computer vision applications to augment virtual training samples (VTS). However, the VTS generating by GANs in the context of hyperspectral image classification suffer from structural inconsistency due to the insufficient number of training samples in order to learn high-order features from the discriminator. This work addresses the scarcity of training samples by designing a GAN, in which the performance of discriminator is improved to produce more structurally coherent VTS. In the proposed method, by splitting the discriminator into two parts, GAN undertakes two tasks: the main task is to learn to distinguish between real and fake samples, and the auxiliary task is to learn to distinguish structurally corrupted and real samples. With this setup, GAN will produce real-like VTS with a higher variation than conventional GAN. Furthermore, in order to reduce the computational cost, subspace-based dimension reduction was performed to obtain the dominant features around the training samples to generate meaningful patterns from the original ones to be used in the learning phase. Based on the experimental results on real, and well-known hyperspectral benchmark images, the proposed method improves the performance compared with GANs-related, and conventional data augmentation strategies.(1)
C1 [Alipour-Fard, Tayeb; Arefi, Hossein] Univ Tehran, Sch Surveying & Geospatial Engn, Tehran 1417466191, Iran.
C3 University of Tehran
RP Arefi, H (corresponding author), Univ Tehran, Sch Surveying & Geospatial Engn, Tehran 1417466191, Iran.
EM tayebalipour@ut.ac.ir; hossein.arefi@ut.ac.ir
RI Alipour-Fard, Tayeb/AAB-6548-2019
OI Alipour-Fard, Tayeb/0000-0003-4777-0128
CR Alipour-Fard T, 2021, IEEE GEOSCI REMOTE S, V18, P1089, DOI 10.1109/LGRS.2020.2990971
   Alipourfard T., 2019, INT ARCH PHOTOGRAMM, V42, P63, DOI [10.5194/isprs-archives-XLII-4-W18-63-2019, DOI 10.5194/ISPRS-ARCHIVES-XLII-4-W18-63-2019]
   Arjovsky M., 2017, ADV NEURAL INFORM PR, P5769
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Basaeed E, 2016, KNOWL-BASED SYST, V99, P19, DOI 10.1016/j.knosys.2016.01.028
   Bittner K, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111262
   Bordes A, 2012, P 15 INT C ARTIFICIA, P127
   Canziani A., 2016, ARXIV160507678, DOI DOI 10.1002/(SICI)1520-6416(199906)127:439::AID-EEJ53.0.CO;2-8
   Chen T, 2019, PROC CVPR IEEE, P12146, DOI 10.1109/CVPR.2019.01243
   Chen YS, 2019, IEEE T GEOSCI REMOTE, V57, P7048, DOI 10.1109/TGRS.2019.2910603
   Chen YS, 2016, IEEE T GEOSCI REMOTE, V54, P6232, DOI 10.1109/TGRS.2016.2584107
   Chintala S, 2015, ARXIV151106434
   Debes C, 2014, IEEE J-STARS, V7, P2405, DOI 10.1109/JSTARS.2014.2305441
   Feng J, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12071149
   Feng J, 2019, IEEE T GEOSCI REMOTE, V57, P5329, DOI 10.1109/TGRS.2019.2899057
   Ghamisi P, 2016, IEEE GEOSCI REMOTE S, V13, P1537, DOI 10.1109/LGRS.2016.2595108
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   HE KM, 2016, PROC CVPR IEEE, P770, DOI DOI 10.1109/CVPR.2016.90
   He NJ, 2019, IEEE T GEOSCI REMOTE, V57, P755, DOI 10.1109/TGRS.2018.2860464
   He T, 2019, PROC CVPR IEEE, P558, DOI 10.1109/CVPR.2019.00065
   He Z, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9101042
   Huang R, 2020, IEEE WINT CONF APPL, P3183, DOI 10.1109/WACV45572.2020.9093525
   Ju Y., 2018, ARXIV180901436
   Karras T., 2017, ARXIV171010196
   Khan A, 2020, ARTIF INTELL REV, V53, P5455, DOI 10.1007/s10462-020-09825-6
   Kingma DP, 2015, 3 INT C LEARN REPR I, DOI DOI 10.1145/1830483.1830503
   Krizhevsky A., 2012, ADV NEURAL INF PROCE, P1097, DOI DOI 10.1145/3065386
   Kunkel B., 1988, P OPTOELECTR TECHN R, DOI [10.1117/12.943611, DOI 10.1117/12.943611]
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li J, 2012, IEEE T GEOSCI REMOTE, V50, P809, DOI 10.1109/TGRS.2011.2162649
   Li W, 2019, IEEE GEOSCI REMOTE S, V16, P593, DOI 10.1109/LGRS.2018.2878773
   Li W, 2017, IEEE T GEOSCI REMOTE, V55, P844, DOI 10.1109/TGRS.2016.2616355
   Li Y, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9010067
   Ma XR, 2016, ISPRS J PHOTOGRAMM, V120, P99, DOI 10.1016/j.isprsjprs.2016.09.001
   Melgani F, 2004, IEEE T GEOSCI REMOTE, V42, P1778, DOI 10.1109/TGRS.2004.831865
   Mirza M., 2014, ARXIV14111784, P1
   Miyato T., 2018, ICLR
   Pan B, 2018, ISPRS J PHOTOGRAMM, V145, P108, DOI 10.1016/j.isprsjprs.2017.11.003
   Paoletti ME, 2019, ISPRS J PHOTOGRAMM, V158, P279, DOI 10.1016/j.isprsjprs.2019.09.006
   Paoletti ME, 2018, ISPRS J PHOTOGRAMM, V145, P120, DOI 10.1016/j.isprsjprs.2017.11.021
   Plaza A, 2009, REMOTE SENS ENVIRON, V113, pS110, DOI 10.1016/j.rse.2007.07.028
   Qin Y., 2018, ARXIV181109567
   Rasti B, 2020, IEEE GEOSC REM SEN M, V8, P60, DOI 10.1109/MGRS.2020.2979764
   Romero A, 2016, IEEE T GEOSCI REMOTE, V54, P1349, DOI 10.1109/TGRS.2015.2478379
   Signoroni A, 2019, J IMAGING, V5, DOI 10.3390/jimaging5050052
   Szegedy C., 2013, ADV NEURAL INF PROCE, P2553, DOI DOI 10.5555/2999792.2999897
   Tao C, 2020, IEEE J-STARS, V13, P914, DOI 10.1109/JSTARS.2020.2974577
   Wang WY, 2021, IEEE GEOSCI REMOTE S, V18, P523, DOI 10.1109/LGRS.2020.2976482
   Windrim L, 2018, IEEE T GEOSCI REMOTE, V56, P2798, DOI 10.1109/TGRS.2017.2783886
   Wu H, 2018, IEEE T IMAGE PROCESS, V27, P1259, DOI 10.1109/TIP.2017.2772836
   Xu YH, 2019, IEEE J-STARS, V12, P1709, DOI 10.1109/JSTARS.2019.2911113
   Yu SQ, 2017, NEUROCOMPUTING, V219, P88, DOI 10.1016/j.neucom.2016.09.010
   Zhang MY, 2019, IEEE T GEOSCI REMOTE, V57, P2669, DOI 10.1109/TGRS.2018.2876123
   Zhang XR, 2014, IEEE J-STARS, V7, P2044, DOI 10.1109/JSTARS.2014.2325741
   Zhao W, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12142185
   Zhao WZ, 2016, IEEE T GEOSCI REMOTE, V54, P4544, DOI 10.1109/TGRS.2016.2543748
   Zhong ZL, 2018, THIRTY-SECOND AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTIETH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / EIGHTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P8191
   Zhou XY, 2019, J SENSORS, V2019, DOI 10.1155/2019/5067081
   Zhu L, 2018, IEEE T GEOSCI REMOTE, V56, P5046, DOI 10.1109/TGRS.2018.2805286
NR 60
TC 0
Z9 0
U1 5
U2 12
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PY 2020
VL 13
BP 5424
EP 5438
DI 10.1109/JSTARS.2020.3022781
PG 15
WC Engineering, Electrical & Electronic; Geography, Physical; Remote
   Sensing; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Physical Geography; Remote Sensing; Imaging Science &
   Photographic Technology
GA NU7EG
UT WOS:000573802800004
OA gold
DA 2022-02-06
ER

PT J
AU Shamsolmoali, P
   Zareapoor, M
   Shen, LL
   Sadka, AH
   Yang, J
AF Shamsolmoali, Pourya
   Zareapoor, Masoumeh
   Shen, Linlin
   Sadka, Abdul Hamid
   Yang, Jie
TI Imbalanced data learning by minority class augmentation using capsule
   adversarial networks
SO NEUROCOMPUTING
LA English
DT Article
DE Adversarial network; Imbalanced learning; Capsule network; Multiclass
   discriminator; Data generation
ID SELECTION; SMOTE
AB The fact that image datasets are often imbalanced poses an intense challenge for deep learning techniques. In this paper, we propose a method to restore the balance in imbalanced images, by coalescing two concurrent methods, generative adversarial networks (GANs) and capsule network. In our model, generative and discriminative networks play a novel competitive game, in which the generator generates samples towards specific classes from multivariate probabilities distribution. The discriminator of our model is designed in a way that while recognizing the real and fake samples, it is also requires to assign classes to the inputs. Since GAN approaches require fully observed data during training, when the training samples are imbalanced, the approaches might generate similar samples which leading to data overfitting. This problem is addressed by providing all the available information from both the class components jointly in the adversarial training. It improves learning from imbalanced data by incorporating the majority distribution structure in the generation of new minority samples. Furthermore, the generator is trained with feature matching loss function to improve the training convergence. In addition, prevents generation of outliers and does not affect majority class space. The evaluations show the effectiveness of our proposed methodology; in particular, the coalescing of capsuleGAN is effective at recognizing highly overlapping classes with much fewer parameters compared with the convolutional-GAN. (c) 2020 Elsevier B.V. All rights reserved.
C1 [Shamsolmoali, Pourya; Zareapoor, Masoumeh; Yang, Jie] Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai, Peoples R China.
   [Shen, Linlin] Shenzhen Univ, Inst Comp Vis, Shenzhen, Peoples R China.
   [Sadka, Abdul Hamid] Brunel Univ, Digital Sci & Technol Hub, London, England.
C3 Shanghai Jiao Tong University; Shenzhen University; Brunel University
RP Yang, J (corresponding author), Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai, Peoples R China.
EM Jieyang@sjtu.edu.cn
FU NSFCNational Natural Science Foundation of China (NSFC) [61876107,
   U1803261]; Committee of Science and Technology, Shanghai [19510711200]
FX This work is supported by NSFC (No: 61876107, U1803261) and Committee of
   Science and Technology, Shanghai (No. 19510711200).
CR Ali-Gombe A, 2019, NEUROCOMPUTING, V361, P212, DOI 10.1016/j.neucom.2019.06.043
   Ando S, 2017, LECT NOTES ARTIF INT, V10534, P770, DOI 10.1007/978-3-319-71249-9_46
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Dai Zihang, 2017, ADV NEURAL INFORM PR
   Das S, 2018, PATTERN RECOGN, V81, P674, DOI 10.1016/j.patcog.2018.03.008
   De Vries Harm, 2017, P ADV NEUR INF PROC, P6594
   Dong Q, 2019, IEEE T PATTERN ANAL, V41, P1367, DOI 10.1109/TPAMI.2018.2832629
   Douzas G, 2018, EXPERT SYST APPL, V91, P464, DOI 10.1016/j.eswa.2017.09.030
   Edwards H., 2017, ARXIV171104340
   Eghbal-Zadeh H, 2019, PROC CVPR IEEE, P5813, DOI 10.1109/CVPR.2019.00597
   Fernandez A., 2018, LEARNING IMBALANCED, DOI [10.1007/978-3-319-98074-4, DOI 10.1007/978-3-319-98074-4]
   Fernandez A, 2018, J ARTIF INTELL RES, V61, P863, DOI 10.1613/jair.1.11192
   Ferrarini B, 2019, LECT NOTES COMPUT SC, V11482, P90, DOI 10.1007/978-3-030-20205-7_8
   Fiore U, 2017, INFORM SCIENCES
   Garcia S, 2018, INFORM SCIENCES, V445, P22, DOI 10.1016/j.ins.2018.03.002
   Ghosh A, 2018, PROC CVPR IEEE, P8513, DOI 10.1109/CVPR.2018.00888
   Gonzalez S, 2019, INFORM SCIENCES, V474, P187, DOI 10.1016/j.ins.2018.09.062
   Gonzalez S, 2017, PATTERN RECOGN, V70, P12, DOI 10.1016/j.patcog.2017.04.028
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gurumurthy S, 2017, PROC CVPR IEEE, P4941, DOI 10.1109/CVPR.2017.525
   He HB, 2008, IEEE IJCNN, P1322, DOI 10.1109/IJCNN.2008.4633969
   Heusel M., ADV NEURAL INFORM PR, P6626
   Hinton GE, 2011, LECT NOTES COMPUT SC, V6791, P44, DOI 10.1007/978-3-642-21735-7_6
   Huang C, 2016, PROC CVPR IEEE, P5375, DOI 10.1109/CVPR.2016.580
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jaiswal A, 2018, P EUR C COMP VIS EC
   Jichao Zhao, 2016, 2016 13th International Conference on Service Systems and Service Management (ICSSSM), P1, DOI 10.1109/ICSSSM.2016.7538614
   Jimenez-Sanchez Amelia, 2018, Intravascular Imaging and Computer Assisted Stenting and Large-Scale Annotation of Biomedical Data and Expert Label Synthesis. 7th Joint International Workshop, CVII-STENT 2018 and Third International Workshop, LABELS 2018. Held in Conjunction with MICCAI 2018. Proceedings: Lecture Notes in Computer Science (LNCS 11043), P150, DOI 10.1007/978-3-030-01364-6_17
   Juefei-Xu F, AS C COMP VIS, P3
   Kliger M, 2018, ARXIV PREPRINT ARXIV
   Krizhevsky A., 2009, TECHNICAL REPORT, DOI 10.1.1.222.9220
   Kuncheva LI, 2019, PROG ARTIF INTELL, V8, P215, DOI 10.1007/s13748-019-00172-4
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li S, 2019, TRANSPORT RES B-METH, V129, P193, DOI 10.1016/j.trb.2019.09.008
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Mariani G., 2018, P IEEE C COMP VIS PA
   Memisevic R., 2016, GENERATIVE ADVERSARI
   Miyato T, 2018, INT C LEARN REPR
   Montahaei E., 2018, ARXIV181108812
   Mullick SS, 2019, IEEE I CONF COMP VIS, P1695, DOI 10.1109/ICCV.2019.00178
   Nair V., 2010, P 27 INT C MACH LEAR, P807
   Odena A, 2017, PR MACH LEARN RES, V70
   Radford A., 2015, ARXIV151106434
   Sabour S., 2017, ADV NEURAL INFORM PR, P3856
   Salimans T., 2016, ADV NEURAL INFORM PR, P2234
   Shamsolmoali P, 2019, NEUROCOMPUTING, V366, P140, DOI 10.1016/j.neucom.2019.07.094
   Singh Naman Deep, 2018, COMPUT SCI
   Stallkamp J, 2012, NEURAL NETWORKS, V32, P323, DOI 10.1016/j.neunet.2012.02.016
   Xiao H., 2017, ABS170807747 CORR
   Yang J., 2019, NEURAL COMPUT APPL, P1
   Zhang XY, 2015, APPL INTELL, V42, P544, DOI 10.1007/s10489-014-0610-5
   Zhang YZ, 2017, PR MACH LEARN RES, V70
NR 52
TC 8
Z9 8
U1 9
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0925-2312
EI 1872-8286
J9 NEUROCOMPUTING
JI Neurocomputing
PD OCT 12
PY 2021
VL 459
BP 481
EP 493
DI 10.1016/j.neucom.2020.01.119
PG 13
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WM4QE
UT WOS:000711070700021
OA Green Submitted
DA 2022-02-06
ER

PT J
AU Wijermars, M
AF Wijermars, Marielle
TI Russia's law 'On news aggregators': Control the news feed, control the
   news?
SO JOURNALISM
LA English
DT Article
DE algorithmic recommender systems; censorship; internet governance; media
   regulation; news aggregators; Russia
ID MEDIA; CONSUMPTION; PERSUASION; PLATFORMS; INTERNET; SPEECH
AB On 1 January 2017, a Russian federal law (208-FZ) came into force that holds news aggregators liable for spreading fake news. Links to news items that originate from registered media outlets - a state-regulated category - are, however, exempt from liability. As a result, news aggregators, such as Yandex News, have revised their algorithms to avoid legal claims. This article argues that the law has created a mechanism of indirect media control enabling the Russian state to influence online news dissemination through existing media regulation structures. It conceptualises five ways in which this mechanism can affect media pluralism in Russia's online news environment, given news aggregators' function as algorithmic gatekeepers directing traffic to news websites. The article argues that the law 'On news aggregators' exemplifies the diversification of Russian regulation of online news from controlling content and targeting content producers towards governing the algorithmic infrastructures that shape news dissemination.
C1 [Wijermars, Marielle] Univ Helsinki, Aleksanteri Inst, Helsinki, Finland.
   [Wijermars, Marielle] Univ Helsinki, Helsinki, Finland.
C3 University of Helsinki; University of Helsinki
RP Wijermars, M (corresponding author), Maastricht Univ, POB 616, NL-6200 MD Maastricht, Netherlands.
EM m.wijermars@maastrichtuniversity.nl
OI Wijermars, Marielle/0000-0001-7735-4403
FU University of Hamburg; Leibniz Institute for Media Research | Hans
   Bredow Institute
FX Previous versions of this article were presented at the British
   Association for Slavonic and East European Studies (BASEES) Annual
   Conference, the University of Bremen and the University of Hamburg. I
   would like to thank the members of the audience of the respective events
   for their valuable feedback. I am also indebted to the Leibniz Institute
   for Media Research | Hans Bredow Institute (HBI) where, during my time
   as an 'Algorithmed Public Spheres' visiting postdoctoral research
   fellow, this research was initiated. Finally, I am thankful to two
   anonymous reviewers for their thoughtful and constructive comments and
   suggestions.
CR [Anonymous], 2016, POIASNITELNAIA  0225
   Balkin JM, 2014, HARVARD LAW REV, V127, P2296
   Bodrunova SS, 2021, JOURNALISM, V22, P2919, DOI 10.1177/1464884920941965
   Bryzgalova E., 2017, VEDOMOSTI       0326
   Dauce F, 2017, LAB-RUSS REV SOC RES, V9, P112, DOI 10.25285/2078-1938-2017-9-2-112-132
   De Corniere A, 2017, 1707 NET, DOI [12/2014/08/Social_media_and_competition-Corniere-Sarvary.pdf, DOI 12/2014/08/SOCIAL_MEDIA_AND_COMPETITION-CORNIERE-SARVARY.PDF]
   Enikolopov R, 2011, AM ECON REV, V101, P3253, DOI 10.1257/aer.101.7.3253
   Ermoshina K, 2017, MEDIA COMMUN-LISBON, V5, P42, DOI 10.17645/mac.v5i1.816
   Fredheim R, 2017, POST-SOV AFF, V33, P34, DOI 10.1080/1060586X.2016.1200797
   GfK, 2019, ISSL GFK PRON INT RO
   Gil R., 2018, WHAT DO NEWS AGGREGA
   Gritsenko D., 2021, PALGRAVE HDB DIGITAL, P1
   Heintz, 2017, AP              0326
   Interfax, 2016, MINK RASKR PRIR NOV
   Kovalev A, 2021, JOURNALISM, V22, P2906, DOI 10.1177/1464884920941964
   Levada Center, 2020, ROSS MED 2020
   Litvinenko A., 2020, DEMOKRATIZATSIYA J P, V28, P393
   Litvinenko A, 2019, PUBLIZISTIK, V64, P225, DOI DOI 10.1007/S11616-019-00486-2
   Lonkila M, 2020, BASEES-ROUT SER RUSS, P17
   Martin GJ, 2017, AM ECON REV, V107, P2565, DOI 10.1257/aer.20160812
   Medialogii, 2020, SMI SOTSM SENT 2020
   Napoli PM, 2015, TELECOMMUN POLICY, V39, P751, DOI 10.1016/j.telpol.2014.12.003
   Napoli PM, 2014, COMMUN THEOR, V24, P340, DOI 10.1111/comt.12039
   Newman N., 2017, REUTERS I DIGITAL NE
   Newman N, 2019, REUTERS I DIGITAL NE
   Nocetti J, 2015, INTERNET POLICY REV, V4, DOI 10.14763/2015.4.380
   Pal J., 2017, IMPACT NEWS AGGREGAT
   Pallin CV, 2017, POST-SOV AFF, V33, P16, DOI 10.1080/1060586X.2015.1121712
   Rulyova N, 2017, DIGIT JOURNAL, V5, P986, DOI 10.1080/21670811.2017.1351882
   Rusiaeva, 2017, RBK             0324
   Rustamova F., 2018, BBC RUSSIAN SER 1218
   Ruzmanova, 2016, ZACHEM NUZHEN ZAKON
   Schimpf?ssl E., 2017, RUSSIAN POLITICS, V2, P32, DOI DOI 10.1163/2451-8921-00201003
   Sivetc L, 2020, BASEES-ROUT SER RUSS, P39
   Sivetc L, 2019, INT J LAW INFORM TEC, V27, P28, DOI 10.1093/ijlit/eay016
   Soldatov A, 2015, RED WEB KREMLINS WAR
   Soldatov O, 2019, ISR LAW REV, V52, P61, DOI 10.1017/S0021223718000250
   State Duma, 2016, STEN OBS
   State Duma, 2018, POIASNITELNAIA  1022
   Surganova E., 2016, RBK             0226
   Szostek J, 2017, EUROPE-ASIA STUD, V69, P284, DOI 10.1080/09668136.2016.1274019
   Urman A, 2019, INT J COMMUN-US, V13, P5158
   Voletskaia K., 2016, VEDOMOSTI       0315
   Volkov Denis, 2017, LEVADA TSENTR
   Wallace J, 2018, DIGIT JOURNAL, V6, P274, DOI 10.1080/21670811.2017.1343648
   Wijermars M., 2019, 69 ANN INT COMM ASS
   Wijermars M, 2020, BASEES-ROUT SER RUSS, P1
   Yandex, 2016, POSL NOV
   Yandex, 2017, NOVOSTI ZA VOSK 0327
   Yandex.Radar, 2020, PROEKT IAND ROSS
   Zvereva V, 2020, BASEES-ROUT SER RUSS, P225
NR 51
TC 4
Z9 4
U1 3
U2 8
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 1464-8849
EI 1741-3001
J9 JOURNALISM
JI Journalism
PD DEC
PY 2021
VL 22
IS 12
SI SI
BP 2938
EP 2954
AR 1464884921990917
DI 10.1177/1464884921990917
EA FEB 2021
PG 17
WC Communication
WE Social Science Citation Index (SSCI)
SC Communication
GA XG8HN
UT WOS:000620317600001
DA 2022-02-06
ER

PT J
AU Nandanwar, L
   Shivakumara, P
   Pal, U
   Lu, T
   Lopresti, D
   Seraogi, B
   Chaudhuri, BB
AF Nandanwar, Lokesh
   Shivakumara, Palaiahnakote
   Pal, Umapada
   Lu, Tong
   Lopresti, Daniel
   Seraogi, Bhagesh
   Chaudhuri, Bidyut B.
TI A New Method for Detecting Altered Text in Document Images
SO INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE
LA English
DT Article
DE Document digitization; DCT coefficients; fused image; altered text
   detection; fraud document; CNN
ID FUSION
AB As more and more office documents are captured, stored, and shared in digital format, and as image editing software are becoming increasingly more powerful, there is a growing concern about document authenticity. To prevent illicit activities, this paper presents a new method for detecting altered text in document images. The proposed method explores the relationship between positive and negative coefficients of DCT to extract the effect of distortions caused by tampering by fusing reconstructed images of respective positive and negative coefficients, which results in Positive-Negative DCT coefficients Fusion (PNDF). To take advantage of spatial information, we propose to fuse R, G, and B color channels of input images, which results in RGBF (RGB Fusion). Next, the same fusion operation is used for fusing PNDF and RGBF, which results in a fused image for the original input one. We compute a histogram to extract features from the fused image, which results in a feature vector. The feature vector is then fed to a deep neural network for classifying altered text images. The proposed method is tested on our own dataset and the standard datasets from the ICPR 2018 Fraud Contest, Altered Handwriting (AH), and faked IMEI number images. The results show that the proposed method is effective and the proposed method outperforms the existing methods irrespective of image type.
C1 [Shivakumara, Palaiahnakote] Univ Malaya, Fac Comp Sci & Informat Technol, Kuala Lumpur, Malaysia.
   [Pal, Umapada; Seraogi, Bhagesh] Indian Stat Inst, Comp Vis & Pattern Recognit Unit, Kolkata, India.
   [Lu, Tong] Nanjing Univ, Natl Key Lab Novel Software Technol, Nanjing, Peoples R China.
   [Lopresti, Daniel] Lehigh Univ, Comp Sci & Engn, Bethlehem, PA 18015 USA.
   [Chaudhuri, Bidyut B.] Techno India Univ, Comp Sci & Engn, Sect 5, Kolkata, India.
C3 Universiti Malaya; Indian Statistical Institute; Indian Statistical
   Institute Kolkata; Nanjing University; Lehigh University
RP Shivakumara, P (corresponding author), Univ Malaya, Fac Comp Sci & Informat Technol, Kuala Lumpur, Malaysia.
EM lokeshnandanwar150@gmail.com; shiva@um.edu.my; umapada@isical.ac.in;
   lutong@nju.edu.cn; lopresti@cse.lehigh.edu; to.bhagesh.sr@gmail.com;
   bbcisical@gmail.com
RI Pal, Umapada/AAC-4930-2022
FU University of Malaya, MalaysiaUniversiti Malaya [GPF096A-2020,
   GPF096B-2020, GPF096C-2020]
FX Palaiahnakote Shivakumara, Lokesh Nandanwar and Umapada Pal of this work
   have received partial support from Faculty Grant (GPF096A-2020,
   GPF096B-2020 and GPF096C-2020), University of Malaya, Malaysia.
CR Alaei F, 2019, EXPERT SYST APPL, V121, P97, DOI 10.1016/j.eswa.2018.12.007
   Artaud C, 2018, INT C PATT RECOG, P13, DOI 10.1109/ICPR.2018.8545428
   Khan MJ, 2018, 2018 13TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS), P393, DOI 10.1109/DAS.2018.26
   Khan Z, 2015, PATTERN RECOGN, V48, P3615, DOI 10.1016/j.patcog.2015.04.008
   Kingma DP, 2015, 3 INT C LEARN REPR I, DOI DOI 10.1145/1830483.1830503
   Kundu S., 2019, P ACPR, P136
   Luo ZP, 2015, PROC INT CONF DOC, P496, DOI 10.1109/ICDAR.2015.7333811
   Narayan S, 1997, INFORM SCIENCES, V99, P69, DOI 10.1016/S0020-0255(96)00200-9
   Nasr G, 2002, FLAIRS C, P381
   Raghunandan KS, 2016, INT CONF FRONT HAND, P25, DOI [10.1109/ICFHR.2016.0018, 10.1109/ICFHR.2016.15]
   Shivakumara P, 2018, INT CONF FRONT HAND, P386, DOI 10.1109/ICFHR-2018.2018.00074
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   van Beusekom J, 2013, INT J DOC ANAL RECOG, V16, P189, DOI 10.1007/s10032-011-0181-5
   Wang W, 2011, 2011 IEEE INT S APPL, P1, DOI DOI 10.1080/01431161.2010.489073
   Wang Z, 2017, PROC INT CONF DOC, P1114, DOI 10.1109/ICDAR.2017.184
   Xu XJ, 2016, BIOMED SIGNAL PROCES, V27, P103, DOI 10.1016/j.bspc.2016.02.008
NR 16
TC 0
Z9 0
U1 0
U2 0
PU WORLD SCIENTIFIC PUBL CO PTE LTD
PI SINGAPORE
PA 5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE
SN 0218-0014
EI 1793-6381
J9 INT J PATTERN RECOGN
JI Int. J. Pattern Recognit. Artif. Intell.
PD SEP 30
PY 2021
VL 35
IS 12
AR 2160010
DI 10.1142/S0218001421600107
PG 22
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WQ8UL
UT WOS:000714085600004
DA 2022-02-06
ER

PT J
AU Chen, SS
   Chang, CC
   Echizen, I
AF Chen, Sisheng
   Chang, Ching-Chun
   Echizen, Isao
TI Steganographic Secret Sharing With GAN-Based Face Synthesis and Morphing
   for Trustworthy Authentication in IoT
SO IEEE ACCESS
LA English
DT Article
DE Cryptography; Faces; Generative adversarial networks; Generators;
   Security; Facial features; Deep learning; Face morphing; face synthesis;
   generative adversarial networks; image steganography; secret sharing
ID SECURE
AB Trust and security are fundamental to the successful adoption of the Internet of Things (IoT). This paper proposes a secure message authentication scheme based on steganographic secret sharing for building trust in IoT systems. In our scheme, the message is split and distributed to two participants by a dealer, and it can be revealed only when the two authorized participants grant their consents. Neither of the participants can disclose the message without the consent of the other. To avoid malicious cyberattacks in IoT communications, each share of message is concealed in the form of a human face image, referred to as the shadow image, via a generative adversarial network (GAN). For each participant, a convolutional neural network (CNN) is trained to extract the share of message from the shadow image generated with the participant's key. Distortions and alterations to the shadow images may occur during the transmission from the dealer to the participant. As a tamper-evident design, each shadow image is morphed with the participant's source image under the participant's customized morphing parameter. Cheater detection is also crucial for involved participants to identify fake shadow images during the secret retrieval process. As a cheating countermeasure, the shadow image for one participant is morphed with that for the other and then morphed further with the given source image. The proposed scheme enables multi-factor authentication in the sense that the message is protected by the keys, source images, and morphing parameters of two participants.
C1 [Chen, Sisheng] Fujian Polytech Normal Univ, Sch Big Data & Artificial Intelligence, Fuzhou 350300, Fujian, Peoples R China.
   [Chen, Sisheng] Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
   [Chang, Ching-Chun; Echizen, Isao] Natl Inst Informat, Tokyo 1018430, Japan.
C3 Feng Chia University; Research Organization of Information & Systems
   (ROIS); National Institute of Informatics (NII) - Japan
RP Chang, CC (corresponding author), Natl Inst Informat, Tokyo 1018430, Japan.
EM c.c.chang.phd@gmail.com
FU Japan Society for Promotion of Science (JSPS) KAKENHI Grant [JP16H06302,
   JP18H04120, JP20K23355, JP21H04907, JP21K18023]; Core Research for
   Evolutional Science and Technology (CREST) from Japan Science and
   Technology Corporation (JST), Japan [JPMJCR18A6, JPMJCR20D3];
   Education-Scientic Project for Youth Teacher of Fujian Province, China
   [JT180618]
FX This work was supported in part by the Japan Society for Promotion of
   Science (JSPS) KAKENHI Grant JP16H06302, Grant JP18H04120, Grant
   JP20K23355, Grant JP21H04907, and Grant JP21K18023; in part by the Core
   Research for Evolutional Science and Technology (CREST) from Japan
   Science and Technology Corporation (JST), Japan, under Grant JPMJCR18A6
   and Grant JPMJCR20D3; and in part by the Education-Scientic Project for
   Youth Teacher of Fujian Province, China, under Grant JT180618.
CR Blakley G. R., 1979, P INT WORKSH MAN REQ, P313, DOI 10.1109/MARK.1979.8817296
   Chang CC, 2011, INFORM SCIENCES, V181, P3073, DOI 10.1016/j.ins.2011.03.002
   Chang CC, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/5580272
   Chang CC, 2020, IEEE ACCESS, V8, P198425, DOI 10.1109/ACCESS.2020.3034936
   Chang CC, 2019, MATH BIOSCI ENG, V16, P3367, DOI 10.3934/mbe.2019168
   Chen TH, 2009, PATTERN RECOGN, V42, P2203, DOI 10.1016/j.patcog.2008.11.015
   Chor B., 1985, 26th Annual Symposium on Foundations of Computer Science (Cat. No.85CH2224-4), P383, DOI 10.1109/SFCS.1985.64
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gutub A, 2020, MULTIMED TOOLS APPL, V79, P7951, DOI 10.1007/s11042-019-08427-x
   Hayes J., 2017, P ADV NEUR INF PROC, P1954
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Hu DH, 2018, IEEE ACCESS, V6, P38303, DOI 10.1109/ACCESS.2018.2852771
   Laine, 2018, INT C LEARN REPR
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li B, 2014, SIGN INF PROC ASS AN, P1, DOI [10.1109/APSIPA.2014, DOI 10.1109/APSIPA.2014.7041565]
   Li J., 2020, P INT C ART INT SEC, V1252, P386
   Lin CC, 2004, J SYST SOFTWARE, V73, P405, DOI 10.1016/S0164-1212(03)00239-5
   Lin PY, 2009, PATTERN RECOGN, V42, P886, DOI 10.1016/j.patcog.2008.09.014
   Liu J, 2020, IEEE ACCESS, V8, P60575, DOI 10.1109/ACCESS.2020.2983175
   Mirza M, 2014, ARXIV PREPRINT ARXIV
   Naor M, 1995, LECT NOTES COMPUTER, V950, P1, DOI DOI 10.1007/BFB0053419
   Patel A., 2015, INT J COMPUT APPL, V5, P156
   Radford A., 2015, CVPR
   Reed S, 2016, PR MACH LEARN RES, V48
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Tang WX, 2019, IEEE T INF FOREN SEC, V14, P2074, DOI 10.1109/TIFS.2019.2891237
   Tang WX, 2017, IEEE SIGNAL PROC LET, V24, P1547, DOI 10.1109/LSP.2017.2745572
   Tang ZH, 2021, IEEE ACCESS, V9, P76908, DOI 10.1109/ACCESS.2021.3075282
   Tian GL, 2020, PROCEEDINGS OF THE 2ND IEEE EURASIA CONFERENCE ON BIOMEDICAL ENGINEERING, HEALTHCARE AND SUSTAINABILITY 2020 (IEEE ECBIOS 2020): BIOMEDICAL ENGINEERING, HEALTHCARE AND SUSTAINABILITY, P172, DOI 10.1109/ECBIOS50299.2020.9203749
   Xu GS, 2016, IEEE SIGNAL PROC LET, V23, P708, DOI 10.1109/LSP.2016.2548421
   Yuan B, 2020, IEEE INTERNET THINGS, V7, P7967, DOI 10.1109/JIOT.2020.2993587
   Zeng JS, 2018, IEEE T INF FOREN SEC, V13, P1200, DOI 10.1109/TIFS.2017.2779446
   Zhang E, 2013, INT J FOUND COMPUT S, V24, P879, DOI 10.1142/S012905411350024X
   Zhang R, 2019, MULTIMED TOOLS APPL, V78, P8559, DOI 10.1007/s11042-018-6951-z
   Zhang ZZ, 2019, STEM CELLS INT, V2019, DOI 10.1155/2019/6183796
   Zhang ZP, 2002, ACM T GRAPHIC, V21, P457
   Zhou LC, 2020, IEEE SIGNAL PROC LET, V27, P166, DOI 10.1109/LSP.2019.2963180
NR 37
TC 0
Z9 0
U1 4
U2 4
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2021
VL 9
BP 116427
EP 116439
DI 10.1109/ACCESS.2021.3105590
PG 13
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA UI2BA
UT WOS:000690418300001
OA gold
DA 2022-02-06
ER

PT J
AU Olmschenk, G
   Zhu, ZG
   Tang, H
AF Olmschenk, Greg
   Zhu, Zhigang
   Tang, Hao
TI Generalizing semi-supervised generative adversarial networks to
   regression using feature contrasting
SO COMPUTER VISION AND IMAGE UNDERSTANDING
LA English
DT Article
DE Generative adversarial learning; Age estimation; Regression
AB In this work, we generalize semi-supervised generative adversarial networks (GANs) from classification problems to regression problems. In the last few years, the importance of improving the training of neural networks using semi-supervised training has been demonstrated for classification problems. We present a novel loss function, called feature contrasting, resulting in a discriminator which can distinguish between fake and real data based on feature statistics. This method avoids potential biases and limitations of alternative approaches. The generalization of semi-supervised GANs to the regime of regression problems of opens their use to countless applications as well as providing an avenue for a deeper understanding of how GANs function. We first demonstrate the capabilities of semi-supervised regression GANs on a toy dataset which allows for a detailed understanding of how they operate in various circumstances. This toy dataset is used to provide a theoretical basis of the semi-supervised regression GAN. We then apply the semi-supervised regression GANs to a number of real-world computer vision applications: age estimation, driving steering angle prediction, and crowd counting from single images. We perform extensive tests of what accuracy can be achieved with significantly reduced annotated data. Through the combination of the theoretical example and real-world scenarios, we demonstrate how semi-supervised GANs can be generalized to regression problems.
C1 [Olmschenk, Greg; Zhu, Zhigang] CUNY City Coll, 160 Convent Ave, New York, NY 10031 USA.
   [Olmschenk, Greg; Zhu, Zhigang] CUNY, Grad Ctr, 365 5th Ave, New York, NY 10016 USA.
   [Tang, Hao] CUNY, Borough Manhattan Community Coll, 199 Chambers St, New York, NY 10007 USA.
C3 City University of New York (CUNY) System; City College of New York
   (CUNY); City University of New York (CUNY) System; City University of
   New York (CUNY) System
RP Olmschenk, G (corresponding author), CUNY, Grad Ctr, 365 5th Ave, New York, NY 10016 USA.
EM golmschenk@gradcenter.cuny.edu
FU DOEUnited States Department of Energy (DOE) [1DE-AC05060R23100,
   1DE-SC0014664]; National Science FoundationNational Science Foundation
   (NSF) [1827505, 1737533]; Bentley Systems, Incorporated, through a
   CUNY-Bentley Collaborative Research Agreement (CRA); Defense
   Intelligence Agency (DIA) via the Rutgers University Consortium for
   Critical Technology Studies
FX This research was initiated under appointments to the U.S. Department of
   Homeland Security (DHS) Science & Technology Directorate Office of
   University Programs, administered by the Oak Ridge Institute for Science
   and Education (ORISE) through an interagency agreement between the U.S.
   Department of Energy (DOE) and DHS. ORISE is managed by ORAU under DOE
   contract number 1DE-AC05060R23100 and 1DE-SC0014664. All opinions
   expressed in this paper are the author's and do not necessarily reflect
   the policies and views of DHS, DOE, or ORAU/ORISE. The research is also
   supported by National Science Foundation through Awards PFI #1827505 and
   SCCPlanning #1737533, and Bentley Systems, Incorporated, through a
   CUNY-Bentley Collaborative Research Agreement (CRA). Additional support
   provided by the Defense Intelligence Agency (DIA) via the Rutgers
   University Consortium for Critical Technology Studies.
CR Ali I, 2015, REMOTE SENS-BASEL, V7, P16398, DOI 10.3390/rs71215841
   Barnett S.A., 2018, ARXIV180611382
   Bazrafkan S, 2018, ARXIV PREPRINT ARXIV
   Bland LM, 2015, CONSERV BIOL, V29, P250, DOI 10.1111/cobi.12372
   Chen S., 2017, SULLY CHEN DRIVING D
   Chintala S., 2017, ARXIV170107875
   Dai Zihang, 2017, ADV NEURAL INFORM PR
   Ding X, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2327
   Dodge Samuel, 2017, ARXIV170502498
   Eigen David, 2014, ADV NEURAL INFORM PR, P2366, DOI DOI 10.1007/978-3-540-28650-9_5
   Elsayed G.F., 2018, ADV NEURAL INFORM PR, P3914
   Fabbro S., 2017, MON NOT R ASTRON SOC
   Fefferman C, 2016, J AM MATH SOC, V29, P983, DOI 10.1090/jams/852
   Goodfellow I., 2016, ARXIV LEARNING
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Gulrajani I., 2017, ADV NEURAL INFORM PR, P5769, DOI DOI 10.5555/3295222.3295327
   Hartikainen J., 2012, ARXIV12064670
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Idrees H., 2018, ARXIV180801050
   LeCun Y, 1999, LECT NOTES COMPUT SC, V1681, P319, DOI 10.1007/3-540-46805-6_19
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Liu YG, 2005, J GEOPHYS RES-OCEANS, V110, DOI 10.1029/2004JC002786
   Lv YS, 2015, IEEE T INTELL TRANSP, V16, P865, DOI 10.1109/TITS.2014.2345663
   Marino DL, 2016, IEEE IND ELEC, P7046, DOI 10.1109/IECON.2016.7793413
   NIU ZX, 2016, PROC CVPR IEEE, P4920, DOI DOI 10.1109/CVPR.2016.532
   Oliveira T. P., 2016, INT J BIG DATA INTEL, V3, P28
   Pan X., 2017, ARXIV170403952
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Radford A., 2015, ARXIV
   Rezagholizadeh M, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2806, DOI 10.1109/ICASSP.2018.8462534
   Rothe R, 2018, INT J COMPUT VISION, V126, P144, DOI 10.1007/s11263-016-0940-3
   Salimans T., 2016, ADV NEURAL INFORM PR, P2234
   Schwarz M, 2015, IEEE INT CONF ROBOT, P1329, DOI 10.1109/ICRA.2015.7139363
   Shi X., 2015, ADV NEURAL INFORM PR, V28, P802
   Souly N., 2017, ARXIV170309695
   Springenberg Jost Tobias, 2015, ARXIV151106390
   Sun J., 2017, ARXIV170805789
   Zhang C, 2015, PROC CVPR IEEE, P833, DOI 10.1109/CVPR.2015.7298684
   Zhang YY, 2016, PROC CVPR IEEE, P589, DOI 10.1109/CVPR.2016.70
NR 39
TC 7
Z9 7
U1 6
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1077-3142
EI 1090-235X
J9 COMPUT VIS IMAGE UND
JI Comput. Vis. Image Underst.
PD SEP
PY 2019
VL 186
BP 1
EP 12
DI 10.1016/j.cviu.2019.06.004
PG 12
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IR6QU
UT WOS:000481564600001
OA Green Submitted
DA 2022-02-06
ER

PT J
AU Abidi, WU
   Daoud, MS
   Ihnaini, B
   Khan, MA
   Alyas, T
   Fatima, A
   Ahmad, M
AF Abidi, Wajhe Ul Husnian
   Daoud, Mohammad Sh.
   Ihnaini, Baha
   Khan, Muhammad Adnan
   Alyas, Tahir
   Fatima, Areej
   Ahmad, Munir
TI Real-Time Shill Bidding Fraud Detection Empowered With Fussed Machine
   Learning
SO IEEE ACCESS
LA English
DT Article
DE Data models; Hidden Markov models; Training; Support vector machines;
   Artificial neural networks; Real-time systems; Labeling; Shill bidding;
   e-auction fraud; online fraud detection; deep learning model
AB Shill Bidding (SB) occurs when the fake bidders are introduced by the seller's side to increase the final price. SB is a crime committed during the e-Auction, and it is pretty difficult to detect because of its normal bidding behavior. The bidder gets a lot of loss because he pays extra money, and the sellers benefit from shill bidding, so this article proposed a fusion base model. This proposed model is split into two parts training and validation, into 70 and 30 percent. This model has been divided into three sub-modules; the first module, two machine learning algorithms named Support vector machine (SVM), and Artificial neural network (ANN) trained parallel on the same dataset and predicting the bidding fraud. The prediction of these models becomes the input of the fuzzy-based fussed module, and fuzzy decide the actual output based on SVM and ANN predictions. On every bid, it predicts whether the fraud is committed or not. If the bidding behavior is normal, continue the bidding; otherwise, cancel the bid and block the user. The prediction accuracy of the proposed fussed machine learning approach is 99.63%. Simulation results have shown that the proposed fussed machine learning approach gives more attractive results than state-of-the-art published methods.
C1 [Abidi, Wajhe Ul Husnian; Alyas, Tahir; Fatima, Areej] Lahore Garrison Univ, Dept Comp Sci, Lahore 54792, Pakistan.
   [Abidi, Wajhe Ul Husnian] Syst Ltd, Digital Commerce Dept, Lahore 54792, Pakistan.
   [Daoud, Mohammad Sh.] Al Ain Univ, Coll Engn, Al Ain, U Arab Emirates.
   [Ihnaini, Baha] Wenzhou Kean Univ, Dept Comp Sci, Wenzhou 325060, Peoples R China.
   [Khan, Muhammad Adnan] Gachon Univ, Dept Software, Pattern Recognit & Machine Learning Lab, Seongnam 13557, South Korea.
   [Ahmad, Munir] Natl Coll Business Adm & Econ, Sch Comp Sci, Lahore 54000, Pakistan.
C3 Wenzhou-Kean University; Gachon University
RP Khan, MA (corresponding author), Gachon Univ, Dept Software, Pattern Recognit & Machine Learning Lab, Seongnam 13557, South Korea.
EM adnan@gachon.ac.kr
RI Abidi, Wajhe Ul Husnain/AAL-6230-2021; Ahmad, Munir/F-7482-2018
OI Ahmad, Munir/0000-0002-5240-0984; Abbas, Dr.
   Sagheer/0000-0001-5289-7831; Alyas, Tahir/0000-0003-0938-3127; Khan,
   Muhammad Adnan/0000-0003-4854-9935; Ihnaini, Baha/0000-0002-2109-4793;
   Fatima, Areej/0000-0002-7264-7941; Abidi, Wajhe/0000-0001-5165-2947
CR Al-Zaben A, 2018, MID EAST CONF BIO, P17, DOI 10.1109/MECBME.2018.8402398
   Alzahrani A, 2019, P 11 INT C AG ART IN, V2, P92
   Anowar F, 2020, J THEOR APPL EL COMM, V15, P81, DOI 10.4067/S0718-18762020000100107
   Anowar F, 2018, 2018 17TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P366, DOI 10.1109/ICMLA.2018.00061
   Dong YJ, 2021, J MULT-VALUED LOG S, V36, P191
   Elshaar S, 2020, P 12 INT C ICAART FE, P173
   Elshaar S, 2020, ICAART: PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON AGENTS AND ARTIFICIAL INTELLIGENCE, VOL 2, P17, DOI 10.5220/0008894100170025
   Elshaar S, 2020, APPL ARTIF INTELL, V34, P47, DOI 10.1080/08839514.2019.1691341
   Ganguly S., 2018, LECT NOTES ARTIFICIA, V10868
   Ganguly S, 2017, LECT NOTES ARTIF INT, V10233, P84, DOI 10.1007/978-3-319-57351-9_11
   Gupta P, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION & AUTOMATION (ICCCA), P901, DOI 10.1109/CCAA.2015.7148504
   McCannon BC, 2020, J BEHAV EXP FINANC, V26, DOI 10.1016/j.jbef.2020.100279
   Trevathan J, 2018, ARXIV181210868
   Trevathan J, 2018, COMPUT SCI REV, V27, P1, DOI 10.1016/j.cosrev.2017.10.001
   Xiao J, 2020, KNOWL-BASED SYST, V189, DOI 10.1016/j.knosys.2019.105118
NR 15
TC 0
Z9 0
U1 3
U2 3
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2021
VL 9
BP 113612
EP 113621
DI 10.1109/ACCESS.2021.3098628
PG 10
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA UC8ES
UT WOS:000686755800001
OA gold
DA 2022-02-06
ER

PT J
AU Wang, JJ
   Gao, F
   Dong, JY
   Du, Q
AF Wang, Junjie
   Gao, Feng
   Dong, Junyu
   Du, Qian
TI Adaptive DropBlock-Enhanced Generative Adversarial Networks for
   Hyperspectral Image Classification
SO IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING
LA English
DT Article
DE Generative adversarial networks; Generators; Training; Feature
   extraction; Gallium nitride; Shape; Hyperspectral sensors; Adaptive
   DropBlock (AdapDrop); deep learning; generative adversarial network
   (GAN); hyperspectral image (HSI) classification
ID SPECTRAL-SPATIAL CLASSIFICATION; EXTINCTION PROFILES; INFORMATION;
   FUSION
AB In recent years, the hyperspectral image (HSI) classification based on generative adversarial networks (GANs) has achieved great progress. GAN-based classification methods can mitigate the limited training sample dilemma to some extent. However, several studies have pointed out that existing GAN-based HSI classification methods are heavily affected by the imbalanced training data problem. The discriminator in GAN always contradicts itself and tries to associate fake labels to the minority-class samples and, thus, impair the classification performance. Another critical issue is the mode collapse in GAN-based methods. The generator is only capable of producing samples within a narrow scope of the data space, which severely hinders the advancement of GAN-based HSI classification methods. In this article, we proposed an Adaptive DropBlock-enhanced Generative Adversarial Networks (ADGANs) for HSI classification. First, to solve the imbalanced training data problem, we adjust the discriminator to be a single classifier, and it will not contradict itself. Second, an adaptive DropBlock (AdapDrop) is proposed as a regularization method employed in the generator and discriminator to alleviate the mode collapse issue. The AdapDrop generated drop masks with adaptive shapes instead of a fixed size region, and it alleviates the limitations of DropBlock in dealing with ground objects with various shapes. Experimental results on three HSI data sets demonstrated that the proposed ADGAN achieved superior performance over state-of-the-art GAN-based methods. Our codes are available at https://github.com/summitgao/HC_ADGAN.
C1 [Wang, Junjie; Gao, Feng; Dong, Junyu] Ocean Univ China, Qingdao Key Lab Mixed Real & Virtual Ocean, Sch Informat Sci & Engn, Qingdao 266100, Peoples R China.
   [Du, Qian] Mississippi State Univ, Dept Elect & Comp Engn, Starkville, MS 39762 USA.
C3 Ocean University of China; Mississippi State University
RP Gao, F (corresponding author), Ocean Univ China, Qingdao Key Lab Mixed Real & Virtual Ocean, Sch Informat Sci & Engn, Qingdao 266100, Peoples R China.
EM gaofeng@ouc.edu.cn
RI Du, Qian/AAB-8840-2022
OI Dong, Junyu/0000-0001-7012-2087; Gao, Feng/0000-0002-1825-328X
FU National Key Research and Development Program of China [2018AAA0100602];
   National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [U1706218]; Key Research and Development
   Program of Shandong Province [2019GHY112048]
FX This work was supported in part by the National Key Research and
   Development Program of China under Grant 2018AAA0100602, in part by the
   National Natural Science Foundation of China under Grant U1706218, and
   in part by the Key Research and Development Program of Shandong Province
   under Grant 2019GHY112048.
CR Arellano P, 2015, ENVIRON POLLUT, V205, P225, DOI 10.1016/j.envpol.2015.05.041
   Benediktsson JA, 2005, IEEE T GEOSCI REMOTE, V43, P480, DOI 10.1109/TGRS.2004.842478
   Chavdarova T., 2018, PROC CVPR IEEE, P9407, DOI DOI 10.1109/CVPR.2018.00980
   Chen C, 2014, IEEE J-STARS, V7, P1047, DOI 10.1109/JSTARS.2013.2295610
   Chen YS, 2017, IEEE GEOSCI REMOTE S, V14, P2355, DOI 10.1109/LGRS.2017.2764915
   Chen YS, 2016, IEEE T GEOSCI REMOTE, V54, P6232, DOI 10.1109/TGRS.2016.2584107
   Chen YS, 2015, IEEE J-STARS, V8, P2381, DOI 10.1109/JSTARS.2015.2388577
   Chen YS, 2014, IEEE J-STARS, V7, P2094, DOI 10.1109/JSTARS.2014.2329330
   Fang LY, 2018, IEEE T GEOSCI REMOTE, V56, P1803, DOI 10.1109/TGRS.2017.2768479
   Fang LY, 2015, IEEE T GEOSCI REMOTE, V53, P6663, DOI 10.1109/TGRS.2015.2445767
   Fauvel M, 2012, PATTERN RECOGN, V45, P381, DOI 10.1016/j.patcog.2011.03.035
   Fauvel M., 2006, P IEEE INT C AC SPEE, pII, DOI [10.1109/ICASSP.2006.1660467., DOI 10.1109/ICASSP.2006.1660467]
   Fauvel M, 2008, IEEE T GEOSCI REMOTE, V46, P3804, DOI 10.1109/TGRS.2008.922034
   Feng J, 2019, IEEE T GEOSCI REMOTE, V57, P5329, DOI 10.1109/TGRS.2019.2899057
   Ghamisi P, 2017, IEEE J-STARS, V10, P3011, DOI 10.1109/JSTARS.2016.2634863
   Ghiasi G., 2018, ADV NEURAL INFORM PR, P10727
   Girshick R., 2014, 2014 IEEE C COMPUTER, P580
   Gong ZQ, 2019, IEEE T GEOSCI REMOTE, V57, P3599, DOI 10.1109/TGRS.2018.2886022
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Gurram P, 2013, IEEE GEOSCI REMOTE S, V10, P1031, DOI 10.1109/LGRS.2012.2227934
   Ham J, 2005, IEEE T GEOSCI REMOTE, V43, P492, DOI 10.1109/TGRS.2004.842481
   Haut JM, 2019, IEEE T GEOSCI REMOTE, V57, P8065, DOI 10.1109/TGRS.2019.2918080
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Kang XD, 2014, IEEE T GEOSCI REMOTE, V52, P2666, DOI 10.1109/TGRS.2013.2264508
   Krizhevsky A., 2012, ADV NEURAL INF PROCE, P1097, DOI DOI 10.1145/3065386
   Li JJ, 2018, IEEE T GEOSCI REMOTE, V56, P3838, DOI 10.1109/TGRS.2018.2813366
   Li ST, 2016, IEEE T GEOSCI REMOTE, V54, P7416, DOI 10.1109/TGRS.2016.2603190
   Li W, 2015, IEEE T GEOSCI REMOTE, V53, P3681, DOI 10.1109/TGRS.2014.2381602
   Li W, 2015, IEEE T GEOSCI REMOTE, V53, P1463, DOI 10.1109/TGRS.2014.2343955
   Licciardi G, 2012, IEEE GEOSCI REMOTE S, V9, P447, DOI 10.1109/LGRS.2011.2172185
   Ma XR, 2018, IEEE T GEOSCI REMOTE, V56, P4781, DOI 10.1109/TGRS.2018.2837142
   Odena A, 2017, PR MACH LEARN RES, V70
   Pan B, 2017, IEEE T GEOSCI REMOTE, V55, P4177, DOI 10.1109/TGRS.2017.2689805
   Pan B, 2017, IEEE J-STARS, V10, P1975, DOI 10.1109/JSTARS.2017.2655516
   Ratle F, 2010, IEEE T GEOSCI REMOTE, V48, P2271, DOI 10.1109/TGRS.2009.2037898
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tang YY, 2015, IEEE T GEOSCI REMOTE, V53, P2467, DOI 10.1109/TGRS.2014.2360672
   Tu B, 2019, IEEE T GEOSCI REMOTE, V57, P5085, DOI 10.1109/TGRS.2019.2896471
   Wan L., 2013, INT C MACHINE LEARNI, P1058
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P3, DOI 10.1109/TGRS.2018.2849692
   Wang QW, 2016, IEEE T GEOSCI REMOTE, V54, P3912, DOI 10.1109/TGRS.2016.2530807
   Yao KS, 2013, INTERSPEECH, P2523
   Zhan Y, 2018, IEEE GEOSCI REMOTE S, V15, P212, DOI 10.1109/LGRS.2017.2780890
   Zhang HK, 2019, IEEE T GEOSCI REMOTE, V57, P5813, DOI 10.1109/TGRS.2019.2902568
   Zhang HK, 2017, REMOTE SENS LETT, V8, P438, DOI 10.1080/2150704X.2017.1280200
   Zhong YF, 2014, IEEE J-STARS, V7, P1235, DOI 10.1109/JSTARS.2014.2303634
   Zhong ZL, 2020, IEEE T CYBERNETICS, V50, P3318, DOI 10.1109/TCYB.2019.2915094
   Zhong ZL, 2018, IEEE T GEOSCI REMOTE, V56, P847, DOI 10.1109/TGRS.2017.2755542
   Zhu L, 2018, IEEE T GEOSCI REMOTE, V56, P5046, DOI 10.1109/TGRS.2018.2805286
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
   Zou JY, 2015, IEEE GEOSCI REMOTE S, V12, P2418, DOI 10.1109/LGRS.2015.2481181
NR 52
TC 3
Z9 3
U1 33
U2 33
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0196-2892
EI 1558-0644
J9 IEEE T GEOSCI REMOTE
JI IEEE Trans. Geosci. Remote Sensing
PD JUN
PY 2021
VL 59
IS 6
BP 5040
EP 5053
DI 10.1109/TGRS.2020.3015843
PG 14
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA SF5ZU
UT WOS:000652834200041
DA 2022-02-06
ER

PT J
AU Suwana, F
AF Suwana, Fiona
TI What motivates digital activism? The case of the Save KPK movement in
   Indonesia
SO INFORMATION COMMUNICATION & SOCIETY
LA English
DT Article
DE Democracy; digital activism; digital media; Indonesia; political
   movement; the Save KPK movement; and young people
ID CIVIC ENGAGEMENT; MEDIA; PARTICIPATION
AB Digital activism has enormous ability to amplify offline and online civic activism and political participation. In Indonesia, digital activism has successfully supported social and political change in recent years. Motivation is an important component of digital activism that can stimulate movements, and can be determined by access to and use of digital media. This article presents a case study of motivations and digital activism in an online political movement in Indonesia through interviews and focus group discussions with fifty-two (n = 52) Indonesian young people (activists and students) who were familiar with digital media and the Save KPK 2015 movement in Indonesia. It investigates the digital activism of the Save KPK movement and the strategies employed to support the movement. The case study offers a deeper understanding of the Save KPK movement (which aimed to support an institution dedicated to eradicating corruption in Indonesia) and provides insights into the motivations of activists who digitally supported the political movement. Its findings explore how internal factors such as experience and beliefs fundamentally influenced young Indonesians to participate in the Save KPK movement using digital media, indicating that intrinsic is an important factor in delivering credible information and participating in the movement. Delivering truthful information about the KPK institution through digital media was seen as vital to combat the distribution of misinformation, such as fake news or hoaxes, and reinforce the political participation that helps to sustain Indonesian democracy as well as that of other democratic countries.
C1 [Suwana, Fiona] Queensland Univ Technol, Digital Media Res Ctr, Creat Ind Fac, Brisbane, Qld 4059, Australia.
C3 Queensland University of Technology (QUT)
RP Suwana, F (corresponding author), Queensland Univ Technol, Digital Media Res Ctr, Creat Ind Fac, Brisbane, Qld 4059, Australia.
EM f.suwana@qut.edu.au
RI Suwana, Fiona/ABB-7166-2020
CR AMR/DOE/SF, 2015, OP SEN DAR JAG MAYA
   [Anonymous], 2015, JAKARTA POST
   Antlov H., 2011, WORKING PAPERS
   Aspinall E., 2014, MONEY POLITICS
   Atton C., 2002, ALTERNATIVE MEDIA
   Banaji S, 2013, JOHN D CATH T MAC
   Bennett WL, 2012, INFORM COMMUN SOC, V15, P739, DOI 10.1080/1369118X.2012.670661
   Bennett WL., 2013, LOGIC CONNECTIVE ACT, DOI DOI 10.1017/CBO9781139198752
   Buckingham D., 2017, FAKE NEWS IS MEDIA L
   Cammaerts B., 2015, JOURNALISM, P1027
   Carpentier N, 2011, MEDIA AND PARTICIPATION: A SITE OF IDEOLOGICAL-DEMOCRATIC STRUGGLE, P1
   Carpini MXD, 2000, POLIT COMMUN, V17, P341, DOI 10.1080/10584600050178942
   Castells M., 2015, NETWORKS OUTRAGE HOP, V2nd Edn
   Clough J., 2015, JAKARTA POST
   Cochrane Joe, 2014, NY TIMES
   Cornwall A., 2008, COMMUNITY DEV J, V43, P269, DOI [10.1093/cdj/bsn010, DOI 10.1093/CDJ/BSN010]
   Curran J, 2012, COMMUN SOC-SER, P1
   Edwards F, 2013, DIGITAL ACTIVISM NON
   Ekstrom M, 2015, COMMUN RES, V42, P796, DOI 10.1177/0093650213476295
   Freedom House, 2016, IND FREED NET 2016
   Freedom House, 2015, IND FREED NET 2015
   Friedland J., 2009, POLITICAL SOCIAL MOV
   Gabrillin A., 2015, KOMPAS
   Gazali E, 2014, INT COMMUN GAZ, V76, P425, DOI 10.1177/1748048514524119
   Gerbaudo P., 2012, TWEETSTREETSOCIA
   Gerbaudo P, 2017, INFORM COMMUN SOC, V20, P185, DOI 10.1080/1369118X.2016.1161817
   Gladwell M., 2010, NEW YORKER
   Held David., 2006, MODELS DEMOCRACY, V3rd ed
   Hill D., 2005, INTERNET INDONESIAS
   Holik I., 2011, JURNAL MAKNA, V1, P41
   Human Rights Watch, 2014, ASIA
   Joyce P, 2010, CULT ECON SOC, P1
   Jurriens E., 2017, DIGITAL INDONESIA CO, P1, DOI DOI 10.1355/9789814786003-007
   Kamau S.C., 2016, DIGITAL ACTIVISM SOC, P115
   Kaun A, 2018, NEW MEDIA SOC, V20, P2186, DOI 10.1177/1461444817731920
   Keane J, 2013, DEMOCRACY AND MEDIA DECADENCE, P1
   Kim EM, 2016, J YOUTH STUD, V19, P438, DOI 10.1080/13676261.2015.1083961
   Kusman A. P., 2017, HOAXES FAKE NEWS CAN
   Lee AYL, 2015, CHIN J COMMUN, V8, P376, DOI 10.1080/17544750.2015.1086399
   Lee FLF, 2016, INFORM COMMUN SOC, V19, P4, DOI 10.1080/1369118X.2015.1093530
   Levine RS, 2008, DISLOCATING RACE AND NATION: EPISODES IN NINETEENTH-CENTURY AMERICAN LITERARY NATIONALISM, P119
   Li W, 2014, 2014 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN CONTROL AND AUTOMATION (CICA), P21
   Lilleker DG, 2017, POLIT COMMUN, V34, P21, DOI 10.1080/10584609.2016.1225235
   Lim M., 2003, CONTESTING MEDIA POW, P273
   Lim M., 2011, ACROSSROADS DEMOCRAT
   Lussier DN, 2012, J DEMOCR, V23, P70, DOI 10.1353/jod.2012.0017
   Mackey T. P., 2016, CONVERSATION
   Mahditama I., 2012, JAKARTA POST
   Mathiesen K, 2014, J MASS MEDIA ETHICS, V29, P2, DOI 10.1080/08900523.2014.863124
   Mattoccia M, 2005, ZOOTAXA, P1
   Mclean J, 2013, GEOGR RES-AUST, V51, P243, DOI 10.1111/1745-5871.12023
   Mietzner M, 2012, DEMOCRATIZATION, V19, P209, DOI 10.1080/13510347.2011.572620
   Mitu B., 2014, REV STIINTE POLITICE, V44, P103
   Morozov E., 2011, NET DELUSION NOT LIB
   Mwaura J, 2017, AFR JOURNAL STUD, V38, P152, DOI 10.1080/23743670.2017.1329249
   Norris P, 2001, DIGITAL DIVIDE CIVIC
   Nugroho Y, 2012, CLICK ACTIVISM NEW M
   Phelan S, 2011, DISCOURSE THEORY AND CRITICAL MEDIA POLITICS, P1
   Phillips Tom, 2014, TELEGRAPH
   Polletta Francesca, 2014, J INT AFF, V68, P79
   Postill John, 2017, DIGITAL INDONESIA CO, P127, DOI [10.1355/9789814786003-014, DOI 10.1355/9789814786003-014]
   Ramli R., 2012, YOUTH FUTURE AGENTS, P11
   Rheingold H., 2008, CIVIC LIFE ONLINE LE, P97, DOI [10.1162/dma1.9780262524827.097, DOI 10.1162/DMAL.9780262524827.097]
   Ricketts A., 2012, ACTIVISTS HDB STEP S
   Ronfeldt David, 2001, NETWORKS NETWARS FUT, P239
   Sandberg LA, 2015, URBAN FORESTS, TREES, AND GREENSPACE: A POLITICAL ECOLOGY PERSPECTIVE, P1
   Savirani A., 2015, CONVERSATION
   Soebagjo N., 2015, CONVERSATION
   Sun XY, 2020, J URBAN AFF, V42, P257, DOI 10.1080/07352166.2018.1443010
   Tan J, 2017, CRIME MEDIA CULT, V13, P171, DOI 10.1177/1741659017710063
   Tapsell Ross, 2015, INDONESIA, P29, DOI DOI 10.5728/INDONESIA.99.0029
   Tornquist O., 2014, JAKARTA POST
   Tsui L, 2015, CHIN J COMMUN, V8, P1, DOI 10.1080/17544750.2015.1058834
   Uqiyanus C. A., 2015, SAVEKPK JADI TRENDIN
   VROMEN A, 2016, DIGITAL CITIZENSHIP
   Weiss ML, 2014, INT DEV PLANN REV, V36, P91, DOI 10.3828/idpr.2014.6
   Wineburg S., 2016, EVALUATING INFORM CO
   Yang GB, 2018, NEW MEDIA SOC, V20, P2107, DOI 10.1177/1461444817731921
   Yasih D. W. P., 2014, PARADOX VIRTUAL YOUT
   Young K., 2017, INDONESIA EXPAT
   [No title captured]
NR 81
TC 9
Z9 9
U1 4
U2 16
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 1369-118X
EI 1468-4462
J9 INFORM COMMUN SOC
JI Info. Commun. Soc.
PD JUL 28
PY 2020
VL 23
IS 9
BP 1295
EP 1310
DI 10.1080/1369118X.2018.1563205
PG 16
WC Communication; Sociology
WE Social Science Citation Index (SSCI)
SC Communication; Sociology
GA MT6PX
UT WOS:000555095900004
OA Green Submitted
DA 2022-02-06
ER

PT J
AU Li, Y
   Tao, JH
   Chao, LL
   Bao, W
   Liu, YZ
AF Li, Ya
   Tao, Jianhua
   Chao, Linlin
   Bao, Wei
   Liu, Yazhu
TI CHEAVD: a Chinese natural emotional audio-visual database
SO JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING
LA English
DT Article
DE Audio-visual database; Natural emotion; Corpus annotation; LSTM;
   Multimodal emotion recognition
ID RECOGNITION; SPEECH; EXPRESSION; FEATURES; MODEL
AB This paper presents a recently collected natural, multimodal, rich-annotated emotion database, CASIA Chinese Natural Emotional Audio-Visual Database (CHEAVD), which aims to provide a basic resource for the research on multimodal multimedia interaction. This corpus contains 140 min emotional segments extracted from films, TV plays and talk shows. 238 speakers, aging from child to elderly, constitute broad coverage of speaker diversity, which makes this database a valuable addition to the existing emotional databases. In total, 26 non-prototypical emotional states, including the basic six, are labeled by four native speakers. In contrast to other existing emotional databases, we provide multi-emotion labels and fake/suppressed emotion labels. To our best knowledge, this database is the first large-scale Chinese natural emotion corpus dealing with multimodal and natural emotion, and free to research use. Automatic emotion recognition with Long Short-Term Memory Recurrent Neural Networks (LSTM-RNN) is performed on this corpus. Experiments show that an average accuracy of 56 % could be achieved on six major emotion states.
C1 [Li, Ya; Tao, Jianhua; Chao, Linlin; Bao, Wei; Liu, Yazhu] Chinese Acad Sci, NLPR, Inst Automat, Beijing, Peoples R China.
   [Tao, Jianhua] Chinese Acad Sci, CAS Ctr Excellence Brain Sci & Intelligence Techn, Inst Automat, Beijing, Peoples R China.
   [Tao, Jianhua] Chinese Acad Sci, Sch Comp & Control Engn, Grad Univ, Beijing, Peoples R China.
   [Bao, Wei; Liu, Yazhu] Jiangsu Normal Univ, Inst Linguist Sci, Xuzhou, Jiangsu, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Automation, CAS; Chinese
   Academy of Sciences; Institute of Automation, CAS; Chinese Academy of
   Sciences; University of Chinese Academy of Sciences, CAS; Jiangsu Normal
   University
RP Li, Y (corresponding author), Chinese Acad Sci, NLPR, Inst Automat, Beijing, Peoples R China.
EM yli@nlpr.ia.ac.cn; jhtao@nlpr.ia.ac.cn; linlin.chao@nlpr.ia.ac.cn;
   jsnubw@163.com; yzliu90@163.com
FU National HighTech Research and Development Program of China (863
   Program)National High Technology Research and Development Program of
   China [2015AA016305]; National Natural Science Foundation of China
   (NSFC)National Natural Science Foundation of China (NSFC) [61305003,
   61425017]; Strategic Priority Research Program of the CAS [XDB02080006];
   Major Program for the National Social Science Fund of China [13ZD189]
FX This work is supported by the National HighTech Research and Development
   Program of China (863 Program) (No. 2015AA016305), the National Natural
   Science Foundation of China (NSFC) (Nos. 61305003, 61425017), the
   Strategic Priority Research Program of the CAS (Grant XDB02080006), and
   partly supported by the Major Program for the National Social Science
   Fund of China (13&ZD189). We thank the data providers for their kind
   permission to make their data for non-commercial, scientific use. Due to
   space limitations, providers' information is available in
   http://www.speakit.cn/. The corpus can be freely achieved at ChineseLDC,
   http://www.chineseldc.org.
CR AVERILL JR, 1975, SEMANTIC ATLAS EMOTI
   Bahdanau D., 2014, ARXIV PREPRINT ARXIV
   Barrett LF, 1998, COGNITION EMOTION, V12, P579, DOI 10.1080/026999398379574
   Bengio Y, 2012, UNSUPERVISED TRANSF, V7, P19
   Burkhardt F., 2005, INTERSPEECH, V5, P1517
   Busso C., 2004, P 6 INT C MULT INT, P205
   Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6
   Butler EA, 2007, EMOTION, V7, P30, DOI 10.1037/1528-3542.7.1.30
   Chao L., 2015, P 5 INT WORKSH AUD V, P65, DOI DOI 10.1145/2808196.2811634
   Chao  L, 2016, ARXIV160308321
   Clavel C., 2004, P INTERSPEECH 2004, P2277
   Clavel C, 2006, 1 INT WORKSH EM CORP, P76
   Cowie R, 2003, SPEECH COMMUN, V40, P5, DOI 10.1016/S0167-6393(02)00071-7
   Devillers L, 2005, NEURAL NETWORKS, V18, P407, DOI 10.1016/j.neunet.2005.03.007
   DEVILLERS L, 2006, P INT C LANG RES EV, P1105
   Dhall A, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P423, DOI 10.1145/2818346.2829994
   Dhall A, 2012, IEEE MULTIMEDIA, V19, P34, DOI 10.1109/MMUL.2012.26
   Douglas-Cowie E, 2003, SPEECH COMMUN, V40, P33, DOI 10.1016/S0167-6393(02)00070-5
   Douglas-Cowie E., 2000, ISCA TUT RES WORKSH
   Douglas-Cowie E, 2007, LECT NOTES COMPUT SC, V4738, P488
   Ekman P., 1999, HDB COGNITION EMOTIO
   El Ayadi M, 2011, PATTERN RECOGN, V44, P572, DOI 10.1016/j.patcog.2010.09.020
   Elfenbein HA, 2002, PSYCHOL BULL, V128, P203, DOI 10.1037//0033-2909.128.2.203
   Engberg Inger, 1996, DOCUMENTATION DANISH
   Eyben F., 2009, AFF COMP INT INT WOR, P1, DOI DOI 10.1109/ACII.2009.5349350
   FEHR B, 1984, J EXP PSYCHOL GEN, V113, P464, DOI 10.1037/0096-3445.113.3.464
   Gao YY, 2012, 2012 8TH INTERNATIONAL SYMPOSIUM ON CHINESE SPOKEN LANGUAGE PROCESSING, P450, DOI 10.1109/ISCSLP.2012.6423508
   Grimm M, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P865, DOI 10.1109/ICME.2008.4607572
   Gross JJ, 1997, PSYCHOL AGING, V12, P590, DOI 10.1037/0882-7974.12.4.590
   Gross JJ, 2002, PSYCHOPHYSIOLOGY, V39, P281, DOI 10.1017/S0048577201393198
   He L., 2015, P 5 INT WORKSH AUD V, P73, DOI DOI 10.1145/2808196.2811641
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735
   Jaimes A, 2007, COMPUT VIS IMAGE UND, V108, P116, DOI 10.1016/j.cviu.2006.10.019
   Kashdan TB, 2008, BEHAV THER, V39, P1, DOI 10.1016/j.beth.2007.02.003
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li Y., 2016, CHIN C PATT REC CCPR
   Li Y, 2015, INT CONF AFFECT, P368, DOI 10.1109/ACII.2015.7344597
   Liu M., 2014, P 16 INT C MULT INT, P494, DOI DOI 10.1145/2663204.2666274
   MARKUS HR, 1991, PSYCHOL REV, V98, P224, DOI 10.1037/0033-295X.98.2.224
   Mathieu B., 2010, P 11 INT SOC MUS INF, P441
   McKeown G, 2012, IEEE T AFFECT COMPUT, V3, P5, DOI 10.1109/T-AFFC.2011.20
   Mehrabian A, 1996, CURR PSYCHOL, V14, P261, DOI 10.1007/BF02686918
   Mehrabian Albert, 1974, APPROACH ENV PSYCHOL
   Mnih V, 2014, P 27 INT C NEURAL IN, V2, P2204
   Morrison D, 2007, SPEECH COMMUN, V49, P98, DOI 10.1016/j.specom.2006.11.004
   Ng HW, 2014, IEEE IMAGE PROC, P343, DOI 10.1109/ICIP.2014.7025068
   Plutchik R., 1980, EMOTION PSYCHOEVOLUT
   Ringeval F., 2015, P 5 INT WORKSH AUD V, P3, DOI DOI 10.1145/2808196.2811642
   Ringeval F., 2013, AUT FAC GEST REC FG, P1, DOI [10.1109/FG.2013.6553805, DOI 10.1109/FG.2013.6553805]
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Russell JA, 2003, ANNU REV PSYCHOL, V54, P329, DOI 10.1146/annurev.psych.54.101601.145102
   SCHRODER M, 2006, P LREC 06 WORKSH COR, P88
   SHAVER P, 1987, J PERS SOC PSYCHOL, V52, P1061, DOI 10.1037/0022-3514.52.6.1061
   Song ML, 2004, PROC CVPR IEEE, P1020
   Steidl S, 2009, AUTOMATIC CLASSIFICA
   Tao JH, 2005, LECT NOTES COMPUT SC, V3784, P981
   Tao Jianhua, 2009, IEEE OCEANS 2009, P1
   Valstar M., 2013, P 3 ACM INT WORKSH A, P3, DOI DOI 10.1145/2512530.2512533
   Ververidis D, 2006, SPEECH COMMUN, V48, P1162, DOI 10.1016/j.specom.2006.04.003
   Wollmer M, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P597
   Wu C. -H., 2014, APSIPA T SIGNAL INF, V3, P12
   Xu X, 2003, CHINESE AFFECTIVE CO, P199
   Yu F, 2001, LECT NOTES COMPUT SC, V2195, P550
   Yuan J., 2002, P 7 INT C SPOK LANG, P2025
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zeng ZH, 2005, PROC CVPR IEEE, P967
   Zhang X, 2012, IEEE T MULTIMEDIA, V14, P995, DOI 10.1109/TMM.2012.2186121
   [No title captured]
NR 68
TC 20
Z9 22
U1 8
U2 30
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 1868-5137
EI 1868-5145
J9 J AMB INTEL HUM COMP
JI J. Ambient Intell. Humaniz. Comput.
PD NOV
PY 2017
VL 8
IS 6
SI SI
BP 913
EP 924
DI 10.1007/s12652-016-0406-z
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Telecommunications
GA FJ6WD
UT WOS:000412897800009
DA 2022-02-06
ER

PT J
AU Yu, IJ
   Nam, SH
   Ahn, W
   Kwon, MJ
   Lee, HK
AF Yu, In-Jae
   Nam, Seung-Hun
   Ahn, Wonhyuk
   Kwon, Myung-Joon
   Lee, Heung-Kyu
TI Manipulation Classification for JPEG Images Using Multi-Domain Features
SO IEEE ACCESS
LA English
DT Article
DE Image forensics; manipulation classification; convolutional neural
   network (CNN); multi-domain features; JPEG compression
ID RESIDUAL NETWORK; STEGANALYSIS; FORENSICS
AB Image forensics comprises the analyses and classifications of manipulations that have been applied to images. The ability to classify various manipulations that have been employed in the process of forgery is essential. Techniques to identify multiple manipulations applied to uncompressed images have been reported thus far, but the forensic approach for JPEG images compressed with various qualities has not been proposed. In this paper, we propose the manipulation classification network (MCNet) to exploit multi-domain features of the spatial, frequency, and compression domains. The proposed MCNet learns several forensic features for each domain through a multi-stream structure and distinguishes manipulations by comprehensively analyzing the fused features. Our work jointly considers visual artifacts caused by image manipulations and compression artifacts due to JPEG compression; therefore, rich forensic features can be explored and learned in the training phase. To enable forgery analysis in the real-world environment, data were generated based on twenty types of manipulation algorithms and various compression parameters. To demonstrate the effectiveness of the proposed MCNet, extensive experiments were conducted using state-of-the-art baselines. Compared to these baselines, our proposed method outperforms in terms of multi-class manipulation classification. In addition, we experimentally proved that the fine-tuned model based on the multi-class manipulation task was effective for different forensic tasks such as DeepFake detection or integrity authentication of JPEG images.
C1 [Yu, In-Jae; Nam, Seung-Hun; Ahn, Wonhyuk; Kwon, Myung-Joon; Lee, Heung-Kyu] Korea Adv Inst Sci & Technol KAIST, Sch Comp, Daejeon 34141, South Korea.
   [Lee, Heung-Kyu] Digital Innotech Co, Daejeon 34184, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST)
RP Lee, HK (corresponding author), Korea Adv Inst Sci & Technol KAIST, Sch Comp, Daejeon 34141, South Korea.; Lee, HK (corresponding author), Digital Innotech Co, Daejeon 34184, South Korea.
EM heunglee@kaist.ac.kr
RI Nam, Seung-Hun/AAT-8449-2021
OI Ahn, Wonhyuk/0000-0002-7900-9504; Nam, Seung-Hun/0000-0002-2576-7342;
   Kwon, Myung-Joon/0000-0002-9784-8440; Yu, In-Jae/0000-0001-9865-2194
FU Institute for Information and Communications Technology Planning and
   Evaluation (IITP) - Korea Government (Development of high reliability
   image and video authentication service for smart media environment)
   [2017-0-01671]; National Research Foundation of Korea (NRF)National
   Research Foundation of Korea [NRF-2019R1A2C2084569]
FX This work was supported in part by the Institute for Information and
   Communications Technology Planning and Evaluation (IITP) funded by
   Minister of Science and ICT (MIST), Korea Government (Development of
   high reliability image and video authentication service for smart media
   environment) under Grant 2017-0-01671, and in part by the National
   Research Foundation of Korea (NRF) under Grant NRF-2019R1A2C2084569.
CR Afchar D., 2018, 2018 IEEE INT WORKSH, P1, DOI DOI 10.1109/WIFS.2018.8630761
   Ahn W, 2020, ELECTRON LETT, V56, P82, DOI 10.1049/el.2019.2719
   Ahn W, 2020, IEEE ACCESS, V8, P137789, DOI 10.1109/ACCESS.2020.3011752
   Barni M, 2017, J VIS COMMUN IMAGE R, V49, P153, DOI 10.1016/j.jvcir.2017.09.003
   Bayar B., 2017, ELECT IMAGING, V2017, P77, DOI DOI 10.2352/ISSN.2470-1173.2017.7.MWSF-328
   Bayar B, 2018, IEEE T INF FOREN SEC, V13, P2691, DOI 10.1109/TIFS.2018.2825953
   Boroumand M, 2019, IEEE T INF FOREN SEC, V14, P1181, DOI 10.1109/TIFS.2018.2871749
   Bychkovsky V, 2011, PROC CVPR IEEE, P97
   Chattopadhay A, 2018, IEEE WINT CONF APPL, P839, DOI 10.1109/WACV.2018.00097
   Chen JS, 2015, IEEE SIGNAL PROC LET, V22, P1849, DOI 10.1109/LSP.2015.2438008
   Chollet F., 2016, XCEPTION DEEP LEARNI, P1251
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Cogranne R, 2019, IH&MMSEC '19: PROCEEDINGS OF THE ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, P125
   Cozzolino D, 2020, IEEE T INF FOREN SEC, V15, P144, DOI 10.1109/TIFS.2019.2916364
   Cozzolino Davide, 2017, P 5 ACM WORKSH INF H, P159, DOI DOI 10.1145/3082031.3083247
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Ferrer C.C, 2020, ARXIV200607397
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   He PS, 2018, IEEE SIGNAL PROC LET, V25, P1369, DOI 10.1109/LSP.2018.2855566
   He PS, 2017, J VIS COMMUN IMAGE R, V48, P149, DOI 10.1016/j.jvcir.2017.06.010
   Hou JU, 2017, IEEE T CIRC SYST VID, V27, P1826, DOI 10.1109/TCSVT.2016.2539828
   Kim DG, 2019, NEUROCOMPUTING, V365, P219, DOI 10.1016/j.neucom.2019.07.084
   Lee SJ, 2017, PROCEEDINGS OF THE FIFTEENTH IAPR INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS - MVA2017, P330, DOI 10.23919/MVA.2017.7986868
   Loshchilov I., 2017, ICLR
   Mayer O, 2020, INT CONF ACOUST SPEE, P2962, DOI 10.1109/ICASSP40776.2020.9054261
   Mayer O, 2020, IEEE T INF FOREN SEC, V15, P1331, DOI 10.1109/TIFS.2019.2924552
   Mo HX, 2018, PROCEEDINGS OF THE 6TH ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY (IH&MMSEC'18), P43, DOI 10.1145/3206004.3206009
   Nam S.-H., 2020, ARXIV200702393
   Nam SH, 2019, IEEE IMAGE PROC, P111, DOI 10.1109/ICIP.2019.8802966
   Nam SH, 2019, IEEE IMAGE PROC, P106, DOI 10.1109/ICIP.2019.8802946
   Park J., 2018, P EUR C COMP VIS MUN, P636
   Paszke A., 2019, NEURAL INFORM PROCES, V32, P8026
   Popescu AC, 2005, IEEE T SIGNAL PROCES, V53, P758, DOI 10.1109/TSP.2004.839932
   Ren Shaoqing, 2017, IEEE Trans Pattern Anal Mach Intell, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rossler A, 2019, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2019.00009
   Ryu SJ, 2014, IEICE T INF SYST, VE97D, P1304, DOI 10.1587/transinf.E97.D.1304
   Ryu SJ, 2013, IEEE T INF FOREN SEC, V8, P1355, DOI 10.1109/TIFS.2013.2272377
   Stamm MC, 2013, IEEE ACCESS, V1, P167, DOI 10.1109/ACCESS.2013.2260814
   Verdoliva L., 2020, ARXIV200106564
   Wu Y., 2019, P IEEE CVF C COMP VI, P9543
   Yang PP, 2020, J IMAGING, V6, DOI 10.3390/jimaging6030009
   Yousfi Y, 2020, IEEE SIGNAL PROC LET, V27, P830, DOI 10.1109/LSP.2020.2993959
   Zhan Y., 2017, P 5 ACM WORKSH INF H, P165, DOI [10.1145/3082031.3083250, DOI 10.1145/3082031.3083250]
   Zhang J, 2020, IEEE SIGNAL PROC LET, V27, P276, DOI 10.1109/LSP.2020.2966888
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
   Zhou P, 2018, PROC CVPR IEEE, P1053, DOI 10.1109/CVPR.2018.00116
NR 46
TC 1
Z9 1
U1 2
U2 4
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2020
VL 8
BP 210837
EP 210854
DI 10.1109/ACCESS.2020.3037735
PG 18
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA PB0BY
UT WOS:000595994200001
OA gold
DA 2022-02-06
ER

PT J
AU Zhang, YQ
   Bai, YH
   Ding, ML
   Ghanem, B
AF Zhang, Yongqiang
   Bai, Yancheng
   Ding, Mingli
   Ghanem, Bernard
TI Multi-task Generative Adversarial Network for Detecting Small Objects in
   the Wild
SO INTERNATIONAL JOURNAL OF COMPUTER VISION
LA English
DT Article
DE Small object detection; Small face detection; Super-resolution network;
   Multi-task generative adversarial network; COCO; WIDER FACE
AB Object detection results have been rapidly improved over a short period of time with the development of deep convolutional neural networks. Although impressive results have been achieved on large/medium sized objects, the performance on small objects is far from satisfactory and one of remaining open challenges is detecting small object in unconstrained conditions (e.g. COCO and WIDER FACE benchmarks). The reason is that small objects usually lack sufficient detailed appearance information, which can distinguish them from the backgrounds or similar objects. To deal with the small object detection problem, in this paper, we propose an end-to-end multi-task generative adversarial network (MTGAN), which is a general framework. In the MTGAN, the generator is a super-resolution network, which can up-sample small blurred images into fine-scale ones and recover detailed information for more accurate detection. The discriminator is a multi-task network, which describes each inputted image patch with a real/fake score, object category scores, and bounding box regression offsets. Furthermore, to make the generator recover more details for easier detection, the classification and regression losses in the discriminator are back-propagated into the generator during training process. Extensive experiments on the challenging COCO and WIDER FACE datasets demonstrate the effectiveness of the proposed method in restoring a clear super-resolved image from a blurred small one, and show that the detection performance, especially for small sized objects, improves over state-of-the-art methods by a large margin.
C1 [Zhang, Yongqiang; Ding, Mingli] Harbin Inst Technol, Sch Instrumentat Sci & Engn, Harbin, Peoples R China.
   [Bai, Yancheng] Chinese Acad Sci, Inst Software, Beijing, Peoples R China.
   [Ghanem, Bernard] King Abdullah Univ Sci & Technol, Visual Comp Ctr, Thuwal, Saudi Arabia.
C3 Harbin Institute of Technology; Chinese Academy of Sciences; Institute
   of Software, CAS; King Abdullah University of Science & Technology
RP Ding, ML (corresponding author), Harbin Inst Technol, Sch Instrumentat Sci & Engn, Harbin, Peoples R China.
EM zhangyongqiang@hit.edu.cn; yancheng.bai.1987@gmail.com;
   dingml@hit.edu.cn; Bernardghanem@gmail.com
OI Zhang, Yongqiang/0000-0002-0437-7337
FU Natural Science Foundation of ChinaNational Natural Science Foundation
   of China (NSFC) [61603372]
FX The majority of this work was done when Yongqiang Zhang was a visiting
   Ph.D. student at King Abdullah University of Science and Technology
   (KAUST), and the others are continued at Harbin Institute of Technology
   (HIT). This work was supported by Natural Science Foundation of China,
   Grant No. 61603372.
CR [Anonymous], 2017, IEEE ICC
   Bai YC, 2018, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2018.00010
   Bai YC, 2018, LECT NOTES COMPUT SC, V11217, P210, DOI 10.1007/978-3-030-01261-8_13
   Bell S, 2016, PROC CVPR IEEE, P2874, DOI 10.1109/CVPR.2016.314
   Berg, 2017, ARXIV170106659
   Cai ZW, 2018, PROC CVPR IEEE, P6154, DOI 10.1109/CVPR.2018.00644
   Cai ZW, 2016, LECT NOTES COMPUT SC, V9908, P354, DOI 10.1007/978-3-319-46493-0_22
   Chen BB, 2018, ADV SOC SCI EDUC HUM, V181, P453
   Chi C., 2018, ABS180902693 CORR
   Chintala S, 2015, ARXIV151106434
   Dai J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1796, DOI 10.1109/ICIT.2016.7475036
   Denton E. L., 2015, ADV NEURAL INFORM PR, P1486, DOI DOI 10.5555/
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Ghanem, 2017, ARXIV170706330
   Girshick R., 2014, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2014.81
   Girshick Ross, 2018, DETECTRON
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   He K., 2016, DEEP RESIDUAL LEARNI, DOI DOI 10.1109/CVPR.2016.90
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI 10.1109/ICCV.2017.322
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   HRADIS M, 2015, P BMVC, V10, P2
   Hu PY, 2017, PROC CVPR IEEE, P1522, DOI 10.1109/CVPR.2017.166
   Isola P., 2017, P IEEE C COMPUTER VI, P5967, DOI DOI 10.1109/CVPR.2017.632
   Jain V., 2010, UMCS2010009, V2, P8
   Jiang HZ, 2017, IEEE INT CONF AUTOMA, P650, DOI [10.1109/FG.2017.82, 10.1109/MWSYM.2017.8058653]
   Kim J, 2016, PROC CVPR IEEE, P1646, DOI 10.1109/CVPR.2016.182
   Kingma DP, 2015, 3 INT C LEARN REPR I, DOI DOI 10.1145/1830483.1830503
   Krizhevsky A., 2012, ADV NEURAL INF PROCE, P1097, DOI DOI 10.1145/3065386
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li J., 2018, ARXIV181010220
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Loffe S., 2015, ABS150203167 ARXIV, P448, DOI DOI 10.1109/CVPR.2016.90
   Mathieu Michael F., 2016, ADV NEURAL INFORM PR, P5040
   Najibi M, 2017, IEEE I CONF COMP VIS, P4885, DOI 10.1109/ICCV.2017.522
   Redmon J, 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.91
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Ren SQ, 2015, ADV NEUR IN, V28
   Ren Shaoqing, 2017, IEEE Trans Pattern Anal Mach Intell, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shen ZQ, 2019, THIRTY-THIRD AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTY-FIRST INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / NINTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P4886, DOI 10.1609/aaai.v33i01.33014886
   Shiri F, 2019, INT J COMPUT VISION, V127, P863, DOI 10.1007/s11263-019-01169-1
   Shrivastava A., 2016, ARXIV PREPRINT ARXIV
   Shrivastava A, 2016, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2016.89
   Simonyan K, 2015, ICLR 2015, DOI DOI 10.1109/CVPR.2015.7298594
   Song YB, 2019, INT J COMPUT VISION, V127, P785, DOI 10.1007/s11263-019-01148-6
   Tang X., 2018, P EUR C COMP VIS ECC, P1
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wan S., 2016, ARXIV160802236
   Wang J., 2017, ARXIV171107246
   Wang Yitong, 2017, ARXIV170905256
   Wang ZW, 2015, IEEE I CONF COMP VIS, P370, DOI 10.1109/ICCV.2015.50
   Wei, 2018, ARXIV181004002
   Wen YD, 2019, INT J COMPUT VISION, V127, P668, DOI 10.1007/s11263-018-01142-4
   Yan J, 2013, SCI WORLD J, DOI 10.1155/2013/458106
   Yan JJ, 2014, PROC CVPR IEEE, P2497, DOI 10.1109/CVPR.2014.320
   YANG S, 2016, PROC CVPR IEEE, P5525, DOI DOI 10.1109/CVPR.2016.596
   Zhang Changzheng, 2018, ARXIV180202142
   Zhang H, 2019, INT J COMPUT VISION, V127, P845, DOI 10.1007/s11263-019-01175-3
   Zhang J., 2017, ABS171200721 CORR
   Zhang SF, 2017, IEEE I CONF COMP VIS, P192, DOI 10.1109/ICCV.2017.30
   Zhang SM, 2019, CHAOS SOLITON FRACT, V127, P1, DOI 10.1016/j.chaos.2019.06.021
   Zhang Y., 2019, IEEE T CIRCUITS SYST, V30, P983
   Zhang Y., 2017, ICMV 2016, V10341
   Zhang YQ, 2019, PATTERN RECOGN LETT, V128, P407, DOI 10.1016/j.patrec.2019.10.005
   Zhang YQ, 2019, PATTERN RECOGN, V94, P74, DOI 10.1016/j.patcog.2019.05.023
   Zhang YQ, 2018, PROC CVPR IEEE, P928, DOI 10.1109/CVPR.2018.00103
   Zhang YQ, 2018, PATTERN RECOGN, V84, P68, DOI 10.1016/j.patcog.2018.07.005
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
   Zhou B., 2014, P 28 ANN C NEUR INF, P487
   ZHU C, 2017, DEEP LEARNING BIOMET
   Zhu CC, 2018, PROC CVPR IEEE, P5127, DOI 10.1109/CVPR.2018.00538
   Zhu CC, 2017, ADV COMPUT VIS PATT, P57, DOI 10.1007/978-3-319-61657-5_3
   Zhu JY, 2016, LECT NOTES COMPUT SC, V9909, P597, DOI 10.1007/978-3-319-46454-1_36
NR 74
TC 5
Z9 5
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0920-5691
EI 1573-1405
J9 INT J COMPUT VISION
JI Int. J. Comput. Vis.
PD JUN
PY 2020
VL 128
IS 6
BP 1810
EP 1828
DI 10.1007/s11263-020-01301-6
EA FEB 2020
PG 19
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA LQ3MN
UT WOS:000516304300001
OA Green Submitted
DA 2022-02-06
ER

PT J
AU Liu, Y
   Chen, W
   Liu, L
   Lew, MS
AF Liu, Yu
   Chen, Wei
   Liu, Li
   Lew, Michael S.
TI SwapGAN: A Multistage Generative Approach for Person-to-Person Fashion
   Style Transfer
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
AB Fashion style transfer has attracted significant attention because it both has interesting scientific challenges and it is also important to the fashion industry. This paper focuses on addressing a practical problem in fashion style transfer, person-to-person clothing swapping, which aims to visualize what the person would look like with the target clothes worn on another person instead of dressing them physically. This problem remains challenging due to varying pose deformations between different person images. In contrast to traditional nonparametric methods that blend or warp the target clothes for the reference person, in this paper we propose a multistage deep generative approach named SwapGAN that exploits three generators and one discriminator in a unified framework to fulfill the task end-to-end. The first and second generators are conditioned on a human pose map and a segmentation map, respectively, so that we can simultaneously transfer the pose style and the clothes style. In addition, the third generator is used to preserve the human body shape during the image synthesis process. The discriminator needs to distinguish two fake image pairs from the real image pair. The entire SwapCAN is trained by integrating the adversarial loss and the mask-consistency loss. The experimental results on the DeepFashion dataset demonstrate the improvements of SwapGAN over other existing approaches through both quantitative and qualitative evaluations. Moreover, we conduct ablation studies on SwapGAN and provide a detailed analysis about its effectiveness.
C1 [Liu, Yu; Chen, Wei; Lew, Michael S.] Leiden Univ, Leiden Inst Adv Comp Sci, NL-2311 Leiden, Netherlands.
   [Liu, Li] Natl Univ Def Technol, Coll Syst Engn, Changsha 410073, Hunan, Peoples R China.
   [Liu, Li] Univ Oulu, Ctr Machine Vis & Signal Anal, Oulu 90014, Finland.
C3 Leiden University; Leiden University - Excl LUMC; National University of
   Defense Technology - China; University of Oulu
RP Lew, MS (corresponding author), Leiden Univ, Leiden Inst Adv Comp Sci, NL-2311 Leiden, Netherlands.
EM y.liu@liacs.leidenuniv.nl; w.chen@liacs.leidenuniv.nl; li.liu@oulu.fi;
   m.s.k.lew@liacs.leidenuniv.nl
OI Liu, li/0000-0002-2011-2873
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61872379]
FX This work was supported by the National Natural Science Foundation of
   China under Grant 61872379. The associate editor coordinating the review
   of this manuscript and approving it for publication was Dr. Lei Zhang.
CR Abadi M., 2015, TENSORFLOW LARGE SCA
   Al-Halah Z, 2017, IEEE I CONF COMP VIS, P388, DOI 10.1109/ICCV.2017.50
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Denton E. L., 2015, ADV NEURAL INFORM PR, P1486, DOI DOI 10.5555/
   Dong Haoye, 2018, ADV NEURAL INFORM PR
   Fu Y., 2017, P 26 INT JOINT C ART, P3721, DOI DOI 10.24963/IJCAI.2017/520
   Garg V., 2017, P ACM C KNOWL DISC D
   Gong K, 2017, PROC CVPR IEEE, P6757, DOI 10.1109/CVPR.2017.715
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Guan P, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185531
   Gultepe U, 2014, COMPUT GRAPH-UK, V43, P31, DOI 10.1016/j.cag.2014.06.001
   Han XT, 2018, PROC CVPR IEEE, P7543, DOI 10.1109/CVPR.2018.00787
   Hauswiesner S, 2013, IEEE T VIS COMPUT GR, V19, P1552, DOI 10.1109/TVCG.2013.67
   Hoffman J, 2018, PR MACH LEARN RES, V80
   Huang X, 2017, PROC CVPR IEEE, P1866, DOI 10.1109/CVPR.2017.202
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jetchev N, 2017, IEEE INT CONF COMP V, P2287, DOI 10.1109/ICCVW.2017.269
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Kanamori Y, 2016, LECT NOTES COMPUT SC, V9550, P1, DOI 10.1007/978-3-662-49247-5_1
   Kiapour MH, 2015, IEEE I CONF COMP VIS, P3343, DOI 10.1109/ICCV.2015.382
   Kingma DP, 2015, 3 INT C LEARN REPR I, DOI DOI 10.1145/1830483.1830503
   Li YC, 2017, IEEE T MULTIMEDIA, V19, P1946, DOI 10.1109/TMM.2017.2690144
   Liang XD, 2016, IEEE T MULTIMEDIA, V18, P1175, DOI 10.1109/TMM.2016.2542983
   Liu DL, 2017, 2017 INTERNATIONAL CONFERENCE ON SMART GRID AND ELECTRICAL AUTOMATION (ICSGEA), P406, DOI 10.1109/ICSGEA.2017.74
   Liu S, 2015, IEEE T MULTIMEDIA, V17, P1347, DOI 10.1109/TMM.2015.2443559
   Liu ZW, 2016, PROC CVPR IEEE, P1096, DOI 10.1109/CVPR.2016.124
   Ma LQ, 2018, PROC CVPR IEEE, P99, DOI 10.1109/CVPR.2018.00018
   Ma YH, 2017, THIRTY-FIRST AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P38
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Mirza M, 2014, ARXIV PREPRINT ARXIV
   Movania M. M., 2013, P ACM SIGGRAPH, P72
   Odena A., 2016, DISTILL, V1, pe3, DOI [10.23915/distill.00003, DOI 10.23915/DISTILL.00003]
   Pons-Moll G, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073711
   Reed S., 2016, P INT C MACH LEARN, P2672
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Salimans T., 2016, NEURIPS, P2234, DOI DOI 10.5555/3157096.3157346
   Siarohin A, 2018, PROC CVPR IEEE, P3408, DOI 10.1109/CVPR.2018.00359
   Ulyanov D., 2017, P IEEE INT C COMP VI, P2242
   Wang B, 2018, 2018 IEEE 3RD INTERNATIONAL CONFERENCE ON CLOUD COMPUTING AND BIG DATA ANALYSIS (ICCCBDA), P589, DOI 10.1109/ICCCBDA.2018.8386584
   Yan XC, 2016, LECT NOTES COMPUT SC, V9908, P776, DOI 10.1007/978-3-319-46493-0_47
   Yang Shan, 2016, ARXIV160801250
   Yoo D, 2016, LECT NOTES COMPUT SC, V9912, P517, DOI 10.1007/978-3-319-46484-8_31
   Zhang H, 2017, IEEE I CONF COMP VIS, P5908, DOI 10.1109/ICCV.2017.629
   Zhang LM, 2018, IEEE T MULTIMEDIA, V20, P1462, DOI 10.1109/TMM.2017.2769799
   Zhang XS, 2017, IEEE T MULTIMEDIA, V19, P2533, DOI 10.1109/TMM.2017.2696825
   Zhao B, 2016, IEEE T MULTIMEDIA, V18, P1111, DOI 10.1109/TMM.2016.2537783
   Zheng Zhaoheng, 2017, [Computational Visual Media, 计算可视媒体], V3, P337
   Zhou Zhenglong, 2012, SIGGRAPH ASIA 2012 T, DOI DOI 10.1145/2407746.2407779
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu SZ, 2017, IEEE I CONF COMP VIS, P1689, DOI 10.1109/ICCV.2017.186
NR 51
TC 13
Z9 13
U1 2
U2 14
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD SEP
PY 2019
VL 21
IS 9
BP 2209
EP 2222
DI 10.1109/TMM.2019.2897897
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA IT6VX
UT WOS:000483015200005
OA Green Accepted
DA 2022-02-06
ER

PT J
AU Lee, S
   Tariq, S
   Shin, Y
   Woo, SS
AF Lee, Sangyup
   Tariq, Shahroz
   Shin, Youjin
   Woo, Simon S.
TI Detecting handcrafted facial image manipulations and GAN-generated
   facial images using Shallow-FakeFaceNet
SO APPLIED SOFT COMPUTING
LA English
DT Article
DE Soft computing; Fake media content detection; Fake image dataset;
   Multimedia forensics; GAN-generated image detection; Deepfake detection
AB The rapid progress of sophisticated image editing tools has made it easier to manipulate original face images and create fake media content by putting one's face to another. In addition to image editing tools, creating natural-looking fake human faces can be easily achieved by Generative Adversarial Networks (GANs). However, malicious use of these new media generation technologies can lead to severe problems, such as the development of fake pornography, defamation, or fraud. In this paper, we introduce a novel Handcrafted Facial Manipulation (HFM) image dataset and soft computing neural network models (Shallow-FakeFaceNets) with an efficient facial manipulation detection pipeline. Our neural network classifier model, Shallow-FakeFaceNet (SFFN), shows the ability to focus on the manipulated facial landmarks to detect fake images. The detection pipeline only relies on detecting fake facial images based on RGB information, not leveraging any metadata, which can be easily manipulated. Our results show that our method achieves the best performance of 72.52% in Area Under the Receiver Operating Characteristic (AUROC), gaining 3.99% F1-score and 2.91% AUROC on detecting handcrafted fake facial images, and 93.99% on detecting small GAN-generated fake images, gaining 1.98% F1-score and 10.44% AUROC compared to the best performing state-of-the-art classifier. This study is targeted for developing an automated defense mechanism to combat fake images used in different online services and applications, leveraging our state-of-the-art hand-crafted fake facial dataset (HFM) and the neural network classifier Shallow-FakeFaceNet (SFFN). In addition, our work presents various experimental results that can help guide better applied soft computing research in the future to effectively combat and detect human and GAN-generated fake face images. (C) 2021 Elsevier B.V. All rights reserved.
C1 [Lee, Sangyup; Tariq, Shahroz] Sungkyunkwan Univ, Dept Comp Sci & Engn, Suwon, South Korea.
   [Shin, Youjin] State Univ New York, Dept Comp Sci & Engn, Incheon, South Korea.
   [Woo, Simon S.] Sungkyunkwan Univ, Dept Appl Data Sci, Coll Comp & Informat, Suwon, South Korea.
C3 Sungkyunkwan University (SKKU); Sungkyunkwan University (SKKU)
RP Woo, SS (corresponding author), Sungkyunkwan Univ, Dept Appl Data Sci, Coll Comp & Informat, Suwon, South Korea.
EM sangyup.lee@g.skku.edu; shahroz@g.skku.edu;
   youjin.shin.1@stonybrook.edu; swoo@g.skku.edu
RI Tariq, Shahroz/AAL-4231-2021
OI Tariq, Shahroz/0000-0001-9090-0579
FU Institute of Information & communications Technology Planning &
   Evaluation (IITP) - Korea government Ministry of Science, ICT (MSIT)
   [2019-0-01343]; Basic Science Research Program through National Research
   Foundation of Korea - Korea government (MSIT) [2020R1C1C1006004]; IITP -
   Korea government (MSIT) [2021-0-00017]; Korea government (MSIT) under
   the High-Potential Individuals Global Training ProgramKorean Government
   [2019-0-01579]
FX We thank the reviewers for their insightful comments and Siho Han for
   carefully reviewing our initial manuscript. This work was supported by
   Institute of Information & communications Technology Planning &
   Evaluation (IITP) grant funded by Korea government Ministry of Science,
   ICT (MSIT) (No. 2019-0-01343, Regional strategic industry convergence
   security core talent training business) and the Basic Science Research
   Program through National Research Foundation of Korea grant funded by
   Korea government (MSIT) (No. 2020R1C1C1006004). Additionally this
   research was partly supported by IITP grant funded by the Korea
   government (MSIT) (No. 2021-0-00017, Original Technology Development of
   Artificial Intelligence Industry) and was supported by the Korea
   government (MSIT), under the High-Potential Individuals Global Training
   Program) (2019-0-01579) supervised by the IITP.
CR Adobe, 2020, ADOBE PHOTOSHOP BEST
   Caplin S, 2019, PHOTOSHOP 2020 NEW F
   Chollet F., 2015, GITHUB REPOS
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Christian J, 2018, OUTL
   Chu H, 2017, GITHUB AUROC AREA RE
   Cole S., 2018, WE ARE TRULY FUCKED, P1
   Computational Intelligence and Photography Lab Yonsei University, 2019, REAL FAKE FACE DETEC
   Cozzolino Davide, 2017, P 5 ACM WORKSH INF H, P159, DOI DOI 10.1145/3082031.3083247
   Durall Ricard, 2019, ARXIV191100686
   Eaton-Rosen Z., 2018, 1 C MED IM DEEP LEAR
   FaceSwapDevs, 2020, DEEPFAKES FACESWAP G
   Farid H, 2009, IEEE T INF FOREN SEC, V4, P154, DOI 10.1109/TIFS.2008.2012215
   Galindo G, 2020, BRUSSELS TIMES
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Han C, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P119, DOI 10.1145/3357384.3357890
   Hashmi MF, 2013, INT CONF INTELL SYST, P188, DOI 10.1109/ISDA.2013.6920733
   He K., 2016, DEEP RESIDUAL LEARNI, DOI DOI 10.1109/CVPR.2016.90
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huh M, 2018, LECT NOTES COMPUT SC, V11215, P106, DOI 10.1007/978-3-030-01252-6_7
   Hussain Zeshan, 2017, AMIA Annu Symp Proc, V2017, P979
   I. de Paz Centeno, 2016, MTCNN FACE DETECTION
   Jeon H., 2015, P IEEE CVF INT C COM
   Jeon H, 2020, PR MACH LEARN RES, V119
   Jung A.B., 2020, IMGAUG
   Karras T., 2017, ARXIV171010196
   Kashyap A, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION & AUTOMATION (ICCCA), P843, DOI 10.1109/CCAA.2015.7148492
   Khalid Hasam, 2020, P IEEE CVF C COMP VI, P656
   Kim D., 2019, BRIT MACH VIS C BMVC
   Kim J, 2019, IEEE INT CONF BIG DA, P6248, DOI 10.1109/BigData47090.2019.9005683
   Kingma D., 2013, ARXIV13126114
   Kowalski M, 2016, FACESWAP GITHUB REPO
   Krawetz, 2007, HACKER FACTOR SOLUTI, V6, P2
   Krawetz N, 2020, NEAL KRAWETZ
   Li YJ, 2019, IEEE INT C BIOINFORM, P303, DOI 10.1109/BIBM47256.2019.8982964
   Lin ZC, 2009, PATTERN RECOGN, V42, P2492, DOI 10.1016/j.patcog.2009.03.019
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Loffe S., 2015, ABS150203167 ARXIV, P448, DOI DOI 10.1109/CVPR.2016.90
   Multimedia Computing Laboratory, 2015, MMC IMAGE FORENSIC T
   Murali S., 2013, ARXIV PREPRINT ARXIV
   News B.B.C., 2019, FAKE VIDEO JOHNSON C
   Park S, 2017, LECT NOTES COMPUT SC, V10112, P189, DOI 10.1007/978-3-319-54184-6_12
   Rossler A, 2019, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2019.00009
   Romano Aja, 2018, VOX, V10, P44
   Roose K, 2018, THENEWYORKTIMES
   Rossler A., 2018, FACEFORENSICS LARGE
   Salimans T., 2016, NEURIPS, P2234, DOI DOI 10.5555/3157096.3157346
   Schlegl T, 2019, MED IMAGE ANAL, V54, P30, DOI 10.1016/j.media.2019.01.010
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Simonyan K, 2015, ICLR 2015, DOI DOI 10.1109/CVPR.2015.7298594
   SZEGEDY C, 2016, PROC CVPR IEEE, P2818, DOI DOI 10.1109/CVPR.2016.308
   Tariq S., 2020, ARXIV200907480
   Tariq S, 2019, SAC '19: PROCEEDINGS OF THE 34TH ACM/SIGAPP SYMPOSIUM ON APPLIED COMPUTING, P1296, DOI 10.1145/3297280.3297410
   Tariq S, 2018, MPS'18: PROCEEDINGS OF THE 2ND INTERNATIONAL WORKSHOP ON MULTIMEDIA PRIVACY AND SECURITY, P81, DOI 10.1145/3267357.3267367
   THIES J, 2016, PROC CVPR IEEE, P2387, DOI DOI 10.1109/CVPR.2016.262
   van den Oord A., 2016, ADV NEURAL INFORM PR, P4797
   van den Oord A, 2016, PR MACH LEARN RES, V48
   Wang J, 2018, ENVIRON TECHNOL, V39, P3055, DOI 10.1080/09593330.2017.1371797
   Wang SY, 2019, IEEE I CONF COMP VIS, P10071, DOI 10.1109/ICCV.2019.01017
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Wei Xiong, 2019, 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P5833, DOI 10.1109/CVPR.2019.00599
   Woo S.S., 2020, ARXIV PREPRINT ARXIV, P416
   Yang JQ, 2015, DIGIT SIGNAL PROCESS, V41, P90, DOI 10.1016/j.dsp.2015.03.014
   Zerdoumi S, 2018, MULTIMED TOOLS APPL, V77, P10091, DOI 10.1007/s11042-017-5045-7
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
   Zhou P, 2018, PROC CVPR IEEE, P1053, DOI 10.1109/CVPR.2018.00116
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 69
TC 2
Z9 2
U1 5
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1568-4946
EI 1872-9681
J9 APPL SOFT COMPUT
JI Appl. Soft. Comput.
PD JUL
PY 2021
VL 105
AR 107256
DI 10.1016/j.asoc.2021.107256
PG 16
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA SE0PT
UT WOS:000651778100009
DA 2022-02-06
ER

PT J
AU Tang, YB
   Wu, XQ
AF Tang, Youbao
   Wu, Xiangqian
TI Salient Object Detection Using Cascaded Convolutional Neural Networks
   and Adversarial Learning
SO IEEE TRANSACTIONS ON MULTIMEDIA
LA English
DT Article
DE Salient object detection; cascaded convolutional neural networks;
   conditional generative adversarial networks; adversarial learning
ID REGION DETECTION
AB Salient object detection has received much attention and achieved great success in last several years. It is still challenging to get clear boundaries and consistent saliencies, which can be considered as the structural information of salient objects. A popular solution is to conduct some post-processes (e.g., conditional random field (CRF)) to refine these structural information. In this paper, a novel cascaded convolutional neural networks (CNNs) based method is proposed to implicitly learn these structural information via adversarial learning for salient object detection (we termed the proposed method as CCAL). A cascaded CNNs model is first designed as a generator G, which consists of an encoder-decoder network for global saliency estimation and a deep residual network for local saliency refinement. It is hard to explicitly learn such structural information due to the limitation of frequently-used pixel-wise loss functions. Instead, a discriminator D is then designed to distinguish the real salient maps (i.e., ground truths) from the fake ones produced by G, based on which an adversarial loss is introduced to optimize G. G and D are trained in a fully end-to-end fashion by following the strategy of conditional generative adversarial networks to make G well learn the structural information. At last, G is able to produce high quality salient maps without requiring any post-process to fool D. Experimental results on eight benchmark datasets demonstrate the effectiveness and efficiency (about 17 fps on graphics processing unit (GPU)) of the proposed method for salient object detection.
C1 [Tang, Youbao; Wu, Xiangqian] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150001, Heilongjiang, Peoples R China.
C3 Harbin Institute of Technology
RP Wu, XQ (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150001, Heilongjiang, Peoples R China.
EM tybxiaobao@gmail.com; xqwu@hit.edu.cn
RI Tang, Youbao/L-7328-2019
OI Tang, Youbao/0000-0001-8719-3375
FU Natural Science Foundation of ChinaNational Natural Science Foundation
   of China (NSFC) [61672194]; National Key R&D Program of China
   [2018YFC0832304]; Distinguished Youth Science Foundation of Heilongjiang
   Province of China [JC2018021]; Shandong Provincial Natural Science
   Foundation, ChinaNatural Science Foundation of Shandong Province
   [ZR2016FM04]; Humanity and Social Science Youth Foundation of the
   Ministry of Education of China [14YJC760001]; Open Foundation of the
   State Key Laboratory of Robotics and System [SKLRS-2019-KF-14]
FX This work was supported in part by the Natural Science Foundation of
   China under Grant 61672194, in part by the National Key R&D Program of
   China under Grant 2018YFC0832304, in part by the Distinguished Youth
   Science Foundation of Heilongjiang Province of China under Grant
   JC2018021, in part by the Shandong Provincial Natural Science
   Foundation, China under Grant ZR2016FM04, in part by the Humanity and
   Social Science Youth Foundation of the Ministry of Education of China
   under Grant 14YJC760001, and in part by Open Foundation of the State Key
   Laboratory of Robotics and System under Grant SKLRS-2019-KF-14. The
   associate editor coordinating the review of this manuscript and
   approving it for publication was Dr. Jingdong Wang.
CR Abadi M., 2016, ARXIV PREPRINT ARXIV, DOI 10.1038/s41598-021-85274-7
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Alpert S, 2012, IEEE T PATTERN ANAL, V34, P315, DOI 10.1109/TPAMI.2011.130
   Borji A, 2015, IEEE T IMAGE PROCESS, V24, P5706, DOI 10.1109/TIP.2015.2487833
   Chen XW, 2017, IEEE I CONF COMP VIS, P1050, DOI 10.1109/ICCV.2017.119
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Fan DP, 2017, IEEE I CONF COMP VIS, P4558, DOI 10.1109/ICCV.2017.487
   Gidaris S, 2015, IEEE I CONF COMP VIS, P1134, DOI 10.1109/ICCV.2015.135
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Gross S., 2016, TRAINING INVESTIGATI
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Hong S, 2015, PR MACH LEARN RES, V37, P597
   Hou QB, 2017, PROC CVPR IEEE, P5300, DOI 10.1109/CVPR.2017.563
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jiang P, 2015, IEEE I CONF COMP VIS, P217, DOI 10.1109/ICCV.2015.33
   Jung C, 2012, IEEE T IMAGE PROCESS, V21, P1272, DOI 10.1109/TIP.2011.2164420
   Kim J, 2014, PROC CVPR IEEE, P883, DOI 10.1109/CVPR.2014.118
   Kingma DP, 2015, 3 INT C LEARN REPR I, DOI DOI 10.1145/1830483.1830503
   Krahenbuhl P., 2011, P NEURIPS, DOI DOI 10.5555/2986459.2986472
   Kuen J, 2016, PROC CVPR IEEE, P3668, DOI 10.1109/CVPR.2016.399
   Ledig C, 2017, PROC IEEE C COMPUT V, P4681
   Li CY, 2015, PROC CVPR IEEE, P2710, DOI 10.1109/CVPR.2015.7298887
   Li GB, 2016, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2016.58
   Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184
   Li HY, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2440174
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   Liu NA, 2016, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.2016.80
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mao Xudong, 2017, P IEEE INT C COMP VI
   Margolin R, 2014, PROC CVPR IEEE, P248, DOI 10.1109/CVPR.2014.39
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Mi JX, 2017, 2017 INTERNATIONAL CONFERENCE ON SECURITY, PATTERN ANALYSIS, AND CYBERNETICS (SPAC), P660, DOI 10.1109/SPAC.2017.8304358
   Mirza M, 2014, ARXIV PREPRINT ARXIV
   Movahedi V., P 2010 IEEE COMP SOC, P49, DOI DOI 10.1109/CVPRW.2010.5543739
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Pan Junting, 2017, ARXIV170101081
   Pan P, 2016, PROCEEDINGS OF 2016 IEEE 9TH UK-EUROPE-CHINA WORKSHOP ON MILLIMETRE WAVES AND TERAHERTZ TECHNOLOGIES (UCMMT), P39, DOI 10.1109/UCMMT.2016.7873954
   Qin Y, 2015, PROC CVPR IEEE, P110, DOI 10.1109/CVPR.2015.7298606
   Quan R, 2018, IEEE T MULTIMEDIA, V20, P1101, DOI 10.1109/TMM.2017.2763780
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rutishauser U, 2004, PROC CVPR IEEE, P37
   Scharfenberger C, 2015, IEEE T IMAGE PROCESS, V24, P457, DOI 10.1109/TIP.2014.2380351
   Simonyan K, 2015, ICLR 2015, DOI DOI 10.1109/CVPR.2015.7298594
   Sun JG, 2015, IEEE T IMAGE PROCESS, V24, P1639, DOI 10.1109/TIP.2015.2403241
   Tang Y, 2017, IEEE T IMAGE PROCESS, V26, P994, DOI [10.1109/TIP.2016.2639440, 10.1109/TIP.2017.2656474]
   Tang YB, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P618, DOI 10.1145/3123266.3123318
   Tang YB, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1083, DOI 10.1145/2733373.2806287
   Tang YB, 2016, LECT NOTES COMPUT SC, V9912, P809, DOI 10.1007/978-3-319-46484-8_49
   Tian YH, 2015, INT J COMPUT VISION, V111, P153, DOI 10.1007/s11263-014-0737-1
   Tong N, 2015, PROC CVPR IEEE, P1884, DOI 10.1109/CVPR.2015.7298798
   Wang LJ, 2015, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR.2015.7298938
   Wang Lijun, 2017, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2017.404
   Wang LZ, 2016, LECT NOTES COMPUT SC, V9908, P825, DOI 10.1007/978-3-319-46493-0_50
   Wang TT, 2018, PROC CVPR IEEE, P3127, DOI 10.1109/CVPR.2018.00330
   Wang TT, 2017, IEEE I CONF COMP VIS, P4039, DOI 10.1109/ICCV.2017.433
   Wang ZL, 2017, IEEE T MULTIMEDIA, V19, P750, DOI 10.1109/TMM.2016.2636739
   Xia C., 2017, P IEEE C COMP VIS PA, P4321
   Xiao HX, 2018, IEEE T MULTIMEDIA, V20, P3239, DOI 10.1109/TMM.2018.2830098
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI 10.1109/ICCV.2015.164
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Ye LW, 2017, IEEE T MULTIMEDIA, V19, P1742, DOI 10.1109/TMM.2017.2693022
   Zhang JM, 2015, IEEE I CONF COMP VIS, P1404, DOI 10.1109/ICCV.2015.165
   Zhang L, 2018, PROC CVPR IEEE, P1741, DOI 10.1109/CVPR.2018.00187
   Zhang PP, 2017, IEEE I CONF COMP VIS, P202, DOI 10.1109/ICCV.2017.31
   Zhang PP, 2017, IEEE I CONF COMP VIS, P212, DOI 10.1109/ICCV.2017.32
   Zhao R, 2015, PROC CVPR IEEE, P1265, DOI 10.1109/CVPR.2015.7298731
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
   Zou WB, 2015, IEEE I CONF COMP VIS, P406, DOI 10.1109/ICCV.2015.54
NR 70
TC 17
Z9 17
U1 2
U2 25
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1520-9210
EI 1941-0077
J9 IEEE T MULTIMEDIA
JI IEEE Trans. Multimedia
PD SEP
PY 2019
VL 21
IS 9
BP 2237
EP 2247
DI 10.1109/TMM.2019.2900908
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA IT6VX
UT WOS:000483015200007
DA 2022-02-06
ER

PT J
AU Hui, Z
   Li, J
   Gao, XB
   Wang, XM
AF Hui, Zheng
   Li, Jie
   Gao, Xinbo
   Wang, Xiumei
TI Progressive perception-oriented network for single image
   super-resolution
SO INFORMATION SCIENCES
LA English
DT Article
DE Perceptual image super-resolution; Progressive related works learning;
   Multi-scale hierarchical fusion
AB Recently, it has been demonstrated that deep neural networks can significantly improve the performance of single image super-resolution (SISR). Numerous studies have concentrated on raising the quantitative quality of super-resolved (SR) images. However, these methods that target PSNR maximization usually produce blurred images at large upscaling factor. The introduction of generative adversarial networks (GANs) can mitigate this issue and show impressive results with synthetic high-frequency textures. Nevertheless, these GAN-based approaches always have a tendency to add fake textures and even artifacts to make the SR image of visually higher-resolution. In this paper, we propose a novel perceptual image super-resolution method that progressively generates visually high-quality results by constructing a stage-wise network. Specifically, the first phase concentrates on minimizing pixel-wise error, and the second stage utilizes the features extracted by the previous stage to pursue results with better structural retention. The final stage employs fine structure features distilled by the second phase to produce more realistic results. In this way, we can maintain the pixel, and structural level information in the perceptual image as much as possible. It is useful to note that the proposed method can build three types of images in a feed-forward process. Also, we explore a new generator that adopts multi-scale hierarchical features fusion. Extensive experiments on benchmark datasets show that our approach is superior to the state-of-the-art methods. Code is available at https://github.com/Zheng222/PPON. (c) 2020 Elsevier Inc. All rights reserved.
C1 [Hui, Zheng; Li, Jie; Gao, Xinbo; Wang, Xiumei] Xidian Univ, Video & Image Proc Syst VIPS Lab, Sch Elect Engn, 2 South Taibai Rd, Xian 710071, Peoples R China.
   [Gao, Xinbo] Chongqing Univ Posts & Telecommun, Chongqing Key Lab Image Cognit, Chongqing 400065, Peoples R China.
C3 Xidian University; Chongqing University of Posts & Telecommunications
RP Gao, XB (corresponding author), Xidian Univ, Video & Image Proc Syst VIPS Lab, Sch Elect Engn, 2 South Taibai Rd, Xian 710071, Peoples R China.; Gao, XB (corresponding author), Chongqing Univ Posts & Telecommun, Chongqing Key Lab Image Cognit, Chongqing 400065, Peoples R China.
EM zheng_hui@aliyun.com; leejie@mail.xidian.edu.cn;
   xbgao@mail.xidian.edu.cn; wangxm@xidian.edu.cn
FU National Key Research and Development Program of China [2018AAA0102702,
   2018AAA0103202]; National Natural Science Foundation of ChinaNational
   Natural Science Foundation of China (NSFC) [61772402, 61671339,
   61871308, 61972305]
FX This work was supported in part by the National Key Research and
   Development Program of China under Grants 2018AAA0102702,
   2018AAA0103202, in part by the National Natural Science Foundation of
   China under Grant 61772402, 61671339, 61871308, and 61972305.
CR Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Blau Yochai, 2018, ECCV WORKSH
   Dai T., 2019, 2 ORDER ATTENTION NE, P11065
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Haris M, 2018, PROC CVPR IEEE, P1664, DOI 10.1109/CVPR.2018.00179
   Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156
   Hui Z, 2018, PROC CVPR IEEE, P723, DOI 10.1109/CVPR.2018.00082
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Jolicoeur-Martineau Alexia, 2019, RELATIVISTIC DISCRIM
   Kim J, 2016, PROC CVPR IEEE, P1646, DOI 10.1109/CVPR.2016.182
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.181, 10.1109/CVPR.2015.7299136]
   Kingma DP., 2015, INT C LEARNING REPRE
   Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li J., 2018, P EUROPEAN C COMPUTE, P517, DOI DOI 10.1145/3390462
   Li Z., 2019, FEEDBACK NETWORK IMA, P3867
   Lim Bee, 2017, P IEEE C COMP VIS PA, P136
   Liu H, 2019, INFORM SCIENCES, V473, P44, DOI 10.1016/j.ins.2018.09.018
   Luo JJ, 2018, INFORM SCIENCES, V462, P315, DOI 10.1016/j.ins.2018.06.030
   Ma C, 2017, COMPUT VIS IMAGE UND, V158, P1, DOI 10.1016/j.cviu.2016.12.009
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Matsui Y, 2017, MULTIMED TOOLS APPL, V76, P21811, DOI 10.1007/s11042-016-4020-z
   Mechrez R., 2018, MAINTAINING NATURAL
   Mehta S, 2018, LECT NOTES COMPUT SC, V11214, P561, DOI 10.1007/978-3-030-01249-6_34
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Park SJ, 2018, P EUR C COMP VIS ECC, P439, DOI [10.1007/978-3-030-01270-0_27, DOI 10.1007/978-3-030-01270-0_27]
   Sajjadi MSM, 2017, IEEE I CONF COMP VIS, P4501, DOI 10.1109/ICCV.2017.481
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Simonyan K., 2015, 3 INT C LEARNING REP, P1
   Soh JW, 2019, PROC CVPR IEEE, P8114, DOI 10.1109/CVPR.2019.00831
   Sohn, 2018, P EUR C COMP VIS ECC, P252
   Tai Y., 2017, P IEEE C COMP VIS PA, P3147
   Tai Y, 2017, IEEE I CONF COMP VIS, P4549, DOI 10.1109/ICCV.2017.486
   Timofte R, 2017, IEEE COMPUT SOC CONF, P1110, DOI 10.1109/CVPRW.2017.149
   Tong T, 2017, IEEE I CONF COMP VIS, P4809, DOI 10.1109/ICCV.2017.514
   Vasu Subeesh, 2018, ECCV WORKSH
   Wang XT, 2018, PROC CVPR IEEE, P606, DOI 10.1109/CVPR.2018.00070
   Wang Xintao, 2018, ECCV WORKSH
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8
   Zhang K, 2018, PROC CVPR IEEE, P3262, DOI 10.1109/CVPR.2018.00344
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhang Y., 2018, P EUR C COMP VIS ECC, P286
   Zhang Y., 2019, ICLR
   Zhang YL, 2018, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2018.00262
   Zhou Y, 2016, INFORM SCIENCES, V367, P337, DOI 10.1016/j.ins.2016.05.024
NR 50
TC 6
Z9 6
U1 5
U2 34
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 0020-0255
EI 1872-6291
J9 INFORM SCIENCES
JI Inf. Sci.
PD FEB 6
PY 2021
VL 546
BP 769
EP 786
DI 10.1016/j.ins.2020.08.114
PG 18
WC Computer Science, Information Systems
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA PB1AW
UT WOS:000596062600001
OA Green Submitted
DA 2022-02-06
ER

PT J
AU Bruns, A
AF Bruns, Axel
TI After the "APIcalypse': social media platforms and their fight against
   critical scholarly research
SO INFORMATION COMMUNICATION & SOCIETY
LA English
DT Article
DE Cambridge Analytica; Social Science One; Facebook; Twitter; Application
   Programming Interface; social media
ID FAKE NEWS; TWITTER
AB In the aftermath of the Cambridge Analytica controversy, social media platform providers such as Facebook and Twitter have severely restricted access to platform data via their Application Programming Interfaces (APIs). This has had a particularly critical effect on the ability of social media researchers to investigate phenomena such as abuse, hate speech, trolling, and disinformation campaigns, and to hold the platforms to account for the role that their affordances and policies might play in facilitating such dysfunction. Alternative data access frameworks, such as Facebook's partnership with the controversial Social Science One initiative, represent an insufficient replacement for fully functional APIs, and the platform providers' actions in responding to the Cambridge Analytica scandal raise suspicions that they have instrumentalised it to actively frustrate critical, independent, public interest scrutiny by scholars. Building on a critical review of Facebook's public statements through its own platforms and the mainstream media, and of the scholarly responses these have drawn, this article outlines the societal implications of the APIcalypse', and reviews potential options for scholars in responding to it.
C1 [Bruns, Axel] Queensland Univ Technol, Digital Media Res Ctr, Brisbane, Qld, Australia.
C3 Queensland University of Technology (QUT)
RP Bruns, A (corresponding author), Queensland Univ Technol, Digital Media Res Ctr, Brisbane, Qld, Australia.
EM a.bruns@qut.edu.au
FU Australian Research CouncilAustralian Research Council [FT130100703,
   LE140100148]
FX This work was supported by Australian Research Council: [Grant Number
   FT130100703, LE140100148].
CR Alaimo, 2018, BLOOMBERG
   Alaimo K., 2017, CNN
   [Anonymous], 2018, ABC NEWS
   [Anonymous], 2018, FACEBOOK NEWSROOM
   Baker B., 2015, TWITTER BLOG
   Ball J., 2018, NEW STATESMAN
   Baran Katsiaryna S., 2017, Journal of Information Management, V5, P33, DOI 10.1633/JISTaP.2017.5.2.3
   Bechmann Anja, 2015, First Monday, V20, DOI 10.5210/fm.v20i12.5968
   Borra E, 2014, ASLIB J INFORM MANAG, V66, P262, DOI 10.1108/AJIM-09-2013-0094
   Bounegru L, 2017, FIELD GUIDE FAKE NEW
   Bruns A., 2018, INTERNET POLICY REV
   BRUNS A, 2016, TRISMA TRACKING INFR
   Bruns A, 2016, PROCEEDINGS OF THE 2016 ACM WEB SCIENCE CONFERENCE (WEBSCI'16), P183, DOI 10.1145/2908131.2908174
   Bucher T., 2013, COMPUTATIONAL CULTUR
   Burgess J, 2015, COMPROMISED DATA: FROM SOCIAL MEDIA TO BIG DATA, P93
   Cadwalladr C., 2018, REVEALED 50 MILLION
   Chapman S, 2003, TOB CONTROL, V12, P13
   Constine J., 2018, FACEBOOK ADMITS CAMB
   Constine J, 2018, FACEBOOK RESTRICTS A
   Flick C, 2016, RES ETHICS REV, V12, P14
   Freelon D, 2018, POLIT COMMUN, V35, P665, DOI 10.1080/10584609.2018.1477506
   Frenkel S, 2018, NY TIMES
   Gadde V., 2018, MEASURING HLTH CONVE
   Grewal P., 2018, SUSPENDING CAMBRIDGE
   Grinberg N, 2019, SCIENCE, V363, P374, DOI 10.1126/science.aau2706
   Hughes C, 2019, NY TIMES
   Johnson R., 2018, TWITTER BLOG
   Kazansky Becky, 2019, GOOD DATA, V4, P244
   King G., 2018, NEW MODEL IND ACAD P
   Kirkorian R., 2014, TWITTER DATAGRANTS S
   Knight First Amendment Institute at Columbia University, 2018, KNIGHT I CALLS FAC L
   Kramer ADI, 2014, P NATL ACAD SCI USA, V111, P8788, DOI 10.1073/pnas.1320040111
   Locke P, 2011, STEM CELL RES THER, V2, DOI 10.1186/scrt63
   Mac R, 2018, BUZZFEED NEWS
   Merrill Jeremy B., 2019, PROPUBLICA
   Nasiritousi N, 2017, ENVIRON POLIT, V26, P621, DOI 10.1080/09644016.2017.1320832
   NATO Strategic Communications Centre of Excellence, 2017, DIG HYDR SEC IMPL FA
   Overly S., 2019, FACEBOOK EXPECTS 5B
   Pasternack A., 2018, FACEBOOK REINSTATES
   Pear Analytics San Antonio TX USA, 2009, TWITT STUD AUG 2009
   Perez S., 2018, TWITT CO EM ADDR WHY
   Pfaffenberger B, 2000, KNOWLEDGE TECH POLIC, V13, P78
   Poletti C., 2019, GOOD DATA, P260
   Raymond ES, 2001, IEEE SPECTRUM, V38, P14, DOI 10.1109/6.938720
   Rieder B., 2018, FACEBOOKS APP REV IN
   Rieder Bernhard, 2013, P 5 ANN ACM WEB SCI, P346, DOI [10.1145/2464464.2464475, DOI 10.1145/2464464.2464475]
   Rogers R, 2014, DESIGNING CRITICAL LITERACY EDUCATION THROUGH CRITICAL DISCOURSE ANALYSIS: PEDAGOGICAL AND RESEARCH TOOLS FOR TEACHER RESEARCHERS, pIX
   Rogers R, 2018, PARTECIP CONFL, V11, P557, DOI 10.1285/i20356609v11i2p557
   Rogers S., 2013, TWITTER BLOG
   Roth Y., 2018, NEW DEV REQUIREMENTS
   Sandvig C., 2017, HEADING COURTHOUSE S
   Schroepfer M, 2018, UPDATE OUR PLANS RES
   Snelson CL, 2016, INT J QUAL METH, V15, DOI 10.1177/1609406915624574
   Social Science One, 2018, REQ PROP SOC MED DEM
   Starbird K., 2018, THIS IS TURNING MY S
   Starbird K., 2018, I KNOW LOT AMAZING P
   Stone B, 2010, TWEET PRESERVATION
   Stromer-Galley J., 2016, ILLUMINATING 2016 PR
   Su J, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16), P1157, DOI 10.1145/2872427.2883040
   Twitter Inc, 2018, TWITT HLTH METR PROP
   United Nations, 1976, INT COV EC SOC CULT
   van Osch W, 2014, COMMUN MONOGR, V81, P285, DOI 10.1080/03637751.2014.921720
   van Schie G, 2017, DATAFIED SOCIETY: STUDYING CULTURE THROUGH DATA, P183
   Venturini T, 2019, DIGIT JOURNAL, V7, P532, DOI 10.1080/21670811.2019.1591927
   Wardle C, 2017, INFORM DISORDER INTE
   Weaver M., 2018, GUARDIAN
   Weller K.., 2015, P 9 INT AAAI C WEB S, P28
   Weller K, 2016, PROCEEDINGS OF THE 2016 ACM WEB SCIENCE CONFERENCE (WEBSCI'16), P166, DOI 10.1145/2908131.2908172
   Woolley S. C., 2017, 201711 COMP PROP RES
   Yach D, 2001, AM J PUBLIC HEALTH, V91, P1745, DOI 10.2105/AJPH.91.11.1745
   Zimmer M, 2014, ASLIB J INFORM MANAG, V66, P250, DOI 10.1108/AJIM-09-2013-0083
NR 71
TC 59
Z9 60
U1 15
U2 57
PU ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 1369-118X
EI 1468-4462
J9 INFORM COMMUN SOC
JI Info. Commun. Soc.
PY 2019
VL 22
IS 11
SI SI
BP 1544
EP 1566
DI 10.1080/1369118X.2019.1637447
EA JUL 2019
PG 23
WC Communication; Sociology
WE Social Science Citation Index (SSCI)
SC Communication; Sociology
GA IV7XS
UT WOS:000475774700001
OA Green Submitted
DA 2022-02-06
ER

PT J
AU Ayoub, J
   Yang, XJ
   Zhou, F
AF Ayoub, Jackie
   Yang, X. Jessie
   Zhou, Feng
TI Combat COVID-19 infodemic using explainable natural language processing
   models
SO INFORMATION PROCESSING & MANAGEMENT
LA English
DT Article
DE COVID-19; Misinformation detection; Trust; BERT; DistilBERT; SHAP
AB Misinformation of COVID-19 is prevalent on social media as the pandemic unfolds, and the associated risks are extremely high. Thus, it is critical to detect and combat such misinformation. Recently, deep learning models using natural language processing techniques, such as BERT (Bidirectional Encoder Representations from Transformers), have achieved great successes in detecting misinformation. In this paper, we proposed an explainable natural language processing model based on DistilBERT and SHAP (Shapley Additive exPlanations) to combat misinformation about COVID-19 due to their efficiency and effectiveness. First, we collected a dataset of 984 claims about COVID-19 with fact-checking. By augmenting the data using back-translation, we doubled the sample size of the dataset and the DistilBERT model was able to obtain good performance (accuracy: 0.972; areas under the curve: 0.993) in detecting misinformation about COVID-19. Our model was also tested on a larger dataset for AAAI2021 COVID-19 Fake News Detection Shared Task and obtained good performance (accuracy: 0.938; areas under the curve: 0.985). The performance on both datasets was better than traditional machine learning models. Second, in order to boost public trust in model prediction, we employed SHAP to improve model explainability, which was further evaluated using a between-subjects experiment with three conditions, i.e., text (T), text+SHAP explanation (TSE), and text+SHAP explanation+source and evidence (TSESE). The participants were significantly more likely to trust and share information related to COVID-19 in the TSE and TSESE conditions than in the T condition. Our results provided good implications for detecting misinformation about COVID-19 and improving public trust.
C1 [Ayoub, Jackie; Zhou, Feng] Univ Michigan, Ind & Mfg Syst Engn, 4901 Evergreen Rd, Dearborn, MI 48128 USA.
   [Yang, X. Jessie] Univ Michigan, Ind & Operat Engn, 1205 Beal Ave, Ann Arbor, MI 48015 USA.
C3 University of Michigan System; University of Michigan; University of
   Michigan System; University of Michigan
RP Zhou, F (corresponding author), Univ Michigan, Ind & Mfg Syst Engn, 4901 Evergreen Rd, Dearborn, MI 48128 USA.
EM fezhou@umich.edu
OI Zhou, Feng/0000-0001-6123-073X
CR Aggarwal A, 2020, EAI ENDORSED TRANS S, V7, DOI 10.4108/eai.13-7-2018.163973
   Akhtar, 2020, ARXIV201103327
   Ayoub J, 2021, TRANSPORT RES F-TRAF, V77, P102, DOI 10.1016/j.trf.2020.12.015
   Bahad P, 2019, PROCEDIA COMPUT SCI, V165, P74, DOI 10.1016/j.procs.2020.01.072
   Beaunoyer E, 2020, COMPUT HUM BEHAV, V111, DOI 10.1016/j.chb.2020.106424
   Benamira A, 2019, PROCEEDINGS OF THE 2019 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2019), P568, DOI 10.1145/3341161.3342958
   CDC, 2020, COR DIS 2019 COVID 1
   Cui LM, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P2961, DOI 10.1145/3357384.3357862
   Devlin J, 2019, PROC C N AM CHAPTER, P4171, DOI DOI 10.18653/V1/N19-1423
   Dong XS, 2020, IEEE T COMPUT SOC SY, V7, P1386, DOI 10.1109/TCSS.2020.3027639
   Doshi-Velez F., 2017, ARXIV 170208608
   Gilda S, 2017, IEEE ST CONF RES DEV, P110, DOI 10.1109/SCORED.2017.8305411
   Gilpin LH, 2018, PR INT CONF DATA SC, P80, DOI 10.1109/DSAA.2018.00018
   Jwa H, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9194062
   Kai Shu, 2017, ACM SIGKDD Explorations Newsletter, V19, P22, DOI 10.1145/3137597.3137600
   Kassam N., 2020, DISINFORMATION CORON
   Kim B., 2016, ADV NEURAL INFORM PR, P2280
   Kovalerchuk B, 2018, IEEE INT CONF BIG DA, P4940, DOI 10.1109/BigData.2018.8622433
   Lai V, 2019, FAT*'19: PROCEEDINGS OF THE 2019 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P29, DOI 10.1145/3287560.3287590
   Lee Dongwon, 2020, COAID COVID 19 HEALT
   Lei B, 2020, ARXIV200616942
   Lundberg S. M., 2018, ABS180203888 ARXIV
   Lundberg SM, 2017, ADV NEUR IN, V30
   Ma J., 2016, P 25 INT JOINT C ART, P3818
   Ma J, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P3049, DOI 10.1145/3308558.3313741
   Molnar C., 2019, INTERPRETABLE MACHIN
   Mosleh M, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0228882
   Ozbay FA, 2020, PHYSICA A, V540, DOI 10.1016/j.physa.2019.123174
   Papalexakis E. E, 2018, P SOCAL NLNP S
   Perez-Rosas V, 2018, P 27 INT C COMPUTATI, P3391
   Reis JCS, 2019, P 10 ACM C WEB SCI A, P17, DOI [10.1145/3292522.3326027, DOI 10.1145/3292522.3326027]
   Ruchansky N, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P797, DOI 10.1145/3132847.3132877
   Rudin C, 2019, NAT MACH INTELL, V1, P206, DOI 10.1038/s42256-019-0048-x
   Sanh V, 2019, ARXIV PREPRINT ARXIV
   Shapley L.S ., 1952, ANN MATH STUD, DOI DOI 10.1515/9781400881970-018
   Shu K, 2019, PROCEEDINGS OF THE TWELFTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'19), P312, DOI 10.1145/3289600.3290994
   Sumbaly Roshan, 2020, USING DETECT COVID 1
   Wang WY, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P422, DOI 10.18653/v1/P17-2067
   Wineburg S, 2019, TEACH COLL REC, V121
   Xie Qizhe, 2019, ARXIV190412848
   Yu PS, 2018, ARXIV180600749, DOI DOI 10.1145/3070644
   Zhou F, 2020, EXPERT SYST APPL, V147, DOI 10.1016/j.eswa.2020.113204
   Zhou XY, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3395046
NR 43
TC 4
Z9 4
U1 2
U2 2
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 0306-4573
EI 1873-5371
J9 INFORM PROCESS MANAG
JI Inf. Process. Manage.
PD JUL
PY 2021
VL 58
IS 4
AR 102569
DI 10.1016/j.ipm.2021.102569
PG 11
WC Computer Science, Information Systems; Information Science & Library
   Science
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Information Science & Library Science
GA SN6BG
UT WOS:000658372100021
PM 33776192
OA Green Submitted, Bronze, Green Published
DA 2022-02-06
ER

PT J
AU Chien, JT
   Peng, KT
AF Chien, Jen-Tzung
   Peng, Kang-Ting
TI Neural adversarial learning for speaker recognition
SO COMPUTER SPEECH AND LANGUAGE
LA English
DT Article
DE Probabilistic linear discriminant analysis; Adversarial learning;
   Manifold learning; Data augmentation; Speaker recognition
ID PLDA
AB This paper presents the adversarial learning approaches to deal with various tasks in speaker recognition based on probabilistic discriminant analysis (PLDA) which is seen as a latent variable model for reconstruction of i-vectors. The first task aims to reduce the dimension of i-vectors based on an adversarial manifold learning where the adversarial neural networks of generator and discriminator are merged to preserve neighbor embedding of i-vectors in a low-dimensional space. The generator is trained to fool the discriminator with the generated samples in latent space. A PLDA subspace model is constructed by jointly minimizing a PLDA reconstruction error, a manifold loss for neighbor embedding and an adversarial loss caused by the generator and discriminator. The second task of adversarial learning is developed to tackle the imbalanced data problem. A PLDA based generative adversarial network is trained to generate new i-vectors to balance the size of training utterances across different speakers. An adversarial augmentation learning is proposed for robust speaker recognition. In particular, the minimax optimization is performed to estimate a generator and a discriminator where the class conditional i-vectors produced by generator could not be distinguished from real i-vectors via discriminator. A multiobjective learning is realized for a specialized neural model with the cosine similarity between real and fake i-vectors as well as the regularization for Gaussianity. Experiments are conducted to show the merit of adversarial learning in subspace construction and data augmentation for PLDA-based speaker recognition. (C) 2019 Elsevier Ltd. All rights reserved.
C1 [Chien, Jen-Tzung; Peng, Kang-Ting] Natl Chiao Tung Univ, Dept Elect & Comp Engn, Hsinchu, Taiwan.
C3 National Yang Ming Chiao Tung University
RP Chien, JT (corresponding author), Natl Chiao Tung Univ, Dept Elect & Comp Engn, Hsinchu, Taiwan.
EM jtchien@nctu.edu.tw
OI Chien, Jen-Tzung/0000-0003-3466-8941
FU Ministry of Science and Technology, TaiwanMinistry of Science and
   Technology, Taiwan [MOST 108-2634-F-009-003]
FX This work was supported by the Ministry of Science and Technology,
   Taiwan, under Grant MOST 108-2634-F-009-003.
CR Che Tong, 2017, INT C LEARN REPR
   Chen K, 2011, IEEE T NEURAL NETWOR, V22, P1744, DOI 10.1109/TNN.2011.2167240
   Chien J.-T., 2018, P SPEAK LANG REC WOR, P342
   Chien JT, 2008, IEEE T AUDIO SPEECH, V16, P239, DOI 10.1109/TASL.2007.910790
   Chien JT, 2017, 2017 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU), P599, DOI 10.1109/ASRU.2017.8268991
   Chien JT, 2017, INT CONF ACOUST SPEE, P4935, DOI 10.1109/ICASSP.2017.7953095
   Chien JT, 2016, INT CONF ACOUST SPEE, P2672, DOI 10.1109/ICASSP.2016.7472162
   Cook J, 2007, P INT C ART INT STAT, P67
   Dehak N, 2011, IEEE T AUDIO SPEECH, V19, P788, DOI 10.1109/TASL.2010.2064307
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Fisher RA, 1938, ANN EUGENIC, V8, P376, DOI 10.1111/j.1469-1809.1938.tb02189.x
   Garcia-Romero D, 2011, 12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5, P256
   Glorot X., 2010, P 13 INT C ART INT S, P249
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Greenberg C.S., 2014, SPEAK LANG REC WORKS, P224
   Kingma D. P., 2014, P INT C LEARN REPR
   Kingma D P, 2015, ICLR
   Li N, 2017, IEEE-ACM T AUDIO SPE, V25, P1371, DOI 10.1109/TASLP.2017.2692304
   Li N, 2017, COMPUT SPEECH LANG, V45, P83, DOI 10.1016/j.csl.2017.04.001
   Lin W. -W., 2018, ODYSSEY, P162
   Lin WW, 2017, COMPUT SPEECH LANG, V45, P503, DOI 10.1016/j.csl.2017.02.009
   Makhzani Alireza, 2016, INT C LEARN REPR
   Man-Wai Mak, 2016, IEEE/ACM Transactions on Audio, Speech and Language Processing, V24, P130, DOI 10.1109/TASLP.2015.2499038
   Min M. R., 2010, P 27 INT C MACH LEAR, P791
   Mirza M, 2014, ARXIV PREPRINT ARXIV
   Odena A, 2017, PR MACH LEARN RES, V70
   Paccanaro A, 2002, ADV NEUR IN, V14, P857
   Prince SJD, 2007, IEEE I CONF COMP VIS, P1751
   Rao W, 2013, IEEE T AUDIO SPEECH, V21, P1012, DOI 10.1109/TASL.2013.2243436
   Snyder D, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5329, DOI 10.1109/ICASSP.2018.8461375
   Snyder D, 2017, INTERSPEECH, P999, DOI 10.21437/Interspeech.2017-620
   Tseng HH, 2017, INT CONF ACOUST SPEE, P2347, DOI 10.1109/ICASSP.2017.7952576
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Watanabe S., 2015, BAYESIAN SPEECH LANG
NR 34
TC 3
Z9 3
U1 0
U2 17
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0885-2308
EI 1095-8363
J9 COMPUT SPEECH LANG
JI Comput. Speech Lang.
PD NOV
PY 2019
VL 58
BP 422
EP 440
DI 10.1016/j.csl.2019.06.003
PG 19
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IM0GC
UT WOS:000477663800023
DA 2022-02-06
ER

PT J
AU Zhao, J
   Xiong, L
   Li, JS
   Xing, JL
   Yan, SC
   Feng, JS
AF Zhao, Jian
   Xiong, Lin
   Li, Jianshu
   Xing, Junliang
   Yan, Shuicheng
   Feng, Jiashi
TI 3D-Aided Dual-Agent GANs for Unconstrained Face Recognition
SO IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE
LA English
DT Article
DE Face synthesis; unconstrained face recognition; 3D face model;
   generative adversarial networks
AB Synthesizing realistic profile faces is beneficial for more efficiently training deep pose-invariant models for large-scale unconstrained face recognition, by augmenting the number of samples with extreme poses and avoiding costly annotation work. However, learning from synthetic faces may not achieve the desired performance due to the discrepancy betwedistributions of the synthetic and real face images. To narrow this gap, we propose a Dual-Agent Generative Adversarial Network (DA-GAN) model, which can improve the realism of a face simulator's output using unlabeled real faces while preserving the identity information during the realism refinement. The dual agents are specially designed for distinguishing real versus fake and identities simultaneously. In particular, we employ an off-the-shelf 3D face model as a simulator to generate profile face images with varying poses. DA-GAN leverages a fully convolutional network as the generator to generate high-resolution images and an auto-encoder as the discriminator with the dual agents. Besides the novel architecture, we make several key modifications to the standard GAN to preserve pose, texture as well as identity, and stabilize the training process: (i) a pose perception loss; (ii) an identity perception loss; (iii) an adversarial loss with a boundary equilibrium regularization term. Experimental results show that DA-GAN not only achieves outstanding perceptual results but also significantly outperforms state-of-the-arts on the large-scale and challenging NIST IJB-A and CFP unconstrained face recognition benchmarks. In addition, the proposed DA-GAN is also a promising new approach for solving generic transfer learning problems more effectively. DA-GAN is the foundation of our winning entry to the NIST IJB-A face recognition competition in which we secured the 1st places on the tracks of verification and identification.
C1 [Zhao, Jian; Yan, Shuicheng; Feng, Jiashi] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 119077, Singapore.
   [Zhao, Jian] Natl Univ Def Technol, Sch Comp, Changsha 410073, Hunan, Peoples R China.
   [Xiong, Lin] Panasonic R&D Ctr Singapore, Core Technol Grp, Learning & Vis, Singapore 469332, Singapore.
   [Li, Jianshu] Natl Univ Singapore, Sch Comp, Singapore 119077, Singapore.
   [Xing, Junliang] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100864, Peoples R China.
   [Yan, Shuicheng] Qihoo 360 AI Inst, Beijing 100015, Peoples R China.
C3 National University of Singapore; National University of Defense
   Technology - China; Panasonic; National University of Singapore; Chinese
   Academy of Sciences; Institute of Automation, CAS
RP Zhao, J (corresponding author), Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 119077, Singapore.
EM zhaojian90@u.nus.edu; lin.xiong@sg.panasonic.com; jianshu@u.nus.edu;
   jlxing@nlpr.ia.ac.cn; eleyans@nus.edu.sg; elefjia@nus.edu.sg
OI Li, Jianshu/0000-0001-8554-6886; Xiong, Lin/0000-0003-3545-227X; Xing,
   Junliang/0000-0001-6801-0510; Zhao, Jian/0000-0002-3508-756X
FU China Scholarship Council (CSC)China Scholarship Council [201503170248];
   National Science Foundation of Chian [61672519]; National University of
   SingaporeNational University of Singapore [R-263-000-C08-133, MOE Tier-I
   R-263-000-C21-112, NUS IDS R-263-000-C67-646, ECRA R-263-000-C87-133]
FX Jian Zhao's research was partially supported by China Scholarship
   Council (CSC) grant 201503170248. Junliang Xing's research was partially
   supported by the National Science Foundation of Chian 61672519. Jiashi
   Feng's research was partially supported by National University of
   Singapore startup R-263-000-C08-133, MOE Tier-I R-263-000-C21-112, NUS
   IDS R-263-000-C67-646 and ECRA R-263-000-C87-133. The authors would like
   to thank Yu Cheng (Nanyang Technological University), Yi Cheng, Yan Xu,
   Jayashree Karlekar, Sugiri Pranata and Shengmei Shen (Core Technology
   Group, Learning & Vision, Panasonic R&D Center Singapore) for helpful
   discussions. Jian Zhao and Lin Xiong make equal contributions. Jian Zhao
   was an intern at Panasonic R&D Center Singapore during this work. Jian
   Zhao is the corresponding author. Homepage:
   https://zhaoj9014.github.io/.
CR AbdAlmageed W., 2016, IEEE WINT C APPL COM, P1, DOI DOI 10.1109/WACV.2016.7477555
   Ahmed N, 2016, UBICOMP'16 ADJUNCT: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P1, DOI 10.1145/2968219.2971457
   Berthelot David, 2017, ARXIV170310717
   Cao Q, 2018, IEEE INT CONF AUTOMA, P67, DOI 10.1109/FG.2018.00020
   Chen J.-C., 2016, P IEEE WINT C APPL C
   Chen J, 2015, IEEE ICC, P1801, DOI 10.1109/ICC.2015.7248586
   Chen JC, 2018, INT J COMPUT VISION, V126, P272, DOI 10.1007/s11263-017-1029-3
   Chen JC, 2016, IEEE IMAGE PROC, P2981, DOI 10.1109/ICIP.2016.7532906
   Chen X, 2016, ADV NEUR IN, V29
   Chollet F., 2015, GITHUB REPOS
   Crosswhite N, 2017, IEEE INT CONF AUTOMA, P1, DOI 10.1109/FG.2017.11
   Gong K, 2017, PROC CVPR IEEE, P6757, DOI 10.1109/CVPR.2017.715
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Guo YD, 2016, LECT NOTES COMPUT SC, V9907, P87, DOI 10.1007/978-3-319-46487-9_6
   Hassner T., 2016, P CVPR WORKSH, P59
   HASSNER T, 2015, PROC CVPR IEEE, P4295, DOI DOI 10.1109/CVPR.2015.7299058
   Hayat M., 2017, P IEEE C COMP VIS PA, P2767
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang R, 2017, IEEE I CONF COMP VIS, P2458, DOI 10.1109/ICCV.2017.267
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Kasabov N, 2016, 2016 IEEE 8TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS (IS), P15, DOI 10.1109/IS.2016.7737434
   Kingma D. P., 2014, ARXIV13126114, DOI DOI 10.1007/S11042-018-6187-Y
   Klare BF, 2015, PROC CVPR IEEE, P1931, DOI 10.1109/CVPR.2015.7298803
   Li JS, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1531, DOI 10.1145/3123266.3123438
   Li JH, 2016, P IEEE RAS-EMBS INT, P1068, DOI 10.1109/BIOROB.2016.7523773
   Liu L., 2018, ARXIV180110324
   Liu L., 2016, ACM MULT C, P691
   Liu L, 2017, PATTERN RECOGN, V62, P135, DOI 10.1016/j.patcog.2016.08.032
   Liu L, 2014, IEEE IMAGE PROC, P718, DOI 10.1109/ICIP.2014.7025144
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Masi I, 2016, PROC CVPR IEEE, P4838, DOI 10.1109/CVPR.2016.523
   Masi I, 2016, LECT NOTES COMPUT SC, V9909, P579, DOI 10.1007/978-3-319-46454-1_35
   Mirza M, 2014, ARXIV PREPRINT ARXIV
   Odena A., 2016, ARXIV161009585
   Parkhi O.M., 2015, P BR MACH VIS, DOI [DOI 10.5244/C.29.41, 10.5244/C.29.41]
   Ranjan R., 2017, COMPUT SCI
   Ranjan R, 2017, IEEE INT CONF AUTOMA, P17, DOI 10.1109/FG.2017.137
   Rezende D. J., 2014, INT C MACH LEARN
   Sagonas C, 2015, IEEE I CONF COMP VIS, P3871, DOI 10.1109/ICCV.2015.441
   Sankaranarayanan Swami, 2016, 2016 IEEE 8 INT C BI, DOI DOI 10.1109/BTAS.2016.7791205
   Shrivastava A., 2017, CVPR, V2, P5
   Simonyan K, 2015, ICLR 2015, DOI DOI 10.1109/CVPR.2015.7298594
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Tran L, 2017, PROC CVPR IEEE, P1283, DOI 10.1109/CVPR.2017.141
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang D., 2015, ICB, V4
   Xiangyu Zhu, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163096
   Xiao ST, 2016, LECT NOTES COMPUT SC, V9905, P57, DOI 10.1007/978-3-319-46448-0_4
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yang J., 2017, P IEEE C COMP VIS PA, P4362
   Yim J, 2015, PROC CVPR IEEE, P676, DOI 10.1109/CVPR.2015.7298667
   Yin X., 2017, P IEEE INT C COMP VI, P3990
   Yin X., 2017, MULTITASK CONVOLUTIO
   Zhao QC, 2017, IEEE CONF IMAGING SY, P65
   Zhu XY, 2015, PROC CVPR IEEE, P787, DOI 10.1109/CVPR.2015.7298679
NR 57
TC 29
Z9 29
U1 1
U2 32
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 0162-8828
EI 1939-3539
J9 IEEE T PATTERN ANAL
JI IEEE Trans. Pattern Anal. Mach. Intell.
PD OCT
PY 2019
VL 41
IS 10
BP 2380
EP 2394
DI 10.1109/TPAMI.2018.2858819
PG 15
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JD1VC
UT WOS:000489763000008
PM 30040629
DA 2022-02-06
ER

PT J
AU Ortega-Bueno, R
   Rosso, P
   Pagola, JEM
AF Ortega-Bueno, Reynier
   Rosso, Paolo
   Medina Pagola, Jose E.
TI Multi-view informed attention-based model for Irony and Satire detection
   in Spanish variants
SO KNOWLEDGE-BASED SYSTEMS
LA English
DT Article
DE Irony and satire; Attention mechanism; Linguistic features;
   Contextualized pre-trained embedding; Fusing representation; Spanish
   variants; Figurative language
ID SENTIMENT ANALYSIS
AB Making machines understand language and reasoning on it has been one of the most challenging problems addressed by Artificial Intelligent researchers. This challenge increases when figurative language is used for communicating complex meanings, intentions, emotions and attitudes in creative and funny ways. In fact, sentiment analysis approaches struggle when facing irony, satire and other figurative languages, particularly those where the explanation of a prediction might arguably be as necessary as the prediction itself. This paper describes a new model MvAttLSTM based on deep learning for irony and satire detection in tweets written in distinct Spanish variants. The proposed model is based on an attentive-LSTM informed with three additional views learned from distinct perspectives. We investigate two strategies to pass these views into MvAttLSTM. We perform an extensive evaluation on three corpora, one for irony detection and two for satire detection. Moreover, in order to study the robustness of our proposed model, we investigate its performance on humor recognition. Experiments confirm that the proposed views help our model to improve its performance. Moreover, they show that affective information benefits our model to detect irony and satire. In particular, a first analysis of the results highlights the discriminating power of emotional features obtained from SenticNet and SEL lexicon. Overall, our system achieves the state-of-the-art performance in irony and satire detection in Spanish variants and competitive results in humor recognition. (C) 2021 Elsevier B.V. All rights reserved.
C1 [Ortega-Bueno, Reynier; Rosso, Paolo] Univ Politecn Valencia, PRHLT Res Ctr, Valencia, Spain.
   [Medina Pagola, Jose E.] Univ Ciencias Informat, Havana, Cuba.
C3 Universitat Politecnica de Valencia
RP Ortega-Bueno, R (corresponding author), Univ Politecn Valencia, PRHLT Res Ctr, Valencia, Spain.
EM rortega@prhlt.upv.es
FU Spanish Ministry of Science and InnovationSpanish Government
   [PGC2018-096212-B-C31]; Generalitat Valenciana, SpainGeneralitat
   Valenciana [PROMETEO/2019/121]
FX The work of the first two authors was in the framework of the research
   project MISMIS-FAKEnHATE on MISinformation and MIScommunication in
   social media: FAKE news and HATE speech (PGC2018-096212-B-C31) , funded
   by Spanish Ministry of Science and Innovation, and DeepPattern
   (PROMETEO/2019/121) , funded by the Generalitat Valenciana, Spain.
CR Abdalla M., 2017, P 8 INT JOINT C NAT 8 INT JOINT C NAT LA, P506
   Abdul-Mageed M., 2019, WORKING NOTES FIRE 2
   Abulaish M, 2020, ACM T WEB, V14, DOI 10.1145/3375547
   Agrawal A, 2018, ACM/SIGIR PROCEEDINGS 2018, P1029, DOI 10.1145/3209978.3210148
   Ahmad T, 2014, INT CONF SOFT COMP, P102, DOI 10.1109/ISCMI.2014.34
   Altin L.S.M., 2019, CEUR WORKSHOP PROC, V2421, P291
   Gonzalez JA, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102262
   Attardo S, 2000, J PRAGMATICS, V32, P793, DOI 10.1016/S0378-2166(99)00070-3
   Bahdanau D., 2014, NEURAL MACHINE TRANS, DOI DOI 10.1146/ANNUREV.NEURO.26.041002.131047
   Balahur A, P 3 WORKSH COMP APPR, P52
   Barbieri F., 2014, P 5 INT C COMP CREAT, P155
   Barbieri F., 2016, CEUR WORKSHOP PROC
   Barbieri F., 2016, P 24 ACM INT C MULT, P531, DOI [10.1145/2964284.2967278, DOI 10.1145/2964284.2967278]
   Barbieri F., 2014, P 5 WORKSH COMP APPR, P50, DOI DOI 10.3115/V1/W14-2609
   Barbieri F, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3967
   Barbieri F, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1215
   Barbieri F, 2015, PROCES LENG NAT, P135
   Barbieri F, 2016, FRONT ARTIF INTEL AP, V288, P239, DOI 10.3233/978-1-61499-696-5-239
   Barbieri F, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P4258
   Barbieri Francesco, 2017, P 15 C EUR CHAPT ASS, V2, P105
   Basile V., 2014, P 4 EV CAMP NAT LANG, P50
   Baziotis C., 2018, ARXIV180406659
   Benamara F., 2020, P 28 INT C COMP LING, P1346, DOI [10.18653/v1/2020.colingmain.116, DOI 10.18653/V1/2020.COLINGMAIN.116]
   Benamara F., 2017, ACT DEFTATALN2017
   Bodria F., 2020, SEBD
   Bojanowski P., 2017, TACL, V5, P135, DOI [DOI 10.1162/TACL_A_00051, 10.1162/tacl_a_00051]
   Bosco C, 2013, IEEE INTELL SYST, V28, P55, DOI 10.1109/MIS.2013.28
   Brown P., 1987, POLITENESS SOME UNIV, DOI [10.2307/3587263, DOI 10.2307/3587263]
   Burfoot C., P ACL IJCNLP 2009 C, P161
   Calvo H, 2020, COMPUT SIST, V24, P1281, DOI [10.13053/CyS-24-3-3487, 10.13053/cys-24-3-3487]
   Cambria Erik, 2020, CIKM '20: Proceedings of the 29th International Conference on Information & Knowledge Management, P105, DOI 10.1145/3340531.3412003
   Carvalho P., 2009, P 1 INT CIKM WORKSH, P53, DOI [10.1145/1651461.1651471, DOI 10.1145/1651461.1651471]
   Cer D., 2018, P 2018 C EMPIRICAL M, P169, DOI DOI 10.18653/V1/D18-2029
   Chauhan DS, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P4351
   Chiruzzo L., 2019, P IB LANG EV FOR BER
   Chiruzzo L, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P5106
   Chung C. K., 2012, APPL NATURAL LANGUAG, P206, DOI [10.4018/978-1-60960-741-8.ch012, DOI 10.4018/978-1-60960-741-8.CH012]
   Chung J, 2014, ARXIV14123555, P1
   Cignarella Alessandra Teresa, 2018, 6 EV CAMP NAT LANG P, V2263, P1
   Clark K, 2019, BLACKBOXNLP WORKSHOP ON ANALYZING AND INTERPRETING NEURAL NETWORKS FOR NLP AT ACL 2019, P276, DOI 10.18653/v1/w19-4828
   Colletta L, 2009, J POP CULT, V42, P856, DOI 10.1111/j.1540-5931.2009.00711.x
   Colston H. L., 2015, USING FIGURATIVE LAN
   Condren C., 2014, ENCY HUMOR STUDIES C, P661
   Conneau A., 2020, P 58 ANN M ASS COMP, P8440, DOI DOI 10.18653/V1/2020.ACL-MAIN.747
   Conneau Alexis, 2017, P 2017 C EMP METH NA, P670, DOI DOI 10.18653/V1/D17-1070
   Dancygier B, 2014, CAMB TEXTBK LINGUIST, P1
   Dashtipour K, 2016, COGN COMPUT, V8, P757, DOI 10.1007/s12559-016-9415-7
   De Sarkar Sohan, 2018, 27 INT C COMP LING C, P3371
   Salas-Zarate MD, 2020, KNOWL INF SYST, V62, P2105, DOI 10.1007/s10115-019-01425-3
   Salas-Zarate MD, 2017, KNOWL-BASED SYST, V128, P20, DOI 10.1016/j.knosys.2017.04.009
   Devlin J, 2019, PROC C N AM CHAPTER, P4171, DOI DOI 10.18653/V1/N19-1423
   Gonzalez MDM, 2015, PROCES LENG NAT, P143
   Dutta Sayandip, 2019, Soft Computing and Signal Processing. Proceedings of ICSCSP 2018. Advances in Intelligent Systems and Computing (AISC 898), P243, DOI 10.1007/978-981-13-3393-4_25
   Espinosa-Anke L., 2017, P 3 WORKSH NOIS US G, P11, DOI [10.18653/v1/W17-4402, DOI 10.18653/V1/W17-4402]
   Esuli A, 2020, IEEE INTELL SYST, V35, P106, DOI 10.1109/MIS.2020.2979203
   Farias DIH, 2017, SENTIMENT ANALYSIS IN SOCIAL NETWORKS, P113, DOI 10.1016/B978-0-12-804412-4.00007-3
   Farias DIH, 2020, J INTELL FUZZY SYST, V39, P2147, DOI 10.3233/JIFS-179880
   Galeshchuk S, 2019, 7TH WORKSHOP ON BALTO-SLAVIC NATURAL LANGUAGE PROCESSING (BSNLP'2019), P120
   Garcia L., 2019, CEUR WORKSHOP PROC
   Garmendia J, 2018, IRONY, Vfirst, DOI [10.1017/9781316136218, DOI 10.1017/9781316136218]
   Ghanem B., 2020, P 42 EUR C IR RES EC, P114, DOI [10.1007/978-3-030-45442-5, DOI 10.1007/978-3-030-45442-5]
   Ghanem B, 2019, ACM INT CONF PR SER, P10, DOI 10.1145/3368567.3368585
   Ghosh A, 2015, P 9 INT WORKSH SEM E, P470, DOI DOI 10.18653/V1/S15-2080
   Ghosh D, 2020, FIGURATIVE LANGUAGE PROCESSING, P1
   Ghosh D, 2017, 18TH ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2017), P186
   Ghosh D, 2018, COMPUT LINGUIST, V44, P755, DOI 10.1162/coli_a_00336
   GIBBS RW, 1995, DISCOURSE PROCESS, V20, P187, DOI 10.1080/01638539509544937
   Golbeck J, 2018, WEBSCI'18: PROCEEDINGS OF THE 10TH ACM CONFERENCE ON WEB SCIENCE, P17, DOI 10.1145/3201064.3201100
   Gonzalez J.A., 2019, CEUR WORKSHOP PROC
   Gonzalez-Agirre A, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2525
   Grice H.P., 1975, SYNTAX SEMANTICS, V3, P42
   GRICE HP, 1978, PRAGMATICS, V0001, P00013
   Guibon G., 2019, INT C COMP LING INT
   Gurillo L.R., 2013, IRONY HUMOR PRAGMATI, V231
   Haiman J, 1998, TALK IS CHEAP SARCAS, DOI [10.1017/s0047404500211032, DOI 10.1017/S0047404500211032]
   Haynes W., 2013, ENCY SYSTEMBIOL, P2354
   Hee C.V, 2017, THESIS U GENT
   Farias DIH, 2016, ACM T INTERNET TECHN, V16, DOI 10.1145/2930663
   Hernandez L., 2011, INT J COMPUT LINGUIS, V2, P267
   Hernandez-Farias I, 2015, LECT NOTES COMPUT SC, V9117, P337, DOI 10.1007/978-3-319-19390-8_38
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735
   Hong J, 2014, P COLING 2014 25 INT, P213
   Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321
   Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328
   Huang Y, 2018, P 12 INT WORKSH SEM, P51, DOI DOI 10.18653/V1/S18-1006
   Huang YH, 2017, LECT NOTES COMPUT SC, V10193, P534, DOI 10.1007/978-3-319-56608-5_45
   Irsoy O., 2014, ADV NEURAL INFORM PR, P2096
   Iyyer M, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1681
   Jasso G, 2016, PROCES LENG NAT, P41
   Joshi A., 2018, INVESTIGATIONS COMPU
   Joshi A., 2016, P 2016 C EMP METH NA, P1006
   Justo R, 2018, COGN COMPUT, V10, P1135, DOI 10.1007/s12559-018-9578-5
   Karoui J., 2019, AUTOMATIC DETECTION, Vfirst, DOI [10.1002/9781119671183, DOI 10.1002/9781119671183]
   Karoui J, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P262
   Karoui J, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P644
   Karouia J., 2017, P 3 INT C AR COMP LI, P116
   Kaymak U., 2013, P 28 ANN ACM S APPL, P703, DOI DOI 10.1145/2480362.2480498
   Khattri A, 2015, P 6 WORKSH COMP APPR, P25
   Kingma DP, 2015, 3 INT C LEARN REPR I, DOI DOI 10.1145/1830483.1830503
   KREUZ RJ, 1989, J EXP PSYCHOL GEN, V118, P374, DOI 10.1037/0096-3445.118.4.374
   Kreuz RJ, 2002, J LANG SOC PSYCHOL, V21, P127, DOI 10.1177/02627X02021002002
   KREUZ RJ, 1993, METAPHOR SYMB ACT, V8, P97, DOI 10.1207/s15327868ms0802_2
   Kumar A, 2020, IEEE ACCESS, V8, P6388, DOI 10.1109/ACCESS.2019.2963630
   Kunneman F, 2015, INFORM PROCESS MANAG, V51, P500, DOI 10.1016/j.ipm.2014.07.006
   Lan Z., 2019, ARXIV PREPRINT ARXIV
   Le Q., 2014, P 31 INT C INT C MAC
   Levi O., 2019, P 2 WORKSH NAT LANG, P31, DOI 10.18653/v1/D19-5004
   Liu Y., 2019, CORR
   Lo SL, 2017, ARTIF INTELL REV, V48, P499, DOI 10.1007/s10462-016-9508-4
   LUCARIELLO J, 1994, J EXP PSYCHOL GEN, V123, P129, DOI 10.1037/0096-3445.123.2.129
   Luong M.-T., 2015, PROC EMNLP, P1412
   Majumder N, 2019, IEEE INTELL SYST, V34, P38, DOI 10.1109/MIS.2019.2904691
   Maynard D, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P4238
   Mikolov T., 2013, P INT C LEARN REPR I, DOI DOI 10.5555/2999792.2999959
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Miranda-Belmonte H.U., 2019, CEUR WORKSHOP PROC
   Nozza D, 2016, KDIR: PROCEEDINGS OF THE 8TH INTERNATIONAL JOINT CONFERENCE ON KNOWLEDGE DISCOVERY, KNOWLEDGE ENGINEERING AND KNOWLEDGE MANAGEMENT - VOL. 1, P68, DOI 10.5220/0006052000680076
   Ortega R., 2019, P IB LANG EV FOR IB
   Ortega-Bueno Reynier, 2019, Progress in Pattern Recognition, Image Analysis, Computer Vision, and Applications. 23rd Iberoamerican Congress, CIARP 2018. Proceedings: Lecture Notes in Computer Science (LNCS 11401), P971, DOI 10.1007/978-3-030-13469-3_112
   Ortega-Bueno R., 2019, CEUR WORKSH P CEUR W
   Ortega-Bueno R, 2018, P 3 WORKSH EV HUM LA, P204
   Ortega-Bueno R., 2018, CEUR WORKSHOP PROC, V2263, P1, DOI [10.4000/books.aaccademia.4638, DOI 10.4000/BOOKS.AACCADEMIA.4638]
   Padro L, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2473
   Pagliardini M., 2018, P N AM CHAPT ASS COM, P528, DOI DOI 10.18653/V1/N18-1049
   Pena A.S., 2018, 4 C INT CIENC COMP I, P1
   Perkins J., 2014, PYTHON 3 TEXT PROCES
   Peters ME, 2018, P C N AM CHAPT ASS C, DOI DOI 10.18653/V1/N18-1202
   Poria Soujanya, 2016, COLING, P1601
   Pota M, 2021, EXPERT SYST APPL, V181, DOI 10.1016/j.eswa.2021.115119
   Pota M, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21010133
   Potamias RA, 2020, NEURAL COMPUT APPL, V32, P17309, DOI 10.1007/s00521-020-05102-3
   Thu PP, 2018, INT J NETW DISTRIB C, V6, P78, DOI 10.2991/ijndc.2018.6.2.3
   Rangel F, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION
   Rappoport, 2010, P 14 C COMP NAT LANG, P107
   Ravi K, 2018, PROCEEDINGS OF 2018 IEEE 17TH INTERNATIONAL CONFERENCE ON COGNITIVE INFORMATICS & COGNITIVE COMPUTING (ICCI*CC 2018), P254, DOI 10.1109/ICCI-CC.2018.8482094
   Raymond J., 2012, INTERPRETING FIGURAT, DOI [10.1080/10926488.2018.1407996, DOI 10.1080/10926488.2018.1407996]
   Reganti AN, 2016, INT CONF DAT MIN WOR, P970, DOI [10.1109/ICDMW.2016.0141, 10.1109/ICDMW.2016.146]
   Reyes A, 2012, LINGUISTIC BASED PAT
   Reyes A, 2013, LANG RESOUR EVAL, V47, P239, DOI 10.1007/s10579-012-9196-x
   Riloff E, 2013, P 2013 C EMP METH NA, P704
   Rocktaschel Tim., 2016, INT C LEARN REPR
   Rubin V., 2016, P 2 WORKSH COMP APPR, P7, DOI DOI 10.18653/V1/W16-0802
   Sanh V, 2019, ARXIV PREPRINT ARXIV
   Saralegi X., 2013, 29 C SOC ESP PROC LE, P143
   Seda Mut Altin L., 2019, CEUR WORKSHOP PROC
   Serrano S., 2020, P 7 ANN M ASS COMP L, P2931
   Sidorov G, 2012, MEX INT C ART INT, P1
   Simpson P, 2003, DISCOURSE SATIRE STY, V2, DOI [10.1177/0963947006060558, DOI 10.1177/0963947006060558]
   Singh RK, 2021, ARTIF INTELL REV, V54, P1385, DOI 10.1007/s10462-020-09884-9
   Smith NA, 2015, P 9 INT C WEB SOC ME, P574
   Socher R, 2014, P 19 C EMPIRICAL MET, V2014, P1532, DOI DOI 10.3115/V1/D14-1162
   Sperber Dan, 1981, RADICAL PRAGMATICS, P295
   Susanto Y, 2020, IEEE INTELL SYST, V35, P96, DOI 10.1109/MIS.2020.2992799
   Tang Y.-j., 2014, P 25 INT C COMP LING, P1269
   Tenney I, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4593
   Thu PP, 2017, 2017 16TH IEEE/ACIS INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCE (ICIS 2017), P209
   Vaswani A, 2017, ADV NEUR IN, V30
   Veale, 2016, P 7 WORKSH COMP APPR, P161, DOI DOI 10.18653/V1/W16-0425
   Veale Tony, 2009, P COGSCI 2009 31 ANN, P1376
   Vig J, 2019, BLACKBOXNLP WORKSHOP ON ANALYZING AND INTERPRETING NEURAL NETWORKS FOR NLP AT ACL 2019, P63
   Vilares D, 2018, 2018 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI), P1292, DOI 10.1109/SSCI.2018.8628718
   Wacholder N, 2011, P 49 ANN M ASS COMP, P581
   Wallace B.C., 2019, P 2019 C N AM CHAPT, DOI DOI 10.18653/V1/N19-1357
   Wallace BC, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1035
   Wallace BC, 2015, ARTIF INTELL REV, V43, P467, DOI 10.1007/s10462-012-9392-5
   Wang Y., 2016, P 2016 C EMPIRICAL M, P606, DOI [10.18653/v1/D16-1058, DOI 10.18653/V1/D16-1058]
   WILSON D, 1992, LINGUA, V87, P53, DOI 10.1016/0024-3841(92)90025-E
   Yang F., 2017, P 2017 C EMP METH NA, P1979, DOI DOI 10.18653/V1/D17-1211
   Yang M, 2017, THIRTY-FIRST AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P5013
   Yang YF, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, P87
   Yang Z., 2016, NAACL HLT, P1480
   Young T, 2018, IEEE COMPUT INTELL M, V13, P55, DOI 10.1109/MCI.2018.2840738
   Zhang SW, 2019, INFORM PROCESS MANAG, V56, P1633, DOI 10.1016/j.ipm.2019.04.006
   Zhou P, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P207, DOI 10.18653/v1/p16-2034
   Zucco C, 2018, IEEE INT C BIOINFORM, P1740, DOI 10.1109/BIBM.2018.8621359
NR 175
TC 0
Z9 0
U1 3
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0950-7051
EI 1872-7409
J9 KNOWL-BASED SYST
JI Knowledge-Based Syst.
PD JAN 10
PY 2022
VL 235
AR 107597
DI 10.1016/j.knosys.2021.107597
PG 24
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WW7WJ
UT WOS:000718121500002
DA 2022-02-06
ER

PT J
AU Zhu, BR
   Zhang, XY
   Gu, M
   Deng, YD
AF Zhu, Biru
   Zhang, Xingyao
   Gu, Ming
   Deng, Yangdong
TI Knowledge Enhanced Fact Checking and Verification
SO IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING
LA English
DT Article
DE Internet; Knowledge based systems; Encyclopedias; Online services;
   Semantics; Feature extraction; Tools; Automated fact checking; knowledge
   selection; knowledge enhanced fact checking
AB As the Internet and social media offer increasing opportunities for organizations and individuals to publicize online contents, it has become essential to develop effective means to identify misinformation like fake news. Recently, fact checking systems have been regarded as a promising tool to automatically deal with large amounts of information. How to effectively take advantage of existing unstructured document knowledge bases and structured knowledge graphs to build robust fact checking systems, however, remains to be a challenge. In this paper, we propose a knowledge enhanced fact checking system, which leverages the Wikidata5M knowledge graph and Wikipedia documents to incorporate external knowledge into the claim to be checked for more robust and accurate fact checking. First, we devise a contextualized knowledge graph selection method to identify the most relevant sub-graph with the checked claim from the large knowledge graph. We then construct a novel claim-evidence-knowledge graph and use a graph attention network to integrate natural language evidence with structured knowledge triplets by allowing them to propagate information among each other. By integrating the claim, retrieved evidence and selected knowledge triplets in a unified claim-evidence-knowledge graph, our method improves the label accuracy of predicted claims by more than 4% on the FEVER dataset over state-of-the-art fact checking models.
C1 [Zhu, Biru; Gu, Ming; Deng, Yangdong] Tsinghua Univ, Sch Software, Beijing 100084, Peoples R China.
   [Zhang, Xingyao] STCA NLP Grp, Microsoft, Beijing 100080, Peoples R China.
C3 Tsinghua University
RP Deng, YD (corresponding author), Tsinghua Univ, Sch Software, Beijing 100084, Peoples R China.
EM lili6138@outlook.com; xingyaozhang@microsoft.com;
   guming@tsinghua.edu.cn; dengyd@tsinghua.edu.cn
FU National Natural Science Foundation of China (NSFC)National Natural
   Science Foundation of China (NSFC) [61527812]
FX This work was supported in part by the National Natural Science
   Foundation of China (NSFC) under Grant 61527812.
CR Chen Q, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1657, DOI 10.18653/v1/P17-1152
   Costa JO, 2018, 2018 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE (WI 2018), P389, DOI 10.1109/WI.2018.00-63
   Devlin J, 2019, PROC C N AM CHAPTER, P4171, DOI DOI 10.18653/V1/N19-1423
   Garcia-Duran Alberto, 2013, ADV NEURAL INFORM PR, V26, P2787
   Gardner M, 2018, NLP OPEN SOURCE SOFTWARE (NLP-OSS), P1
   Gottschalk Simon, 2018, The Semantic Web. 15th International Conference, ESWC 2018. Proceedings: LNCS 10843, P272, DOI 10.1007/978-3-319-93417-4_18
   Han J., 2020, P FIND ASS COMP LING, P1475
   Hanselowski A., 2018, P 1 WORKSH FACT EXTR, DOI DOI 10.18653/V1/W18-5516
   Lee N, 2020, FACT EXTRACTION AND VERIFICATION (FEVER), P36
   Lin Bill Yuchen, 2019, P C EMP METH NAT LAN, P2829, DOI DOI 10.18653/V1/D19-1282
   Liu WJ, 2020, AAAI CONF ARTIF INTE, V34, P2901
   Liu Y., 2019, CORR
   Liu Zhenghao, 2020, P 58 ANN M ASS COMP, P7342
   Ma J, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2561
   Nie Y., 2019, P 2019 C EMP METH NA, P2553
   Nie YX, 2019, THIRTY-THIRD AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTY-FIRST INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / NINTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P6859
   Petroni F., 2019, P EMNLP IJCNLP, P2463, DOI DOI 10.18653/V1/D19-1250
   Qiu D., 2019, P 2019 C EMP METH NA, P5898
   Scaiella U, 2010, P 19 ACM INT C INF K, P1625, DOI DOI 10.1145/1871437.1871689
   Soleimani Amir, 2020, Advances in Information Retrieval. 42nd European Conference on IR Research, ECIR 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12036), P359, DOI 10.1007/978-3-030-45442-5_45
   Su Y., THE OPEN, V2, P2021
   Sun, 2020, P 28 INT C COMP LING, P3660
   Thorne J., 2018, FEVER LARGE SCALE DA, P809, DOI 10.18653/v1/N18-1074
   Velickovi P., 2018, P INT C LEARN REPR, P1
   Wang Minjie, 2019, ARXIV190901315
   Wang X., 2021, T ASSOC COMPUT LING, V9, P176
   Wang Z., 2020, P 28 INT C COMP LING, P6498
   Yoneda T., 2019, P 1 WORKSH FACT EXTR, P97, DOI 10.18653/ v1/ w18-5515.
   Zhang ZY, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1441
   Zhong Wanjun, 2020, P 58 ANN M ASS COMP, P6170
   Zhou J, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P892
NR 31
TC 0
Z9 0
U1 1
U2 1
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2329-9290
EI 2329-9304
J9 IEEE-ACM T AUDIO SPE
JI IEEE-ACM Trans. Audio Speech Lang.
PY 2021
VL 29
BP 3132
EP 3143
DI 10.1109/TASLP.2021.3120636
PG 12
WC Acoustics; Engineering, Electrical & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Acoustics; Engineering
GA WR0LO
UT WOS:000714201100001
DA 2022-02-06
ER

PT J
AU Rajapaksha, P
   Farahbakhsh, R
   Crespi, N
AF Rajapaksha, Praboda
   Farahbakhsh, Reza
   Crespi, Noel
TI BERT, XLNet or RoBERTa: The Best Transfer Learning Model to Detect
   Clickbaits
SO IEEE ACCESS
LA English
DT Article
DE Transfer learning; Bit error rate; Task analysis; Social networking
   (online); Adaptation models; Blogs; Data models; Clickbait; fake news;
   transfer learning; BERT; RoBERTa; XLNet; Twitter; news clickbaits; deep
   learning
AB Clickbait can be a spam or an advert which more often provides a link to commercial website and it can also be a headline to news media website which makes money from page views by providing eye-catchy headlines with deceptive news. This paper focuses on the latter definition in order to identify news clickbaits that are published in Twitter. The aim of this work is to use recent Transfer Learning models to detect news clickbaits by adding various configuration changes to the existing models. Based on the author's knowledge, this is the first attempt to adapt Transfer Learning to classify Clickbaits in social media. In this work we fine-tuned BERT, XLNet and RoBERTa models by integrating novel configuration changes into their default architectures such as model expansion, pruning and data augmentation strategies. Webis Clickbait dataset was used to train these models and the best performed model at the Webit Clickbait competition 2017 was considered as our benchmark. The analyses in this work are mainly focused on eight different scenarios after applying several fine-tuning approaches and model configuration changes to the default Transfer Learning models. The results shown that, our modified Transfer Learning approaches outperformed the considered benchmark. In our experiments, the best performed Transfer Learning model was RoBERTa with the integration of an additional non-linear layer with the hidden output tensor. this configuration has achieved 19.12% more accuracy in compared to the benchmark model for the binary classification. There is no significant performance improvement when each model expanded by adding an extra RNN layer(s). Apart from that, we experimented with another labelled clickbait dataset (Kaggle clickbait challenge) to explore the performance of our fine-tuned models under different scenarios.
C1 [Rajapaksha, Praboda; Farahbakhsh, Reza; Crespi, Noel] Inst Polytech Paris, CNRS Lab UMR5157, F-91764 Palaiseau, France.
RP Rajapaksha, P (corresponding author), Inst Polytech Paris, CNRS Lab UMR5157, F-91764 Palaiseau, France.
EM praboda.rajapaksha@telecom-sudparis.eu
OI Rajapaksha, Praboda/0000-0002-6747-6367
CR Abdul-Mageed M., 2019, WORKING NOTES FIRE 2
   Anand A, 2017, LECT NOTES COMPUT SC, V10193, P541, DOI 10.1007/978-3-319-56608-5_46
   Antoun Wissam, 2020, 2020 IEEE International Conference on Informatics, IoT, and Enabling Technologies (ICIoT), P519, DOI 10.1109/ICIoT48696.2020.9089487
   Bauhaus-Universitat Weimar, WEB CLICKB CHALL
   Chakraborty A, 2016, PROCEEDINGS OF THE 2016 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING ASONAM 2016, P9, DOI 10.1109/ASONAM.2016.7752207
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Chicco D, 2020, BMC GENOMICS, V21, DOI 10.1186/s12864-019-6413-7
   Cho K, 2014, P 2014 C EMPIRICAL M, DOI [10.3115/v1/D14-1179, DOI 10.3115/V1/D14-1179]
   Clark K, 2019, BLACKBOXNLP WORKSHOP ON ANALYZING AND INTERPRETING NEURAL NETWORKS FOR NLP AT ACL 2019, P276, DOI 10.18653/v1/w19-4828
   Devlin J, 2019, PROC C N AM CHAPTER, P4171, DOI DOI 10.18653/V1/N19-1423
   Dong MQ, 2019, LECT NOTES ARTIF INT, V11440, P56, DOI 10.1007/978-3-030-16145-3_5
   Fan A., ARXIV190911556
   Ganesh P., ARXIV200211985
   Glenski M., 2017, ARXIV171006390
   GLUE, GEN LANG UND EV GLUE
   Gordon MA, 2020, 5TH WORKSHOP ON REPRESENTATION LEARNING FOR NLP (REPL4NLP-2020), P143
   Guderlei M., 2020, P 28 INT C COMP LING, P6339
   Ha Y., 2018, P INT AAAI C WEB SOC, V12
   iPavlov Research Group, CLICKB NEWS DET
   Jwa H, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9194062
   Kingma DP, 2015, 3 INT C LEARN REPR I, DOI DOI 10.1145/1830483.1830503
   Kumar V, 2018, ACM/SIGIR PROCEEDINGS 2018, P1225, DOI 10.1145/3209978.3210144
   Liu XD, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4487
   Liu Y., 2019, ARXIV190711692
   McCoy R. Thomas, 2019, ARXIV191102969
   Omidvar A., 2018, P ANN INT S INF MAN, V898, P220, DOI 10.1007/978- 3-030-11680-4_22
   Peters ME, 2018, P C N AM CHAPT ASS C, DOI DOI 10.18653/V1/N18-1202
   Potthast Martin, 2016, Advances in Information Retrieval. 38th European Conference on IR Research, ECIR 2016. Proceedings; LNCS 9626, P810, DOI 10.1007/978-3-319-30671-1_72
   Rajapaksha P., 2019, IEEE ACCESS, DOI [10.1109/ACCESS.2019.2902491, DOI 10.1109/ACCESS.2019.2902491]
   Rajapaksha P, 2018, 2018 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM), P535, DOI 10.1109/ASONAM.2018.8508534
   Rony M. M. U., 2017, P 2017 IEEE ACM INT, P232, DOI DOI 10.1145/3110025.3110054
   Sun C, 2019, LECT NOTES ARTIF INT, V11856, P194, DOI 10.1007/978-3-030-32381-3_16
   Talmor A, 2020, T ASSOC COMPUT LING, V8, P743, DOI 10.1162/tacl_a_00342
   Tang S, 2019, LECT NOTES COMPUT SC, V11956, P363, DOI 10.1007/978-3-030-37429-7_36
   Vaswani A, 2017, ADV NEUR IN, V30
   Vlad G.-A., 2019, P 2 WORKSH NAT LANG, P148
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Yogatama Dani, 2019, ARXIV190111373CSSTAT
   Zellers R., 2019, ADV NEURAL INFORM PR
   Zheng HT, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10050138
   Zhou Y., 2017, ARXIV171005364
NR 41
TC 0
Z9 0
U1 2
U2 2
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2021
VL 9
BP 154704
EP 154716
DI 10.1109/ACCESS.2021.3128742
PG 13
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Telecommunications
GA XC4MK
UT WOS:000721988600001
OA gold
DA 2022-02-06
ER

PT J
AU Chatterjee, S
   Ghosh, K
   Banerjee, A
   Banerjee, S
AF Chatterjee, Sankhadeep
   Ghosh, Kushankur
   Banerjee, Arghasree
   Banerjee, Soumen
TI Forecasting COVID-19 Outbreak Through Fusion of Internet Search, Social
   Media, and Air Quality Data: A Retrospective Study in Indian Context
SO IEEE TRANSACTIONS ON COMPUTATIONAL SOCIAL SYSTEMS
LA English
DT Article; Early Access
DE COVID-19; Social networking (online); Market research; Pandemics;
   Internet; Coronaviruses; Blogs; Air quality; coronavirus disease
   (COVID-19); Internet search; SARS-CoV-2; social media
ID FAKE NEWS
AB This article proposes a machine learning augmented technique to predict the coronavirus disease (COVID-19) outbreak in India by combining Internet search trends along with social media data retrieved from Twitter. A comprehensive list of suitable search words has been used to select a large collection of Tweets, and the Internet search trends of the same keywords have been fetched. First, a lag correlation analysis is conducted to find the number of days, ahead of the current time, required to make an accurate prediction of COVID-19 cases. Second, both shallow and deep learning methods are engaged to predict the number of COVID-19 cases in a specific geospatial location in India. Thereafter, statewise air pollution data collected from the Central Pollution Control Board, Government of India, are amalgamated to understand the effect of air pollution in spreading of COVID-19 disease. The air pollution monitoring parameters have been combined to understand their effects in the prediction of COVID-19 cases in the Indian context. Experimental results reveal that accurate predictions can be made 85 days ahead of the current time using the proposed method (r > 0.85), thereby establishing its ingenuity in the prediction of COVID-19 spread in advance.
C1 [Chatterjee, Sankhadeep] Univ Engn & Management, Dept Comp Sci & Technol, Kolkata 700160, India.
   [Ghosh, Kushankur; Banerjee, Arghasree] Univ Engn & Management, Dept Comp Sci & Engn, Kolkata 700160, India.
   [Banerjee, Soumen] Univ Engn & Management, Dept Elect & Commun Engn, Kolkata 711103, India.
RP Chatterjee, S (corresponding author), Univ Engn & Management, Dept Comp Sci & Technol, Kolkata 700160, India.
EM chatterjeesankhadeep.cu@gmail.com; kush1999.kg@gmail.com;
   prof.sbanerjee@gmail.com; banerjeearghasree@gmail.com
RI ; Chatterjee, Sankhadeep/F-4672-2017
OI Ghosh, Kushankur/0000-0002-4761-120X; Chatterjee,
   Sankhadeep/0000-0002-3930-4699
CR [Anonymous], 2020, LANCET, V396, P649, DOI 10.1016/S0140-6736(20)31856-0
   [Anonymous], 2020, INDIA COVID 19 TRACK
   [Anonymous], MANUAL MONITORING DA
   Ayyoubzadeh SM, 2020, JMIR PUBLIC HLTH SUR, V6, P192, DOI 10.2196/18828
   Banerjee A, 2020, MULTIMED TOOLS APPL, V79, P35995, DOI 10.1007/s11042-020-09138-4
   Chimmula VKR, 2020, CHAOS SOLITON FRACT, V135, DOI 10.1016/j.chaos.2020.109864
   Dev S. M., 2020, COVID 19 IMPACT INDI
   Dong XS, 2020, IEEE T COMPUT SOC SY, V7, P1386, DOI 10.1109/TCSS.2020.3027639
   Fahrudin T., 2020, P INT C DAT SCI ITS, P1
   Fattorini D, 2020, ENVIRON POLLUT, V264, DOI 10.1016/j.envpol.2020.114732
   Ferrucci R, 2020, FRONT PSYCHIATRY, V11, DOI 10.3389/fpsyt.2020.559266
   Giusti EM, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.01684
   Goel A, 2020, JCR-J CLIN RHEUMATOL, V26, P220, DOI 10.1097/RHU.0000000000001508
   Gupta P, 2021, IEEE T COMPUT SOC SY, V8, P992, DOI 10.1109/TCSS.2020.3042446
   Gupta Rajan, 2020, ACM Digital Government: Research and Practice, V1, DOI 10.1145/3411761
   Husnayain A, 2020, INT J INFECT DIS, V95, P221, DOI 10.1016/j.ijid.2020.03.021
   Johnsen T. K., 2020, P INT C INN INT INF, P1
   Lamsal R, 2021, APPL INTELL, V51, P2790, DOI 10.1007/s10489-020-02029-z
   Li CL, 2020, EUROSURVEILLANCE, V25, P7, DOI 10.2807/1560-7917.ES.2020.25.10.2000199
   Li LF, 2020, IEEE T COMPUT SOC SY, V7, P556, DOI 10.1109/TCSS.2020.2980007
   Lin QY, 2020, INT J INFECT DIS, V93, P211, DOI 10.1016/j.ijid.2020.02.058
   Lin YH, 2020, BRAIN BEHAV IMMUN, V87, P30, DOI 10.1016/j.bbi.2020.04.020
   Liu D, 2020, INT J MACH LEARN CYB, V11, P989, DOI 10.1007/s13042-020-01095-6
   Mahmoodzadeh A, 2021, NEURAL COMPUT APPL, V33, P321, DOI 10.1007/s00521-020-05006-2
   Maji Avijit, 2020, Transp Res Interdiscip Perspect, V7, P100187, DOI 10.1016/j.trip.2020.100187
   Majumdar P, 2020, CHRONOBIOL INT, V37, P1191, DOI 10.1080/07420528.2020.1786107
   Malki Z, 2020, CHAOS SOLITON FRACT, V138, DOI 10.1016/j.chaos.2020.110137
   Masum MH, 2020, GLOB J ENVIRON SCI M, V6, P85, DOI 10.22034/GJESM.2019.06.SI.08
   Mavragani A, 2020, JMIR PUBLIC HLTH SUR, V6, P233, DOI 10.2196/18941
   Mondal M Rubaiyat Hossain, 2020, Inform Med Unlocked, V20, P100374, DOI 10.1016/j.imu.2020.100374
   Nabi KN, 2021, RESULTS PHYS, V24, DOI 10.1016/j.rinp.2021.104137
   Ortiz-Martinez Y, 2020, TRAVEL MED INFECT DI, V37, DOI 10.1016/j.tmaid.2020.101703
   Pandey PK, 2020, IEEE T COMPUT SOC SY, V7, P1447, DOI 10.1109/TCSS.2020.3025296
   Parbat D, 2020, CHAOS SOLITON FRACT, V138, DOI 10.1016/j.chaos.2020.109942
   Piccialli F, 2021, INFORM SYST FRONT, V23, P1467, DOI 10.1007/s10796-021-10131-x
   Priya S, 2020, IEEE T COMPUT SOC SY, V7, P389, DOI 10.1109/TCSS.2019.2957208
   Pulla P, 2020, NATURE, V583, P180, DOI 10.1038/d41586-020-01865-w
   Rahimi I, 2021, NEURAL COMPUT APPL, DOI 10.1007/s00521-020-05626-8
   Safi M., 2021, INDIAS SHOCKING SURG
   Sarkar K, 2020, CHAOS SOLITON FRACT, V139, DOI 10.1016/j.chaos.2020.110049
   Shahid F, 2020, CHAOS SOLITON FRACT, V140, DOI 10.1016/j.chaos.2020.110212
   Shastri S, 2020, CHAOS SOLITON FRACT, V140, DOI 10.1016/j.chaos.2020.110227
   Shen CH, 2020, J MED INTERNET RES, V22, DOI 10.2196/19421
   Shrivastava G, 2020, IEEE T COMPUT SOC SY, V7, P1159, DOI 10.1109/TCSS.2020.3014135
   Singh RP, 2020, AIR QUAL ATMOS HLTH, V13, P921, DOI 10.1007/s11869-020-00863-1
   Vaman RS, 2020, INDIAN J MED RES, V151, P493, DOI 10.4103/ijmr.IJMR_2205_20
   Venkatesh U, 2020, Healthc Inform Res, V26, P175, DOI 10.4258/hir.2020.26.3.175
   World Health Organization, 2020, COR DIS COVID 19 PAN
   Worldometer, 2020, CORONAVIRUS DIS COVI
   Xu K, 2020, IEEE T COMPUT SOC SY, V7, P546, DOI 10.1109/TCSS.2020.2970602
   Yadav M, 2020, CHAOS SOLITON FRACT, V139, DOI 10.1016/j.chaos.2020.110050
   Yuan Xiaoling, 2020, Explor Res Hypothesis Med, V5, P1, DOI 10.14218/ERHM.2020.00023
   Zambrano-Monserrate MA, 2020, AIR QUAL ATMOS HLTH, V13, P929, DOI 10.1007/s11869-020-00866-y
   Zangari S, 2020, SCI TOTAL ENVIRON, V742, DOI 10.1016/j.scitotenv.2020.140496
   Zhou JL, 2021, IEEE T COMPUT SOC SY, V8, P982, DOI 10.1109/TCSS.2020.3047604
   Zou H, 2005, J R STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x
NR 56
TC 0
Z9 0
U1 0
U2 0
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2329-924X
J9 IEEE T COMPUT SOC SY
JI IEEE Trans. Comput. Soc. Syst.
DI 10.1109/TCSS.2022.3140320
EA JAN 2022
PG 12
WC Computer Science, Cybernetics; Computer Science, Information Systems
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA YK8ZA
UT WOS:000745492800001
DA 2022-02-06
ER

PT J
AU Lai, M
   Cignarella, AT
   Farias, DIH
   Bosco, C
   Patti, V
   Rosso, P
AF Lai, Mirko
   Cignarella, Alessandra Teresa
   Hernandez Farias, Delia Irazu
   Bosco, Cristina
   Patti, Viviana
   Rosso, Paolo
TI Multilingual stance detection in social media political debates
SO COMPUTER SPEECH AND LANGUAGE
LA English
DT Article
DE Stance detection; Multilingual; Contextual features; Political debates;
   Twitter
AB Stance Detection is the task of automatically determining whether the author of a text is in favor, against, or neutral towards a given target. In this paper we investigate the portability of tools performing this task across different languages, by analyzing the results achieved by a Stance Detection system (i.e. MultiTACOS) trained and tested in a multilingual setting.
   First of all, a set of resources on topics related to politics for English, French, Italian, Spanish and Catalan is provided which includes: novel corpora collected for the purpose of this study, and benchmark corpora exploited in Stance Detection tasks and evaluation exercises known in literature. We focus in particular on the novel corpora by describing their development and by comparing them with the benchmarks. Second, MultiTACOS is applied with different sets of features especially designed for Stance Detection, with a specific focus to exploring and combining both features based on the textual content of the tweet (e.g., style and affective load) and features based on contextual information that do not emerge directly from the text. Finally, for better highlighting the contribution of the features that most positively affect system performance in the multilingual setting, a features analysis is provided, together with a qualitative analysis of the misclassified tweets for each of the observed languages, devoted to reflect on the open challenges. (c) 2020 Elsevier Ltd. All rights reserved.
C1 [Lai, Mirko; Cignarella, Alessandra Teresa; Bosco, Cristina; Patti, Viviana] Univ Torino, Dipartimento Informat, Turin, Italy.
   [Cignarella, Alessandra Teresa; Rosso, Paolo] Univ Politecn Valencia, PRHLT Res Ctr, Valencia, Spain.
   [Hernandez Farias, Delia Irazu] Univ Guanajuato, Div Ciencias & Ingn, Campus Leon, Leon, Mexico.
C3 University of Turin; Universitat Politecnica de Valencia; Universidad de
   Guanajuato
RP Lai, M (corresponding author), Univ Torino, Dipartimento Informat, Turin, Italy.
EM mirko.lai@unito.it
RI Patti, Viviana/ABD-9967-2020
OI Bosco, Cristina/0000-0002-8857-4484
FU Progetto di Ateneo/CSP [S1618_L2_BOSC_01]; Spanish MICINNSpanish
   Government [PGC2018096212-B-C31]
FX Cristina Bosco and Viviana Patti are partially supported by Progetto di
   Ateneo/CSP 2016 (Immigrants, Hate and Prejudice in Social Media,
   S1618_L2_BOSC_01). The work of Paolo Rosso was partially funded bythe
   Spanish MICINN under the research project MISMIS-FAKEnHATE on
   MISinformation and MIScommunication in social media: FAKE news and HATE
   speech (PGC2018096212-B-C31).
CR Alsarhan A, 2011, EURASIP J WIREL COMM, DOI 10.1186/1687-1499-2011-36
   Augenstein I., 2016, ARXIV160605464, P876
   Balahur A, 2014, COMPUT SPEECH LANG, V28, P56, DOI 10.1016/j.csl.2013.03.004
   Bethard S., 2016, P 10 INT WORKSH SEM
   Blondel VD, 2008, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2008/10/P10008
   Boiy E, 2009, INFORM RETRIEVAL, V12, P526, DOI 10.1007/s10791-008-9070-z
   Bosco C., 2017, ENCY SOCIAL NETWORK, P1, DOI DOI 10.1007/978-1-4614-7163-9_110172-1
   Bosco C., 2016, P 2016 LREC WORKSH E, P67
   Celli F., 2016, P WORKSH COMP MOD PE, P110
   Cuquerella C.A., 2018, CEUR WORKSHOP PROC, P167
   Del Tredici M., 2019, P 2019 C EMP METH NA, P4706, DOI [10.18653/v1/D19-1477, DOI 10.18653/V1/D19-1477]
   DellaPosta D, 2015, AM J SOCIOL, V120, P1473, DOI 10.1086/681254
   Denecke Kerstin, 2008, 2008 IEEE 24th International Conference on Data Engineering Workshop (ICDE Workshop), P507, DOI 10.1109/ICDEW.2008.4498370
   Dev K, 2018, LECT NOTES COMPUT SC, V10772, P529, DOI 10.1007/978-3-319-76941-7_40
   Farias, 2017, P IBEREVAL CEUR WS, P185
   Hu, 2013, J DATA ANA INFO P, V1, P19, DOI DOI 10.4236/JDAIP.2013.13004
   Hu M., 2004, P 10 ACM SIGKDD INT, P168
   Kucuk D., 2019, ARXIV190104787
   Lai M., 2019, LANGUAGE STRUCTURE P
   Lai M, 2018, LECT NOTES COMPUT SC, V10859, P15, DOI 10.1007/978-3-319-91947-8_2
   Lai M, 2017, LECT NOTES ARTIF INT, V10061, P155, DOI 10.1007/978-3-319-62434-1_13
   Liao S.S., 2011, P 2011 ICONFERENCE, P804, DOI DOI 10.1145/1940761.1940913
   Magdy W, 2016, PROCEEDINGS OF THE 2016 ACM WEB SCIENCE CONFERENCE (WEBSCI'16), P95, DOI 10.1145/2908131.2908150
   Mirko Lai, 2017, Experimental IR Meets Multilinguality, Multimodality, and Interaction. 8th International Conference of the CLEF Association, CLEF 2017. Proceedings: LNCS 10456, P112, DOI 10.1007/978-3-319-65813-1_10
   Mohammad S, 2016, P 10 INT WORKSH SEM, P31
   Mohammad SM, 2017, ACM T INTERNET TECHN, V17, DOI 10.1145/3003433
   Mohammad SM, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3945
   Mohammad SM, 2013, COMPUT INTELL-US, V29, P436, DOI 10.1111/j.1467-8640.2012.00460.x
   Nakov P., 2013, 2 JOINT C LEX COMP S, P312
   Nielsen F.A., 2011, P ESWC2011 WORKSH MA, P93, DOI DOI 10.1016/J.KN0SYS.2015.06.015
   Pennebaker J. W., 2001, LINGUISTIC INQUIRY W, P71
   Raghavan UN, 2007, PHYS REV E, V76, DOI 10.1103/PhysRevE.76.036106
   Rajadesingan Ashwin, 2014, Social Computing, Behavioral-Cultural Modeling and Prediction. 7th International Conference, SBP 2014. Proceedings: LNCS 8393, P153, DOI 10.1007/978-3-319-05579-4_19
   Respall V.M., 2017, TECHNICAL REPORT
   Rosenthal S., 2015, P 9 INT WORKSH SEM E, P451, DOI DOI 10.18653/V1/S15-2078
   Sanguinetti Manuela, 2017, 4 INT C DEP LING DEP, P229
   Schmid H., 1994, COLING 1994 P 15 C C, V1, P172
   Schmid H, 1995, TREETAGGER LANGUAGE, V43, P28
   Segura-Bedmar I., 2018, P 3 WORKSH EV HUM LA, P180
   Somasundaran Swapna, 2009, P ACL IJCNLP
   Taule M., 2018, CEUR WS C 20 WORK NO, P149
   Taule Mariona, 2017, P 2 WORKSH EV HUM LA, P157
   Tromp E., 2011, 2011 IEEE International Conference on Data Mining Workshops, P1247, DOI 10.1109/ICDMW.2011.152
   Tutek M., 2016, P 10 INT WORKSH SEM, P464
   Vychegzhanin SV, 2019, PROGRAM COMPUT SOFT+, V45, P228, DOI 10.1134/S0361768819050074
   Wei P., 2018, INT JOINT C NEUR NET, P1
   Wei W, 2016, 2016 INTERNATIONAL CONFERENCE ON EDUCATION SCIENCE AND EDUCATION MANAGEMENT (ESEM 2016), P385
   WEST DM, 1991, POLITICAL BEHAV, V0013
   Whissell C, 2009, PSYCHOL REP, V105, P509, DOI 10.2466/PR0.105.2.509-521
   Wilson TS, 2005, PHIL EDUC, P347, DOI 10.3115/1220575.1220619
   Yuan JH, 2019, THIRTY-THIRD AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTY-FIRST INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / NINTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P7426
   Zappavigna M, 2015, SOC SEMIOT, V25, P274, DOI 10.1080/10350330.2014.996948
   Zarrella G., 2016, P INT WORKSH SEM EV
   Zhou SQ, 2019, 2019 18TH EUROPEAN CONTROL CONFERENCE (ECC), P1, DOI 10.23919/ECC.2019.8796140
NR 54
TC 14
Z9 14
U1 2
U2 12
PU ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0885-2308
EI 1095-8363
J9 COMPUT SPEECH LANG
JI Comput. Speech Lang.
PD SEP
PY 2020
VL 63
AR 101075
DI 10.1016/j.csl.2020.101075
PG 27
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA LP7FB
UT WOS:000534481900006
OA Green Published
DA 2022-02-06
ER

PT J
AU Hrckova, A
   Moro, R
   Srba, I
   Bielikova, M
AF Hrckova, Andrea
   Moro, Robert
   Srba, Ivan
   Bielikova, Maria
TI Quantitative and qualitative analysis of linking patterns of mainstream
   and partisan online news media in Central Europe
SO ONLINE INFORMATION REVIEW
LA English
DT Article; Early Access
DE Partisan online news media; Media profiling; Central Europe; Hyperlink
   network analysis; Content analysis; COVID-19
AB Purpose - Partisan news media, which often publish extremely biased, one-sided or even false news, are gaining popularity world-wide and represent a major societal issue. Due to a growing number of such media, a need for automatic detection approaches is of high demand. Automatic detection relies on various indicators (e.g. content characteristics) to identify new partisan media candidates and to predict their level of partisanship. The aim of the research is to investigate to a deeper extent whether it would be appropriate to rely on the hyperlinks as possible indicators for better automatic partisan news media detection.
   Design/methodology/approach - The authors utilized hyperlink network analysis to study the hyperlinks of partisan and mainstream media. The dataset involved the hyperlinks of 18 mainstream media and 15 partisan media in Slovakia and Czech Republic. More than 171 million domain pairs of inbound and outbound hyperlinks of selected online news media were collected with Ahrefs tool, analyzed and visualized with Gephi software. Additionally, 300 articles covering COVID-19 from both types of media were selected for content analysis of hyperlinks to verify the reliability of quantitative analysis and to provide more detailed analysis.
   Findings - The authors conclude that hyperlinks are reliable indicators of media affinity and linking patterns could contribute to partisan news detection. The authors found out that especially the incoming links with dofollow attribute to news websites are reliable indicators for assessing the type of media, as partisan media rarely receive links with dofollow attribute from mainstream media. The outgoing links are not such reliable indicators as both mainstream and partisan media link to mainstream sources similarly.
   Originality/value - In contrast to the extensive amount of research aiming at fake news detection within a piece of text or multimedia content (e.g. news articles, social media posts), the authors shift to characterization of the whole news media. In addition, the authors did a geographical shift from more researched US-based media to so far under-researched European context, particularly Central Europe. The results and conclusions can serve as a guide how to derive new features for an automatic detection of possibly partisan news media by means of artificial intelligence (AI).
C1 [Hrckova, Andrea; Moro, Robert; Srba, Ivan; Bielikova, Maria] Kempelen Inst Intelligent Technol, Web & User Data Proc Grp, Bratislava, Slovakia.
RP Hrckova, A (corresponding author), Kempelen Inst Intelligent Technol, Web & User Data Proc Grp, Bratislava, Slovakia.
EM andrea.hrckova@kinit.sk
RI Srba, Ivan/AAI-6628-2021; Bielikova, Maria/E-5787-2013
OI Srba, Ivan/0000-0003-3511-5337; Bielikova, Maria/0000-0003-4105-3494
CR Allcott H, 2017, J ECON PERSPECT, V31, P211, DOI 10.1257/jep.31.2.211
   Baly R., 2018, P 2018 C EMP METH NA, DOI [10.18653/v1/D18-1389, DOI 10.18653/V1/D18-1389, 10.18653/v1/d18-1389]
   Baly R, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P3364
   Baly Ramy, 2020, P 2020 C EMP METH NA, P4982, DOI DOI 10.18653/V1/2020.EMNLP-MAIN.404
   Bhatt S, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), P545, DOI 10.1145/3184558.3188725
   Bjorneborn L, 2004, J AM SOC INF SCI TEC, V55, P1216, DOI 10.1002/asi.20077
   Cazalens S, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), P565, DOI 10.1145/3184558.3188727
   Chen ZH, 2020, WWW'20: COMPANION PROCEEDINGS OF THE WEB CONFERENCE 2020, P584, DOI 10.1145/3366424.3385772
   Choras M, 2021, APPL SOFT COMPUT, V101, DOI 10.1016/j.asoc.2020.107050
   De Maeyer J, 2012, JOURNAL PRACT, V6, P692, DOI 10.1080/17512786.2012.667273
   Dhoju S, 2019, COMPANION OF THE WORLD WIDE WEB CONFERENCE (WWW 2019 ), P981, DOI 10.1145/3308560.3316741
   Fourney A, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P2071, DOI 10.1145/3132847.3133147
   FRUCHTERMAN TMJ, 1991, SOFTWARE PRACT EXPER, V21, P1129, DOI 10.1002/spe.4380211102
   Guo B, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3393880
   Herman E, 1988, MANUFACTURING CONSEN
   Himelboim I, 2010, J BROADCAST ELECTRON, V54, P373, DOI 10.1080/08838151.2010.499050
   Hrckova A, 2019, BIBL-AN INVESTIG, V15, P421
   Jackson M. H., 1997, J COMPUT-MEDIAT COMM, V3, DOI DOI 10.1111/J.1083-6101.1997.TB00063.X
   Kotonya Neema, 2020, P 28 INT C COMP LING, P5430, DOI DOI 10.18653/V1/2020.COLING-MAIN.474
   Makulova S., 2011, OPTIMALIZACIA WEBOVY
   Morstatter F, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), P621, DOI 10.1145/3184558.3188733
   Nakov P., 2021, SURVEY PREDICTING FA
   Pak C, 2020, INT J COMMUN-US, V14, P3546
   Park HW, 2008, QUAL QUANT, V42, P687, DOI 10.1007/s11135-007-9109-z
   Sampor Z., 2020, MONITORING MEDIA PLU
   Stetka V., 2020, MONITORING MEDIA PLU
   Szabo G, 2015, INTERSECTIONS-E EUR, V1, P122, DOI 10.17356/ieejsp.v1i1.30
   Verma Nitin, 2017, Proceedings of the Association for Information Science and Technology, V54, DOI 10.1002/pra2.2017.14505401046
   Vosoughi S, 2018, SCIENCE, V359, P1146, DOI 10.1126/science.aap9559
   Zeifman I., 2017, CLOSER LOOK MOST ACT
   Zhou XY, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3395046
NR 31
TC 0
Z9 0
U1 1
U2 1
PU EMERALD GROUP PUBLISHING LTD
PI BINGLEY
PA HOWARD HOUSE, WAGON LANE, BINGLEY BD16 1WA, W YORKSHIRE, ENGLAND
SN 1468-4527
EI 1468-4535
J9 ONLINE INFORM REV
JI Online Inf. Rev.
DI 10.1108/OIR-10-2020-0441
EA DEC 2021
PG 20
WC Computer Science, Information Systems; Information Science & Library
   Science
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Information Science & Library Science
GA XH7IW
UT WOS:000725604700001
DA 2022-02-06
ER

PT J
AU Luo, H
   Cai, M
   Cui, Y
AF Luo, Han
   Cai, Meng
   Cui, Ying
TI Spread of Misinformation in Social Networks: Analysis Based on Weibo
   Tweets
SO SECURITY AND COMMUNICATION NETWORKS
LA English
DT Article
ID FAKE NEWS; FALSE NEWS; MEDIA
AB Social networks are filled with a large amount of misinformation, which often misleads the public to make wrong decisions, stimulates negative public emotions, and poses serious threats to public safety and social order. The spread of misinformation in social networks has also become a widespread concern among scholars. In the study, we took the misinformation spread on social media as the research object and compared it with true information to better understand the characteristics of the spread of misinformation in social networks. This study adopts a deep learning method to perform content analysis and emotion analysis on misinformation dataset and true information dataset and adopts an analytic network process to analyze the differences between misinformation and true information in terms of network diffusion characteristics. The research findings reveal that the spread of misinformation on social media is influenced by content features and different emotions and consequently produces different changes. The related research findings enrich the existing research and make a certain contribution to the governance of misinformation and the maintenance of network order.
C1 [Luo, Han; Cai, Meng] Xi An Jiao Tong Univ, Sch Humanities & Social Sci, Xian 710049, Peoples R China.
   [Cui, Ying] Xidian Univ, Sch Mechano Elect Engn, Xian 710071, Peoples R China.
C3 Xi'an Jiaotong University; Xidian University
RP Cai, M (corresponding author), Xi An Jiao Tong Univ, Sch Humanities & Social Sci, Xian 710049, Peoples R China.
EM mengcai@mail.xjtu.edu.cn
OI Cui, Ying/0000-0002-5524-7444
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [71501153]; Innovation Capability Support
   Project of Shaanxi Province of China [2021KRM135]; Research Fund of
   Grand Teory and Practical Problem in Philosophy and Social Science of
   Shaanxi Province of China [2021ND0221]; Research Fund of the Education
   Department of Shaanxi Province of China [20JG020]; Natural Science
   Foundation of Shaanxi Province of ChinaNatural Science Foundation of
   Shaanxi Province [2019JM-572]
FX +is research was funded by the National Natural Science Foundation of
   China under Grant no. 71501153, the Innovation Capability Support
   Project of Shaanxi Province of China under Grant no. 2021KRM135, the
   Research Fund of Grand +eory and Practical Problem in Philosophy and
   Social Science of Shaanxi Province of China under Grant no. 2021ND0221,
   the Research Fund of the Education Department of Shaanxi Province of
   China under Grant no. 20JG020, and the Natural Science Foundation of
   Shaanxi Province of China under Grant no. 2019JM-572.
CR Ahmed H.., 2017, DETECTING OPINION SP
   Allcott H, 2017, J ECON PERSPECT, V31, P211, DOI 10.1257/jep.31.2.211
   Borgatti SP, 2009, SCIENCE, V323, P892, DOI 10.1126/science.1165821
   Brennen JS, TYPES SOURCES CLAIMS
   Bringmann LF, 2019, J ABNORM PSYCHOL, V128, P892, DOI 10.1037/abn0000446
   Camacho D, 2020, INFORM FUSION, V63, P88, DOI 10.1016/j.inffus.2020.05.009
   Caulfield Timothy, 2020, Nature, DOI 10.1038/d41586-020-01266-z
   [陈慧敏 Chen Huimin], 2021, [计算机研究与发展, Journal of Computer Research and Development], V58, P1366
   Chen L, 2018, J MED INTERNET RES, V20, DOI 10.2196/11515
   Cheng KF, 2020, IEEE ACCESS, V8, P16387, DOI 10.1109/ACCESS.2020.2967103
   Faris Robert., 2017, BERKMAN KLEIN CTR RE, V6
   Ghenai Amira, 2018, Proceedings of the ACM on Human-Computer Interaction, V2, DOI 10.1145/3274327
   GRANOVETTER MS, 1973, AM J SOCIOL, V78, P1360, DOI 10.1086/225469
   Grinberg N, 2019, SCIENCE, V363, P374, DOI 10.1126/science.aau2706
   Guess AM, 2020, P NATL ACAD SCI USA, V117, P15536, DOI 10.1073/pnas.1920498117
   Guo L, 2020, JOURNALISM STUD, V21, P2176, DOI 10.1080/1461670X.2020.1827012
   Hollowood E., FAKE NEWS TIME C 19
   Jang SM, 2018, COMPUT HUM BEHAV, V84, P103, DOI 10.1016/j.chb.2018.02.032
   Jones-Jang SM, 2021, AM BEHAV SCI, V65, P371, DOI 10.1177/0002764219869406
   King K.K.., 2021, INT J INFORM MANAGE, DOI [10.1016/j.ijinfomgt.2021.102390, DOI 10.1016/J.IJINFOMGT.2021.102390]
   Klimiuk K, 2021, HUM VACC IMMUNOTHER, V17, P2026, DOI 10.1080/21645515.2020.1850072
   Kodinariya T. M., 2013, INT J-TORONTO, V1, P90
   Kusen Ema, 2018, Online Social Networks and Media, V5, P37, DOI 10.1016/j.osnem.2017.12.002
   Lai YN, 2020, WORLD WIDE WEB, V23, P2771, DOI 10.1007/s11280-020-00803-0
   Lazer DMJ, 2018, SCIENCE, V359, P1094, DOI 10.1126/science.aao2998
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Leng Y.., ANAL MISINFORMATION
   Lewandowsky S, 2012, PSYCHOL SCI PUBL INT, V13, P106, DOI 10.1177/1529100612451018
   Li L, 2019, LECT NOTES COMPUT SC, V11604, P596, DOI 10.1007/978-3-030-23597-0_49
   Liu B, 2020, J AMB INTEL HUM COMP, V11, P451, DOI 10.1007/s12652-018-1095-6
   Liu M, 2017, TSINGHUA SCI TECHNOL, V22, P619, DOI 10.23919/TST.2017.8195345
   Liu P, 2016, FOOD POLICY, V63, P102, DOI 10.1016/j.foodpol.2016.07.005
   Loia V, 2014, KNOWL-BASED SYST, V58, P75, DOI 10.1016/j.knosys.2013.09.024
   Luo F, 2016, INT C COMP SUPP COOP, P276, DOI 10.1109/CSCWD.2016.7566001
   Ma J., 2016, P 25 INT JOINT C ART, P3818
   Ma R, 2008, COMMUN Q, V56, P376, DOI 10.1080/01463370802448204
   Malecki KMC, 2021, CLIN INFECT DIS, V72, P697, DOI 10.1093/cid/ciaa758
   Mikolov T, 2013, EFFICIENT ESTIMATION
   Ng LHX, 2021, IEEE INTERNET COMPUT, V25, P84, DOI 10.1109/MIC.2020.3040516
   Nguyen N.K., 2016, INT S INT UNC KNOWL
   Oh O, 2013, MIS QUART, V37, P407, DOI 10.25300/MISQ/2013/37.2.05
   Pastor-Satorras R, 2015, REV MOD PHYS, V87, P925, DOI 10.1103/RevModPhys.87.925
   Pennycook G, 2021, NATURE, V592, P590, DOI 10.1038/s41586-021-03344-2
   Pennycook G, 2019, P NATL ACAD SCI USA, V116, P2521, DOI 10.1073/pnas.1806781116
   Pennycook G, 2019, COGNITION, V188, P39, DOI 10.1016/j.cognition.2018.06.011
   Poria S, 2017, NEUROCOMPUTING, V261, P217, DOI 10.1016/j.neucom.2016.09.117
   Pulido CM, 2020, INT SOCIOL, V35, P377, DOI 10.1177/0268580920914755
   Rojecki A, 2016, NEW MEDIA SOC, V18, P25, DOI 10.1177/1461444814535724
   Saqr M, 2019, BMC MED EDUC, V19, DOI 10.1186/s12909-019-1599-6
   Sell TK, 2020, BMC PUBLIC HEALTH, V20, DOI 10.1186/s12889-020-08697-3
   Shin J, 2018, COMPUT HUM BEHAV, V83, P278, DOI 10.1016/j.chb.2018.02.008
   Soe SO, 2018, J DOC, V74, P309, DOI 10.1108/JD-05-2017-0075
   Van Bavel JJ, 2018, TRENDS COGN SCI, V22, P213, DOI 10.1016/j.tics.2018.01.004
   Vargo CJ, 2018, NEW MEDIA SOC, V20, P2028, DOI 10.1177/1461444817712086
   Vosoughi S, 2018, SCIENCE, V359, P1146, DOI 10.1126/science.aap9559
   Wang P, 2015, SCI CHINA INFORM SCI, V58, DOI 10.1007/s11432-014-5237-y
   Xiaorui T., 2014, LIB INFORM SERVICE, V58, P59
   Xiong H., 2016, BIG DATA COMPLEX SOC
   Xu GX, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/5567991
   Zannettou S, 2019, ACM J DATA INF QUAL, V11, DOI 10.1145/3309699
   Zarocostas J, 2020, LANCET, V395, P676, DOI 10.1016/S0140-6736(20)30461-X
   Zhang L, 2017, ASIAN J COMMUN, V27, P322, DOI 10.1080/01292986.2017.1290124
   Zhao YH, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2020.102390
   Zhao YH, 2017, HEALTH INFO LIBR J, V34, P268, DOI 10.1111/hir.12192
   Zollo F, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0138740
   Zubiaga A, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0150989
NR 66
TC 0
Z9 0
U1 3
U2 3
PU WILEY-HINDAWI
PI LONDON
PA ADAM HOUSE, 3RD FL, 1 FITZROY SQ, LONDON, WIT 5HE, ENGLAND
SN 1939-0114
EI 1939-0122
J9 SECUR COMMUN NETW
JI Secur. Commun. Netw.
PD DEC 16
PY 2021
VL 2021
AR 7999760
DI 10.1155/2021/7999760
PG 23
WC Computer Science, Information Systems; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Telecommunications
GA XY9IH
UT WOS:000737277600004
OA gold
DA 2022-02-06
ER

PT J
AU Miller, ML
   Vaccari, C
AF Miller, Michael L.
   Vaccari, Cristian
TI Digital Threats to Democracy: Comparative Lessons and Possible Remedies
SO INTERNATIONAL JOURNAL OF PRESS-POLITICS
LA English
DT Editorial Material
DE democracy; digital media; disinformation; participation; comparative
   research
ID SOCIAL MEDIA; FAKE NEWS; POLITICS; INTERNET; CIVILITY; ONLINE; FALSE
AB We introduce a special issue that collects eight articles, comprising research from twenty-three countries and four continents on the sources, impact on citizens, and possible remedies to various digital threats to democracy, ranging from disinformation to hate speech to state interference with online freedoms. We set these contributions against the backdrop of a profound change in how scholars think about the implications of digital media for democracy. From the utopianism that prevailed from the 1990s until the early 2010s, the post-2016 reckoning has led to a change in the kinds of questions scholars ask, with the focus gradually shifting to investigations of the threats, rather than the benefits, of the Internet. The eight contributions presented in this special issue employ a variety of disciplinary approaches and methods, often comparing different countries, to address some of the most pressing questions on how the Internet can hinder the feasibility and well-functioning of democracy around the world. We conclude by setting out three challenges for future research on digital media and politics: a growing but still partial understanding of the extent and impact of the main digital threats to democracy; the risk that the dominant approaches become overly pessimistic, or founded on weak normative grounds; and the risk that research overemphasizes direct and short-term implications of digital threats on individuals and specific groups at the expense of indirect and medium-term effects on collective norms and expectations of behavior.
C1 [Miller, Michael L.] Social Sci Res Council, Media & Democracy Program, 300 Cadman Plaza West,15th Floor, Brooklyn, NY 11201 USA.
   [Vaccari, Cristian] Loughborough Univ, Polit Commun, Loughborough, Leics, England.
   [Vaccari, Cristian] Loughborough Univ, Ctr Res Commun & Culture, Loughborough, Leics, England.
C3 Loughborough University; Loughborough University
RP Miller, ML (corresponding author), Social Sci Res Council, Media & Democracy Program, 300 Cadman Plaza West,15th Floor, Brooklyn, NY 11201 USA.
EM miller@ssrc.org
CR Bailard Catie Snow., 2014, DEMOCRACYS DOUBLE ED
   Baran, 1962, DISTRIBUTED COMMUNIC
   Barlow J.P., 1996, DECLARATION INDEPEND
   Barlow J. P., 2000, DEBATE INTERNET GOVE
   Bartels, 2017, DEMOCRACY REALISTS W, V4
   Benkler Y., 2006, WEALTH NETWORKS SOCI
   Benkler Yochai., 2018, NETWORK PROPAGANDA M
   Bennett WL, 2018, J COMMUN, V68, P243, DOI 10.1093/joc/jqx017
   Bennett WL., 2013, LOGIC CONNECTIVE ACT, DOI DOI 10.1017/CBO9781139198752
   Bimber  B, 2003, CAMPAIGNING ONLINE I
   Bimber B., 2003, INFORM AM DEMOCRACY
   Bimber B, 2020, NEW MEDIA SOC, V22, P700, DOI 10.1177/1461444819893980
   Boatright RobertG., 2019, CRISIS CIVILITY POLI
   Boydstun AE, 2020, PERSPECT POLIT, V18, P128, DOI 10.1017/S153759271900238X
   Brock A, 2012, J BROADCAST ELECTRON, V56, P529, DOI 10.1080/08838151.2012.732147
   Castells M., 2007, INT J COMMUN, V1, P29, DOI DOI 10.1080/13691180903390885
   Chadwick A, 2019, NEW CRISIS PUBLIC CO
   Chadwick A., 2009, I S J LAW POLICY INF, V5, P9, DOI DOI 10.7551/MITPRESS/9006.003.0005
   Chadwick A., 2006, INTERNET POLITICS ST
   Chadwick A, 2018, NEW MEDIA SOC, V20, P4255, DOI 10.1177/1461444818769689
   CHEN GM, 2019, SOCIAL MEDIA SOC, V5, DOI DOI 10.1177/+
   Clark David D, 1992, 24 M INT ENG TASK FO
   Coleman S, 2009, COMMUN SOC POLIT, P1, DOI 10.1017/CBO9780511818271
   D'Angelo P., 2004, MASS COMMUNICATION S, V7, P3, DOI [10.1207/s15327825mcs0701_2, DOI 10.1207/S15327825MCS0701_2]
   Deibert R, 2012, INFORM REVOL GLOB PO, P1
   Deibert R, 2010, ACCESS CONTROLLED SH
   Deibert R, 2008, ACCESDENIED PRACTI
   DiMaggio Paul., 2004, SOCIAL INEQUALITY, P355
   DiResta R., 2018, TACTICS TROPES INTER TACTICS TROPES INTER
   Drezner D. W., 2004, FOREIGN POLICY, V145, P32, DOI DOI 10.2307/4152942
   Dunaway J, 2019, INFORM COMMUN SOC, DOI 10.1080/1369118X.2019.1631367
   Entman R., 1990, DEMOCRACY CITIZENS M
   Erikson R., 2002, MACROPOLITY
   Flynn DJ, 2017, POLIT PSYCHOL, V38, P127, DOI 10.1111/pops.12394
   Galloway Alexander R., 2004, PROTOCOL CONTROL EXI
   Geiger A, 2018, AM HAVE VIEWED GOVT
   Gibson R, 2003, POLITICAL PARTIES IN
   Giglietto F, 2020, INFORM COMMUN SOC, V23, P867, DOI 10.1080/1369118X.2020.1739732
   Giglietto F, 2019, CURR SOCIOL, V67, P625, DOI 10.1177/0011392119837536
   Goldsmith Jack L., 2006, WHO CONTROLS INTERNE
   Golovchenko Y, 2020, INT J PRESS/POLIT, V25, P357, DOI 10.1177/1940161220912682
   Greenwald G, 2013, GUARDIAN, V6, P6
   Guess A, 2019, SCI ADV, V5, DOI 10.1126/sciadv.aau4586
   Hacker JacobS., 2010, WINNER TAKE ALL POLI
   Hargittai E, 2015, INFORM COMMUN SOC, V18, P424, DOI 10.1080/1369118X.2014.957711
   HEDRICK A, 2018, INT J COMMUN US, V12, P1057
   Hindman M., 2018, INTERNET TRAP DIGITA
   Hindman M., 2005, PERSPECT POLIT, V3, P121
   Hindman Matthew, 2008, MYTH DIGITAL DEMOCRA
   Howard P., 2018, IRA POLITICAL POLARI
   Howard P. N., 2006, NEW MEDIA CAMPAIGNS
   Howard P.N., 2010, DIGITAL ORIGINS DICT
   Humprecht E, 2020, INT J PRESS/POLIT, V25, P493, DOI 10.1177/1940161219900126
   Jamieson KH., 2018, CYBERWAR RUSSIAN HAC, VIllustrated
   Johnson DR, 1996, STANFORD LAW REV, V48, P1367, DOI 10.2307/1229390
   Kalathil S., 2003, OPEN NETWORKS CLOSED
   Karpf D., 2019, MEDIAWELL       1210
   Koc-Michalska K, 2020, INT J PRESS/POLIT, V25, P447, DOI 10.1177/1940161220912693
   Liang F, 2018, POLICY INTERNET, V10, P415, DOI 10.1002/poi3.183
   Lukito J, 2020, INT J PRESS/POLIT, V25, P196, DOI 10.1177/1940161219895215
   Lupia Arthur., 1998, DEMOCRATIC DILEMMA C
   Lyon D., 2015, SURVEILLANCE SNOWDEN
   Lyons B., 2020, INT J PRESS POLITICS, V25
   Mabry E. A., 1997, J COMPUT-MEDIAT COMM, V2
   Margolis M., 2000, POLITICS USUAL CYBER
   McIlwain C., 2019, BLACK SOFTWARE INTER
   Morozov E., 2012, NET DELUSION DARK SI
   Nash V., 2019, J MEDIA LAW, V11, P18
   Negroponte N., 1995, BEING DIGITAL
   Ng EWJ, 2005, J COMPUT-MEDIAT COMM, V10
   Norris P, 2019, CULTURAL BACKLASH: TRUMP, BREXIT, AND AUTHORITARIAN POPULISM, P1, DOI 10.1017/9781108595841
   Norris P, 2001, DIGITAL DIVIDE CIVIC
   Papacharissi Z, 2004, NEW MEDIA SOC, V6, P259, DOI 10.1177/1461444804041444
   Papacharissi Z, 2002, NEW MEDIA SOC, V4, P9, DOI 10.1177/14614440222226244
   Patterson T.E., 1994, OUT ORDER INCISIVE B
   Pennycook G, 2019, COGNITION, V188, P39, DOI 10.1016/j.cognition.2018.06.011
   Phillips W., 2015, THIS IS WHY WE CANT
   Plattner, 2012, LIBERATION TECHNOLOG
   Przeworski A, 2019, CRISES OF DEMOCRACY, P1, DOI 10.1017/9781108671019
   Rheingold Howard, 2002, SMART MOBS NEXT SOCI
   Roberts M. E., 2018, CENSORED DISTRACTION
   Robertson CT, 2020, INT J PRESS/POLIT, V25, P217, DOI 10.1177/1940161219898055
   Rossini P., COMMUNICATION RES
   Shapiro Andrew, 1999, CONTROL REVOLUTION I
   Shirky C., 2009, HERE COMES EVERYBODY
   Sobieraj S., 2019, MEDIAWELL       1022
   Steele CK, 2016, SOC MEDIA SOC, V2, DOI 10.1177/2056305116683205
   Steele CK, 2018, TELEV NEW MEDIA, V19, P112, DOI 10.1177/1527476417709535
   Stier S, 2020, INT J PRESS/POLIT, V25, P426, DOI 10.1177/1940161220907018
   Stoycheff E, 2020, INT J PRESS/POLIT, V25, P390, DOI 10.1177/1940161220909741
   Stromback J., 2005, JOURNALISM STUD, V6, P331
   Surowiecki J., 2004, WISDOM CROWDS WHY MA
   Tapscott D., 2006, WIKINOMICS MASS COLL
   Tenove C, 2020, INT J PRESS/POLIT, V25, P517, DOI 10.1177/1940161220918740
   Tromble R, 2019, POLIT COMMUN, V36, P324, DOI 10.1080/10584609.2019.1609860
   Tufekci Z, 2012, J COMMUN, V62, P363, DOI 10.1111/j.1460-2466.2012.01629.x
   Udupa S., 2020, FIELD DISINFORMATION
   Vaccari C., 2013, DIGITAL POLITICS W D
   Vaccari C, 2020, SOC MEDIA SOC, V6, DOI 10.1177/2056305120903408
   Vaccari C, 2019, INT J PRESS/POLIT, V24, P3, DOI 10.1177/1940161218809819
   Vaidhyanathan Siva., 2018, ANTISOCIAL MEDIA FAC
   van Dijk JA., 2005, DEEPENING DIVIDE INE
   Waisbord S, 2018, JOURNALISM STUD, V19, P1866, DOI 10.1080/1461670X.2018.1492881
   Wells C, 2016, POLIT COMMUN, V33, P669, DOI 10.1080/10584609.2016.1224416
   Whitten-Woodring J, 2020, INT J PRESS/POLIT, V25, P407, DOI 10.1177/1940161220919666
   Wolfsfeld G, 2013, INT J PRESS/POLIT, V18, P115, DOI 10.1177/1940161212471716
   Wu T., 2017, ATTENTION MERCHANTS
   Zhang YN, 2018, NEW MEDIA SOC, V20, P3161, DOI 10.1177/1461444817744390
   Zuboff S., 2019, AGE SURVEILLANCE CAP
   [No title captured]
NR 110
TC 11
Z9 11
U1 3
U2 20
PU SAGE PUBLICATIONS INC
PI THOUSAND OAKS
PA 2455 TELLER RD, THOUSAND OAKS, CA 91320 USA
SN 1940-1612
EI 1940-1620
J9 INT J PRESS/POLIT
JI Int. J. Press-Polit.
PD JUL
PY 2020
VL 25
IS 3
SI SI
BP 333
EP 356
AR 1940161220922323
DI 10.1177/1940161220922323
EA MAY 2020
PG 24
WC Communication; Political Science
WE Social Science Citation Index (SSCI)
SC Communication; Government & Law
GA MH3NA
UT WOS:000532912800001
OA Green Submitted
DA 2022-02-06
ER

PT J
AU Varshney, D
   Vishwakarma, DK
AF Varshney, Deepika
   Vishwakarma, Dinesh Kumar
TI A review on rumour prediction and veracity assessment in online social
   network
SO EXPERT SYSTEMS WITH APPLICATIONS
LA English
DT Review
DE Online social media; Rumor detection, review; Veracity
ID FAKE NEWS; COLLECTION; CUES
AB In the present era, the social network is used as an important medium for sharing thoughts and opinions of an individual. The main reason behind this is, it provides a fast-spreading of information among the public easily, requiring a very low cost of access. This leads to having online social media as one of the stepping stones to encourage false content and influencing public opinion and its decision. Rumour is one of the prominent forms of misleading information on social media and should be detected as early as possible for avoiding their significant effects. Due to these reasons, the researchers have put their keen interest in developing an effective rumour detection framework in the last years. In this paper, we mainly focused on six main aspects. Firstly, we discuss rumours from a definition perspective that have been considered in the state-of-the-art and describe the generalized model of rumour detection. Secondly, we discuss how to get access to data from different social media platforms, and presents various state-of-the-art methods to gather these data, as well as publicly available datasets. Third, we describe a different set of features that have been considered in rumour detection approaches. Fourth, we provide deep insight into the various methods used to employ rumour detection and its veracity assessment on multimedia data (Text and Images) with some practical implications. Whereas in the fifth aspect, the constraints of the study have been discussed. Finally, we concluded with useful findings and suggested future directions.
C1 [Varshney, Deepika; Vishwakarma, Dinesh Kumar] Delhi Technol Univ, Dept Informat Technol, Delhi 110042, India.
C3 Delhi Technological University
RP Vishwakarma, DK (corresponding author), Delhi Technol Univ, Dept Informat Technol, Delhi 110042, India.
EM dinesh@dtu.ac.in
RI Vishwakarma, Dinesh/L-3815-2018
OI Vishwakarma, Dinesh/0000-0002-1026-0047
CR Agichtein E., 2008, P 2008 INT C WEB SEA, P183, DOI [10.1145/1341531.1341557, DOI 10.1145/1341531.1341557]
   Alzanin SM, 2019, KNOWL-BASED SYST, V185, DOI 10.1016/j.knosys.2019.104945
   Ardizzone E, 2015, IEEE T INF FOREN SEC, V10, P2084, DOI 10.1109/TIFS.2015.2445742
   Armstrong CL, 2009, J COMPUT-MEDIAT COMM, V14, P435, DOI 10.1111/j.1083-6101.2009.01448.x
   Asghar MZ, 2021, J AMB INTEL HUM COMP, V12, P4315, DOI 10.1007/s12652-019-01527-4
   Boididou C, 2018, INT J MULTIMED INF R, V7, P71, DOI 10.1007/s13735-017-0143-x
   Boididou C, 2014, WWW'14 COMPANION: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P743, DOI 10.1145/2567948.2579323
   Bondielli A, 2019, INFORM SCIENCES, V497, P38, DOI 10.1016/j.ins.2019.05.035
   Cai GY, 2014, 2014 PROCEEDINGS OF THE IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2014), P912, DOI 10.1109/ASONAM.2014.6921694
   Cao J., 2020, ARXIV PREPRINT ARXIV
   Cao J., 2018, ABS18070 CORR
   Castillo C., 2011, WWW, P675
   Chen WL, 2018, PATTERN RECOGN LETT, V105, P226, DOI 10.1016/j.patrec.2017.10.014
   Duong CT, 2017, LECT NOTES COMPUT SC, V10538, P125, DOI 10.1007/978-3-319-68155-9_10
   Dang A., 2019, P 52 HAW INT C SYST
   Derczynski L., 2017, ABS170400 CORR
   DiFonzo N, 2007, DIOGENES, V54, P19, DOI 10.1177/0392192107073433
   Driscoll K, 2014, INT J COMMUN-US, V8, P1745
   Fard AE, 2019, IEEE T COMPUT SOC SY, V6, P830, DOI 10.1109/TCSS.2019.2931186
   Floos Ahmad Yahya M., 2016, International Journal of Knowledge Society Research, V7, P72, DOI 10.4018/IJKSR.2016040105
   Fu F. Q., 2017, SCI REP-UK
   Geng YX, 2019, 2019 IEEE 4TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING AND BIG DATA ANALYSIS (ICCCBDA), P120, DOI 10.1109/ICCCBDA.2019.8725715
   Giasemidis G., 2016, ABS16110 CORR
   Gravanis G, 2019, EXPERT SYST APPL, V128, P201, DOI 10.1016/j.eswa.2019.03.036
   Guo H, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P943, DOI 10.1145/3269206.3271709
   Gupta A., 2014, ABS14055 CORR
   Gupta A, 2013, PROCEEDINGS OF THE 22ND INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'13 COMPANION), P729
   Hamidian S., 2019, ABS19120 ARXIV
   Hamidian S., 2015, P 5 INT C SOC MED TE, P71
   Han S., 2019, NEURAL LANGUAGE MODE
   Han Sooji, 2019, DATA AUGMENTATION RU
   Jin ZW, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P795, DOI 10.1145/3123266.3123454
   Jin ZW, 2017, IEEE T MULTIMEDIA, V19, P598, DOI 10.1109/TMM.2016.2617078
   JOHNSON SC, 1967, PSYCHOMETRIKA, V32, P241, DOI 10.1007/BF02289588
   Kai Shu, 2017, ACM SIGKDD Explorations Newsletter, V19, P22, DOI 10.1145/3137597.3137600
   Khoo L. M. S., 2020, ARXIV PREPRINT ARXIV
   Kotteti C. M. M., 2020, ARXIV PREPRINT ARXIV
   Kumar A, 2020, ALGO INTELL SY, P239, DOI 10.1007/978-981-15-0222-4_21
   Kumar S., 2018, ARXIV180408559
   Kumar S, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5047
   Kwon S, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0168344
   Kwon S, 2013, IEEE DATA MINING, P1103, DOI 10.1109/ICDM.2013.61
   Liang G, 2015, IEEE TRANS COMPUT SO, V2, P99, DOI 10.1109/TCSS.2016.2517458
   Liang G, 2016, 2016 12TH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (ICNC-FSKD), P1523, DOI 10.1109/FSKD.2016.7603402
   Lin CH, 2020, INT J HUM RESOUR MAN, V31, P2840, DOI [10.1080/09585192.2018.1474938, 10.1007/s11042-018-6922-4]
   Liu Y, 2016, IEEE TRANS COMPUT SO, V3, P46, DOI 10.1109/TCSS.2016.2612980
   Liu YW, 2019, LECT NOTES COMPUT SC, V11496, P139, DOI 10.1007/978-3-030-19274-7_11
   Lomborg S, 2014, INFORM SOC, V30, P256, DOI 10.1080/01972243.2014.915276
   Lorek K, 2015, COMPUT SCI-AGH, V16, P157, DOI 10.7494/csci.2015.16.2.157
   Ma J., 2016, P 21 INT JOINT C ART, P826
   Ma J., 2015, P 24 ACM INT C INF K, V19-23, P1751, DOI DOI 10.1145/2806416.2806607
   Ma J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1980
   Ma J, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P708, DOI 10.18653/v1/P17-1066
   Mathioudakis M., 2010, SIGMOD C
   Meel P, 2020, EXPERT SYST APPL, V153, DOI 10.1016/j.eswa.2019.112986
   Metaxas P. T., 2015, CSCW 15, P69, DOI [10.1145/2685553.2702691, DOI 10.1145/2685553.2702691]
   Mohd Shariff Shafiza, 2014, Advances in Information Retrieval. 36th European Conference on IR Research, ECIR 2014. Proceedings: LNCS 8416, P513, DOI 10.1007/978-3-319-06028-6_50
   Moya I, 2017, KNOWL-BASED SYST, V123, P200, DOI 10.1016/j.knosys.2017.02.015
   Nguyen T., 2017, ABS17110 CORR
   Olteanu A, 2015, PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON COMPUTER-SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING (CSCW'15), P994, DOI 10.1145/2675133.2675242
   Poddar L, 2018, PROC INT C TOOLS ART, P65, DOI 10.1109/ICTAI.2018.00021
   Qazvinian V., 2011, P 2011 C EMP METH NA, P1589
   Roy A., 2018, ARXIV PREPRINT ARXIV
   Saez-Trumper D., 2014, FAKE TWEET BUSTER WE
   Sampson J, 2016, CIKM'16: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P2377, DOI 10.1145/2983323.2983697
   Santhoshkumar S, 2020, SOC NETW ANAL MIN, V10, DOI 10.1007/s13278-020-00634-x
   Shang JB, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P2117, DOI 10.1145/3269206.3272020
   Shelke Sushila, 2019, Online Social Networks and Media, V9, P30, DOI 10.1016/j.osnem.2018.12.001
   Shen CH, 2019, NEW MEDIA SOC, V21, P438, DOI 10.1177/1461444818799526
   Shu K, 2019, COMPUT MATH ORGAN TH, V25, P60, DOI 10.1007/s10588-018-09280-3
   Song C., 2018, CED CREDIBLE EARLY D
   Song C., 2019, IEEE T KNOWL DATA EN
   Sun MF, 2017, J MATH BIOL, V74, P1263, DOI 10.1007/s00285-016-1057-6
   Takahashi T, 2012, JOINT INT CONF SOFT, P452, DOI 10.1109/SCIS-ISIS.2012.6505254
   Tarmizi FAA, 2019, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE AND SYSTEMS (ICISS 2019), P60, DOI 10.1145/3322645.3322688
   Vishwakarma DK, 2019, COGN SYST RES, V58, P217, DOI 10.1016/j.cogsys.2019.07.004
   Vosoughi S, 2017, ACM T KNOWL DISCOV D, V11, DOI 10.1145/3070644
   Wang ZX, 2021, IEEE T SYST MAN CY-S, V51, P1267, DOI 10.1109/TSMC.2019.2896022
   Wang ZH, 2019, IEEE ACCESS, V7, P103000, DOI 10.1109/ACCESS.2019.2928044
   Wu K, 2015, PROC INT CONF DATA, P651, DOI 10.1109/ICDE.2015.7113322
   Xiang Lin, 2019, Natural Language Processing and Chinese Computing. 8th CCF International Conference, NLPCC 2019. Proceedings. Lecture Notes in Artificial Intelligence, Subseries of Lecture Notes in Computer Science (LNAI 11839), P338, DOI 10.1007/978-3-030-32236-6_30
   Xin Xia, 2012, Intelligence and Security Informatics. Proceedings Pacific Asia Workshop, PAISI 2012, P45, DOI 10.1007/978-3-642-30428-6_4
   Xu N., 2018, MNRD MERGED NEURAL M, DOI [10.1109/IJCNN.2018.8489582, DOI 10.1109/IJCNN.2018.8489582]
   Yang F., 2012, P ACM SIGKDD WORKSH, P13
   Yang J., 2011, PROC, P177, DOI [10.1145/1935826.1935863, DOI 10.1145/1935826.1935863]
   Yang ZF, 2015, 2015 12TH WEB INFORMATION SYSTEM AND APPLICATION CONFERENCE (WISA), P53, DOI 10.1109/WISA.2015.19
   Zannettou S, 2019, ACM J DATA INF QUAL, V11, DOI 10.1145/3309699
   Zeller B, 1948, ANN AM ACAD POLIT SS, V257, P240, DOI 10.1177/000271624825700169
   Zhang HL, 2016, ACM T INFORM SYST, V34, DOI 10.1145/2885494
   Zhang Q, 2015, LECT NOTES ARTIF INT, V9362, P113, DOI 10.1007/978-3-319-25207-0_10
   Zhao Z, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P1395, DOI 10.1145/2736277.2741637
   Zubiaga A., 2016, LEARNING REPORTING D
   Zubiaga A., 2015, DETECTING RUMOURS SO
   Zubiaga A., 2015, AAAI WORKSH, P35
   Zubiaga A, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3161603
   Zubiaga A, 2015, WWW'15 COMPANION: PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P347, DOI 10.1145/2740908.2743052
NR 96
TC 3
Z9 3
U1 18
U2 32
PU PERGAMON-ELSEVIER SCIENCE LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
SN 0957-4174
EI 1873-6793
J9 EXPERT SYST APPL
JI Expert Syst. Appl.
PD APR 15
PY 2021
VL 168
AR 114208
DI 10.1016/j.eswa.2020.114208
PG 21
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic; Operations Research & Management Science
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering; Operations Research & Management Science
GA RN7SD
UT WOS:000640552200001
DA 2022-02-06
ER

PT J
AU Gagliardone, I
   Diepeveen, S
   Findlay, K
   Olaniran, S
   Pohjonen, M
   Tallam, E
AF Gagliardone, Iginio
   Diepeveen, Stephanie
   Findlay, Kyle
   Olaniran, Samuel
   Pohjonen, Matti
   Tallam, Edwin
TI Demystifying the COVID-19 Infodemic: Conspiracies, Context, and the
   Agency of Users
SO SOCIAL MEDIA + SOCIETY
LA English
DT Article
DE conspiracy theories; mis/disinformation; Africa; COVID-19; social media
ID FAKE NEWS; HATE; AFRICA; ONLINE
AB This article presents new empirical insights into what people do with conspiracy theories during crises. By suppressing the impulse to distinguish between truth and falsehood, which has characterized most scholarship on the COVID-19 "infodemic," and engaging with claims surrounding two popular COVID-19 conspiracies-on 5G and on Bill Gates-in South Africa and Nigeria, we illustrate how conspiracies morph as they interact with different socio-political contexts. Drawing on a mixed-method analysis of more than 6 million tweets, we examine how, in each country, conspiracies have uniquely intersected with longer-term discourses and political projects. In Nigeria, the two conspiracies were both seized as opportunities to extend criticism to the ruling party. In South Africa, they produced distinctive responses: while the 5G conspiracy had limited buy-in, the Gates conspiracy resonated with deep-rooted resentment toward the West, corporate interests, and what is seen as a paternalistic attitude of some external actors toward Africa. These findings stress the importance of taking conspiracy theories seriously, rather than dismissing them simply as negative externalities of digital ecosystems. Situating conspiracies in specific dynamics of trust and mistrust can make an important difference when designing responses that are not limited to broadcasting truthful information, but can also enable interventions that account for deeply rooted sentiments of suspicion toward specific issues and actors, which can vary significantly across communities.
C1 [Gagliardone, Iginio; Olaniran, Samuel] Univ Witwatersrand, Media Studies, Johannesburg, South Africa.
   [Findlay, Kyle] Univ Witwatersrand, ZA-2050 Johannesburg, South Africa.
   [Diepeveen, Stephanie] Univ Cambridge, Polit & Int Studies, Cambridge, England.
   [Pohjonen, Matti] Univ Helsinki, Media & Commun, Helsinki, Finland.
   [Tallam, Edwin] Moi Univ, Nairobi, Kenya.
C3 University of Witwatersrand; University of Witwatersrand; University of
   Cambridge; University of Helsinki; Moi University
RP Gagliardone, I (corresponding author), Univ Witwatersrand, ZA-2050 Johannesburg, South Africa.
EM iginio.gagliardone@wits.ac.za
RI Olaniran, Samuel/F-2204-2018
OI Olaniran, Samuel/0000-0003-2219-0856; Pohjonen,
   Matti/0000-0003-1702-6402
FU Cambridge-Africa ALBORADA Fund
FX The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: The
   research was supported by the Cambridge-Africa ALBORADA Fund.
CR Abidin C, 2020, SOC MEDIA SOC, V6, DOI 10.1177/2056305120948223
   Ahmed W, 2020, J MED INTERNET RES, V22, DOI 10.2196/19458
   Paz MA, 2020, SAGE OPEN, V10, DOI 10.1177/2158244020973022
   Blondel VD, 2008, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2008/10/P10008
   Boltanski L., 2014, MYSTERIES CONSPIRACI
   Bradshaw S., 2018, CHALLENGING TRUTH TR
   Bruns A, 2020, MEDIA INT AUST, V177, P12, DOI 10.1177/1329878X20946113
   Butter M., 2020, HDB CONSPIRACY THEOR
   Carey Matthew., 2017, MISTRUST ETHNOGRAPHI
   Chandaliya P. K., 2019, P IEEE INT C EL COMP, P1
   Chen L, 2020, ARXIV200410225CS
   Cheruiyot D, 2021, MEDIA CULT SOC, V43, P189, DOI 10.1177/0163443720960907
   Cinelli M, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-73510-5
   Cocks T., 2021, REUTERS 0203
   Coronavirus: Nigeria confirms first case in Sub-Saharan Africa, 2020, BBC NEWS 0228
   Ferrara E., 2020, COVID 19 TWITTER BOT
   Ferrara E, 2020, J COMPUT SOC SCI, V3, P271, DOI 10.1007/s42001-020-00094-5
   Fish S, 1997, CRIT INQUIRY, V23, P378, DOI 10.1086/448833
   Gagliardone I, 2019, INT J COMMUN-US, V13, P3068
   Gruzd A, 2020, BIG DATA SOC, V7, DOI 10.1177/2053951720938405
   Havey NF, 2020, J COMPUT SOC SCI, V3, P319, DOI 10.1007/s42001-020-00089-2
   Jungherr A, 2021, SOC MEDIA SOC, V7, DOI 10.1177/2056305121988928
   Kapantai E, 2021, NEW MEDIA SOC, V23, P1301, DOI 10.1177/1461444820959296
   Kazeem Yomi, 2020, QUARTZ AFRICA
   Madrid-Morales D, 2021, INT J COMMUN-US, V15, P1200
   Mare A, 2019, AFR JOURNAL STUD, V40, P1, DOI 10.1080/23743670.2020.1788295
   Matiwane Z., 2021, TIMESLIVE JAN
   Mignolo WD, 2014, CURR SOCIOL, V62, P584, DOI 10.1177/0011392114524513
   Nielsen R., 2020, NAVIGATING INFODEMIC
   Pohjonen M, 2017, INT J COMMUN-US, V11, P1173
   Polletta F, 2017, AM J CULT SOCIOL, V5, P392, DOI 10.1057/s41290-017-0037-7
   Seo H., 2021, INT J COMMUN-US, V15, P8
   Shahsavari S., 2020, ARXIV PREPRINT ARXIV
   Sharma K., 2020, COVID 19 SOCIAL MED
   South African Government, 2020, MIN ZWEL MKHIZ REP 1
   Srinivasan S, 2019, J EAST AFR STUD, V13, P2, DOI 10.1080/17531055.2018.1547259
   Usigbe L., 2021, AFRICA RENEWAL
   Vidgen B., 2020, DETECTING E ASIAN PR
   Wasserman H, 2020, JOURNALISM, V21, P3, DOI 10.1177/1464884917746861
   Willems W., 2014, GLOBAL S, V8, P7
   Willems W., 2016, EVERYDAY MEDIA CULTU
   Ziems C, 2020, 200512423 ARXIV
NR 42
TC 0
Z9 0
U1 11
U2 11
PU SAGE PUBLICATIONS LTD
PI LONDON
PA 1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND
SN 2056-3051
J9 SOC MEDIA SOC
JI Soc. Med. Soc.
PD JUL
PY 2021
VL 7
IS 3
AR 20563051211044233
DI 10.1177/20563051211044233
PG 16
WC Communication
WE Social Science Citation Index (SSCI)
SC Communication
GA UT2YO
UT WOS:000697987000001
OA Green Submitted, Green Published, gold
DA 2022-02-06
ER

PT J
AU Gharavi, E
   Veisi, H
   Rosso, P
AF Gharavi, Erfaneh
   Veisi, Hadi
   Rosso, Paolo
TI Scalable and language-independent embedding-based approach for
   plagiarism detection considering obfuscation type: no training phase
SO NEURAL COMPUTING & APPLICATIONS
LA English
DT Article
DE Text alignment; Language-independent plagiarism detection; Word
   embedding; Text representation; Obfuscation type
AB The efficiency and scalability of plagiarism detection systems have become a major challenge due to the vast amount of available textual data in several languages over the Internet. Plagiarism occurs in different levels of obfuscation, ranging from the exact copy of original materials to text summarization. Consequently, designed algorithms to detect plagiarism should be robust to the diverse languages and different types of obfuscation in plagiarism cases. In this paper, we employ text embedding vectors to compare similarity among documents to detect plagiarism. Word vectors are combined by a simple aggregation function to represent a text document. This representation comprises semantic and syntactic information of the text and leads to efficient text alignment among suspicious and original documents. By comparing representations of sentences in source and suspicious documents, pair sentences with the highest similarity are considered as the candidates or seeds of plagiarism cases. To filter and merge these seeds, a set of parameters, including Jaccard similarity and merging threshold, are tuned by two different approaches: offline tuning and online tuning. The offline method, which is used as the benchmark, regulates a unique set of parameters for all types of plagiarism by several trials on the training corpus. Experiments show improvements in performance by considering obfuscation type during threshold tuning. In this regard, our proposed online approach uses two statistical methods to filter outlier candidates automatically by their scale of obfuscation. By employing the online tuning approach, no distinct training dataset is required to train the system. We applied our proposed method on available datasets in English, Persian and Arabic languages on the text alignment task to evaluate the robustness of the proposed methods from the language perspective as well. As our experimental results confirm, our efficient approach can achieve considerable performance on the different datasets in various languages. Our online threshold tuning approach without any training datasets works as well as, or even in some cases better than, the training-base method.
C1 [Gharavi, Erfaneh; Veisi, Hadi] Univ Tehran, Fac New Sci & Technol, Data & Signal Proc Lab, Tehran, Iran.
   [Rosso, Paolo] Univ Politecn Valencia, PRHLT Res Ctr, Valencia, Spain.
C3 University of Tehran; Universitat Politecnica de Valencia
RP Veisi, H (corresponding author), Univ Tehran, Fac New Sci & Technol, Data & Signal Proc Lab, Tehran, Iran.
EM e.gharavi@ut.ac.ir; h.veisi@ut.ac.ir; prosso@dsic.upv.es
RI Veisi, Hadi/AAV-2769-2020
OI Veisi, Hadi/0000-0003-2372-7969
FU Spanish MICINNSpanish Government [PGC2018-096212-B-C31]
FX The work of Paolo Rosso was partially funded by the Spanish MICINN under
   the research Project MISMIS-FAKEn-HATE on Misinformation and
   Miscommunication in social media: FAKE news and HATE speech
   (PGC2018-096212-B-C31).
CR Agarwal B, 2018, INFORM PROCESS MANAG, V54, P922, DOI 10.1016/j.ipm.2018.06.005
   ALSUHAIQI M, 2018, ASIAN J RES COMPUT S, V2, P1, DOI DOI 10.9734/AJRC0S/2018/V2I330075
   Alvi F, 2014, CLEF WORKING NOTES, P939
   Asghari H, 2016, CEUR WORKSH P 2016, V1737, P135
   Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223
   Bojanowski P, 2016, ARXIV160704606
   Cao QM, 2015, NEURAL COMPUT APPL, V26, P995, DOI 10.1007/s00521-014-1792-9
   Chong M, 2010, LANGUAGE
   Clough P, 2003, OLD NEW CHALLENGES A, P14
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Daelemans Walter, 2008, MACHINE LEARNING KNO
   Ehsan N, 2019, J INF SCI, V45, P443, DOI 10.1177/0165551518787696
   Eiselt M.P., 2009, 3 PAN WORKSH UNC PLA, P1
   ESTEKI F, 2016, CEUR WORKSHOP P, V1737, P149
   Ferrero J, 2017, P 15 C EUR CHAPT ASS, V2, DOI [10.18653/v1/E17-2066, DOI 10.18653/V1/E17-2066]
   Firth J, 1957, STUDIES LINGUISTIC A
   Gharavi E, 2016, DEEP LEARNING APPROA
   Gharavi Erfaneh, 2018, TEXT PROCESSING, P94
   Glinos D, 2014, CLEF WORKING NOTES, P958
   Gross P, 2014, CEUR WORKSH P WORK N, P966
   Hoad TC, 2003, J AM SOC INF SCI TEC, V54, P203, DOI 10.1002/asi.10170
   Kalchbrenner N, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P655, DOI 10.3115/v1/p14-1062
   Le Q., 2014, P 31 INT C INT C MAC
   Leilei K, 2012, APPROACHES CANDIDATE
   Leilei K, 2013, CEUR WORKSHOP P
   Livermore M. A., 2018, 201861 VIRG PUBL LAW
   Mashhadirajab F, 2016, FIRE WORKING NOTES, P167
   Mikolov T., 2013, P NAACL 2013, P746
   Mikolov T, 2013, P ICLR WORKSH, V1, P1
   Minaei B, 2016, FIRE WORKING NOTES, P172
   Mitchell J, 2010, COGNITIVE SCI, V34, P1388, DOI 10.1111/j.1551-6709.2010.01106.x
   Momtaz M., 2016, FIRE 2019 WORKING NO, P176
   Ng, 2011, ADV NEURAL INFORM PR, P801
   Paccanaro A, 2001, IEEE T KNOWL DATA EN, V13, P232, DOI 10.1109/69.917563
   Palkovskii Y, 2013, USING HYBRID SIMILAR
   Palkovskii Yurii, 2014, CLEF 2014 EV LABS, P984
   Pennington J, 2014, EMNLP, P1532, DOI 10.3115/v1/D14-1162
   Potthast M., 2010, P 23 INT C COMP LING, P997
   Potthast M., 2014, CEUR WORKSHOP PROC, V1180, P845
   Potthast M, 2013, CEUR WORKSHOP P, V1179
   Rodriguez Torrejon D, 2014, CEUR WORKSHOP P, V1180, P997
   Sanchez-Perez M, 2014, CEUR WORKSHOP P, P1004
   Sanchez-Vega F, 2019, PATTERN ANAL APPL, V22, P669, DOI 10.1007/s10044-017-0674-z
   Shrestha P, 2014, CLEF WORKING NOTES, P1012
   Shrestha P, 2013, NOTEBOOK PAN CLEF
   Socher R., 2012, P 2012 JOINT C EMP M, P1201, DOI DOI 10.1162/153244303322533223
   SOCHER R, 2014, THESIS
   Suchomel S, 2013, DIVERSE QUERIES FEAT
   Tai KS, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1556
   Talebpour A, 2016, CEUR WORKSHOP P, V1737, P180
NR 50
TC 2
Z9 2
U1 4
U2 7
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 0941-0643
EI 1433-3058
J9 NEURAL COMPUT APPL
JI Neural Comput. Appl.
PD JUL
PY 2020
VL 32
IS 14
BP 10593
EP 10607
DI 10.1007/s00521-019-04594-y
EA NOV 2019
PG 15
WC Computer Science, Artificial Intelligence
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA MD6OP
UT WOS:000495052100002
OA Green Published
DA 2022-02-06
ER

PT J
AU Boughida, M
   Boubekeur, T
AF Boughida, Malik
   Boubekeur, Tamy
TI Bayesian Collaborative Denoising for Monte Carlo Rendering
SO COMPUTER GRAPHICS FORUM
LA English
DT Article; Proceedings Paper
CT 28th Eurographics Symposium on Rendering Co-Located with the Workshop on
   Material Appearance Modeling
CY JUN 19-21, 2017
CL Helsinki, FINLAND
ID IMAGE; RECONSTRUCTION; PHOTOGRAPHY; FLASH
AB The stochastic nature of Monte Carlo rendering algorithms inherently produces noisy images. Essentially, three approaches have been developed to solve this issue: improving the ray-tracing strategies to reduce pixel variance, providing adaptive sampling by increasing the number of rays in regions needing so, and filtering the noisy image as a post-process. Although the algorithms from the latter category introduce bias, they remain highly attractive as they quickly improve the visual quality of the images, are compatible with all sorts of rendering effects, have a low computational cost and, for some of them, avoid deep modifications of the rendering engine. In this paper, we build upon recent advances in both non-local and collaborative filtering methods to propose a new efficient denoising operator for Monte Carlo rendering. Starting from the local statistics which emanate from the pixels sample distribution, we enrich the image with local covariance measures and introduce a nonlocal bayesian filter which is specifically designed to address the noise stemming from Monte Carlo rendering. The resulting algorithm only requires the rendering engine to provide for each pixel a histogram and a covariance matrix of its color samples. Compared to state-of-the-art sample-based methods, we obtain improved denoising results, especially in dark areas, with a large increase in speed and more robustness with respect to the main parameter of the algorithm. We provide a detailed mathematical exposition of our bayesian approach, discuss extensions to multiscale execution, adaptive sampling and animated scenes, and experimentally validate it on a collection of scenes.
C1 [Boughida, Malik; Boubekeur, Tamy] Paris Saclay Univ, LTCI, Telecom ParisTech, Paris, France.
C3 IMT - Institut Mines-Telecom; Institut Polytechnique de Paris;
   Universite Paris Saclay
RP Boughida, M (corresponding author), Paris Saclay Univ, LTCI, Telecom ParisTech, Paris, France.
FU ANRFrench National Research Agency (ANR) [16-LCV2-0009-01]; BPI France
FX This work is partially supported by the ANR 16-LCV2-0009-01 ALLEGORI
   grant and the BPI France PAPAYA grant.
CR Bauszat P, 2015, COMPUT GRAPH FORUM, V34, P597, DOI 10.1111/cgf.12587
   Bitterli B., 2016, COMPUTER GRAPHICS FO, V35
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   DABOV K, 2006, P SPIE, V6064
   Delbracio M, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2532708
   Eisemann E, 2004, ACM T GRAPHIC, V23, P673, DOI 10.1145/1015706.1015778
   Georgiev I, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366211
   Humphreys G., 2010, PHYS BASED RENDERING
   Jensen H. W., 1996, Rendering Techniques '96. Proceedings of the Eurographics Workshop. Eurographics, P21
   Kajiya J. T., 1986, Computer Graphics, V20, P143
   Kalantari NK, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766977
   Kalantari NK, 2013, COMPUT GRAPH FORUM, V32, P93, DOI 10.1111/cgf.12029
   Lafortune E. P., 1993, EDUGRAPHICS '93. First International Conference on Graphics Education. COMPUGRAPHICS '93. Third International Conference on Computational Graphics and Visualization Techniques. Combined Proceedings, P145
   Lebrun M, 2013, SIAM J IMAGING SCI, V6, P1665, DOI 10.1137/120874989
   Lebrun M, 2012, ACTA NUMER, V21, P475, DOI 10.1017/S0962492912000062
   Li TM, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366213
   MOON B, 2015, ACM T GRAPH, V0034, P00004
   MOON B, 2014, ACM T GRAPH TOG, V33, P1, DOI DOI 10.1145/2641762
   Moon B, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925936
   Petschnigg G, 2004, ACM T GRAPHIC, V23, P664, DOI 10.1145/1015706.1015777
   Rousselle F, 2013, COMPUT GRAPH FORUM, V32, P121, DOI 10.1111/cgf.12219
   Rousselle F, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366214
   Rousselle F, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024193
   Sen P., 2012, ACM T GRAPHIC, V31, P3, DOI DOI 10.1145/2167076.2167083
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Veach E., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P65
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xu RF, 2005, IEEE COMPUT GRAPH, V25, P31, DOI 10.1109/MCG.2005.31
   Zwicker M, 2015, COMPUT GRAPH FORUM, V34, P667, DOI 10.1111/cgf.12592
NR 29
TC 11
Z9 13
U1 0
U2 2
PU WILEY
PI HOBOKEN
PA 111 RIVER ST, HOBOKEN 07030-5774, NJ USA
SN 0167-7055
EI 1467-8659
J9 COMPUT GRAPH FORUM
JI Comput. Graph. Forum
PD JUL
PY 2017
VL 36
IS 4
BP 137
EP 153
DI 10.1111/cgf.13231
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA EZ8HR
UT WOS:000404966100013
DA 2022-02-06
ER

PT J
AU Sarracen, GLD
   Rosso, P
AF De la Pena Sarracen, Gretel Liz
   Rosso, Paolo
TI Offensive keyword extraction based on the attention mechanism of BERT
   and the eigenvector centrality using a graph representation
SO PERSONAL AND UBIQUITOUS COMPUTING
LA English
DT Article; Early Access
DE Unsupervised keyword extraction; Offensive language detection; Attention
   mechanism; Graph representation
AB The proliferation of harmful content on social media affects a large part of the user community. Therefore, several approaches have emerged to control this phenomenon automatically. However, this is still a quite challenging task. In this paper, we explore the offensive language as a particular case of harmful content and focus our study in the analysis of keywords in available datasets composed of offensive tweets. Thus, we aim to identify relevant words in those datasets and analyze how they can affect model learning. For keyword extraction, we propose an unsupervised hybrid approach which combines the multi-head self-attention of BERT and a reasoning on a word graph. The attention mechanism allows to capture relationships among words in a context, while a language model is learned. Then, the relationships are used to generate a graph from what we identify the most relevant words by using the eigenvector centrality. Experiments were performed by means of two mechanisms. On the one hand, we used an information retrieval system to evaluate the impact of the keywords in recovering offensive tweets from a dataset. On the other hand, we evaluated a keyword-based model for offensive language detection. Results highlight some points to consider when training models with available datasets.
C1 [De la Pena Sarracen, Gretel Liz; Rosso, Paolo] Univ Politecn Valencia, Valencia 46022, Spain.
C3 Universitat Politecnica de Valencia
RP Sarracen, GLD (corresponding author), Univ Politecn Valencia, Valencia 46022, Spain.
EM gredela@posgrado.upv.es
OI De la Pena Sarracen, Gretel Liz/0000-0003-4448-2323
FU Spanish Ministry of Science and InnovationSpanish Government
   [PGC2018-096212-B-C31]; EU-FEDER Comunitat Valenciana 2014-2020 grant
   [IDIFEDER/2018/025]; CRUE-CSIC agreement; Springer Nature
FX Open Access funding provided thanks to the CRUE-CSIC agreement with
   Springer Nature. This research work was partially funded by the Spanish
   Ministry of Science and Innovation under the research project
   MISMIS-FAKEnHATE on Misinformation and Miscommunication in social media:
   FAKE news and HATE speech (PGC2018-096212-B-C31). The authors thank also
   the EU-FEDER Comunitat Valenciana 2014-2020 grant IDIFEDER/2018/025.
CR Ashraf SI, 2019, INT C INT HUM COMP I, P87
   Basile V., 2019, SEMEVAL NAACL HLT, DOI DOI 10.18653/V1/S19-2007
   Berry MW., 2010, TEXT MINING APPL THE, DOI [10.1002/9780470689646, DOI 10.1002/9780470689646]
   Boudin F., 2013, P 6 INT JOINT C NAT, P834
   Brin S, 1998, COMPUT NETWORKS ISDN, V30, P107, DOI 10.1016/S0169-7552(98)00110-X
   Buttcher Stefan., 2016, INFORM RETRIEVAL IMP
   Casula C, 2020, P 14 WORKSH SEM EV, P1539
   Chaudhari S., 2019, ARXIV PREPRINT ARXIV
   Dai W, 2020, ARXIV200413432
   De la Pena Sarracen GL, 2020, P 14 WORKSH SEM EV, P1605
   deAlbornoz, 2018, CEUR WORKSHOP P, V2150, P214
   Devlin J, 2019, PROC C N AM CHAPTER, P4171, DOI DOI 10.18653/V1/N19-1423
   Firoozeh N, 2020, NAT LANG ENG, V26, P259, DOI 10.1017/S1351324919000457
   Hasan KS, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1262
   Hu XH, 2006, ICDM 2006: SIXTH IEEE INTERNATIONAL CONFERENCE ON DATA MINING, WORKSHOPS, P19
   Kathait SS, 2017, INT J COMPUT APPL, V162
   Kaur J., 2010, INT J COMPUTER SCI I, V7, P144
   Kingma DP, 2015, 3 INT C LEARN REPR I, DOI DOI 10.1145/1830483.1830503
   Kumar, 2019, P 2019 C N AM CHAPT, V1, P1415, DOI DOI 10.18653/V1/N19-1144
   Mandl T, 2019, ACM INT CONF PR SER, P14, DOI 10.1145/3368567.3368584
   Marcos Zampieri, 2020, P SEMEVAL, P1
   Mihalcea R., 2004, P EMNLP, P404
   Nasar Z, 2019, INFORM PROCESS MANAG, V56, DOI 10.1016/j.ipm.2019.102088
   Newman MEJ, 2008, NEW PALGRAVE ENCY EC, V2, P1
   Pappagari R, 2019, 2019 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU 2019), P838, DOI 10.1109/ASRU46091.2019.9003958
   Pitsilis GK, 2018, APPL INTELL, V48, P4730, DOI 10.1007/s10489-018-1242-y
   Poletto F, 2021, LANG RESOUR EVAL, V55, P477, DOI 10.1007/s10579-020-09502-8
   Robertson S. E., 1995, Text REtrieval Conference (TREC-3) (NIST SP 500-225), P109
   Rosenthal S, 2020, ARXIV200414454
   Sahrawat D., 2019, ARXIV191008840
   Uglow H, 2019, ARXIV190307445
   Vashistha N, 2020, ONLINE MULTILINGUAL
   Vaswani A, 2017, ADV NEUR IN, P5998
   Wang S, 2020, ARXIV201003542
   Wiedemann G, 2020, P 14 WORKSHOP SEMANT, P1638
   Wiegand M., 2019, P 2019 C N AM CHAPT, V1, P602
   Witten I. H., 2005, DESIGN USABILITY DIG, P129
   Xiong Ao, 2020, 2020 International Wireless Communications and Mobile Computing (IWCMC), P1364, DOI 10.1109/IWCMC48107.2020.9148491
   Zampieri M, 2019, ARXIV190308983, DOI DOI 10.18653/V1/S19-2010
NR 39
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER LONDON LTD
PI LONDON
PA 236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND
SN 1617-4909
EI 1617-4917
J9 PERS UBIQUIT COMPUT
JI Pers. Ubiquitous Comput.
DI 10.1007/s00779-021-01605-5
EA AUG 2021
PG 13
WC Computer Science, Information Systems; Telecommunications
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Telecommunications
GA UI1CB
UT WOS:000690353300001
OA hybrid
DA 2022-02-06
ER

PT J
AU Kim, YK
   Kim, Y
   Jeong, CS
AF Kim, Yoon-Ki
   Kim, Yongsung
   Jeong, Chang-Sung
TI RIDE: real-time massive image processing platform on distributed
   environment
SO EURASIP JOURNAL ON IMAGE AND VIDEO PROCESSING
LA English
DT Article
DE Real-time; Image processing; Distributed and parallel processing;
   Heterogeneous computing
AB As the demand for real-time data processing increases, a high-speed processing platform for large-scale stream data becomes necessary. For fast processing large-scale stream data, it is essential to use multiple distributed nodes. So far, there have been few studies on real-time massive image processing through efficient management and allocation of heterogeneous resources for various user-specified nodes on distributed environments. In this paper, we shall present a new platform called RIDE (Real-time massive Image processing platform on Distributed Environment) which efficiently allocates resources and executes load balancing according to the amount of stream data on distributed environments. It minimizes communication overhead by using a parallel processing strategy which handles the stream data considering both coarse-grained and fine-grained parallelism simultaneously. Coarse-grained parallelism is achieved by the automatic allocation of input streams onto partitions of broker buffer each processed by its corresponding worker node, and maximized by adaptive resource management which adjusts the number of worker nodes in a group according to the frame rate in real time. Fine-grained parallelism is achieved by parallel processing of task on each worker node and maximized by allocating heterogeneous resources such as GPU and embedded machines appropriately. Moreover, it provides a scheme of application topology which has a great advantage for higher performance by configuring the worker nodes of each stage using adaptive heterogeneous resource management. Finally, it supports dynamic fault tolerance for real-time image processing through the coordination between components in our system.
C1 [Kim, Yoon-Ki; Kim, Yongsung; Jeong, Chang-Sung] Korea Univ, Dept Elect Engn, Seoul, South Korea.
C3 Korea University
RP Jeong, CS (corresponding author), Korea Univ, Dept Elect Engn, Seoul, South Korea.
EM csjeong@korea.ac.kr
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [2017R1D1A1B03035461]; Brain
   Korea 21 Plus Project; Institute for Information & communications
   Technology Promotion(IITP) - Korean government (MSIP) [2018-0-00739]
FX This research was supported by the Basic Science Research Program
   through the National Research Foundation of Korea (NRF) funded by the
   Ministry of Education (2017R1D1A1B03035461), the Brain Korea 21 Plus
   Project in 2018, and the Institute for Information & communications
   Technology Promotion(IITP) grant funded by the Korean government (MSIP)
   (No. 2018-0-00739, Deep learning-based natural language contents
   evaluation technology for detecting fake news).
CR Awad AS, 2011, IEEE SIGNAL PROC LET, V18, P407, DOI 10.1109/LSP.2011.2154330
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Condie T., 2010, NSDI, V10, P20
   Dean J, 2004, USENIX ASSOCIATION PROCEEDINGS OF THE SIXTH SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDE '04), P137
   Fang LY, 2015, IEEE GEOSCI REMOTE S, V12, P419, DOI 10.1109/LGRS.2014.2345419
   Fang LY, 2014, ISPRS J PHOTOGRAMM, V87, P229, DOI 10.1016/j.isprsjprs.2013.11.010
   Fatahalian K., 2004, P ACM SIGGRAPH EUROG, P133, DOI [DOI 10.1145/1058129.1058148, 10.1145/1058129.1058148]
   Hwang D-H, 2010, 7 INT C NETW COMM, P211
   Jeong CS., 2017, P 6 AIRCC INT C PAR, P207
   Jeong I-K, 2012, P 33 AS C REM SENS N, P1489
   Jung In-Yong, 2013, INT J MULTIMEDIA UBI, V8, P19
   Kreps J, 2011, NETDB, V11, P1, DOI DOI 10.1007/BF00640482
   Ma Y, 2016, COMPUTING, V98, P7, DOI 10.1007/s00607-014-0392-y
   NUSSBAUMER HJ, 2012, FAST FOURIER TRANSFO, P2
   Shvachko K., 2010, SYMPOSIUM, P1, DOI DOI 10.1109/MSST.2010.5496972
   Toshniwa A, 2014, SIGMOD'14: PROCEEDINGS OF THE 2014 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P147, DOI 10.1145/2588555.2595641
   Younge Andrew J, 2010, 2010 International Conference on Green Computing (Green Comp), P357, DOI 10.1109/GREENCOMP.2010.5598294
   Zaharia M., 2012, NSDI, P2
   Zhang F, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16040494
NR 19
TC 2
Z9 2
U1 0
U2 2
PU SPRINGEROPEN
PI LONDON
PA CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND
SN 1687-5176
EI 1687-5281
J9 EURASIP J IMAGE VIDE
JI EURASIP J. Image Video Process.
PD JUN 1
PY 2018
AR 39
DI 10.1186/s13640-018-0279-5
PG 13
WC Engineering, Electrical & Electronic; Imaging Science & Photographic
   Technology
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Engineering; Imaging Science & Photographic Technology
GA GH9HU
UT WOS:000433981000001
OA gold
DA 2022-02-06
ER

EF